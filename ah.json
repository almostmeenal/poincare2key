[{"id": "2007", "text": "The creation of a high-fidelity finite element model of the kidney for use in\n\ttrauma research\nA detailed finite element model of the human kidney for trauma research has\n\tbeen created directly from the National Library of Medicine Visible\n\tHuman Female (VHF) Project data set. An image segmentation and organ\n\treconstruction software package has been developed and employed to\n\ttransform the 2D VHF images into a 3D polygonal representation.\n\tNonuniform rational B-spline (NURBS) surfaces were then mapped to the\n\tpolygonal surfaces, and were finally utilized to create a robust 3D\n\thexahedral finite element mesh within a commercially available meshing\n\tsoftware. The model employs a combined viscoelastic and hyperelastic\n\tmaterial model to successfully simulate the behaviour of biological\n\tsoft tissues. The finite element model was then validated for use in\n\tbiomechanical research\n", "keywords": "high-fidelity finite element model; kidney; trauma research; National Library\n\tof Medicine; Visible Human Female project; medical data set; image\n\tsegmentation; organ reconstruction; physically based animation;\n\tsoftware package; 3D polygonal representation; 2D VHF images;\n\tnonuniform rational B-spline surfaces; NURBS; polygonal surfaces; 3D\n\thexahedral finite element mesh; viscoelastic model; hyperelastic\n\tmaterial model; biological soft tissues; biomechanical research\n", "topicrank": [["fidelity finite element model", "trauma research", "reconstruction software package", "model", "vhf"], ["fidelity finite element model", "trauma research", "reconstruction software package", "model", "vhf", "kidney", "use", "surfaces", "human female", "medicine visible"]], "textrank": [["finite element model", "finite element", "3d polygonal", "project data", "medicine visible"], ["finite element model", "finite element", "3d polygonal", "project data", "medicine visible", "national library", "polygonal", "rational", "software", "vhf"]], "positionrank": [["finite element model", "material model", "model", "trauma research", "human kidney"], ["finite element model", "material model", "model", "trauma research", "human kidney", "biomechanical research", "creation", "kidney", "3d polygonal representation", "human female"]], "multipartiterank": [["fidelity finite element model", "trauma research", "kidney", "use", "vhf"], ["fidelity finite element model", "trauma research", "kidney", "use", "vhf", "reconstruction software package", "high", "model", "human female", "surfaces"]]}, {"id": "2042", "text": "Hybrid simulation of space plasmas: models with massless fluid representation\n\tof electrons. IV. Kelvin-Helmholtz instability\nFor pt.III. see Prikl. Mat. Informatika, MAKS Press, no. 4, p. 5-56 (2000).\n\tThis is a survey of the literature on hybrid simulation of the\n\tKelvin-Helmholtz instability. We start with a brief review of the\n\ttheory: the simplest model of the instability - a transition layer in\n\tthe form of a tangential discontinuity; compressibility of the medium;\n\tfinite size of the velocity shear region; pressure anisotropy. We then\n\tdescribe the electromagnetic hybrid model (ions as particles and\n\telectrons as a massless fluid) and the main numerical schemes. We\n\treview the studies on two-dimensional and three-dimensional hybrid\n\tsimulation of the process of particle mixing across the magnetopause\n\tshear layer driven by the onset of a Kelvin-Helmholtz instability. The\n\tarticle concludes with a survey of literature on hybrid simulation of\n\tthe Kelvin-Helmholtz instability in finite-size objects: jets moving\n\tacross the magnetic field in the middle of the field reversal layer;\n\tinteraction between a magnetized plasma flow and a cylindrical plasma\n\tsource with zero own magnetic field\n", "keywords": "hybrid simulation; space plasmas; massless fluid representation;\n\tKelvin-Helmholtz instability; transition layer; tangential\n\tdiscontinuity; pressure anisotropy; electromagnetic hybrid model;\n\tthree-dimensional hybrid simulation; magnetopause shear layer; field\n\treversal layer; magnetized plasma flow; cylindrical plasma source\n", "topicrank": [["helmholtz instability", "hybrid simulation", "kelvin", "finite size", "transition layer"], ["helmholtz instability", "hybrid simulation", "kelvin", "finite size", "transition layer", "literature", "massless fluid representation", "survey", "electrons", "dimensional"]], "textrank": [["field reversal layer", "hybrid model", "shear layer", "helmholtz instability .", "hybrid"], ["field reversal layer", "hybrid model", "shear layer", "helmholtz instability .", "hybrid", "magnetic field", "brief review", "no .", "maks press", "helmholtz instability"]], "positionrank": [["hybrid simulation", "electromagnetic hybrid model", "dimensional hybrid", "massless fluid representation", "helmholtz instability"], ["hybrid simulation", "electromagnetic hybrid model", "dimensional hybrid", "massless fluid representation", "helmholtz instability", "massless fluid", "simulation", "space plasmas", "kelvin", "instability"]], "multipartiterank": [["hybrid simulation", "helmholtz instability", "kelvin", "literature", "finite size"], ["hybrid simulation", "helmholtz instability", "kelvin", "literature", "finite size", "massless fluid representation", "transition layer", "electrons", "survey", "dimensional"]]}, {"id": "308", "text": "On-line Homework/Quiz/Exam applet: freely available Java software for\n\tevaluating performance on line\nThe Homework/Quiz/Exam applet is a freely available Java program that can be\n\tused to evaluate student performance on line for any content authored\n\tby a teacher. It has database connectivity so that student scores are\n\tautomatically recorded. It allows several different types of questions.\n\tEach question can be linked to images and detailed story problems.\n\tThree levels of feedback are provided to student responses. It allows\n\tteachers to randomize the sequence of questions and to randomize which\n\tof several options is the correct answer in multiple-choice questions.\n\tThe creation and editing of questions involves menu selections, button\n\tpresses, and the typing of content; no programming knowledge is\n\trequired. The code is open source in order to encourage modifications\n\tthat will meet individual pedagogical needs\n", "keywords": "online Homework/Quiz/Exam applet; freely available Java software; online\n\tstudent performance evaluation; teacher authored content; database\n\tconnectivity; automatic student score recording; images; detailed story\n\tproblems; feedback; randomized question sequence; multiple-choice\n\tquestions; question editing; question creation; menu selections; button\n\tpresses; typing content; individual pedagogical needs\n", "topicrank": [["questions", "content", "line", "quiz", "exam applet"], ["questions", "content", "line", "quiz", "exam applet", "performance", "student scores", "line homework", "available java software", "menu selections"]], "textrank": [["several different", "choice questions", "correct answer", "database connectivity", "exam applet"], ["several different", "choice questions", "correct answer", "database connectivity", "exam applet", "line homework", "student", "java", "pedagogical", "story"]], "positionrank": [["available java software", "line homework", "available java program", "exam applet", "line"], ["available java software", "line homework", "available java program", "exam applet", "line", "student performance", "quiz", "homework", "performance", "student scores"]], "multipartiterank": [["questions", "quiz", "line homework", "exam applet", "line"], ["questions", "quiz", "line homework", "exam applet", "line", "performance", "available java software", "content", "student scores", "menu selections"]]}, {"id": "215", "text": "A conceptual framework for evaluation of information technology investments\nThe decision to acquire a new information technology poses a number of serious\n\tevaluation and selection problems to technology managers, because the\n\tnew system must not only meet current information requirements of the\n\torganisation, but also the needs for future expansion. Tangible and\n\tintangible benefits factors, as well as risks factors, must be\n\tidentified and evaluated. The paper provides a review of ten major\n\tevaluation categories and available models, which fall under each\n\tcategory, showing their advantages and disadvantages in handling the\n\tabove difficulties. This paper describes strategic implications\n\tinvolved in the selection decision, and the inherent difficulties in:\n\t(1) choosing or developing a model, (2) obtaining realistic inputs for\n\tthe model, and (3) making tradeoffs among the conflicting factors. It\n\tproposes a conceptual framework to help the decision maker in choosing\n\tthe most appropriate methodology in the evaluation process. It also\n\toffers a new model, called GAHP, for the evaluation problem combining\n\tinteger goal linear programming and analytic hierarchy process (AHP) in\n\ta single hybrid multiple objective multi-criteria model. A goal\n\tprogramming methodology, with zero-one integer variables and mixed\n\tinteger constraints, is used to set goal target values against which\n\tinformation technology alternatives are evaluated and selected. AHP is\n\tused to structure the evaluation process providing pairwise comparison\n\tmechanisms to quantify subjective, nonmonetary, intangible benefits and\n\trisks factors, in deriving data for the model. A case illustration is\n\tprovided showing how GAHP can be formulated and solved\n", "keywords": "information technology investments; technology managers; information\n\trequirements; risks factors; evaluation categories; selection decision;\n\ttradeoffs; decision maker; analytic hierarchy process; hybrid multiple\n\tobjective multi-criteria model; goal programming methodology; zero-one\n\tinteger variables; mixed integer constraints; goal target values;\n\tinformation technology alternatives; pairwise comparison mechanisms;\n\tnonmonetary benefits; intangible benefits; group decision process\n", "topicrank": [["evaluation", "model", "information technology investments", "risks factors", "decision"], ["evaluation", "model", "information technology investments", "risks factors", "decision", "intangible benefits factors", "paper", "integer variables", "difficulties", "appropriate methodology"]], "textrank": [["hybrid multiple objective multi - criteria", "new information technology", "integer goal linear programming", "information technology", "evaluation process"], ["hybrid multiple objective multi - criteria", "new information technology", "integer goal linear programming", "information technology", "evaluation process", "goal target", "selection decision", "benefits factors", "hierarchy process", "programming methodology"]], "positionrank": [["new information technology", "information technology investments", "information technology alternatives", "conceptual framework", "evaluation process"], ["new information technology", "information technology investments", "information technology alternatives", "conceptual framework", "evaluation process", "evaluation problem", "evaluation categories", "current information requirements", "technology managers", "evaluation"]], "multipartiterank": [["evaluation", "information technology investments", "decision", "model", "conceptual framework"], ["evaluation", "information technology investments", "decision", "model", "conceptual framework", "risks factors", "serious", "selection problems", "intangible benefits factors", "paper"]]}, {"id": "250", "text": "Aim for the enterprise: Microsoft Project 2002\nA long-time favorite of project managers, Microsoft Project 2002 is making its\n\tenterprise debut. Its new Web-based collaboration tools and improved\n\tscalability with OLAP support make it much easier to manage multiple\n\tWeb projects with disparate workgroups and budgets\n", "keywords": "Microsoft Project 2002; Web-based collaboration tools; scalability; OLAP\n\tsupport; multiple Web project management; workgroups; budgets\n", "topicrank": [["microsoft project", "new web", "enterprise", "time favorite", "disparate workgroups"], ["microsoft project", "new web", "enterprise", "time favorite", "disparate workgroups", "multiple", "olap support", "scalability", "easier", "long"]], "textrank": [["enterprise debut", "time favorite", "web", "project", "enterprise"], ["enterprise debut", "time favorite", "web", "project", "enterprise"]], "positionrank": [["microsoft project", "project managers", "enterprise debut", "time favorite", "enterprise"], ["microsoft project", "project managers", "enterprise debut", "time favorite", "enterprise", "new web", "collaboration tools", "web projects", "olap support", "disparate workgroups"]], "multipartiterank": [["microsoft project", "enterprise", "new web", "time favorite", "long"], ["microsoft project", "enterprise", "new web", "time favorite", "long", "collaboration tools", "olap support", "scalability", "enterprise debut", "multiple"]]}, {"id": "1996", "text": "Quality image metrics for synthetic images based on perceptual color\n\tdifferences\nDue to the improvement of image rendering processes, and the increasing\n\timportance of quantitative comparisons among synthetic color images, it\n\tis essential to define perceptually based metrics which enable to\n\tobjectively assess the visual quality of digital simulations. In\n\tresponse to this need, this paper proposes a new methodology for the\n\tdetermination of an objective image quality metric, and gives an answer\n\tto this problem through three metrics. This methodology is based on the\n\tLLAB color space for perception of color in complex images, a\n\tmodification of the CIELab1976 color space. The first metric proposed\n\tis a pixel by pixel metric which introduces a local distance map\n\tbetween two images. The second metric associates, to a pair of images,\n\ta global value. Finally, the third metric uses a recursive subdivision\n\tof the images to obtain an adaptative distance map, rougher but less\n\texpensive to compute than the first method\n", "keywords": "quality image metrics; synthetic images; perceptual color differences; image\n\trendering; color images; perceptually based metrics; visual quality;\n\tdigital simulations; LLAB color space; CIELab1976 color space; pixel by\n\tpixel metric; local distance map; global value; recursive subdivision;\n\tadaptative distance map\n", "topicrank": [["synthetic images", "perceptual color", "new methodology", "local distance map", "metrics"], ["synthetic images", "perceptual color", "new methodology", "local distance map", "metrics", "quality image metrics", "pixel", "first metric", "perception", "quantitative comparisons"]], "textrank": [["image quality metric", "color images", "first metric", "quality image", "image rendering"], ["image quality metric", "color images", "first metric", "quality image", "image rendering", "metric", "color", "global value", "new methodology", "digital simulations"]], "positionrank": [["quality image metrics", "synthetic color images", "objective image quality", "synthetic images", "llab color space"], ["quality image metrics", "synthetic color images", "objective image quality", "synthetic images", "llab color space", "image rendering processes", "visual quality", "cielab1976 color space", "perceptual color", "complex images"]], "multipartiterank": [["synthetic images", "perceptual color", "quality image metrics", "differences", "improvement"], ["synthetic images", "perceptual color", "quality image metrics", "differences", "improvement", "image rendering processes", "new methodology", "metrics", "images", "quantitative comparisons"]]}, {"id": "2162", "text": "More constructions for Boolean algebras\nWe construct Boolean algebras with prescribed behaviour concerning depth for\n\tthe free product of two Boolean algebras over a third, in ZFC using\n\tpcf; assuming squares we get results on ultraproducts. We also deal\n\twith the family of cardinalities and topological density of homomorphic\n\timages of Boolean algebras (you can translate it to topology-on the\n\tcardinalities of closed subspaces); and lastly we deal with\n\tinequalities between cardinal invariants, mainly d(B)/sup kappa\n\t/<|B| implies ind(B)>/sup kappa /V Depth(B)>or=log(|B|)\n", "keywords": "Boolean algebras; prescribed behaviour; free product; ZFC; ultraproducts;\n\thomomorphic images; cardinal invariants\n", "topicrank": [["boolean algebras", "cardinalities", "topological density", "homomorphic", "images"], ["boolean algebras", "cardinalities", "topological density", "homomorphic", "images", "results", "squares", "pcf", "family", "zfc"]], "textrank": [["free product", "prescribed behaviour", "boolean algebras", "more constructions", "kappa"], ["free product", "prescribed behaviour", "boolean algebras", "more constructions", "kappa", "topological"]], "positionrank": [["boolean algebras", "more constructions", "prescribed behaviour", "free product", "topological density"], ["boolean algebras", "more constructions", "prescribed behaviour", "free product", "topological density", "depth", "cardinalities", "images", "zfc", "pcf"]], "multipartiterank": [["boolean algebras", "cardinalities", "topological density", "homomorphic", "images"], ["boolean algebras", "cardinalities", "topological density", "homomorphic", "images", "results", "squares", "family", "pcf", "zfc"]]}, {"id": "2127", "text": "System embedding. Polynomial equations\nThe class of solutions of the polynomial equations including their\n\tgeneralizations in the form of the Bezout matrix identities was\n\tconstructed analytically using the technology of constructive system\n\tembedding. The structure of a solution depends on the number of steps\n\tof the Euclidean algorithm and is obtained explicitly by appropriate\n\tsubstitutions. Illustrative and descriptive examples are presented\n", "keywords": "determinate systems; polynomial equations; Bezout matrix identities;\n\tconstructive system embedding; Euclidean algorithm\n", "topicrank": [["system embedding", "polynomial equations", "constructive system", "substitutions", "illustrative"], ["system embedding", "polynomial equations", "constructive system", "substitutions", "illustrative", "number", "structure", "steps", "solutions", "solution"]], "textrank": [["euclidean algorithm", "polynomial equations", "matrix", "system", "descriptive"], ["euclidean algorithm", "polynomial equations", "matrix", "system", "descriptive"]], "positionrank": [["system embedding", "polynomial equations", "constructive system", "embedding", "bezout matrix identities"], ["system embedding", "polynomial equations", "constructive system", "embedding", "bezout matrix identities", "solutions", "class", "technology", "generalizations", "structure"]], "multipartiterank": [["system embedding", "polynomial equations", "class", "solutions", "generalizations"], ["system embedding", "polynomial equations", "class", "solutions", "generalizations", "constructive system", "form", "substitutions", "illustrative", "bezout matrix identities"]]}, {"id": "290", "text": "MEMS applications in computer disk drive dual-stage servo systems\nWe present a decoupled discrete time pole placement design method, which can be\n\tcombined with a self-tuning scheme to compensate variations in the\n\tmicroactuator's (MA's) resonance mode. Section I of the paper describes\n\tthe design and fabrication of a prototype microactuator with an\n\tintegrated gimbal structure. Section II presents a decoupled\n\ttrack-following controller design and a self-tuning control scheme to\n\tcompensate for the MA's resonance mode variations\n", "keywords": "computer disk drive dual-stage servo systems; MEMS; microactuator; servo\n\tcontrol; hard disk drives; decoupled discrete time pole placement\n\tdesign method; self-tuning scheme; electrostatic design; fabrication\n\tprocess; track-following controller design\n", "topicrank": [["design", "scheme", "microactuator", "self", "resonance mode"], ["design", "scheme", "microactuator", "self", "resonance mode", "fabrication", "gimbal structure", "section ii", "computer disk drive dual", "track"]], "textrank": [["discrete time pole placement design", "disk drive", "design", "section", "mode"], ["discrete time pole placement design", "disk drive", "design", "section", "mode", "servo", "mems"]], "positionrank": [["stage servo systems", "computer disk drive", "mems applications", "controller design", "resonance mode variations"], ["stage servo systems", "computer disk drive", "mems applications", "controller design", "resonance mode variations", "design", "resonance mode", "section i", "section ii", "prototype microactuator"]], "multipartiterank": [["microactuator", "design", "scheme", "self", "resonance mode"], ["microactuator", "design", "scheme", "self", "resonance mode", "fabrication", "variations", "computer disk drive dual", "paper", "gimbal structure"]]}, {"id": "1956", "text": "Dynamical transition to periodic motions of a recurrent bus induced by nonstops\nWe study the dynamical behavior of a recurrent bus on a circular route with\n\tmany bus stops when the recurrent bus passes some bus stops without\n\tstopping. The recurrent time (one period) is described in terms of a\n\tnonlinear map. It is shown that the recurrent bus exhibits the complex\n\tperiodic behaviors. The dynamical transitions to periodic motions occur\n\tby increasing nonstops. The periodic motions depend on the property of\n\tan attractor of the nonlinear map. The period n of the attractor varies\n\tsensitively with the number of nonstops\n", "keywords": "dynamical transition; periodic motions; recurrent bus; nonstops; circular\n\troute; recurrent time; nonlinear map; complex periodic behaviors;\n\tattractor\n", "topicrank": [["recurrent bus", "periodic motions", "dynamical transition", "nonstops", "many bus stops"], ["recurrent bus", "periodic motions", "dynamical transition", "nonstops", "many bus stops", "nonlinear map", "attractor", "complex", "circular route", "period"]], "textrank": [["recurrent bus", "circular route", "dynamical", "bus", "periodic"], ["recurrent bus", "circular route", "dynamical", "bus", "periodic", "recurrent", "period"]], "positionrank": [["recurrent bus", "many bus stops", "bus stops", "periodic motions", "dynamical transition"], ["recurrent bus", "many bus stops", "bus stops", "periodic motions", "dynamical transition", "dynamical behavior", "dynamical transitions", "recurrent time", "periodic behaviors", "circular route"]], "multipartiterank": [["dynamical transition", "periodic motions", "recurrent bus", "nonstops", "many bus stops"], ["dynamical transition", "periodic motions", "recurrent bus", "nonstops", "many bus stops", "nonlinear map", "attractor", "circular route", "dynamical transitions", "complex"]]}, {"id": "228", "text": "Rapid microwell polymerase chain reaction with subsequent ultrathin-layer gel\n\telectrophoresis of DNA\nLarge-scale genotyping, mapping and expression profiling require affordable,\n\tfully automated high-throughput devices enabling rapid,\n\thigh-performance analysis using minute quantities of reagents. In this\n\tpaper, we describe a new combination of microwell polymerase chain\n\treaction (PCR) based DNA amplification technique with automated\n\tultrathin-layer gel electrophoresis analysis of the resulting products.\n\tThis technique decreases the reagent consumption (total reaction volume\n\t0.75-1 mu L), the time requirement of the PCR (15-20 min) and\n\tsubsequent ultrathin-layer gel electrophoresis based fragment analysis\n\t(5 min) by automating the current manual procedure and reducing the\n\thuman intervention using sample loading robots and computerized real\n\ttime data analysis. Small aliquots (0.2 mu L) of the submicroliter size\n\tPCR reaction were transferred onto loading membranes and analyzed by\n\tultrathin-layer gel electrophoresis which is a novel, high-performance\n\tand automated microseparation technique. This system employs integrated\n\tscanning laser-induced fluorescence-avalanche photodiode detection and\n\tcombines the advantages of conventional slab and capillary gel\n\telectrophoresis. Visualization of the DNA fragments was accomplished by\n\t\"in migratio\" complexation with ethidium bromide during the\n\telectrophoresis process also enabling real time imaging and data\n\tanalysis\n", "keywords": "rapid microwell polymerase chain reaction; ultrathin-layer gel electrophoresis;\n\tDNA amplification; large-scale genotyping; expression profiling; rapid\n\thigh-performance analysis; automated electrophoresis analysis; reagent\n\tconsumption; sample loading robots; computerized real time data\n\tanalysis; automated microseparation; integrated scanning LIF APD\n\tdetection; complexation with ethidium bromide; real time imaging\n", "topicrank": [["layer gel", "subsequent ultrathin", "high", "electrophoresis", "dna"], ["layer gel", "subsequent ultrathin", "high", "electrophoresis", "dna", "pcr", "performance analysis", "time data analysis", "reaction", "rapid microwell polymerase chain reaction"]], "textrank": [["microwell polymerase chain reaction", "gel electrophoresis analysis", "dna amplification technique", "microwell polymerase chain", "real time"], ["microwell polymerase chain reaction", "gel electrophoresis analysis", "dna amplification technique", "microwell polymerase chain", "real time", "gel electrophoresis", "reaction", "time", "minute quantities", "throughput devices"]], "positionrank": [["layer gel electrophoresis", "microwell polymerase chain", "layer gel", "pcr reaction", "dna amplification technique"], ["layer gel electrophoresis", "microwell polymerase chain", "layer gel", "pcr reaction", "dna amplification technique", "time data analysis", "total reaction volume", "performance analysis", "electrophoresis process", "capillary gel"]], "multipartiterank": [["layer gel", "subsequent ultrathin", "rapid microwell polymerase chain reaction", "electrophoresis", "dna"], ["layer gel", "subsequent ultrathin", "rapid microwell polymerase chain reaction", "electrophoresis", "dna", "high", "pcr", "large", "performance analysis", "scale genotyping"]]}, {"id": "370", "text": "Virtual borders, real laws [Internet activity and treaties]\nNational governments are working to tame activity on the Internet. They have\n\tworked steadily to extend control over online activities that they\n\tbelieve affect their interests, even when the activities occur outside\n\ttheir borders. These usually involve what governments regard as their\n\tdomain: protecting public order, enforcing commercial laws, and,\n\toccasionally, protecting consumer interests. Methods have included\n\tassertions or legal jurisdiction based on where material is accessible\n\tinstead of where it originates, and the blocking of sites, service\n\tproviders, or entire high level domains from access by citizens. Such\n\tinstances are mentioned in this article. Whilst larger companies are\n\table to defend themselves against overseas lawsuits, individuals and\n\tsmaller organizations lack the resources to defend what are often\n\tnormal business activities at home, but could violate the laws of local\n\tjurisdictions in countries around the world. The problems of libel are\n\tdiscussed as are the blocking of certain sites by certain countries.\n\tEfforts to draw up Internet treaties are also mentioned\n", "keywords": "national governments; Internet activity; online activities; public order\n\tprotection; commercial laws enforcement; legal jurisdiction; consumer\n\tinterests protection; Internet sites blocking; lawsuits; Internet\n\ttreaties\n", "topicrank": [["real laws", "online activities", "sites", "countries", "blocking"], ["real laws", "online activities", "sites", "countries", "blocking", "internet activity", "interests", "national governments", "virtual borders", "entire high level domains"]], "textrank": [["business activities", "high level", "legal jurisdiction", "consumer interests", "public order"], ["business activities", "high level", "legal jurisdiction", "consumer interests", "public order", "national governments", "virtual borders", "certain", "internet", "laws"]], "positionrank": [["internet activity", "virtual borders", "internet treaties", "real laws", "commercial laws"], ["internet activity", "virtual borders", "internet treaties", "real laws", "commercial laws", "national governments", "laws", "internet", "activity", "borders"]], "multipartiterank": [["real laws", "virtual borders", "internet activity", "online activities", "national governments"], ["real laws", "virtual borders", "internet activity", "online activities", "national governments", "treaties", "sites", "interests", "blocking", "internet"]]}, {"id": "2082", "text": "Managing safety and strategic stocks to improve materials requirements planning\n\tperformance\nThis paper provides a methodology for managing safety and strategic stocks in\n\tmaterials requirements planning (MRP) environments to face uncertainty\n\tin market demand. A set of recommended guidelines suggest where to\n\tposition, how to dimension and when to replenish both safety and\n\tstrategic stocks. Trade-offs between stock positioning and dimensioning\n\tand between stock positioning and replenishment order triggering are\n\toutlined. The study reveals also that most of the decisions are system\n\tspecific, so that they should be evaluated in a quantitative manner\n\tthrough simulation. A case study is reported, where the benefits from\n\tadopting the new proposed methodology lie in achieving the target\n\tservice level even under peak demand conditions, with the value of\n\tsafety stocks as a whole growing only by about 20 per cent\n", "keywords": "MRP; materials requirements planning; market demand; strategic stocks; safety\n\tstocks; inventory management; variance control; stock replenishment;\n\tservice level; peak demand\n", "topicrank": [["safety", "strategic stocks", "stock positioning", "methodology", "materials requirements"], ["safety", "strategic stocks", "stock positioning", "methodology", "materials requirements", "study", "offs", "trade", "system", "dimensioning"]], "textrank": [["methodology lie", "case study", "quantitative manner", "replenishment order", "stock positioning"], ["methodology lie", "case study", "quantitative manner", "replenishment order", "stock positioning", "materials requirements", "demand", "stocks", "study", "methodology"]], "positionrank": [["safety stocks", "strategic stocks", "materials requirements", "safety", "peak demand conditions"], ["safety stocks", "strategic stocks", "materials requirements", "safety", "peak demand conditions", "stock positioning", "methodology lie", "market demand", "methodology", "service level"]], "multipartiterank": [["safety", "strategic stocks", "stock positioning", "materials requirements", "methodology"], ["safety", "strategic stocks", "stock positioning", "materials requirements", "methodology", "study", "trade", "offs", "paper", "dimensioning"]]}, {"id": "335", "text": "Fresh voices, big ideas [IBM internship program]\nIBM is matching up computer-science and MBA students with its business managers\n\tin an 11-week summer internship program and challenging them to develop\n\tinnovative technology ideas\n", "keywords": "internship program; IBM business managers; MBA college students;\n\tcomputer-science students; patents\n", "topicrank": [["ibm internship program", "science", "mba students", "computer", "big ideas"], ["ibm internship program", "science", "mba students", "computer", "big ideas", "ibm", "business managers", "fresh voices", "innovative technology ideas"]], "textrank": [["technology ideas", "fresh voices", "internship", "ideas"], ["technology ideas", "fresh voices", "internship", "ideas"]], "positionrank": [["ibm internship program", "summer internship program", "fresh voices", "big ideas", "innovative technology ideas"], ["ibm internship program", "summer internship program", "fresh voices", "big ideas", "innovative technology ideas", "ibm", "business managers", "mba students", "computer", "science"]], "multipartiterank": [["ibm internship program", "big ideas", "science", "computer", "mba students"], ["ibm internship program", "big ideas", "science", "computer", "mba students", "ibm", "fresh voices", "business managers", "summer internship program", "innovative technology ideas"]]}, {"id": "249", "text": "Randomized two-process wait-free test-and-set\nWe present the first explicit, and currently simplest, randomized algorithm for\n\ttwo-process wait-free test-and-set. It is implemented with two 4-valued\n\tsingle writer single reader atomic variables. A test-and-set takes at\n\tmost 11 expected elementary steps, while a reset takes exactly 1\n\telementary step. Based on a finite-state analysis, the proofs of\n\tcorrectness and expected length are compressed into one table\n", "keywords": "randomized two-process wait-free test-and-set; randomized algorithm; 4-valued\n\tsingle writer single reader atomic variables; expected elementary\n\tsteps; finite-state analysis; correctness proofs; symmetry breaking;\n\tasynchronous distributed protocols; fault-tolerance; shared memory;\n\twait-free read/write registers\n", "topicrank": [["free test", "process wait", "elementary steps", "randomized", "state analysis"], ["free test", "process wait", "elementary steps", "randomized", "state analysis", "proofs", "finite", "correctness", "simplest", "length"]], "textrank": [["single reader atomic", "free test", "process wait", "elementary", "single"], ["single reader atomic", "free test", "process wait", "elementary", "single", "test", "randomized"]], "positionrank": [["randomized algorithm", "free test", "process wait", "test", "first explicit"], ["randomized algorithm", "free test", "process wait", "test", "first explicit", "single reader", "single writer", "atomic variables", "set takes", "elementary steps"]], "multipartiterank": [["randomized", "process wait", "free test", "elementary steps", "state analysis"], ["randomized", "process wait", "free test", "elementary steps", "state analysis", "simplest", "finite", "proofs", "correctness", "reset"]]}, {"id": "1972", "text": "Online auctions: dynamic pricing and the lodging industry\nThe traditional channels of distribution for overnight accommodation are\n\trapidly being displaced by Web site scripting, online intermediaries,\n\tand specialty brokers. Businesses that pioneered Internet usage relied\n\ton it as a sales and marketing alternative to predecessor product\n\tdistribution channels. As such, Web sites replace the traditional\n\ttrading model to the Internet. Web-enabled companies are popular\n\tbecause the medium renders the process faster, less costly, highly\n\treliable, and secure. Auction-based models impact business models by\n\tconverting the price setting mechanism from supplier-centric to\n\tmarket-centric and transforming the trading model from \"one to many\" to\n\t\"many to many.\" Historically, pricing was based on the cost of\n\tproduction plus a margin of profit. Traditionally, as products and\n\tservices move through the supply chain, from the producer to the\n\tconsumer, various intermediaries added their share of profit to the\n\tprice. As Internet based mediums of distribution become more prevalent,\n\ttraditional pricing models are being supplanted with dynamic pricing. A\n\tdynamic pricing model represents a flexible system that changes prices\n\tnot only from product to product, but also from customer to customer\n\tand transaction to transaction. Many industry leaders are skeptical of\n\tthe long run impact of online auctions on lodging industry profit\n\tmargins, despite the fact pricing theory suggests that an increase in\n\tthe flow of information results in efficient market pricing. The future\n\tof such endeavors remains promising, but controversial\n", "keywords": "online auctions; dynamic pricing; lodging industry; overnight accommodations;\n\tWeb site scripting; online intermediaries; specialty brokers; Internet\n\tusage; sales; marketing; trading model; business models; price setting\n\tmechanism; supply chain\n", "topicrank": [["dynamic pricing", "many", "profit", "internet usage", "distribution"], ["dynamic pricing", "many", "profit", "internet usage", "distribution", "traditional channels", "web site scripting", "predecessor product", "online auctions", "price"]], "textrank": [["traditional pricing models", "market pricing", "pricing model", "pricing", "models impact"], ["traditional pricing models", "market pricing", "pricing model", "pricing", "models impact", "online intermediaries", "web site", "industry", "run impact", "traditional channels"]], "positionrank": [["online auctions", "dynamic pricing model", "traditional pricing models", "dynamic pricing", "online intermediaries"], ["online auctions", "dynamic pricing model", "traditional pricing models", "dynamic pricing", "online intermediaries", "efficient market pricing", "fact pricing theory", "industry profit", "many industry leaders", "lodging industry"]], "multipartiterank": [["online auctions", "dynamic pricing", "distribution", "traditional channels", "internet usage"], ["online auctions", "dynamic pricing", "distribution", "traditional channels", "internet usage", "web site scripting", "many", "profit", "predecessor product", "centric"]]}, {"id": "1937", "text": "Nonlinear extrapolation algorithm for realization of a scalar random process\nA method of construction of a nonlinear extrapolation algorithm is proposed.\n\tThis method makes it possible to take into account any nonlinear random\n\tdependences that exist in an investigated process and are described by\n\tmixed central moment functions. The method is based on the V. S.\n\tPugachev canonical decomposition apparatus. As an example, the problem\n\tof nonlinear extrapolation is solved for a moment function of third\n\torder\n", "keywords": "nonlinear extrapolation algorithm; scalar random process; nonlinear random\n\tdependences; mixed central moment functions; canonical decomposition\n\tapparatus; moment function\n", "topicrank": [["nonlinear extrapolation algorithm", "method", "account", "third", "construction"], ["nonlinear extrapolation algorithm", "method", "account", "third", "construction", "dependences", "moment function", "scalar random process", "possible", "problem"]], "textrank": [["central moment", "random process", "nonlinear random", "canonical decomposition", "nonlinear extrapolation"], ["central moment", "random process", "nonlinear random", "canonical decomposition", "nonlinear extrapolation", "moment", "process", "v."]], "positionrank": [["nonlinear extrapolation algorithm", "nonlinear extrapolation", "scalar random process", "nonlinear", "investigated process"], ["nonlinear extrapolation algorithm", "nonlinear extrapolation", "scalar random process", "nonlinear", "investigated process", "method", "moment function", "canonical decomposition apparatus", "realization", "v. s."]], "multipartiterank": [["nonlinear extrapolation algorithm", "method", "realization", "construction", "scalar random process"], ["nonlinear extrapolation algorithm", "method", "realization", "construction", "scalar random process", "account", "possible", "dependences", "nonlinear random", "mixed central moment functions"]]}, {"id": "2146", "text": "Trusted...or...trustworthy: the search for a new paradigm for computer and\n\tnetwork security\nThis paper sets out a number of major questions and challenges which include:\n\t(a) just what is meant by `trusted' or `trustworthy' systems after 20\n\tyears of experience, or more likely, lack of business level experience,\n\twith the 'trusted computer system' criteria anyway; (b) does anyone\n\treally care about the adoption of international standards for computer\n\tsystem security evaluation by IT product and system manufacturers and\n\tsuppliers (IS 15408) and, if so, how does it all relate to business\n\trisk management anyway (IS 17799); (c) with the explosion of adoption\n\tof the microcomputer and personal computer some 20 years ago, has the\n\tindustry abandoned all that it learnt about security during the\n\t`mainframe era'; or - `whatever happened to MULTICS' and its lessons;\n\t(d) has education kept up with security requirements by industry and\n\tgovernment alike in the need for safe and secure operation of large\n\tscale and networked information systems on national and international\n\tbases, particularly where Web or Internet-based information services\n\tare being proposed as the major `next best thing' in the IT industry;\n\t(e) has the `fourth generation' of computer professionals inherited the\n\tspirit of information systems management and control that resided by\n\tnecessity with the last `generation', the professionals who developed\n\tand created the applications for shared mainframe and minicomputer\n\tsystems?\n", "keywords": "computer security; network security; trusted systems; trustworthy systems;\n\tinternational standards; IS 15408; business risk management; IS 17799;\n\tIT manufacturers; microcomputer; personal computer; MULTICS; education;\n\tlarge scale information systems; Web; Internet-based information\n\tservices; fourth generation computer professionals; information systems\n\tmanagement; information systems control\n", "topicrank": [["computer", "systems", "network security", "international standards", "major questions"], ["computer", "systems", "network security", "international standards", "major questions", "industry", "years", "adoption", "business level experience", "fourth generation"]], "textrank": [["information systems management", "system security", "computer system", "information systems", "level experience"], ["information systems management", "system security", "computer system", "information systems", "level experience", "security", "computer", "fourth generation", "best thing", "secure operation"]], "positionrank": [["trusted computer system", "system security evaluation", "computer professionals", "personal computer", "network security"], ["trusted computer system", "system security evaluation", "computer professionals", "personal computer", "network security", "computer", "information systems management", "new paradigm", "networked information systems", "business level experience"]], "multipartiterank": [["computer", "network security", "systems", "international standards", "major questions"], ["computer", "network security", "systems", "international standards", "major questions", "trustworthy", "adoption", "years", "business level experience", "new paradigm"]]}, {"id": "2103", "text": "The social impact of Internet gambling\nTechnology has always played a role in the development of gambling practices\n\tand continues to provide new market opportunities. One of the fastest\n\tgrowing areas is that of Internet gambling. The effect of such\n\ttechnologies should not be accepted uncritically, particularly as there\n\tmay be areas of potential concern based on what is known about problem\n\tgambling offline. This article has three aims. First, it overviews some\n\tof the main social concerns about the rise of Internet gambling.\n\tSecond, it looks at the limited research that has been carried out in\n\tthis area. Third, it examines whether Internet gambling is doubly\n\taddictive, given research that suggests that the Internet can be\n\taddictive itself. It is concluded that technological developments in\n\tInternet gambling will increase the potential for problem gambling\n\tglobally, but that many of the ideas and speculations outlined in this\n\tarticle need to be addressed further by large-scale empirical studies\n", "keywords": "social impact; Internet gambling; market opportunities; technological\n\tdevelopments; addiction; electronic cash; psychology\n", "topicrank": [["internet gambling", "gambling practices", "problem", "potential concern", "areas"], ["internet gambling", "gambling practices", "problem", "potential concern", "areas", "article", "addictive", "limited research", "ideas", "development"]], "textrank": [["new market opportunities", "gambling", "technological developments", "limited research", "potential concern"], ["new market opportunities", "gambling", "technological developments", "limited research", "potential concern", "social", "empirical", "potential", "research"]], "positionrank": [["internet gambling", "problem gambling", "gambling practices", "gambling offline", "internet"], ["internet gambling", "problem gambling", "gambling practices", "gambling offline", "internet", "main social concerns", "social impact", "new market opportunities", "potential concern", "technology"]], "multipartiterank": [["internet gambling", "gambling practices", "areas", "problem", "potential concern"], ["internet gambling", "gambling practices", "areas", "problem", "potential concern", "article", "development", "addictive", "limited research", "gambling offline"]]}, {"id": "4", "text": "Industry insiders loading up on cheap company stock\nA surge of telecom executives and directors purchasing their own companies,\n\tstock in the last two months points toward a renewed optimism in the\n\tbeleaguered sector, say some observers, who view the rash of insider\n\tbuying as a vote of confidence from management. Airgate PCS, Charter\n\tCommunications, Cox Communications, Crown Castle International, Nextel\n\tCommunications and Nortel Networks all have seen infusions of insider\n\tinvestment this summer, echoing trends in both the telecom industry and\n\tthe national economy\n", "keywords": "telecom industry; insider investment\n", "topicrank": [["communications", "insider", "cheap company stock", "airgate pcs", "management"], ["communications", "insider", "cheap company stock", "airgate pcs", "management", "confidence", "crown castle international", "charter", "industry insiders", "vote"]], "textrank": [["telecom industry", "airgate pcs", "beleaguered sector", "months points", "own companies"], ["telecom industry", "airgate pcs", "beleaguered sector", "months points", "own companies", "castle", "company", "telecom", "industry", "communications"]], "positionrank": [["cheap company stock", "telecom industry", "industry insiders", "telecom executives", "stock"], ["cheap company stock", "telecom industry", "industry insiders", "telecom executives", "stock", "own companies", "surge", "months points", "national economy", "directors"]], "multipartiterank": [["communications", "industry insiders", "cheap company stock", "insider", "telecom executives"], ["communications", "industry insiders", "cheap company stock", "insider", "telecom executives", "surge", "airgate pcs", "charter", "crown castle international", "management"]]}, {"id": "354", "text": "Fault-tolerant Hamiltonian laceability of hypercubes\nIt is known that every hypercube Q/sub n/ is a bipartite graph. Assume that\n\tn>or=2 and F is a subset of edges with |F|<or=n-2. We prove that\n\tthere exists a Hamiltonian path in Q/sub n/-F between any two vertices\n\tof different partite sets. Moreover, there exists a path of length\n\t2/sup n/-2 between any two vertices of the same partite set. Assume\n\tthat n>or=3 and F is a subset of edges with |F|<or=n-3. We prove\n\tthat there exists a Hamiltonian path in Q/sub n/-{v}-F between any two\n\tvertices in the partite set without v. Furthermore, all bounds are\n\ttight\n", "keywords": "fault-tolerant Hamiltonian laceability; hypercubes; bipartite graph; edge\n\tsubset; Hamiltonian path; vertices; partite sets; tight bounds\n", "topicrank": [["hamiltonian path", "vertices", "edges", "subset", "different partite sets"], ["hamiltonian path", "vertices", "edges", "subset", "different partite sets", "tolerant hamiltonian laceability", "length", "hypercubes", "fault", "n-2"]], "textrank": [["sup n/-2", "bipartite graph", "sub n/", "hypercube q", "partite"], ["sup n/-2", "bipartite graph", "sub n/", "hypercube q", "partite", "hamiltonian", "sub", "q"]], "positionrank": [["tolerant hamiltonian laceability", "hamiltonian path", "hypercube q", "fault", "hypercubes"], ["tolerant hamiltonian laceability", "hamiltonian path", "hypercube q", "fault", "hypercubes", "q", "different partite sets", "bipartite graph", "sub n/", "path"]], "multipartiterank": [["vertices", "hamiltonian path", "edges", "subset", "different partite sets"], ["vertices", "hamiltonian path", "edges", "subset", "different partite sets", "tolerant hamiltonian laceability", "length", "hypercubes", "path", "fault"]]}, {"id": "311", "text": "Information architecture without internal theory: an inductive design process\nThis article suggests that Information Architecture (IA) design is primarily an\n\tinductive process. Although top-level goals, user attributes and\n\tavailable content are periodically considered, the process involves\n\tbottom-up design activities. IA is inductive partly because it lacks\n\tinternal theory, and partly because it is an activity that supports\n\temergent phenomena (user experiences) from basic design components. The\n\tnature of IA design is well described by Constructive Induction (CI), a\n\tdesign process that involves locating the best representational\n\tframework for the design problem, identifying a solution within that\n\tframework and translating it back to the design problem at hand. The\n\tfuture of IA, if it remains inductive or develops a body of theory (or\n\tboth), is considered\n", "keywords": "information architecture design; inductive design process; bottom-up design\n\tactivities; internal theory; emergent phenomena; user experiences;\n\tconstructive induction\n", "topicrank": [["design", "inductive design process", "internal theory", "user attributes", "framework"], ["design", "inductive design process", "internal theory", "user attributes", "framework", "information architecture", "inductive", "level goals", "top", "emergent phenomena"]], "textrank": [["design", "available content", "level goals", "internal theory", "information architecture"], ["design", "available content", "level goals", "internal theory", "information architecture", "user", "theory", "emergent"]], "positionrank": [["inductive design process", "design process", "ia design", "inductive process", "basic design components"], ["inductive design process", "design process", "ia design", "inductive process", "basic design components", "information architecture", "design problem", "design activities", "design", "internal theory"]], "multipartiterank": [["design", "inductive design process", "internal theory", "information architecture", "user attributes"], ["design", "inductive design process", "internal theory", "information architecture", "user attributes", "article", "level goals", "top", "inductive process", "inductive"]]}, {"id": "369", "text": "Nissan v. Nissan [trademark dispute]\nIs a trademark dispute a case of David v. Goliath or a corporation fending off\n\ta greedy opportunist? This paper discusses the case of Uzi Nissan, who\n\tis locked in a multimillion-dollar legal battle over whether or not his\n\tuse of the nissan.com Internet domain name infringes upon Japan's\n\tNissan Motor Co.'s trademark. At the heart of the matter is the impact\n\tof the global Internet on trademark law, which traditionally has been\n\tstrongly influenced by geographic considerations. The paper discusses\n\tthe background to the case from both sides and the issues involved\n", "keywords": "trademark dispute; Uzi Nissan; nissan.com Internet domain name; Nissan Motor\n\tCompany trademark; global Internet; trademark law\n", "topicrank": [["trademark dispute", "case", "nissan", "paper", "david"], ["trademark dispute", "case", "nissan", "paper", "david", "goliath", "matter", "global internet", "corporation", "impact"]], "textrank": [["internet domain", "nissan motor", "geographic considerations", "greedy opportunist", "internet"], ["internet domain", "nissan motor", "geographic considerations", "greedy opportunist", "internet", "legal", "trademark", "nissan"]], "positionrank": [["nissan motor co.", "trademark dispute", "uzi nissan", "nissan", "trademark law"], ["nissan motor co.", "trademark dispute", "uzi nissan", "nissan", "trademark law", "trademark", "case", "global internet", "greedy opportunist", "paper"]], "multipartiterank": [["trademark dispute", "nissan", "case", "paper", "david"], ["trademark dispute", "nissan", "case", "paper", "david", "goliath", "corporation", "greedy opportunist", "global internet", "matter"]]}, {"id": "401", "text": "A digital-to-analog converter based on differential-quad switching\nA high-conversion-rate high-resolution oversampling digital-to-analog converter\n\t(DAC) for direct digital modulation is addressed in this paper. A new\n\ttype of switching scheme, called differential-quad switching, is\n\tpresented. To verify the feasibility of this scheme, essential parts\n\twith some auxiliary circuitry for interfacing were fabricated in a 0.8-\n\tmu m CMOS technology. Measured results show that the switching scheme\n\tprovides 11-b resolution at 100 MSamples/s and 6-b at 1 GSamples/s. The\n\tdegradation in signal-to-noise ratio is not observed for the variation\n\tof the supply voltage down to 1.5 V, which means the proposed scheme is\n\tsuitable for low-voltage applications\n", "keywords": "high-conversion-rate DAC; high-resolution DAC; oversampling DAC;\n\tdigital-to-analog converter; CMOS technology; direct digital\n\tmodulation; differential-quad switching; signal-to-noise ratio; SNR;\n\t1.5 V; 0.8 micron\n", "topicrank": [["switching scheme", "digital", "high", "resolution", "quad switching"], ["switching scheme", "digital", "high", "resolution", "quad switching", "differential", "analog converter", "supply voltage", "type", "conversion"]], "textrank": [["m cmos", "auxiliary circuitry", "essential parts", "rate high", "analog converter"], ["m cmos", "auxiliary circuitry", "essential parts", "rate high", "analog converter", "voltage", "switching", "digital", "high"]], "positionrank": [["direct digital modulation", "analog converter", "switching scheme", "quad switching", "digital"], ["direct digital modulation", "analog converter", "switching scheme", "quad switching", "digital", "scheme", "differential", "resolution", "rate", "conversion"]], "multipartiterank": [["switching scheme", "digital", "high", "resolution", "quad switching"], ["switching scheme", "digital", "high", "resolution", "quad switching", "differential", "analog converter", "conversion", "scheme", "type"]]}, {"id": "2023", "text": "Diffraction limit for a circular mask with a periodic rectangular apertures\n\tarray\nA mask with periodic apertures imaging system is adopted very widely and plays\n\ta leading role in modern technology for uses such as pinhole cameras,\n\tcoded imaging systems, optical information processing, etc. because of\n\tits high resolution, its infinite depth of focus, and its usefulness\n\tover a broad frequency spectra ranging from visible light to X-rays and\n\tgamma rays. While the masks with periodic apertures investigated in the\n\tliterature are limited only to far-field diffraction, they do not take\n\tthe shift of apertures within the mask into consideration. Therefore\n\tthe derivation of the far-field diffraction for a single aperture\n\tcannot be applied to a mask with periodic apertures. The far-field\n\tdiffraction formula modified for a multiaperture mask has been proposed\n\tin the past, the analysis remains too complicated to offer some\n\tpractical guidance for mask design. We study a circular mask with\n\tperiodic rectangular apertures and develop an easier way to interpret\n\tit. First, the near-field diffraction intensity of a circular aperture\n\tis calculated by means of Lommel's function. Then the convolution of\n\tthe circular mask diffraction with periodic rectangular apertures is\n\tput together, and we can present a simple mathematical tool to analyze\n\tthe mask properties including the intensity distribution, blurring\n\taberration, and the criterion of defining the far- or near-field\n\tdiffraction. This concept can also be expanded to analyze different\n\ttypes of masks with the arbitrarily shaped apertures\n", "keywords": "diffraction limit; circular mask; periodic rectangular apertures array; pinhole\n\tcameras; coded imaging systems; optical information processing; high\n\tresolution; infinite depth of focus; broad frequency spectra; visible\n\tlight; x rays; gamma rays; periodic apertures; far-field diffraction;\n\tmask; single aperture; far-field diffraction formula; multiaperture\n\tmask; periodic rectangular apertures; convolution; circular mask\n\tdiffraction; near-field diffraction; arbitrarily shaped apertures\n", "topicrank": [["circular mask", "periodic rectangular apertures", "field diffraction", "far", "diffraction limit"], ["circular mask", "periodic rectangular apertures", "field diffraction", "far", "diffraction limit", "near", "masks", "single aperture", "lommel", "infinite depth"]], "textrank": [["circular mask diffraction", "diffraction intensity", "circular mask", "apertures imaging", "- rays"], ["circular mask diffraction", "diffraction intensity", "circular mask", "apertures imaging", "- rays", "diffraction", "mask", "circular aperture", "infinite depth", "high resolution"]], "positionrank": [["circular mask diffraction", "periodic rectangular apertures", "field diffraction intensity", "circular mask", "field diffraction"], ["circular mask diffraction", "periodic rectangular apertures", "field diffraction intensity", "circular mask", "field diffraction", "periodic apertures", "diffraction limit", "diffraction formula", "mask design", "multiaperture mask"]], "multipartiterank": [["circular mask", "periodic rectangular apertures", "diffraction limit", "field diffraction", "far"], ["circular mask", "periodic rectangular apertures", "diffraction limit", "field diffraction", "far", "mask", "single aperture", "array", "periodic apertures", "near"]]}, {"id": "394", "text": "Model intestinal microflora in computer simulation: a simulation and modeling\n\tpackage for host-microflora interactions\nThe ecology of the human intestinal microflora and its interaction with the\n\thost are poorly understood. Though more and more data are being\n\tacquired, in part using modern molecular methods, development of a\n\tquantitative theory has not kept pace with this increase in observing\n\tpower. This is in part due to the complexity of the system and to the\n\tlack of simulation environments in which to test what the ecological\n\teffect of a hypothetical mechanism of interaction would be, before\n\tresorting to laboratory experiments. The MIMICS project attempts to\n\taddress this through the development of a cellular automaton for\n\tsimulation of the intestinal microflora. In this paper, the design and\n\tevaluation of this simulator is discussed\n", "keywords": "human intestines; intestinal microflora; molecular methods; observing power;\n\tsystem complexity; microbial ecology; parallel computing;\n\thost-microflora interactions; quantitative theory; MIMICS project;\n\tcomplex microbial ecosystem\n", "topicrank": [["model intestinal microflora", "computer simulation", "development", "interaction", "part"], ["model intestinal microflora", "computer simulation", "development", "interaction", "part", "host", "modern molecular methods", "hypothetical mechanism", "effect", "ecological"]], "textrank": [["intestinal microflora", "laboratory experiments", "hypothetical mechanism", "quantitative theory", "more data"], ["intestinal microflora", "laboratory experiments", "hypothetical mechanism", "quantitative theory", "more data", "molecular", "simulation", "microflora", "mimics", "more"]], "positionrank": [["model intestinal microflora", "human intestinal microflora", "intestinal microflora", "computer simulation", "microflora interactions"], ["model intestinal microflora", "human intestinal microflora", "intestinal microflora", "computer simulation", "microflora interactions", "simulation environments", "simulation", "host", "cellular automaton", "package"]], "multipartiterank": [["model intestinal microflora", "computer simulation", "host", "simulation", "interaction"], ["model intestinal microflora", "computer simulation", "host", "simulation", "interaction", "package", "part", "development", "ecology", "modern molecular methods"]]}, {"id": "2066", "text": "Product and process innovations in the life cycle of an industry\nFilson (2001) uses industry-level data on firm numbers, price, quantity and\n\tquality along with an equilibrium model of industry evolution to\n\testimate the nature and effects of quality and cost improvements in the\n\tpersonal computer industry and four other new industries. This paper\n\tstudies the personal computer industry in more detail and shows that\n\tthe model explains some peculiar patterns that cannot be explained by\n\tprevious life-cycle models. The model estimates are evaluated using\n\thistorical studies of the evolution of the personal computer industry\n\tand patterns that require further model development are described\n", "keywords": "technological change; life-cycle models; industry dynamics; personal computer\n\tmarket; microelectronics; equilibrium model; industry evolution; PC\n\tindustry; production cost\n", "topicrank": [["industry", "equilibrium model", "quality", "life cycle", "industry evolution"], ["industry", "equilibrium model", "quality", "life cycle", "industry evolution", "firm numbers", "price", "level data", "effects", "quantity"]], "textrank": [["computer industry", "life cycle", "model", "firm numbers", "level data"], ["computer industry", "life cycle", "model", "firm numbers", "level data", "process innovations", "new", "cycle", "life", "industry"]], "positionrank": [["personal computer industry", "life cycle", "industry evolution", "process innovations", "industry"], ["personal computer industry", "life cycle", "industry evolution", "process innovations", "industry", "previous life", "cycle models", "product", "model estimates", "further model development"]], "multipartiterank": [["industry", "quality", "equilibrium model", "life cycle", "industry evolution"], ["industry", "quality", "equilibrium model", "life cycle", "industry evolution", "level data", "firm numbers", "personal computer industry", "filson", "price"]]}, {"id": "27", "text": "A formal model of computing with words\nClassical automata are formal models of computing with values. Fuzzy automata\n\tare generalizations of classical automata where the knowledge about the\n\tsystem's next state is vague or uncertain. It is worth noting that like\n\tclassical automata, fuzzy automata can only process strings of input\n\tsymbols. Therefore, such fuzzy automata are still (abstract) devices\n\tfor computing with values, although a certain vagueness or uncertainty\n\tare involved in the process of computation. We introduce a new kind of\n\tfuzzy automata whose inputs are instead strings of fuzzy subsets of the\n\tinput alphabet. These new fuzzy automata may serve as formal models of\n\tcomputing with words. We establish an extension principle from\n\tcomputing with values to computing with words. This principle indicates\n\tthat computing with words can be implemented with computing with values\n\twith the price of a big amount of extra computations\n", "keywords": "formal model; computing with words; fuzzy automata; fuzzy subsets; input\n\talphabet; extension principle; pushdown automata\n", "topicrank": [["classical automata", "values", "words", "formal model", "strings"], ["classical automata", "values", "words", "formal model", "strings", "input", "extension principle", "next state", "vague", "uncertain"]], "textrank": [["new fuzzy automata", "fuzzy automata", "fuzzy", "extension principle", "input alphabet"], ["new fuzzy automata", "fuzzy automata", "fuzzy", "extension principle", "input alphabet", "certain vagueness", "next state", "formal", "new", "automata"]], "positionrank": [["new fuzzy automata", "such fuzzy automata", "fuzzy automata", "classical automata", "formal model"], ["new fuzzy automata", "such fuzzy automata", "fuzzy automata", "classical automata", "formal model", "formal models", "fuzzy subsets", "words", "values", "input alphabet"]], "multipartiterank": [["classical automata", "formal model", "words", "values", "fuzzy automata"], ["classical automata", "formal model", "words", "values", "fuzzy automata", "strings", "input", "formal models", "next state", "generalizations"]]}, {"id": "289", "text": "Noise effect on memory recall in dynamical neural network model of hippocampus\nWe investigate some noise effect on a neural network model proposed by Araki\n\tand Aihara (1998) for the memory recall of dynamical patterns in the\n\thippocampus and the entorhinal cortex; the noise effect is important\n\tsince the release of transmitters at synaptic clefts, the operation of\n\tgate of ion channels and so on are known as stochastic phenomena. We\n\tconsider two kinds of noise effect due to a deterministic noise and a\n\tstochastic noise. By numerical simulations, we find that reasonable\n\tvalues of noise give better performance on the memory recall of\n\tdynamical patterns. Furthermore we investigate the effect of the\n\tstrength of external inputs on the memory recall\n", "keywords": "hippocampus; dynamical neural network model; noise effect; memory recall;\n\tdynamical patterns; entorhinal cortex; synaptic clefts; gate of ion\n\tchannels; stochastic phenomena; deterministic noise; stochastic noise;\n\tbrain functions; numerical simulations; synaptic strength; inhibitory\n\tconnection\n", "topicrank": [["noise effect", "memory recall", "deterministic noise", "dynamical neural network model", "dynamical patterns"], ["noise effect", "memory recall", "deterministic noise", "dynamical neural network model", "dynamical patterns", "hippocampus", "transmitters", "synaptic clefts", "values", "release"]], "textrank": [["dynamical neural network", "stochastic noise", "neural network", "synaptic clefts", "entorhinal cortex"], ["dynamical neural network", "stochastic noise", "neural network", "synaptic clefts", "entorhinal cortex", "memory recall", "noise", "stochastic", "dynamical"]], "positionrank": [["noise effect", "stochastic noise", "deterministic noise", "noise", "neural network model"], ["noise effect", "stochastic noise", "deterministic noise", "noise", "neural network model", "memory recall", "effect", "dynamical patterns", "hippocampus", "stochastic phenomena"]], "multipartiterank": [["noise effect", "memory recall", "deterministic noise", "dynamical neural network model", "hippocampus"], ["noise effect", "memory recall", "deterministic noise", "dynamical neural network model", "hippocampus", "dynamical patterns", "transmitters", "synaptic clefts", "release", "important"]]}, {"id": "2186", "text": "Strategies for high throughput, templated zeolite synthesis\nThe design and redesign of high throughput experiments for zeolite synthesis\n\tare addressed. A model that relates materials function to the chemical\n\tcomposition of the zeolite and the structure directing agent is\n\tintroduced. Using this model, several Monte Carlo-like design protocols\n\tare evaluated. Multi-round protocols are bound to be effective, and\n\tstrategies that use a priori information about the structure-directing\n\tlibraries are found to be the best\n", "keywords": "templated zeolite synthesis; high throughput strategies; materials function;\n\tchemical composition; structure directing agent; Monte Carlo-like\n\tdesign protocols; multi-round protocols; a priori information;\n\tcatalytic activity; catalytic selectivity; organo-cation template\n\tmolecules; combinatorial methods; random energy model; figure of merit;\n\tmaterial discovery; small molecule design; Voronoi diagram;\n\tphase-dependent random Gaussian variables; Metropolis-type method;\n\tligand libraries; reflecting boundary conditions\n", "topicrank": [["templated zeolite synthesis", "high throughput", "design", "structure", "model"], ["templated zeolite synthesis", "high throughput", "design", "structure", "model", "strategies", "composition", "redesign", "chemical", "several monte carlo"]], "textrank": [["- round protocols", "design protocols", "priori information", "monte", "zeolite"], ["- round protocols", "design protocols", "priori information", "monte", "zeolite", "throughput", "-", "design"]], "positionrank": [["templated zeolite synthesis", "high throughput experiments", "zeolite synthesis", "high throughput", "like design protocols"], ["templated zeolite synthesis", "high throughput experiments", "zeolite synthesis", "high throughput", "like design protocols", "zeolite", "strategies", "design", "several monte carlo", "redesign"]], "multipartiterank": [["templated zeolite synthesis", "high throughput", "design", "strategies", "structure"], ["templated zeolite synthesis", "high throughput", "design", "strategies", "structure", "model", "redesign", "high throughput experiments", "composition", "chemical"]]}, {"id": "231", "text": "Writing the fulfillment RFP [publishing]\nFor the uninitiated, writing a request for proposal can seem both mysterious\n\tand daunting. Here's a format that will make you look like a pro the\n\tfirst time out\n", "keywords": "request for proposal; fulfillment; publisher\n", "topicrank": [["request", "proposal", "publishing", "uninitiated", "fulfillment rfp"], ["request", "proposal", "publishing", "uninitiated", "fulfillment rfp", "mysterious", "pro", "first time", "format"]], "textrank": [["fulfillment rfp", "first"], ["fulfillment rfp", "first"]], "positionrank": [["fulfillment rfp", "publishing", "request", "proposal", "first time"], ["fulfillment rfp", "publishing", "request", "proposal", "first time", "pro", "format"]], "multipartiterank": [["request", "proposal", "publishing", "uninitiated", "fulfillment rfp"], ["request", "proposal", "publishing", "uninitiated", "fulfillment rfp", "mysterious", "pro", "first time", "format"]]}, {"id": "274", "text": "MTD-PLS: a PLS-based variant of the MTD method. II. Mapping ligand-receptor\n\tinteractions. Enzymatic acetic acid esters hydrolysis\nThe PLS variant of the MTD method (T.I. Oprea et al., SAR QSAR Environ. Res.\n\t2001, 12, 75-92) was applied to a series of 25 acetylcholinesterase\n\thydrolysis substrates. Statistically significant MTD-PLS models (q/sup\n\t2/ between 0.7 and 0.8) are in agreement with previous MTD models, with\n\tthe advantage that local contributions are understood beyond the\n\toccupancy/nonoccupancy interpretation in MTD. A \"chemically intuitive\"\n\tapproach further forces MTD-PLS coefficients to assume only negative\n\t(or zero) values for fragmental volume descriptors and positive (or\n\tzero) values for fragmental hydrophobicity descriptors. This further\n\tseparates the various kinds of local interactions at each vertex of the\n\tMTD hypermolecule, making this method suitable for medicinal chemistry\n\tsynthesis planning\n", "keywords": "minimum topological difference method; MTD-PLS models; PLS-based variant;\n\tligand-receptor interactions mapping; enzymatic acetic acid esters\n\thydrolysis; acetylcholinesterase hydrolysis substrates; chemically\n\tintuitive approach; fragmental volume descriptors; fragmental\n\thydrophobicity descriptors; hypermolecule; medicinal chemistry\n\tsynthesis planning; steric misfit; additive approach; intermolecular\n\tforce categories; regression coefficients; ligand binding affinity;\n\thydrogen bonding; polarizabilities; statistical model stability\n", "topicrank": [["mtd", "pls", "interactions", "fragmental volume descriptors", "values"], ["mtd", "pls", "interactions", "fragmental volume descriptors", "values", "variant", "nonoccupancy interpretation", "receptor", "enzymatic acetic acid esters hydrolysis", "hydrolysis substrates"]], "textrank": [["further forces mtd", "mtd method .", "acetic acid esters hydrolysis", "mtd method", "mtd models"], ["further forces mtd", "mtd method .", "acetic acid esters hydrolysis", "mtd method", "mtd models", "mtd .", "mtd", "pls models", "nonoccupancy interpretation", "al ."]], "positionrank": [["mtd method", "further forces mtd", "previous mtd models", "significant mtd", "mtd hypermolecule"], ["mtd method", "further forces mtd", "previous mtd models", "significant mtd", "mtd hypermolecule", "mtd", "pls variant", "pls models", "pls coefficients", "pls"]], "multipartiterank": [["mtd", "pls", "variant", "nonoccupancy interpretation", "interactions"], ["mtd", "pls", "variant", "nonoccupancy interpretation", "interactions", "values", "fragmental volume descriptors", "mtd method", "occupancy", "receptor"]]}, {"id": "2021", "text": "One-step digit-set-restricted modified signed-digit adder using an incoherent\n\tcorrelator based on a shared content-addressable memory\nAn efficient one-step digit-set-restricted modified signed-digit (MSD) adder\n\tbased on symbolic substitution is presented. In this technique, carry\n\tpropagation is avoided by introducing reference digits to restrict the\n\tintermediate carry and sum digits to {1,0} and {0,1}, respectively. The\n\tproposed technique requires significantly fewer minterms and simplifies\n\tsystem complexity compared to the reported one-step MSD addition\n\ttechniques. An incoherent correlator based on an optoelectronic shared\n\tcontent-addressable memory processor is suggested to perform the\n\taddition operation. In this technique, only one set of minterms needs\n\tto be stored, independent of the operand length\n", "keywords": "one-step digit-set-restricted modified signed-digit adder; incoherent\n\tcorrelator; shared content-addressable memory; symbolic substitution;\n\treference digits; intermediate carry; sum digits; minterms; system\n\tcomplexity; optoelectronic shared content-addressable memory processor;\n\taddition operation; operand length\n", "topicrank": [["technique", "msd", "step digit", "addressable memory", "content"], ["technique", "msd", "step digit", "addressable memory", "content", "fewer minterms", "correlator", "digit adder", "reference digits", "simplifies"]], "textrank": [["step msd addition", "step digit", "incoherent correlator", "symbolic substitution", "memory"], ["step msd addition", "step digit", "incoherent correlator", "symbolic substitution", "memory", "addition", "digit", "msd", "reference", "correlator"]], "positionrank": [["step digit", "step msd addition", "digit adder", "addressable memory processor", "incoherent correlator"], ["step digit", "step msd addition", "digit adder", "addressable memory processor", "incoherent correlator", "digit", "addressable memory", "correlator", "addition operation", "content"]], "multipartiterank": [["step digit", "digit adder", "content", "correlator", "addressable memory"], ["step digit", "digit adder", "content", "correlator", "addressable memory", "technique", "msd", "incoherent", "fewer minterms", "efficient"]]}, {"id": "396", "text": "Convolution-based global simulation technique for millimeter-wave photodetector\n\tand photomixer circuits\nA fast convolution-based time-domain approach to global photonic-circuit\n\tsimulation is presented that incorporates a physical device model in\n\tthe complete detector or mixer circuit. The device used in the\n\tdemonstration of this technique is a GaAs metal-semiconductor-metal\n\t(MSM) photodetector that offers a high response speed for the detection\n\tand generation of millimeter waves. Global simulation greatly increases\n\tthe accuracy in evaluating the complete circuit performance because it\n\taccounts for the effects of the millimeter-wave embedding circuit.\n\tDevice and circuit performance are assessed by calculating optical\n\tresponsivity and bandwidth. Device-only simulations using GaAs MSMs are\n\tcompared with global simulations that illustrate the strong\n\tinterdependence between device and external circuit\n", "keywords": "convolution-based time-domain approach; global photonic-circuit simulation;\n\tphysical device model; GaAs MSM photodetector; millimeter-wave\n\tphotodetector; photomixer; MM-wave embedding circuit; optical\n\tresponsivity; bandwidth; convolution-based global simulation; GaAs\n", "topicrank": [["circuit", "physical device model", "millimeter", "global simulation technique", "gaas metal"], ["circuit", "physical device model", "millimeter", "global simulation technique", "gaas metal", "wave photodetector", "simulations", "convolution", "semiconductor", "responsivity"]], "textrank": [["wave embedding circuit", "complete circuit", "global simulation", "circuit", "fast convolution"], ["wave embedding circuit", "complete circuit", "global simulation", "circuit", "fast convolution", "photomixer circuits", "global", "response", "gaas", "device"]], "positionrank": [["global simulation technique", "global simulation", "wave embedding circuit", "fast convolution", "complete circuit performance"], ["global simulation technique", "global simulation", "wave embedding circuit", "fast convolution", "complete circuit performance", "global simulations", "convolution", "wave photodetector", "circuit performance", "physical device model"]], "multipartiterank": [["global simulation technique", "circuit", "convolution", "physical device model", "millimeter"], ["global simulation technique", "circuit", "convolution", "physical device model", "millimeter", "device", "wave photodetector", "gaas metal", "global photonic", "domain approach"]]}, {"id": "2064", "text": "The effects of emotions on bounded rationality: a comment on Kaufman\nBruce Kaufman's article (1999), \"Emotional arousal as a source of bounded\n\trationality\", objective is to present an additional source of bounded\n\trationality, one that is not due to cognitive constraints, but to high\n\temotional arousal. In doing so, Kaufman is following a long tradition\n\tof thinkers who have contrasted emotion with reason, claiming, for the\n\tmost part, that emotions are a violent force hindering rational\n\tthinking. This paper aims to challenge Kaufman's unidimensional idea\n\tregarding the connection between high emotional arousal and decision\n\tmaking\n", "keywords": "bounded rationality; decision making; rational thinking; psychology; emotion;\n\tYerkes-Dodson law\n", "topicrank": [["kaufman", "emotional arousal", "rationality", "emotions", "source"], ["kaufman", "emotional arousal", "rationality", "emotions", "source", "rational", "thinking", "violent force", "cognitive constraints", "due"]], "textrank": [["most part", "long tradition", "cognitive constraints", "additional source", "bruce kaufman"], ["most part", "long tradition", "cognitive constraints", "additional source", "bruce kaufman", "emotional", "source", "kaufman"]], "positionrank": [["high emotional arousal", "bruce kaufman", "emotional arousal", "kaufman", "rationality"], ["high emotional arousal", "bruce kaufman", "emotional arousal", "kaufman", "rationality", "emotions", "additional source", "effects", "comment", "violent force"]], "multipartiterank": [["kaufman", "emotional arousal", "rationality", "source", "emotions"], ["kaufman", "emotional arousal", "rationality", "source", "emotions", "rational", "high", "comment", "cognitive constraints", "thinking"]]}, {"id": "403", "text": "High-voltage transistor scaling circuit techniques for high-density\n\tnegative-gate channel-erasing NOR flash memories\nIn order to scale high-voltage transistors for high-density negative-gate\n\tchannel-erasing NOR flash memories, two circuit techniques were\n\tdeveloped. A proposed level shifter with low operating voltage is\n\tcomposed of three parts, a latch holding the negative erasing voltage,\n\ttwo coupling capacitors connected with the latched nodes in the latch,\n\tand high-voltage drivers inverting the latch, resulting in reduction of\n\tthe maximum internal voltage by 0.5 V. A proposed high-voltage\n\tgenerator adds a path-gate logic to a conventional high-voltage\n\tgenerator to realize both low noise and low ripple voltage, resulting\n\tin a reduction of the maximum internal voltage by 0.5 V. As a result,\n\tthese circuit techniques along with high coupling-ratio cell technology\n\tcan scale down the high-voltage transistors by 15% and can realize\n\thigher density negative-gate channel-erase NOR flash memories in\n\tcomparison with the source-erase NOR flash memories\n", "keywords": "HV transistor scaling circuit techniques; high-density NOR flash memories;\n\tnegative-gate channel-erasing flash memories; level shifter; low\n\toperating voltage shifter; high-voltage drivers; high-voltage\n\tgenerator; path-gate logic; HV generator; low noise; low ripple\n\tvoltage; high coupling-ratio cell technology\n", "topicrank": [["high", "voltage transistor", "flash memories", "density", "gate channel"], ["high", "voltage transistor", "flash memories", "density", "gate channel", "circuit techniques", "latch", "gate", "generator", "negative"]], "textrank": [["internal voltage", "voltage", "density negative", "level shifter", "flash memories"], ["internal voltage", "voltage", "density negative", "level shifter", "flash memories", "circuit techniques", "cell", "gate", "high", "low"]], "positionrank": [["negative erasing voltage", "maximum internal voltage", "high coupling", "low ripple voltage", "low operating voltage"], ["negative erasing voltage", "maximum internal voltage", "high coupling", "low ripple voltage", "low operating voltage", "voltage transistors", "voltage transistor", "voltage drivers", "voltage", "gate channel"]], "multipartiterank": [["high", "voltage transistor", "circuit techniques", "density", "gate channel"], ["high", "voltage transistor", "circuit techniques", "density", "gate channel", "flash memories", "negative", "latch", "gate", "voltage transistors"]]}, {"id": "2099", "text": "Analyzing the potential of a firm: an operations research approach\nAn approach to analyzing the potential of a firm, which is understood as the\n\tfirm's ability to provide goods or (and) services to be supplied to a\n\tmarketplace under restrictions imposed by a business environment in\n\twhich the firm functions, is proposed. The approach is based on using\n\tlinear inequalities and, generally, mixed variables in modelling this\n\tability for a broad spectrum of industrial, transportation,\n\tagricultural, and other types of firms and allows one to formulate\n\tproblems of analyzing the potential of a firm as linear programming\n\tproblems or mixed programming problems with linear constraints. This\n\tapproach generalizes a previous one which was proposed for a more\n\tnarrow class of models, and allows one to effectively employ a widely\n\tavailable software for solving practical problems of the considered\n\tkind, especially for firms described by large scale models of\n\tmathematical programming\n", "keywords": "firm potential analysis; operations research; OR; linear inequalities;\n\tindustrial firms; transportation firms; agricultural firms; linear\n\tprogramming; mixed programming; large-scale models; mathematical\n\tprogramming\n", "topicrank": [["firm", "problems", "linear inequalities", "operations research approach", "potential"], ["firm", "problems", "linear inequalities", "operations research approach", "potential", "ability", "models", "firms", "industrial", "broad spectrum"]], "textrank": [["mixed programming problems", "linear programming", "programming", "broad spectrum", "firm functions"], ["mixed programming problems", "linear programming", "programming", "broad spectrum", "firm functions", "business environment", "linear", "scale", "research", "problems"]], "positionrank": [["operations research approach", "mixed programming problems", "firm functions", "linear programming", "firm"], ["operations research approach", "mixed programming problems", "firm functions", "linear programming", "firm", "approach", "potential", "linear constraints", "practical problems", "problems"]], "multipartiterank": [["firm", "operations research approach", "problems", "linear inequalities", "potential"], ["firm", "operations research approach", "problems", "linear inequalities", "potential", "approach", "ability", "firms", "models", "linear programming"]]}, {"id": "2184", "text": "The evolution of information systems: Their impact on organizations and\n\tstructures\nInformation systems and organization structures have been highly interconnected\n\twith each other. Over the years, information systems architectures as\n\twell as organization structures have evolved from centralized to more\n\tdecentralized forms. This research looks at the evolution of both\n\tinformation systems and organization structures. In the process, it\n\tlooks into the impact of computers on organizations, and examines the\n\tways organization structures have changed, in association with changes\n\tin information system architectures. It also suggests logical linkages\n\tbetween information system architectures and their \"fit\" with certain\n\torganization structures and strategies. It concludes with some\n\timplications for emerging and future organizational forms, and provides\n\ta quick review of the effect of the Internet on small businesses\n\ttraditionally using stand-alone computers\n", "keywords": "information systems evolution; information system architectures\n", "topicrank": [["information systems", "structures", "organizations", "impact", "computers"], ["information systems", "structures", "organizations", "impact", "computers", "evolution", "certain", "internet", "small businesses", "changes"]], "textrank": [["information system architectures", "information systems architectures", "organizational forms", "quick review", "logical linkages"], ["information system architectures", "information systems architectures", "organizational forms", "quick review", "logical linkages", "information systems", "organization", "forms"]], "positionrank": [["information systems architectures", "information systems", "ways organization structures", "information system architectures", "organization structures"], ["information systems architectures", "information systems", "ways organization structures", "information system architectures", "organization structures", "structures", "evolution", "organizations", "decentralized forms", "future organizational forms"]], "multipartiterank": [["information systems", "structures", "organization structures", "organizations", "impact"], ["information systems", "structures", "organization structures", "organizations", "impact", "evolution", "computers", "information system architectures", "research", "decentralized forms"]]}, {"id": "233", "text": "The Canadian National Site Licensing Project\nIn January 2000, a consortium of 64 universities in Canada signed a historic\n\tinter-institutional agreement that launched the Canadian National Site\n\tLicensing Project (CNSLP), a three-year pilot project aimed at\n\tbolstering the research and innovation capacity of the country's\n\tuniversities. CNSLP tests the feasibility of licensing, on a national\n\tscale, electronic versions of scholarly publications; in its initial\n\tphases the project is focused on full-text electronic journals and\n\tresearch databases in science, engineering, health and environmental\n\tdisciplines. This article provides an overview of the CNSLP initiative,\n\tsummarizes organizational and licensing accomplishments to date, and\n\toffers preliminary observations on challenges and opportunities for\n\tsubsequent phases of the project\n", "keywords": "Canadian National Site Licensing Project; inter-institutional agreement;\n\tresearch and innovation; CNSLP; academic libraries; information\n\tresources; electronic scholarly publications; full-text electronic\n\tjournals; research databases\n", "topicrank": [["cnslp", "canadian national site licensing project", "year pilot project", "research", "licensing project"], ["cnslp", "canadian national site licensing project", "year pilot project", "research", "licensing project", "universities", "health", "engineering", "environmental", "science"]], "textrank": [["national site licensing project", "- institutional", "pilot project", "national site", "licensing project"], ["national site licensing project", "- institutional", "pilot project", "national site", "licensing project", "cnslp initiative", "research databases", "scholarly publications", "innovation capacity", "electronic"]], "positionrank": [["canadian national site", "licensing project", "year pilot project", "project", "licensing"], ["canadian national site", "licensing project", "year pilot project", "project", "licensing", "cnslp initiative", "cnslp", "electronic versions", "electronic journals", "universities"]], "multipartiterank": [["canadian national site licensing project", "cnslp", "universities", "licensing project", "year pilot project"], ["canadian national site licensing project", "cnslp", "universities", "licensing project", "year pilot project", "research", "january", "innovation capacity", "consortium", "canada"]]}, {"id": "276", "text": "Assessment of the macrocyclic effect for the complexation of crown-ethers with\n\talkali cations using the substructural molecular fragments method\nThe Substructural Molecular Fragments method (Solov'ev, V. P.; Varnek, A. A.;\n\tWipff, G. J. Chem. Inf. Comput. Sci. 2000, 40, 847-858) was applied to\n\tassess stability constants (logK) of the complexes of crown-ethers,\n\tpolyethers, and glymes with Na/sup +/, K/sup +/, and Cs/sup +/ in\n\tmethanol. One hundred forty-seven computational models including\n\tdifferent fragment sets coupled with linear or nonlinear fitting\n\tequations were applied for the data sets containing 69 (Na/sup +/), 123\n\t(K/sup +/), and 31 (Cs/sup +/) compounds. To account for the\n\t\"macrocyclic effect\" for crown-ethers, an additional \"cyclicity\"\n\tdescriptor was used. \"Predicted\" stability constants both for\n\tmacrocyclic compounds and for their open-chain analogues are in good\n\tagreement with the experimental data reported earlier and with those\n\tstudied experimentally in this work. The macrocyclic effect as a\n\tfunction of cation and ligand is quantitatively estimated for all\n\tstudied crown-ethers\n", "keywords": "substructural molecular fragments method; stability constants; complexation;\n\tcrown-ethers; alkali cations; macrocyclic effect; computational models;\n\tdifferent fragment sets; nonlinear fitting equations; linear fitting\n\tequations; cyclicity descriptor; open-chain analogues; data mining;\n\tstructure-property tool; molecular graph decomposition; quantitative\n\tstructure-properties relationship; augmented atom; TRAIL program;\n\tstatistical parameters; thermodynamic parameters\n", "topicrank": [["crown", "ethers", "sup", "macrocyclic effect", "stability constants"], ["crown", "ethers", "sup", "macrocyclic effect", "stability constants", "data sets", "compounds", "substructural molecular fragments method", "nonlinear fitting", "chain analogues"]], "textrank": [["molecular fragments", "data sets", "fragment sets", "nonlinear fitting", "computational models"], ["molecular fragments", "data sets", "fragment sets", "nonlinear fitting", "computational models", "stability constants", "sci .", "v. p.", "alkali cations", "j."]], "positionrank": [["macrocyclic effect", "macrocyclic compounds", "crown", "assessment", "ethers"], ["macrocyclic effect", "macrocyclic compounds", "crown", "assessment", "ethers", "a. a.", "alkali cations", "complexation", "stability constants", "g. j. chem"]], "multipartiterank": [["crown", "sup", "ethers", "macrocyclic effect", "stability constants"], ["crown", "sup", "ethers", "macrocyclic effect", "stability constants", "data sets", "compounds", "nonlinear fitting", "substructural molecular fragments method", "linear"]]}, {"id": "25", "text": "Identification of evolving fuzzy rule-based models\nAn approach to identification of evolving fuzzy rule-based (eR) models is\n\tproposed. eR models implement a method for the noniterative update of\n\tboth the rule-base structure and parameters by incremental unsupervised\n\tlearning. The rule-base evolves by adding more informative rules than\n\tthose that previously formed the model. In addition, existing rules can\n\tbe replaced with new rules based on ranking using the informative\n\tpotential of the data. In this way, the rule-base structure is\n\tinherited and updated when new informative data become available,\n\trather than being completely retrained. The adaptive nature of these\n\tevolving rule-based models, in combination with the highly transparent\n\tand compact form of fuzzy rules, makes them a promising candidate for\n\tmodeling and control of complex processes, competitive to neural\n\tnetworks. The approach has been tested on a benchmark problem and on an\n\tair-conditioning component modeling application using data from an\n\tinstallation serving a real building. The results illustrate the\n\tviability and efficiency of the approach\n", "keywords": "evolving fuzzy rule-based models; identification; noniterative update;\n\trule-base structure; incremental unsupervised learning; ranking;\n\tinformative potential; fuzzy rules; complex processes; air-conditioning\n\tcomponent modeling; adaptive nonlinear control; fault detection; fault\n\tdiagnostics; performance analysis; forecasting; knowledge extraction;\n\trobotics; behavior modeling\n", "topicrank": [["fuzzy rule", "base structure", "models", "data", "approach"], ["fuzzy rule", "base structure", "models", "data", "approach", "rules", "informative rules", "complex processes", "identification", "competitive"]], "textrank": [["informative rules", "component modeling", "fuzzy rules", "compact form", "adaptive nature"], ["informative rules", "component modeling", "fuzzy rules", "compact form", "adaptive nature", "incremental unsupervised", "noniterative update", "er models", "base", "informative"]], "positionrank": [["fuzzy rule", "er models", "rule", "fuzzy rules", "identification"], ["fuzzy rule", "er models", "rule", "fuzzy rules", "identification", "models", "base structure", "new informative data", "informative rules", "base evolves"]], "multipartiterank": [["fuzzy rule", "models", "rule", "approach", "base structure"], ["fuzzy rule", "models", "rule", "approach", "base structure", "data", "identification", "rules", "informative rules", "complex processes"]]}, {"id": "2179", "text": "Guidelines, the Internet, and personal health: insights from the Canadian\n\tHEALNet experience\nThe objectives are to summarize the insights gained in collaborative research\n\tin a Canadian Network of Centres of Excellence, devoted to the\n\tpromotion of evidence-based practice, and to relate this experience to\n\tInternet support of health promotion and consumer health informatics. A\n\tsubjective review of insights is undertaken. Work directed the\n\tdevelopment of systems incorporating guidelines, care maps, etc., for\n\tuse by professionals met with limited acceptance. Evidence-based tools\n\tfor health care consumers are a desirable complement but require\n\tradically different content and delivery modes. In addition to\n\tevidence-based material offered by professionals, a wide array of\n\tInternet-based products and services provided by consumers for\n\tconsumers emerged and proved a beneficial complement. The\n\tconsumer-driven products and services provided via the Internet are a\n\tpotentially important and beneficial complement of traditional health\n\tservices. They affect the health consumer-provider roles and require\n\tchanges in healthcare practices\n", "keywords": "collaborative research; Canadian Network of Centres of Excellence;\n\tevidence-based practice; Internet support; health promotion; consumer\n\thealth informatics; personal health; health consumer-provider roles\n", "topicrank": [["internet", "evidence", "services", "consumer health informatics", "desirable complement"], ["internet", "evidence", "services", "consumer health informatics", "desirable complement", "insights", "health care consumers", "professionals", "promotion", "products"]], "textrank": [["health care", "health", "different content", "limited acceptance", "subjective review"], ["health care", "health", "different content", "limited acceptance", "subjective review", "internet support", "canadian network", "collaborative research", "healnet experience", "care"]], "positionrank": [["consumer health informatics", "health care consumers", "health consumer", "personal health", "health promotion"], ["consumer health informatics", "health care consumers", "health consumer", "personal health", "health promotion", "traditional health", "guidelines", "internet support", "insights", "internet"]], "multipartiterank": [["internet", "insights", "evidence", "health care consumers", "desirable complement"], ["internet", "insights", "evidence", "health care consumers", "desirable complement", "canadian", "consumer health informatics", "healnet experience", "services", "promotion"]]}, {"id": "2144", "text": "The perils of privacy\nThe recent string of failures among dotcom companies has heightened fears of\n\tprivacy abuse. What should happen to the names and addresses on a\n\tcustomer list if these details were obtained under a privacy policy\n\twhich specified no disclosure to any third party? Should the personal\n\tdata in the list be deemed to be an asset of a failing company which\n\tcan be transferred to any future (third party) purchaser for its\n\tpurposes? Or should the privacy policy take precedence over the\n\tcommercial concerns of the purchaser?\n", "keywords": "privacy abuse; customer list; privacy policy; disclosure\n", "topicrank": [["privacy", "third party", "customer list", "purchaser", "failures"], ["privacy", "third party", "customer list", "purchaser", "failures", "dotcom companies", "recent string", "data", "personal", "addresses"]], "textrank": [["third party", "customer list", "dotcom companies", "recent string", "privacy"], ["third party", "customer list", "dotcom companies", "recent string", "privacy", "list"]], "positionrank": [["privacy policy", "privacy abuse", "privacy", "recent string", "dotcom companies"], ["privacy policy", "privacy abuse", "privacy", "recent string", "dotcom companies", "perils", "failures", "third party", "customer list", "fears"]], "multipartiterank": [["privacy", "recent string", "perils", "customer list", "third party"], ["privacy", "recent string", "perils", "customer list", "third party", "failures", "dotcom companies", "privacy policy", "purchaser", "fears"]]}, {"id": "2101", "text": "All-optical XOR gate using semiconductor optical amplifiers without additional\n\tinput beam\nThe novel design of an all-optical XOR gate by using cross-gain modulation of\n\tsemiconductor optical amplifiers has been suggested and demonstrated\n\tsuccessfully at 10 Gb/s. Boolean AB and AB of the two input signals A\n\tand B have been obtained and combined to achieve the all-optical XOR\n\tgate. No additional input beam such as a clock signal or continuous\n\twave light is used in this new design, which is required in other\n\tall-optical XOR gates\n", "keywords": "semiconductor optical amplifiers; all-optical-XOR gate; design; cross-gain\n\tmodulation; Boolean logic; 10 Gbit/s\n", "topicrank": [["optical xor gate", "semiconductor optical amplifiers", "novel design", "additional", "continuous"], ["optical xor gate", "semiconductor optical amplifiers", "novel design", "additional", "continuous", "input beam", "wave light", "clock signal", "gate", "boolean ab"]], "textrank": [["- optical xor", "input signals", "input beam", "- gain", "optical"], ["- optical xor", "input signals", "input beam", "- gain", "optical", "design", "boolean"]], "positionrank": [["optical xor gate", "optical xor gates", "optical xor", "optical amplifiers", "additional input beam"], ["optical xor gate", "optical xor gates", "optical xor", "optical amplifiers", "additional input beam", "input beam", "input signals a", "gate", "novel design", "semiconductor"]], "multipartiterank": [["optical xor gate", "semiconductor optical amplifiers", "additional", "input beam", "novel design"], ["optical xor gate", "semiconductor optical amplifiers", "additional", "input beam", "novel design", "continuous", "wave light", "clock signal", "gate", "optical xor"]]}, {"id": "1970", "text": "eMarketing: restaurant Web sites that click\nA number of global companies have adopted electronic commerce as a means of\n\treducing transaction related expenditures, connecting with current and\n\tpotential customers, and enhancing revenues and profitability. If a\n\trestaurant is to have an Internet presence, what aspects of the\n\tbusiness should be highlighted? Food service companies that have\n\tsuccessfully ventured onto the web have employed assorted web-based\n\ttechnologies to create a powerful marketing tool of unparalleled\n\tstrength. Historically, it has been difficult to create a set of\n\tcriteria against which to evaluate website effectiveness. As\n\tpractitioners consider additional resources for website development,\n\tthe effectiveness of e-marketing investment becomes increasingly\n\timportant. Care must be exercised to ensure that the quality of the\n\tsite adheres to high standards and incorporates evolving technology, as\n\tappropriate. Developing a coherent website strategy, including an\n\teffective website design, are proving critical to an effective web\n\tpresence\n", "keywords": "e-marketing; restaurant Web sites; electronic commerce; Internet presence; food\n\tservice companies; revenues; profitability\n", "topicrank": [["web", "website effectiveness", "internet presence", "restaurant web sites", "additional resources"], ["web", "website effectiveness", "internet presence", "restaurant web sites", "additional resources", "unparalleled", "powerful marketing tool", "website development", "practitioners", "expenditures"]], "textrank": [["effective website", "website", "effective web", "service companies", "high standards"], ["effective website", "website", "effective web", "service companies", "high standards", "additional resources", "internet presence", "potential customers", "electronic commerce", "global companies"]], "positionrank": [["restaurant web sites", "global companies", "effective web", "food service companies", "web"], ["restaurant web sites", "global companies", "effective web", "food service companies", "web", "effective website design", "restaurant", "electronic commerce", "website effectiveness", "coherent website strategy"]], "multipartiterank": [["web", "restaurant web sites", "website effectiveness", "internet presence", "global companies"], ["web", "restaurant web sites", "website effectiveness", "internet presence", "global companies", "additional resources", "unparalleled", "powerful marketing tool", "number", "transaction"]]}, {"id": "1935", "text": "Identification of states of complex systems with estimation of admissible\n\tmeasurement errors on the basis of fuzzy information\nThe problem of identification of states of complex systems on the basis of\n\tfuzzy values of informative attributes is considered. Some estimates of\n\ta maximally admissible degree of measurement error are obtained that\n\tmake it possible, using the apparatus of fuzzy set theory, to correctly\n\tidentify the current state of a system\n", "keywords": "complex systems states identification; admissible measurement errors; fuzzy\n\tinformation; informative attributes; measurement error; fuzzy set\n\ttheory\n", "topicrank": [["complex systems", "states", "fuzzy information", "admissible", "basis"], ["complex systems", "states", "fuzzy information", "admissible", "basis", "identification", "measurement errors", "estimation", "problem", "informative attributes"]], "textrank": [["fuzzy set", "informative attributes", "complex systems", "fuzzy", "measurement"], ["fuzzy set", "informative attributes", "complex systems", "fuzzy", "measurement", "admissible"]], "positionrank": [["complex systems", "fuzzy information", "fuzzy set theory", "identification", "fuzzy values"], ["complex systems", "fuzzy information", "fuzzy set theory", "identification", "fuzzy values", "measurement errors", "states", "admissible degree", "measurement error", "basis"]], "multipartiterank": [["complex systems", "basis", "states", "admissible", "fuzzy information"], ["complex systems", "basis", "states", "admissible", "fuzzy information", "measurement errors", "identification", "estimation", "problem", "fuzzy values"]]}, {"id": "2200", "text": "Labscape: a smart environment for the cell biology laboratory\nLabscape is a smart environment that we designed to improve the experience of\n\tpeople who work in a cell biology laboratory. Our goal in creating it\n\twas to simplify, laboratory work by making information available where\n\tit is needed and by collecting and organizing data where and when it is\n\tcreated into a formal representation that others can understand and\n\tprocess. By helping biologists produce a more complete record of their\n\twork with less effort, Labscape is designed to foster improved\n\tcollaboration in conjunction with increased individual efficiency and\n\tsatisfaction. A user-driven system, although technologically\n\tconservative, embraces a central goal of ubiquitous computing: to\n\tenhance the ability to perform domain tasks through fluid interaction\n\twith computational resources. Smart environments could soon replace the\n\tpen and paper commonly used in the laboratory setting\n", "keywords": "cell biology; Labscape; laboratory work; ubiquitous computing; smart\n\tenvironment; experimental technologies; biochemical procedure\n", "topicrank": [["smart environment", "labscape", "laboratory work", "goal", "cell biology laboratory"], ["smart environment", "labscape", "laboratory work", "goal", "cell biology laboratory", "less effort", "conjunction", "individual efficiency", "domain tasks", "fluid interaction"]], "textrank": [["biology laboratory", "individual efficiency", "less effort", "complete record", "formal representation"], ["biology laboratory", "individual efficiency", "less effort", "complete record", "formal representation", "information available", "laboratory", "smart", "goal"]], "positionrank": [["cell biology laboratory", "smart environment", "smart environments", "laboratory work", "laboratory setting"], ["cell biology laboratory", "smart environment", "smart environments", "laboratory work", "laboratory setting", "labscape", "central goal", "fluid interaction", "computational resources", "complete record"]], "multipartiterank": [["smart environment", "cell biology laboratory", "labscape", "laboratory work", "goal"], ["smart environment", "cell biology laboratory", "labscape", "laboratory work", "goal", "less effort", "information available", "people", "conjunction", "experience"]]}, {"id": "356", "text": "Operational phase-space probability distribution in quantum communication\n\ttheory\nOperational phase-space probability distributions are useful tools for\n\tdescribing quantum mechanical systems, including quantum communication\n\tand quantum information processing systems. It is shown that quantum\n\tcommunication channels with Gaussian noise and quantum teleportation of\n\tcontinuous variables are described by operational phase-space\n\tprobability distributions. The relation of operational phase-space\n\tprobability distribution to the extended phase-space formalism proposed\n\tby Chountasis and Vourdas (1998) is discussed\n", "keywords": "operational phase-space probability distribution; quantum communication theory;\n\tquantum mechanical systems; quantum information processing systems;\n\tGaussian noise; quantum teleportation; continuous variables; extended\n\tphase-space formalism\n", "topicrank": [["operational phase", "space probability distribution", "quantum communication", "space", "quantum mechanical systems"], ["operational phase", "space probability distribution", "quantum communication", "space", "quantum mechanical systems", "gaussian noise", "communication channels", "relation", "theory", "continuous variables"]], "textrank": [["space probability", "quantum communication", "useful tools", "quantum", "probability"], ["space probability", "quantum communication", "useful tools", "quantum", "probability", "phase", "space", "communication", "gaussian"]], "positionrank": [["space probability distribution", "space probability distributions", "operational phase", "quantum communication", "probability distribution"], ["space probability distribution", "space probability distributions", "operational phase", "quantum communication", "probability distribution", "probability distributions", "extended phase", "space formalism", "quantum teleportation", "space"]], "multipartiterank": [["operational phase", "space probability distribution", "quantum communication", "space", "quantum mechanical systems"], ["operational phase", "space probability distribution", "quantum communication", "space", "quantum mechanical systems", "theory", "useful tools", "space probability distributions", "communication channels", "gaussian noise"]]}, {"id": "313", "text": "Information architecture: notes toward a new curriculum\nThere are signs that information architecture is coalescing into a field of\n\tprofessional practice. However, if it is to become a profession, it\n\tmust develop a means of educating new information architects. Lessons\n\tfrom other fields suggest that professional education typically evolves\n\talong a predictable path, from apprenticeships to trade schools to\n\tcollege- and university-level education. Information architecture\n\teducation may develop more quickly to meet the growing demands of the\n\tinformation society. Several pedagogical approaches employed in other\n\tfields may be adopted for information architecture education, as long\n\tas the resulting curricula provide an interdisciplinary approach and\n\tbalance instruction in technical and design skills with consideration\n\tof theoretical concepts. Key content areas are information\n\torganization, graphic. design, computer science, user and usability\n\tstudies, and communication. Certain logistics must be worked out,\n\tincluding where information architecture studies should be housed and\n\twhat kinds of degrees should be offered and at what levels. The\n\tsuccessful information architecture curriculum will be flexible and\n\tadaptable in order to meet the changing needs of students and the\n\tmarketplace\n", "keywords": "professional practice; information organization; graphic design; computer\n\tscience; usability studies; information architects; professional\n\teducation; pedagogical approaches; information architecture education\n", "topicrank": [["information architecture", "professional education", "design skills", "computer science", "graphic"], ["information architecture", "professional education", "design skills", "computer science", "graphic", "key content areas", "organization", "user", "usability", "technical"]], "textrank": [["information architecture education", "information architecture", "professional education", "information", "computer science"], ["information architecture education", "information architecture", "professional education", "information", "computer science", "theoretical concepts", "design skills", "balance instruction", "interdisciplinary approach", "predictable path"]], "positionrank": [["information architecture education", "information architecture studies", "information architecture", "new information architects", "information society"], ["information architecture education", "information architecture studies", "information architecture", "new information architects", "information society", "information", "new curriculum", "professional education", "other fields", "level education"]], "multipartiterank": [["information architecture", "professional education", "design skills", "signs", "notes"], ["information architecture", "professional education", "design skills", "signs", "notes", "level education", "university", "new curriculum", "college-", "education"]]}, {"id": "2059", "text": "Acquiring materials in the history of science, technology, and medicine\nThis article provides detailed advice on acquiring new, out-of-print, and rare\n\tmaterials in the history of science, technology, and medicine for the\n\tbeginner in these fields. The focus is on the policy formation, basic\n\treference tools, and methods of collection development and acquisitions\n\tthat are the necessary basis for success in this endeavor\n", "keywords": "out-of-print books; special collections; library acquisitions; science;\n\ttechnology; medicine; rare materials; policy formation; basic reference\n\ttools; collection development\n", "topicrank": [["science", "technology", "history", "medicine", "materials"], ["science", "technology", "history", "medicine", "materials", "basic", "collection development", "reference tools", "policy formation", "methods"]], "textrank": [["collection development", "reference tools", "policy formation", "detailed advice"], ["collection development", "reference tools", "policy formation", "detailed advice"]], "positionrank": [["technology", "materials", "science", "history", "medicine"], ["technology", "materials", "science", "history", "medicine", "detailed advice", "article", "print", "policy formation", "reference tools"]], "multipartiterank": [["science", "technology", "history", "medicine", "materials"], ["science", "technology", "history", "medicine", "materials", "basic", "collection development", "reference tools", "policy formation", "methods"]]}, {"id": "1954", "text": "Estimating long-range dependence: finite sample properties and confidence\n\tintervals\nA major issue in financial economics is the behavior of asset returns over long\n\thorizons. Various estimators of long-range dependence have been\n\tproposed. Even though some have known asymptotic properties, it is\n\timportant to test their accuracy by using simulated series of different\n\tlengths. We test R/S analysis, detrended fluctuation analysis and\n\tperiodogram regression methods on samples drawn from Gaussian white\n\tnoise. The DFA statistics turns out to be the unanimous winner.\n\tUnfortunately, no asymptotic distribution theory has been derived for\n\tthis statistics so far. We were able, however, to construct empirical\n\t(i.e. approximate) confidence intervals for all three methods. The\n\tobtained values differ largely from heuristic values proposed by some\n\tauthors for the R/S statistics and are very close to asymptotic values\n\tfor the periodogram regression method\n", "keywords": "long-range dependence; finite sample properties; confidence intervals;\n\tfinancial economics; asset returns; long horizons; asymptotic\n\tproperties; detrended fluctuation analysis; periodogram regression\n\tmethods; Gaussian white noise; heuristic values\n", "topicrank": [["long", "confidence", "range dependence", "values", "periodogram regression methods"], ["long", "confidence", "range dependence", "values", "periodogram regression methods", "dfa statistics", "various estimators", "horizons", "asset", "different"]], "textrank": [["asymptotic values", "asymptotic distribution", "asymptotic properties", "s statistics", "s analysis"], ["asymptotic values", "asymptotic distribution", "asymptotic properties", "s statistics", "s analysis", "sample properties", "confidence intervals", "major issue", "range dependence", "regression"]], "positionrank": [["range dependence", "finite sample properties", "confidence intervals", "major issue", "asymptotic properties"], ["range dependence", "finite sample properties", "confidence intervals", "major issue", "asymptotic properties", "various estimators", "financial economics", "confidence", "intervals", "periodogram regression methods"]], "multipartiterank": [["long", "confidence", "range dependence", "periodogram regression methods", "values"], ["long", "confidence", "range dependence", "periodogram regression methods", "values", "dfa statistics", "finite sample properties", "intervals", "various estimators", "horizons"]]}, {"id": "193", "text": "Twenty years of the literature on acquiring out-of-print materials\nThis article reviews the last two-and-a-half decades of literature on acquiring\n\tout-of-print materials to assess recurring issues and identify changing\n\tpractices. The out-of-print literature is uniform in its assertion that\n\tlibraries need to acquire o.p. materials to replace worn or damaged\n\tcopies, to replace missing copies, to duplicate copies of heavily used\n\tmaterials, to fill gaps in collections, to strengthen weak collections,\n\tto continue to develop strong collections, and to provide materials for\n\tnew courses, new programs, and even entire new libraries\n", "keywords": "out-of-print materials; recurring issues; changing practices; out-of-print\n\tbooks; library materials; acquisition\n", "topicrank": [["print materials", "literature", "copies", "collections", "libraries"], ["print materials", "literature", "copies", "collections", "libraries", "new courses", "uniform", "assertion", "gaps", "worn"]], "textrank": [["print materials", "new", "weak collections", "half decades", "collections"], ["print materials", "new", "weak collections", "half decades", "collections", "print", ".", "materials"]], "positionrank": [["print literature", "print materials", "literature", "entire new libraries", "materials"], ["print literature", "print materials", "literature", "entire new libraries", "materials", "new courses", "new programs", "years", "libraries", "half decades"]], "multipartiterank": [["print materials", "literature", "materials", "copies", "collections"], ["print materials", "literature", "materials", "copies", "collections", "half decades", "article", "libraries", "last", "uniform"]]}, {"id": "2160", "text": "Challenges and trends in discrete manufacturing\nOver 50 years ago, the 100,000 workers at Ford's Rouge automobile factory\n\tturned out 1200 cars per day. Nowadays, Ford's plant on that same site\n\tstill produces 800 cars each day but with just 3000 workers. Similar\n\tstories abound in the manufacturing industries; technology revolution\n\tand evolution; a shift from vertical integration, better business and\n\tproduction practices and improved industrial relations-all have changed\n\tmanufacturing beyond recognition. So what are the current challenges\n\tand trends in manufacturing? Certainly, the relentless advance of\n\ttechnology will continue, as will user pressure for more customized\n\tdesign or improved environmental friendliness. Some trends are already\n\twith us and more, as yet indiscernible, will come. But one major,\n\tfundamental shift now resounding throughout industry is the way in\n\twhich information involving every single aspect of the manufacturing\n\tprocess is being integrated into one seamless system\n", "keywords": "discrete manufacturing; challenges; automobile factory; technology revolution;\n\ttechnology evolution; business practices; production practices;\n\tindustrial relations; trends; seamless manufacturing process\n", "topicrank": [["discrete manufacturing", "trends", "shift", "technology revolution", "workers"], ["discrete manufacturing", "trends", "shift", "technology revolution", "workers", "ford", "day", "cars", "challenges", "vertical integration"]], "textrank": [["industrial relations", "production practices", "better business", "vertical integration", "technology revolution"], ["industrial relations", "production practices", "better business", "vertical integration", "technology revolution", "same site", "automobile", "manufacturing", "technology", "shift"]], "positionrank": [["discrete manufacturing", "manufacturing industries", "current challenges", "manufacturing", "challenges"], ["discrete manufacturing", "manufacturing industries", "current challenges", "manufacturing", "challenges", "trends", "rouge automobile factory", "technology revolution", "years", "workers"]], "multipartiterank": [["discrete manufacturing", "trends", "challenges", "ford", "workers"], ["discrete manufacturing", "trends", "challenges", "ford", "workers", "day", "manufacturing", "cars", "technology revolution", "shift"]]}, {"id": "2125", "text": "Stochastic systems with a random jump in phase trajectory: stability of their\n\tmotions\nThe probabilistic stability of the perturbed motion of a system with parameters\n\tunder the action of a general Markov process is studied. The phase\n\tvector is assumed to experience random jumps when the structure the\n\tsystem suffers random jumps. Such a situation is encountered, for\n\texample, in the motion of a solid with random jumps in its mass. The\n\tmean-square stability of random-structure linear systems and stability.\n\tof nonlinear systems in the first approximation are studied. The\n\tapplied approach is helpful in studying the asymptotic probabilistic\n\tstability and mean-square exponential stability of stochastic systems\n\tthrough the stability of the respective deterministic systems\n", "keywords": "stochastic systems; random jump; phase trajectory; general Markov process;\n\tasymptotic probabilistic stability; mean-square exponential stability\n", "topicrank": [["stability", "random jump", "stochastic systems", "system", "structure"], ["stability", "random jump", "stochastic systems", "system", "structure", "perturbed motion", "phase", "mean", "asymptotic probabilistic", "solid"]], "textrank": [["- square stability", "deterministic systems", "linear systems", "random -", "- square"], ["- square stability", "deterministic systems", "linear systems", "random -", "- square", "probabilistic stability", "systems", "perturbed motion", "markov", "random"]], "positionrank": [["square exponential stability", "stochastic systems", "probabilistic stability", "respective deterministic systems", "stability"], ["square exponential stability", "stochastic systems", "probabilistic stability", "respective deterministic systems", "stability", "linear systems", "nonlinear systems", "random jumps", "random jump", "general markov process"]], "multipartiterank": [["stability", "random jump", "stochastic systems", "phase", "random jumps"], ["stability", "random jump", "stochastic systems", "phase", "random jumps", "system", "structure", "perturbed motion", "mean", "motions"]]}, {"id": "292", "text": "Novel active noise-reducing headset using earshell vibration control\nActive noise-reducing (ANR) headsets are available commercially in applications\n\tvarying from aviation communication to consumer audio. Current ANR\n\tsystems use passive attenuation at high frequencies and\n\tloudspeaker-based active noise control at low frequencies to achieve\n\tbroadband noise reduction. This paper presents a novel ANR headset in\n\twhich the external noise transmitted to the user's ear via earshell\n\tvibration is reduced by controlling the vibration of the earshell using\n\tforce actuators acting against an inertial mass or the earshell\n\theadband. Model-based theoretical analysis using velocity feedback\n\tcontrol showed that current piezoelectric actuators provide sufficient\n\tforce but require lower stiffness for improved low-frequency\n\tperformance. Control simulations based on experimental data from a\n\tlaboratory headset showed that good performance can potentially be\n\tachieved in practice by a robust feedback controller, while a\n\tsingle-frequency real-time control experiment verified that noise\n\treduction can be achieved using earshell vibration control\n", "keywords": "active noise-reducing headset; earshell vibration control; aviation\n\tcommunication; consumer audio; passive attenuation; broadband noise\n\treduction; external noise transmission; force actuators; inertial mass;\n\tvelocity feedback control; piezoelectric actuators; stiffness; robust\n\tfeedback controller; single-frequency real-time control\n", "topicrank": [["earshell vibration control", "novel active noise", "control", "anr", "frequency"], ["earshell vibration control", "novel active noise", "control", "anr", "frequency", "force actuators", "high frequencies", "performance", "vibration", "broadband noise reduction"]], "textrank": [["noise control", "vibration control", "current piezoelectric actuators", "low frequencies", "anr headset"], ["noise control", "vibration control", "current piezoelectric actuators", "low frequencies", "anr headset", "control", "current anr", "noise", "inertial mass", "passive attenuation"]], "positionrank": [["active noise control", "novel active noise", "earshell vibration control", "active noise", "novel anr headset"], ["active noise control", "novel active noise", "earshell vibration control", "active noise", "novel anr headset", "broadband noise reduction", "external noise", "noise", "time control experiment", "control simulations"]], "multipartiterank": [["novel active noise", "earshell vibration control", "headset", "anr", "control"], ["novel active noise", "earshell vibration control", "headset", "anr", "control", "earshell", "high frequencies", "headsets", "force actuators", "frequency"]]}, {"id": "2038", "text": "Choice from a three-element set: some lessons of the 2000 presidential campaign\n\tin the United States\nWe consider the behavior of four choice rules - plurality voting, approval\n\tvoting, Borda count, and self-consistent choice - when applied to\n\tchoose the best option from a three-element set. It is assumed that the\n\ttwo main options are preferred by a large majority of the voters, while\n\tthe third option gets a very small number of votes and influences the\n\telection outcome only when the two main options receive a close number\n\tof votes. When used to rate the main options, Borda count and\n\tself-consistent choice contain terms that allow both for the \"strength\n\tof preferences\" of the voters and the rating of the main candidates by\n\tvoters who vote for the third option. In this way, it becomes possible\n\tto determine more reliably the winner when plurality voting or approval\n\tvoting produce close results\n", "keywords": "three-element set; 2000 presidential campaign; plurality voting; approval\n\tvoting; Borda count; self-consistent choice\n", "topicrank": [["plurality voting", "choice", "main options", "voters", "best option"], ["plurality voting", "choice", "main options", "voters", "best option", "approval", "borda count", "self", "votes", "close number"]], "textrank": [["close number", "plurality voting", "united states", "presidential campaign", "element set"], ["close number", "plurality voting", "united states", "presidential campaign", "element set", "main", "option", "choice", "close", "number"]], "positionrank": [["consistent choice", "choice rules", "choice", "plurality voting", "element set"], ["consistent choice", "choice rules", "choice", "plurality voting", "element set", "borda count", "main options", "voting", "presidential campaign", "third option"]], "multipartiterank": [["choice", "plurality voting", "main options", "element set", "best option"], ["choice", "plurality voting", "main options", "element set", "best option", "approval", "voters", "borda count", "self", "voting"]]}, {"id": "2005", "text": "State-of-the-art in orthopaedic surgical navigation with a focus on medical\n\timage modalities\nThis paper presents a review of surgical navigation systems in orthopaedics and\n\tcategorizes these systems according to the image modalities that are\n\tused for the visualization of surgical action. Medical images used to\n\tbe an essential part of surgical education and documentation as well as\n\tdiagnosis and operation planning over many years. With the recent\n\tintroduction of navigation techniques in orthopaedic surgery, a new\n\tfield of application has been opened. Today surgical navigation systems\n\t- also known as image-guided surgery systems - are available for\n\tvarious applications in orthopaedic surgery. They visualize the\n\tposition and orientation of surgical instruments as graphical overlays\n\tonto a medical image of the operated anatomy on a computer monitor.\n\tPreoperative image data such as computed tomography scans or intra\n\toperatively generated images (for example, ultrasonic, endoscopic or\n\tfluoroscopic images) are suitable for this purpose. A new category of\n\tmedical images termed 'surgeon-defined anatomy' has been developed that\n\texclusively relies upon the usage of navigation technology. Points on\n\tthe anatomy are digitized interactively by the surgeon and are used to\n\tbuild up an abstract geometrical model of the bony structures to be\n\toperated on. This technique may be used when no other image data is\n\tavailable or appropriate for a given application\n", "keywords": "orthopaedic surgical navigation; medical image modalities; surgical action\n\tvisualization; medical image processing; surgical education;\n\timage-guided surgery systems; surgical instruments; graphical overlays;\n\tcomputer monitor; computed tomography scans; intra operatively\n\tgenerated images; surgeon-defined anatomy; abstract geometrical model;\n\tbony structures; image registration\n", "topicrank": [["medical", "surgical action", "orthopaedic surgical navigation", "image modalities", "operated anatomy"], ["medical", "surgical action", "orthopaedic surgical navigation", "image modalities", "operated anatomy", "navigation techniques", "orthopaedic surgery", "new", "images", "systems"]], "textrank": [["surgical navigation", "image data", "medical image", "surgical", "image"], ["surgical navigation", "image data", "medical image", "surgical", "image", "medical images", "computer monitor", "operated anatomy", "graphical overlays", "various applications"]], "positionrank": [["orthopaedic surgical navigation", "surgical navigation systems", "medical image", "surgical instruments", "surgical education"], ["orthopaedic surgical navigation", "surgical navigation systems", "medical image", "surgical instruments", "surgical education", "surgical action", "orthopaedic surgery", "image modalities", "preoperative image data", "other image data"]], "multipartiterank": [["medical", "orthopaedic surgical navigation", "image modalities", "surgical action", "focus"], ["medical", "orthopaedic surgical navigation", "image modalities", "surgical action", "focus", "orthopaedic surgery", "systems", "medical images", "navigation techniques", "operated anatomy"]]}, {"id": "2040", "text": "Inverse problems for a mathematical model of ion exchange in a compressible ion\n\texchanger\nA mathematical model of ion exchange is considered, allowing for ion exchanger\n\tcompression in the process of ion exchange. Two inverse problems are\n\tinvestigated for this model, unique solvability is proved, and\n\tnumerical solution methods are proposed. The efficiency of the proposed\n\tmethods is demonstrated by a numerical experiment\n", "keywords": "inverse problems; mathematical model; ion exchange; compressible ion exchanger;\n\tion exchanger compression; unique solvability; numerical solution\n\tmethods\n", "topicrank": [["ion exchange", "mathematical model", "exchanger", "inverse problems", "numerical solution methods"], ["ion exchange", "mathematical model", "exchanger", "inverse problems", "numerical solution methods", "process", "compression", "unique solvability", "efficiency", "numerical experiment"]], "textrank": [["numerical solution", "inverse problems", "ion", "numerical"], ["numerical solution", "inverse problems", "ion", "numerical"]], "positionrank": [["ion exchange", "ion exchanger", "compressible ion", "inverse problems", "mathematical model"], ["ion exchange", "ion exchanger", "compressible ion", "inverse problems", "mathematical model", "model", "exchanger", "numerical solution methods", "unique solvability", "process"]], "multipartiterank": [["ion exchange", "mathematical model", "exchanger", "inverse problems", "process"], ["ion exchange", "mathematical model", "exchanger", "inverse problems", "process", "compression", "numerical solution methods", "compressible ion", "ion exchanger", "unique solvability"]]}, {"id": "1994", "text": "A comparison of computational color constancy Algorithms. II. Experiments with\n\timage data\nFor pt.I see ibid., vol. 11, no.9, p.972-84 (2002). We test a number of the\n\tleading computational color constancy algorithms using a comprehensive\n\tset of images. These were of 33 different scenes under 11 different\n\tsources representative of common illumination conditions. The\n\talgorithms studied include two gray world methods, a version of the\n\tRetinex method, several variants of Forsyth's (1990) gamut-mapping\n\tmethod, Cardei et al.'s (2000) neural net method, and Finlayson et\n\tal.'s color by correlation method (Finlayson et al. 1997, 2001; Hubel\n\tand Finlayson 2000). We discuss a number of issues in applying color\n\tconstancy ideas to image data, and study in depth the effect of\n\tdifferent preprocessing strategies. We compare the performance of the\n\talgorithms on image data with their performance on synthesized data.\n\tAll data used for this study are available online at\n\thttp://www.cs.sfu.ca/~color/data, and implementations for most of the\n\talgorithms are also available (http://www.cs.sfu.ca/~color/code).\n\tExperiments with synthesized data (part one of this paper) suggested\n\tthat the methods which emphasize the use of the input data statistics,\n\tspecifically color by correlation and the neural net algorithm, are\n\tpotentially the most effective at estimating the chromaticity of the\n\tscene illuminant. Unfortunately, we were unable to realize comparable\n\tperformance on real images. Here exploiting pixel intensity proved to\n\tbe more beneficial than exploiting the details of image chromaticity\n\tstatistics, and the three-dimensional (3-D) gamut-mapping algorithms\n\tgave the best performance\n", "keywords": "computational color constancy algorithms; images; image data; illumination\n\tconditions; gray world methods; Retinex method; gamut-mapping method;\n\tneural net method; color by correlation method; preprocessing\n\tstrategies; synthesized data; input data statistics; chromaticity;\n\tscene illuminant; pixel intensity\n", "topicrank": [["image data", "algorithms", "performance", "color", "different scenes"], ["image data", "algorithms", "performance", "color", "different scenes", "finlayson et", "retinex method", "correlation method", "images", "gamut"]], "textrank": [["color constancy algorithms .", "color constancy algorithms", "real images .", "scene illuminant .", "net method"], ["color constancy algorithms .", "color constancy algorithms", "real images .", "scene illuminant .", "net method", "data .", "image data", "different preprocessing", "images .", "pixel intensity"]], "positionrank": [["image data", "mapping algorithms", "input data statistics", "algorithms", "color"], ["image data", "mapping algorithms", "input data statistics", "algorithms", "color", "constancy ideas", "al .", "neural net method", "data", "correlation method"]], "multipartiterank": [["image data", "algorithms", "color", "performance", "different scenes"], ["image data", "algorithms", "color", "performance", "different scenes", "finlayson et", "retinex method", "data", "images", "correlation method"]]}, {"id": "2118", "text": "Solutions for cooperative games\nA new concept of the characteristic function is defined. It matches cooperative\n\tgames far better than the classical characteristic function and is\n\tuseful in reducing the number of decisions that can be used as the\n\tunique solution of a game\n", "keywords": "cooperative games; characteristic function; decisions; unique solution;\n\ttransferrable utility\n", "topicrank": [["cooperative games", "characteristic function", "number", "games", "decisions"], ["cooperative games", "characteristic function", "number", "games", "decisions", "new concept", "useful", "solutions", "unique solution", "game"]], "textrank": [["cooperative games", "characteristic", "games", "cooperative", "new"], ["cooperative games", "characteristic", "games", "cooperative", "new"]], "positionrank": [["classical characteristic function", "cooperative games", "characteristic function", "new concept", "games"], ["classical characteristic function", "cooperative games", "characteristic function", "new concept", "games", "solutions", "number", "unique solution", "decisions", "game"]], "multipartiterank": [["cooperative games", "characteristic function", "new concept", "solutions", "games"], ["cooperative games", "characteristic function", "new concept", "solutions", "games", "number", "cooperative", "decisions", "useful", "classical characteristic function"]]}, {"id": "217", "text": "Vendor qualifications for IT staff and networking\nIn some cases, vendor-run accreditation schemes can offer an objective measure\n\tof a job applicant's skills, but they do not always indicate the true\n\textent of practical abilities\n", "keywords": "vendor-run accreditation schemes; job applicant; IT staff; network\n\tadministrators; practical abilities\n", "topicrank": [["vendor qualifications", "extent", "cases", "job applicant", "accreditation schemes"], ["vendor qualifications", "extent", "cases", "job applicant", "accreditation schemes", "true", "skills", "objective measure", "practical abilities", "networking"]], "textrank": [["it staff", "vendor qualifications", "accreditation", "vendor"], ["it staff", "vendor qualifications", "accreditation", "vendor"]], "positionrank": [["vendor qualifications", "vendor", "it staff", "accreditation schemes", "objective measure"], ["vendor qualifications", "vendor", "it staff", "accreditation schemes", "objective measure", "networking", "cases", "job applicant", "skills", "practical abilities"]], "multipartiterank": [["vendor qualifications", "cases", "networking", "extent", "accreditation schemes"], ["vendor qualifications", "cases", "networking", "extent", "accreditation schemes", "job applicant", "true", "skills", "objective measure", "practical abilities"]]}, {"id": "252", "text": "Reaching for five nines: ActiveWatch and SiteSeer\nEvery Web admin's dream is achieving the fabled five nines-99.999 percent\n\tuptime. To attain such availability, your Web site must be down no more\n\tthan about five minutes per year. Technologies like RAID, clustering,\n\tand load balancing make this easier, but to actually track uptime,\n\tmaintain auditable records, and discover patterns in failures to\n\tprevent downtime in the future, you'll need to set up external\n\tmonitoring. Because your Internet connection is a key factor in\n\tmeasuring uptime, you must monitor your site from the Internet itself,\n\tbeyond your firewall. You could monitor with custom software on remote\n\thosts, or you could use one of the two reasonably priced services\n\tavailable: Mercury Interactive's ActiveWatch and Freshwater Software's\n\tSiteSeer. (Freshwater Software has been a subsidiary of Mercury\n\tInteractive for about a year now.) The two services offer a slightly\n\tdifferent mix of features and target different markets. Both services\n\toffer availability and performance monitoring from several remote\n\tlocations, alerts to email or pager, and periodic reports. They differ\n\tin what's most easily monitored, and in the way you interact with the\n\tservices\n", "keywords": "Web site; uptime tracking; auditable records; failure pattern discovery;\n\tdowntime; external monitoring; Internet connection; Mercury Interactive\n\tActiveWatch; Freshwater Software SiteSeer; performance monitoring;\n\tavailability monitoring; remote locations; email alerts; pager alerts;\n\tperiodic reports\n", "topicrank": [["services", "custom software", "uptime", "remote", "mercury interactive"], ["services", "custom software", "uptime", "remote", "mercury interactive", "monitoring", "activewatch", "year", "siteseer", "different mix"]], "textrank": [["key factor", "internet connection", "auditable records", "load balancing", "such availability"], ["key factor", "internet connection", "auditable records", "load balancing", "such availability", "nines-99.999 percent", "different", "software", "web", "availability"]], "positionrank": [["web admin", "web site", "freshwater software", "such availability", "activewatch"], ["web admin", "web site", "freshwater software", "such availability", "activewatch", "nines-99.999 percent", "mercury interactive", "siteseer", "uptime", "custom software"]], "multipartiterank": [["custom software", "services", "uptime", "remote", "monitoring"], ["custom software", "services", "uptime", "remote", "monitoring", "activewatch", "mercury interactive", "internet connection", "year", "siteseer"]]}, {"id": "1969", "text": "Modeling self-consistent multi-class dynamic traffic flow\nIn this study, we present a systematic self-consistent multiclass multilane\n\ttraffic model derived from the vehicular Boltzmann equation and the\n\ttraffic dispersion model. The multilane domain is considered as a\n\ttwo-dimensional space and the interaction among vehicles in the domain\n\tis described by a dispersion model. The reason we consider a multilane\n\tdomain as a two-dimensional space is that the driving behavior of road\n\tusers may not be restricted by lanes, especially motorcyclists. The\n\tdispersion model, which is a nonlinear Poisson equation, is derived\n\tfrom the car-following theory and the equilibrium assumption. Under the\n\tconcept that all kinds of users share the finite section, the density\n\tis distributed on a road by the dispersion model. In addition, the\n\tdynamic evolution of the traffic flow is determined by the systematic\n\tgas-kinetic model derived from the Boltzmann equation. Multiplying\n\tBoltzmann equation by the zeroth, first- and second-order moment\n\tfunctions, integrating both side of the equation and using chain rules,\n\twe can derive continuity, motion and variance equation, respectively.\n\tHowever, the second-order moment function, which is the square of the\n\tindividual velocity, is employed by previous researches does not have\n\tphysical meaning in traffic flow\n", "keywords": "self-consistent multiclass dynamic traffic flow modeling; multilane traffic\n\tmodel; vehicular Boltzmann equation; traffic dispersion model; road\n\tusers; nonlinear Poisson equation; car-following theory; dynamic\n\tevolution; variance equation; motion equation; Poisson equation\n", "topicrank": [["traffic model", "vehicular boltzmann equation", "consistent multiclass multilane", "order moment", "users"], ["traffic model", "vehicular boltzmann equation", "consistent multiclass multilane", "order moment", "users", "second", "road", "domain", "traffic flow", "dimensional space"]], "textrank": [["consistent multiclass multilane", "dynamic traffic", "traffic model", "poisson equation", "boltzmann equation"], ["consistent multiclass multilane", "dynamic traffic", "traffic model", "poisson equation", "boltzmann equation", "consistent multi", "finite section", "equilibrium assumption", "dimensional space", "systematic self"]], "positionrank": [["traffic dispersion model", "traffic model", "traffic flow", "consistent multiclass multilane", "systematic self"], ["traffic dispersion model", "traffic model", "traffic flow", "consistent multiclass multilane", "systematic self", "dispersion model", "vehicular boltzmann equation", "boltzmann equation", "kinetic model", "self"]], "multipartiterank": [["traffic model", "consistent multiclass multilane", "vehicular boltzmann equation", "self", "dispersion model"], ["traffic model", "consistent multiclass multilane", "vehicular boltzmann equation", "self", "dispersion model", "domain", "dimensional space", "users", "road", "systematic self"]]}, {"id": "376", "text": "Recursive state estimation for multiple switching models with unknown\n\ttransition probabilities\nThis work considers hybrid systems with continuous-valued target states and\n\tdiscrete-valued regime variable. The changes (switches) of the regime\n\tvariable are modeled by a finite state Markov chain with unknown and\n\trandom transition probabilities following Dirichlet distributions. Our\n\twork analytically derives the marginal posterior distribution of the\n\tstates and regime variables, the transition probabilities being\n\tintegrated out. This leads to a variety of recursive hybrid state\n\testimation schemes which are an appealing intuitive and straightforward\n\textension of standard algorithms. Their performance is illustrated by a\n\tmaneuvering target tracking example\n", "keywords": "recursive state estimation; multiple switching models; unknown transition\n\tprobabilities; hybrid systems; continuous-valued target states;\n\tdiscrete-valued regime variable; finite state Markov chain; random\n\ttransition probabilities; Dirichlet distributions; marginal posterior\n\tdistribution; maneuvering target tracking\n", "topicrank": [["regime variable", "transition probabilities", "unknown", "target states", "work"], ["regime variable", "transition probabilities", "unknown", "target states", "work", "recursive state estimation", "straightforward", "extension", "hybrid systems", "standard algorithms"]], "textrank": [["hybrid state", "state markov", "state estimation", "dirichlet distributions", "target states"], ["hybrid state", "state markov", "state estimation", "dirichlet distributions", "target states", "posterior", "regime", "transition", "switching", "hybrid"]], "positionrank": [["recursive state estimation", "recursive hybrid state", "random transition probabilities", "transition probabilities", "multiple switching models"], ["recursive state estimation", "recursive hybrid state", "random transition probabilities", "transition probabilities", "multiple switching models", "estimation schemes", "regime variable", "hybrid systems", "regime variables", "target states"]], "multipartiterank": [["regime variable", "transition probabilities", "recursive state estimation", "unknown", "target states"], ["regime variable", "transition probabilities", "recursive state estimation", "unknown", "target states", "work", "multiple switching models", "hybrid systems", "discrete", "changes"]]}, {"id": "2084", "text": "Evaluation of combined dispatching and routeing strategies for a flexible\n\tmanufacturing system\nThis paper deals with the evaluation of combined dispatching and routeing\n\tstrategies on the performance of a flexible manufacturing system. Three\n\trouteing policies - no alternative routings, alternative routeing\n\tdynamics and alternative routeing plans - are considered with four\n\tdispatching rules with finite buffer capacity. In addition, the effect\n\tof changing part mix ratios is also discussed. The performance measures\n\tconsidered are makespan, average machine utilization, average flow time\n\tand average delay at local input buffers. Simulation results indicate\n\tthat the alternative routings dynamic policy gives the best results in\n\tthree performance measures except for average delay at local input\n\tbuffers. Further, the effect of changing part mix ratios is not\n\tsignificant\n", "keywords": "alternative routings; flexible manufacturing system; FMS; dispatching rules;\n\tfinite buffer capacity; part mix ratios; average flow time\n", "topicrank": [["routeing policies", "performance", "local input buffers", "average delay", "manufacturing system"], ["routeing policies", "performance", "local input buffers", "average delay", "manufacturing system", "alternative routings", "routeing strategies", "dispatching", "simulation results", "effect"]], "textrank": [["alternative routings dynamic", "alternative routeing", "average flow", "average machine", "alternative routings"], ["alternative routings dynamic", "alternative routeing", "average flow", "average machine", "alternative routings", "routeing", "average", "results", "input", "mix"]], "positionrank": [["flexible manufacturing system", "alternative routeing plans", "routeing strategies", "alternative routeing", "manufacturing system"], ["flexible manufacturing system", "alternative routeing plans", "routeing strategies", "alternative routeing", "manufacturing system", "routeing policies", "evaluation", "alternative routings", "strategies", "dispatching"]], "multipartiterank": [["routeing policies", "manufacturing system", "routeing strategies", "performance", "dispatching"], ["routeing policies", "manufacturing system", "routeing strategies", "performance", "dispatching", "alternative routings", "evaluation", "local input buffers", "average delay", "flexible"]]}, {"id": "333", "text": "Teaching psychology as a laboratory science in the age of the Internet\nFor over 30 years, psychologists have relied on computers to teach experimental\n\tpsychology. With the advent of experiment generators, students can\n\tcreate well-designed experiments and can test sophisticated hypotheses\n\tfrom the start of their undergraduate training. Characteristics of new\n\tNet-based experiment generators are discussed and compared with\n\ttraditional stand-alone generators. A call is made to formally evaluate\n\tthe instructional effectiveness of the wide range of experiment\n\tgenerators now available. Specifically, software should be evaluated in\n\tterms of known learning outcomes, using appropriate control groups. The\n\tmany inherent differences between any two software programs should be\n\tmade clear. The teacher's instructional method should be fully\n\tdescribed and held constant between comparisons. Finally, the often\n\tcomplex interaction between the teacher's instructional method and the\n\tpedagogical details of the software must be considered\n", "keywords": "experimental psychology teaching; laboratory science; Internet; computers;\n\twell-designed experiments; hypothesis testing; undergraduate training;\n\tNet-based experiment generators; stand-alone generators; instructional\n\teffectiveness; software; known learning outcomes; control groups;\n\tteacher instructional method; pedagogical details\n", "topicrank": [["experiment generators", "instructional effectiveness", "software", "generators", "teacher"], ["experiment generators", "instructional effectiveness", "software", "generators", "teacher", "psychology", "characteristics", "new", "undergraduate training", "net"]], "textrank": [["learning outcomes", "wide range", "undergraduate training", "sophisticated hypotheses", "experiment generators"], ["learning outcomes", "wide range", "undergraduate training", "sophisticated hypotheses", "experiment generators", "laboratory science", "inherent", "control", "instructional", "software"]], "positionrank": [["experiment generators", "laboratory science", "psychology", "generators", "age"], ["experiment generators", "laboratory science", "psychology", "generators", "age", "experiment", "internet", "years", "psychologists", "instructional method"]], "multipartiterank": [["experiment generators", "instructional effectiveness", "generators", "software", "psychology"], ["experiment generators", "instructional effectiveness", "generators", "software", "psychology", "teacher", "new", "characteristics", "instructional method", "wide range"]]}, {"id": "2164", "text": "Electronic signatures - much ado?\nWhilst the market may be having a crisis of confidence regarding the prospects\n\tfor e-commerce, the EU and the Government continue apace to develop the\n\tlegal framework. Most recently, this has resulted in the Electronic\n\tSignatures Regulations 2002. These Regulations were made on 13 February\n\t2002 and came into force on 8 March 2002. The Regulations implement the\n\tEuropean Electronic Signatures Directive (1999/93/EC). Critics may say\n\tthat the Regulations were implemented too late (they were due to have\n\tbeen implemented by 19 July 2001), with too short a consultation period\n\t(25 January 2002 to 12 February 2002) and with an unconvincing case as\n\tto what they add to English law (as to which, read on). The author\n\texplains the latest development on e-signatures and the significance of\n\tCertification Service Providers (CSPs)\n", "keywords": "e-commerce; legal framework; Electronic Signatures Regulations 2002; European\n\tElectronic Signatures Directive\n", "topicrank": [["electronic signatures", "regulations", "signatures regulations", "february", "consultation period"], ["electronic signatures", "regulations", "signatures regulations", "february", "consultation period", "confidence", "certification service providers", "short", "crisis", "apace"]], "textrank": [["electronic signatures - much ado", "- signatures", "electronic signatures", "unconvincing case", "consultation period"], ["electronic signatures - much ado", "- signatures", "electronic signatures", "unconvincing case", "consultation period", "legal framework", "signatures", "service", "-", "electronic"]], "positionrank": [["electronic signatures", "signatures regulations", "electronic", "signatures", "e - commerce"], ["electronic signatures", "signatures regulations", "electronic", "signatures", "e - commerce", "much ado", "regulations", "certification service providers", "e", "market"]], "multipartiterank": [["electronic signatures", "much ado", "regulations", "signatures regulations", "confidence"], ["electronic signatures", "much ado", "regulations", "signatures regulations", "confidence", "crisis", "market", "february", "prospects", "apace"]]}, {"id": "2121", "text": "Flexibility analysis of complex technical systems under uncertainty\nAn important problem in designing technical systems under partial uncertainty\n\tof the initial physical, chemical, and technological data is the\n\tdetermination of a design in which the technical system is flexible,\n\ti.e., its control system is capable of guaranteeing that the\n\tconstraints hold even under changes in external and internal factors\n\tand application of fuzzy mathematical models in its design. Three\n\tflexibility problems, viz., the flexibility of a technical system of\n\tgiven structure, structural flexibility of a technical system, and the\n\toptimal design guaranteeing the flexibility of a technical system, are\n\tstudied. Two approaches to these problems are elaborated. Results of a\n\tcomputation experiment are given\n", "keywords": "flexibility analysis; complex technical systems; partial uncertainty; control\n\tsystem; fuzzy mathematical models; structural flexibility; optimal\n\tdesign\n", "topicrank": [["technical system", "flexibility analysis", "design", "complex technical systems", "uncertainty"], ["technical system", "flexibility analysis", "design", "complex technical systems", "uncertainty", "flexibility problems", "external", "internal factors", "fuzzy mathematical models", "changes"]], "textrank": [["technical system", "technological data", "initial physical", "partial uncertainty", "important problem"], ["technical system", "technological data", "initial physical", "partial uncertainty", "important problem", "flexibility", "technical", "mathematical", "system", "uncertainty"]], "positionrank": [["complex technical systems", "technical system", "technical systems", "flexibility analysis", "flexibility problems"], ["complex technical systems", "technical system", "technical systems", "flexibility analysis", "flexibility problems", "structural flexibility", "flexibility", "partial uncertainty", "control system", "important problem"]], "multipartiterank": [["flexibility analysis", "complex technical systems", "uncertainty", "technical system", "design"], ["flexibility analysis", "complex technical systems", "uncertainty", "technical system", "design", "important problem", "technical systems", "initial physical", "partial uncertainty", "chemical"]]}, {"id": "296", "text": "Using the Web to answer legal reference questions\nIn an effort to help non-law librarians with basic legal reference questions,\n\tthe author highlights three basic legal Web sites and outlines useful\n\tsubject-specific Web sites that focus on statutes and regulations, case\n\tlaw and attorney directories\n", "keywords": "World Wide Web; legal reference questions; nonlaw librarians; case law;\n\tattorney directories\n", "topicrank": [["web", "case", "regulations", "legal reference questions", "subject"], ["web", "case", "regulations", "legal reference questions", "subject", "law", "statutes", "useful", "attorney directories", "author"]], "textrank": [["legal web", "legal reference", "- law", "web", "law"], ["legal web", "legal reference", "- law", "web", "law", "-", "attorney"]], "positionrank": [["legal reference questions", "specific web sites", "web", "law", "effort"], ["legal reference questions", "specific web sites", "web", "law", "effort", "author", "subject", "attorney directories", "statutes", "regulations"]], "multipartiterank": [["web", "legal reference questions", "effort", "case", "regulations"], ["web", "legal reference questions", "effort", "case", "regulations", "subject", "law", "useful", "statutes", "author"]]}, {"id": "38", "text": "A PID standard: What, why, how?\nThe paper is written for all who develop and use P&IDs. It will aid in solving\n\tthe long existing and continuing problem of confusing information on\n\tP&IDs. The acronym P&ID is widely understood to mean the principal\n\tdocument used to define the details of how a process works and how it\n\tis controlled. The ISA Dictionary definition for P&ID tells what they\n\tdo, \"show the interconnection of process equipment and the\n\tinstrumentation used to control the process. In the process industry a\n\tstandard set of symbols is used to prepare drawings of processes. The\n\tinstrument symbols used in these drawings are generally based on\n\tISA-S5.1.\" In the paper the ISA standard is referred to as ISA-5.1. The\n\tarticle develops the concept of the \"standard\" and poses some of the\n\tquestions that the \"standard\" can answer\n", "keywords": "P&ID standard; principal document; process controlled; ISA-5.1; ISA standard\n", "topicrank": [["process", "pid standard", "isa dictionary definition", "symbols", "drawings"], ["process", "pid standard", "isa dictionary definition", "symbols", "drawings", "paper", "processes", "document", "principal", "interconnection"]], "textrank": [["isa standard", "isa dictionary", "process equipment", "instrument symbols", "acronym p&id"], ["isa standard", "isa dictionary", "process equipment", "instrument symbols", "acronym p&id", "standard", "process", "isa", "symbols", "p&id"]], "positionrank": [["pid standard", "isa standard", "standard set", "standard", "process industry"], ["pid standard", "isa standard", "standard set", "standard", "process industry", "process equipment", "isa dictionary definition", "process", "instrument symbols", "isa"]], "multipartiterank": [["pid standard", "process", "isa dictionary definition", "symbols", "paper"], ["pid standard", "process", "isa dictionary definition", "symbols", "paper", "drawings", "document", "principal", "details", "problem"]]}, {"id": "2199", "text": "Activity and location recognition using wearable sensors\nUsing measured acceleration and angular velocity data gathered through\n\tinexpensive, wearable sensors, this dead-reckoning method can determine\n\ta user's location, detect transitions between preselected locations,\n\tand recognize and classify sitting, standing, and walking behaviors.\n\tExperiments demonstrate the proposed method's effectiveness\n", "keywords": "measured acceleration; angular velocity; wearable sensors; dead-reckoning\n\tmethod; user's location; preselected locations; transitions; sitting;\n\tstanding; walking\n", "topicrank": [["location recognition", "wearable sensors", "reckoning method", "dead", "transitions"], ["location recognition", "wearable sensors", "reckoning method", "dead", "transitions", "angular velocity data", "user", "measured acceleration", "inexpensive", "preselected locations"]], "textrank": [["measured acceleration", "wearable sensors", "location recognition", "velocity", "location"], ["measured acceleration", "wearable sensors", "location recognition", "velocity", "location"]], "positionrank": [["wearable sensors", "angular velocity data", "location recognition", "measured acceleration", "location"], ["wearable sensors", "angular velocity data", "location recognition", "measured acceleration", "location", "activity", "reckoning method", "method", "preselected locations", "user"]], "multipartiterank": [["wearable sensors", "location recognition", "reckoning method", "dead", "measured acceleration"], ["wearable sensors", "location recognition", "reckoning method", "dead", "measured acceleration", "angular velocity data", "activity", "inexpensive", "user", "transitions"]]}, {"id": "1950", "text": "General solution of a density functionally gradient piezoelectric cantilever\n\tand its applications\nWe have used the plane strain theory of transversely isotropic bodies to study\n\ta piezoelectric cantilever. In order to find the general solution of a\n\tdensity functionally gradient piezoelectric cantilever, we have used\n\tthe inverse method (i.e. the Airy stress function method). We have\n\tobtained the stress and induction functions in the form of polynomials\n\tas well as the general solution of the beam. Based on this general\n\tsolution, we have deduced the solutions of the cantilever under\n\tdifferent loading conditions. Furthermore, as applications of this\n\tgeneral solution in engineering, we have studied the tip deflection and\n\tblocking force of a piezoelectric cantilever actuator. Finally, we have\n\taddressed a method to determine the density distribution profile for a\n\tgiven piezoelectric material\n", "keywords": "plane strain theory; transversely isotropic bodies; inverse method; Airy stress\n\tfunction; polynomials; loading conditions; piezoelectric cantilever\n\tactuator; density distribution profile; piezoelectric material\n", "topicrank": [["general solution", "piezoelectric cantilever", "density", "applications", "inverse method"], ["general solution", "piezoelectric cantilever", "density", "applications", "inverse method", "induction functions", "form", "polynomials", "solution", "stress"]], "textrank": [["stress function method", "piezoelectric cantilever", "general solution", "distribution", "loading"], ["stress function method", "piezoelectric cantilever", "general solution", "distribution", "loading", "strain", "piezoelectric", "cantilever", "stress", "method"]], "positionrank": [["general solution", "piezoelectric cantilever actuator", "piezoelectric cantilever", "solution", "piezoelectric material"], ["general solution", "piezoelectric cantilever actuator", "piezoelectric cantilever", "solution", "piezoelectric material", "cantilever", "density distribution profile", "density", "plane strain theory", "inverse method"]], "multipartiterank": [["general solution", "piezoelectric cantilever", "density", "applications", "inverse method"], ["general solution", "piezoelectric cantilever", "density", "applications", "inverse method", "order", "induction functions", "form", "polynomials", "isotropic bodies"]]}, {"id": "197", "text": "Mixture of experts classification using a hierarchical mixture model\nA three-level hierarchical mixture model for classification is presented that\n\tmodels the following data generation process: (1) the data are\n\tgenerated by a finite number of sources (clusters), and (2) the\n\tgeneration mechanism of each source assumes the existence of individual\n\tinternal class-labeled sources (subclusters of the external cluster).\n\tThe model estimates the posterior probability of class membership\n\tsimilar to a mixture of experts classifier. In order to learn the\n\tparameters of the model, we have developed a general training approach\n\tbased on maximum likelihood that results in two efficient training\n\talgorithms. Compared to other classification mixture models, the\n\tproposed hierarchical model exhibits several advantages and provides\n\timproved classification performance as indicated by the experimental\n\tresults\n", "keywords": "hierarchical mixture model; classification; data generation process; Bayes\n\tclassifier; experts classifier; posterior probability of class\n\tmembership\n", "topicrank": [["hierarchical mixture model", "internal class", "sources", "experts classification", "mixture"], ["hierarchical mixture model", "internal class", "sources", "experts classification", "mixture", "data generation process", "individual", "existence", "similar", "experts classifier"]], "textrank": [["classification mixture", "experts classification", "hierarchical mixture", "classification", "posterior probability"], ["classification mixture", "experts classification", "hierarchical mixture", "classification", "posterior probability", "external cluster", "finite number", "training", "generation", "mixture"]], "positionrank": [["hierarchical mixture model", "hierarchical model", "mixture", "experts classification", "improved classification performance"], ["hierarchical mixture model", "hierarchical model", "mixture", "experts classification", "improved classification performance", "model", "classification", "experts classifier", "class membership", "data generation process"]], "multipartiterank": [["hierarchical mixture model", "experts classification", "mixture", "internal class", "sources"], ["hierarchical mixture model", "experts classification", "mixture", "internal class", "sources", "data generation process", "model", "individual", "existence", "subclusters"]]}, {"id": "213", "text": "An application of fuzzy linear regression to the information technology in\n\tTurkey\nFuzzy set theory deals with the vagueness of human thought. A major\n\tcontribution of fuzzy set theory is its capability of representing\n\tvague knowledge. Fuzzy set theory is very practical when sufficient and\n\treliable data isn't available. Information technology (IT) is the\n\tacquisition, processing, storage and dissemination of information in\n\tall its forms (auditory, pictorial, textual and numerical) through a\n\tcombination of computers, telecommunication, networks and electronic\n\tdevices. IT includes matters concerned with the furtherance of computer\n\tscience and technology, design, development, installation and\n\timplementation of information systems and applications. In the paper,\n\tassuming that there are n independent variables and the regression\n\tfunction is linear, the possible levels of information technology (the\n\tsale levels of computer equipment) in Turkey are forecasted by using\n\tfuzzy linear regression. The independent variables assumed are the\n\timport level and the export level of computer equipment\n", "keywords": "fuzzy linear regression; information technology; Turkey; vague knowledge\n\trepresentation; IT; computers; telecommunication; electronic devices;\n\tcomputer science; computer technology; information systems; regression\n\tfunction; computer equipment export level\n", "topicrank": [["information technology", "fuzzy set theory deals", "computer", "fuzzy linear regression", "information"], ["information technology", "fuzzy set theory deals", "computer", "fuzzy linear regression", "information", "possible levels", "turkey", "telecommunication", "networks", "pictorial"]], "textrank": [["fuzzy set theory", "fuzzy linear", "information systems", "information technology", "computer equipment"], ["fuzzy set theory", "fuzzy linear", "information systems", "information technology", "computer equipment", "matters concerned", "reliable data", "vague knowledge", "human thought", "level"]], "positionrank": [["fuzzy linear regression", "fuzzy set theory", "information technology", "information systems", "information"], ["fuzzy linear regression", "fuzzy set theory", "information technology", "information systems", "information", "technology", "n independent variables", "regression", "human thought", "independent variables"]], "multipartiterank": [["information technology", "fuzzy set theory deals", "fuzzy linear regression", "computer", "information"], ["information technology", "fuzzy set theory deals", "fuzzy linear regression", "computer", "information", "turkey", "fuzzy set theory", "possible levels", "computer equipment", "dissemination"]]}, {"id": "256", "text": "Debugging Web applications\nThe author considers how one can save time tracking down bugs in Web-based\n\tapplications by arming yourself with the right tools and programming\n\tpractices. A wide variety of debugging tools have been written with Web\n\tdevelopers in mind\n", "keywords": "Web application debugging tools; programming\n", "topicrank": [["web", "right tools", "web applications", "developers", "bugs"], ["web", "right tools", "web applications", "developers", "bugs", "wide variety", "practices", "mind", "time", "author"]], "textrank": [["web applications", "right", "applications", "web"], ["web applications", "right", "applications", "web"]], "positionrank": [["web applications", "web", "right tools", "applications", "wide variety"], ["web applications", "web", "right tools", "applications", "wide variety", "tools", "time", "author", "bugs", "practices"]], "multipartiterank": [["web applications", "web", "right tools", "author", "bugs"], ["web applications", "web", "right tools", "author", "bugs", "time", "wide variety", "developers", "practices", "mind"]]}, {"id": "1990", "text": "Electrical facility construction work for information network structuring by\n\tthe use of sewage conduits\nTo confront the advent of the advanced information society, there has been a\n\tpressing demand for the adjustment of the communications infrastructure\n\tand the structuring of the information network by utilizing the sewage\n\tconduits. The City of Tokyo is promoting a project by the name of the\n\tsewer optical fiber teleway (SOFT) network plan. According to this\n\tplan, the total distance of the optical fiber network laid in the sewer\n\tconduits is scheduled to reach about 470 km by the end of March 2000.\n\tAt the final stage, this distance will reach 800 km as a whole. We\n\tcompleted the construction work for the information control facilities\n\tscattered in 11 places inclusive of the Treatment Site S, with the\n\tintention to adjust and extend the information transmission network\n\tlaid through the above-mentioned optical fiber network, to be used\n\texclusively by the Bureau of Sewerage. This construction work is\n\tdescribed in the paper\n", "keywords": "electrical facility construction work; information network structuring; sewage\n\tconduits; communications infrastructure; Tokyo; sewer optical fiber\n\tteleway network plan; information control facilities; Treatment Site S;\n\tinformation transmission network; Bureau of Sewerage; asynchronous\n\ttransmission mode switches; ATM switches\n", "topicrank": [["sewage conduits", "sewer optical fiber teleway", "information network", "electrical facility construction work", "network plan"], ["sewage conduits", "sewer optical fiber teleway", "information network", "electrical facility construction work", "network plan", "total distance", "city", "tokyo", "soft", "sewage"]], "textrank": [["optical fiber network", "information network", "information control", "facility construction", "optical fiber"], ["optical fiber network", "information network", "information control", "facility construction", "optical fiber", "information", "total distance", "communications infrastructure", "sewage conduits", "network"]], "positionrank": [["information transmission network", "information network", "optical fiber network", "construction work", "information control facilities"], ["information transmission network", "information network", "optical fiber network", "construction work", "information control facilities", "network plan", "advanced information society", "sewage conduits", "conduits", "sewage"]], "multipartiterank": [["sewage conduits", "electrical facility construction work", "information network", "sewer optical fiber teleway", "network plan"], ["sewage conduits", "electrical facility construction work", "information network", "sewer optical fiber teleway", "network plan", "conduits", "use", "total distance", "soft", "advent"]]}, {"id": "40", "text": "New tuning method for PID controller\nIn this paper, a tuning method for proportional-integral-derivative (PID)\n\tcontroller and the performance assessment formulas for this method are\n\tproposed. This tuning method is based on a genetic algorithm based PID\n\tcontroller design method. For deriving the tuning formula, the genetic\n\talgorithm based design method is applied to design PID controllers for\n\ta variety of processes. The relationship between the controller\n\tparameters and the parameters that characterize the process dynamics\n\tare determined and the tuning formula is then derived. Using simulation\n\tstudies, the rules for assessing the performance of a PID controller\n\ttuned by the proposed method are also given. This makes it possible to\n\tincorporate the capability to determine if the PID controller is well\n\ttuned or not into an autotuner. An autotuner based on this new tuning\n\tmethod and the corresponding performance assessment rules is also\n\testablished. Simulations and real-time experimental results are given\n\tto demonstrate the effectiveness and usefulness of these formulas\n", "keywords": "tuning method; PID controller; proportional-integral-derivative controller;\n\tgenetic algorithm; controller design method; process dynamics;\n\tautotuner\n", "topicrank": [["new tuning method", "pid controller", "method", "pid", "performance assessment"], ["new tuning method", "pid controller", "method", "pid", "performance assessment", "genetic algorithm", "parameters", "autotuner", "integral", "derivative"]], "textrank": [["controller design method", "tuning method", "performance assessment", "pid controller", "design pid"], ["controller design method", "tuning method", "performance assessment", "pid controller", "design pid", "design method", "process dynamics", "genetic algorithm", "tuning", "experimental"]], "positionrank": [["new tuning method", "tuning method", "controller design method", "new tuning", "pid controller"], ["new tuning method", "tuning method", "controller design method", "new tuning", "pid controller", "design method", "tuning formula", "method", "pid controllers", "pid"]], "multipartiterank": [["new tuning method", "pid controller", "method", "pid", "performance assessment"], ["new tuning method", "pid controller", "method", "pid", "performance assessment", "controller", "genetic algorithm", "paper", "tuning method", "proportional"]]}, {"id": "2159", "text": "Real-time enterprise solutions for discrete manufacturing and consumer goods\nCustomer satisfaction and a focus on core competencies have dominated the\n\tthinking of a whole host of industries in recent years. However, one\n\toutcome, the outsourcing of noncore activities, has made the production\n\tof goods-from order entry to final delivery-more and more complex.\n\tSuppliers, subsuppliers, producers and customers are therefore busy\n\tadopting a new, more collaborative approach. This is mainly taking the\n\tform of order-driven planning and scheduling of production, but it is\n\talso being steered by a need to reduce inventories and working capital\n\tas well as a desire to increase throughput and optimize production\n", "keywords": "real-time enterprise solutions; discrete manufacturing; consumer goods;\n\tcustomer satisfaction; core competencies; order-driven planning;\n\tproduction scheduling; working capital reduction; inventories reduction\n", "topicrank": [["production", "order entry", "consumer goods", "producers", "subsuppliers"], ["production", "order entry", "consumer goods", "producers", "subsuppliers", "customers", "suppliers", "industries", "whole host", "scheduling"]], "textrank": [["noncore activities", "recent years", "whole host", "core competencies", "customer satisfaction"], ["noncore activities", "recent years", "whole host", "core competencies", "customer satisfaction", "consumer goods", "discrete manufacturing", "enterprise", "goods"]], "positionrank": [["time enterprise solutions", "consumer goods", "discrete manufacturing", "customer satisfaction", "goods"], ["time enterprise solutions", "consumer goods", "discrete manufacturing", "customer satisfaction", "goods", "core competencies", "focus", "whole host", "order entry", "recent years"]], "multipartiterank": [["consumer goods", "production", "order entry", "discrete manufacturing", "customer satisfaction"], ["consumer goods", "production", "order entry", "discrete manufacturing", "customer satisfaction", "time enterprise solutions", "subsuppliers", "producers", "focus", "industries"]]}, {"id": "2001", "text": "A simple graphic approach for observer decomposition\nBased upon the proposition that the roles of inputs and outputs in a physical\n\tsystem and those in the corresponding output-injection observer do not\n\treally have to be consistent, a systematic procedure is developed in\n\tthis work to properly divide a set of sparse system models and\n\tmeasurement models into a number of independent subsets with the help\n\tof a visual aid. Several smaller sub-observers can then be constructed\n\taccordingly to replace the original one. The size of each sub-observer\n\tmay be further reduced by strategically selecting one or more appended\n\tstates. These techniques are shown to be quite effective in relieving\n\ton-line computation load of the output-injection observers and also in\n\tidentifying detectable sub-systems\n", "keywords": "graphic approach; observer decomposition; output-injection observer; sparse\n\tsystem models; measurement models; independent subsets; sub-observers;\n\tonline computation load; detectable subsystems\n", "topicrank": [["system", "corresponding output", "injection observer", "inputs", "outputs"], ["system", "corresponding output", "injection observer", "inputs", "outputs", "roles", "physical", "independent subsets", "number", "measurement models"]], "textrank": [["sub - observer", "smaller sub -", "corresponding output -", "sub -", "output -"], ["sub - observer", "smaller sub -", "corresponding output -", "sub -", "output -", "system models", "independent subsets", "systematic procedure", "-", "computation"]], "positionrank": [["simple graphic approach", "sub - observer", "observer decomposition", "injection observer", "sparse system models"], ["simple graphic approach", "sub - observer", "observer decomposition", "injection observer", "sparse system models", "injection observers", "proposition", "corresponding output", "system", "measurement models"]], "multipartiterank": [["system", "corresponding output", "injection observer", "physical", "inputs"], ["system", "corresponding output", "injection observer", "physical", "inputs", "outputs", "roles", "proposition", "observer decomposition", "independent subsets"]]}, {"id": "2044", "text": "Three-dimensional geometrical optics code for indoor propagation\nThis paper presents a program, GO 3D, for computing the fields of a transmitter\n\tin an indoor environment using geometrical optics. The program uses an\n\t\"image tree\" data structure to construct the images needed to compute\n\tall the rays carrying fields above a preset \"threshold\" value, no\n\tmatter how many reflections are needed. The paper briefly describes the\n\tinput file required to define wall construction, the floor plan, the\n\ttransmitter, and the receiver locations. A case study consisting of a\n\tlong corridor with a small room on one side is used to demonstrate the\n\tfeatures of the GO 3D program\n", "keywords": "three-dimensional geometrical optics; 3D geometrical optics code; indoor\n\tpropagation; image tree data structure; image construction; wall\n\tconstruction; floor plan; transmitter; receiver locations; ray tracing;\n\tdata visualisation\n", "topicrank": [["fields", "indoor propagation", "program", "transmitter", "dimensional geometrical optics code"], ["fields", "indoor propagation", "program", "transmitter", "dimensional geometrical optics code", "paper", "go 3d", "threshold", "preset", "value"]], "textrank": [["geometrical optics", "input file", "many reflections", "data structure", "image tree"], ["geometrical optics", "input file", "many reflections", "data structure", "image tree", "3d", "indoor", "wall"]], "positionrank": [["go 3d program", "geometrical optics", "indoor propagation", "indoor environment", "program"], ["go 3d program", "geometrical optics", "indoor propagation", "indoor environment", "program", "go 3d", "paper", "image tree", "transmitter", "fields"]], "multipartiterank": [["indoor propagation", "dimensional geometrical optics code", "program", "paper", "fields"], ["indoor propagation", "dimensional geometrical optics code", "program", "paper", "fields", "transmitter", "go 3d", "threshold", "preset", "value"]]}, {"id": "21", "text": "Discrete output feedback sliding mode control of second order systems - a\n\tmoving switching line approach\nThe sliding mode control systems (SMCS) for which the switching variable is\n\tdesigned independent of the initial conditions are known to be\n\tsensitive to parameter variations and extraneous disturbances during\n\tthe reaching phase. For second order systems this drawback is\n\teliminated by using the moving switching line technique where the\n\tswitching line is initially designed to pass the initial conditions and\n\tis subsequently moved towards a predetermined switching line. In this\n\tpaper, we make use of the above idea of moving switching line together\n\twith the reaching law approach to design a discrete output feedback\n\tsliding mode control. The main contributions of this work are such that\n\twe do not require to use system states as it makes use of only the\n\toutput samples for designing the controller. and by using the moving\n\tswitching line a low sensitivity system is obtained through shortening\n\tthe reaching phase. Simulation results show that the fast output\n\tsampling feedback guarantees sliding motion similar to that obtained\n\tusing state feedback\n", "keywords": "sliding mode control; switching variable; parameter variations; moving\n\tswitching line; discrete output feedback; fast output sampling\n\tfeedback; state feedback\n", "topicrank": [["switching line approach", "mode control", "second order systems", "phase", "output samples"], ["switching line approach", "mode control", "second order systems", "phase", "output samples", "discrete output feedback", "initial conditions", "use", "feedback guarantees", "parameter variations"]], "textrank": [["switching line approach", "output feedback", "mode control systems", "switching line", "sensitivity system"], ["switching line approach", "output feedback", "mode control systems", "switching line", "sensitivity system", "order systems", "mode control", "output", "parameter variations", "initial conditions"]], "positionrank": [["discrete output feedback", "switching line approach", "second order systems", "mode control", "switching line technique"], ["discrete output feedback", "switching line approach", "second order systems", "mode control", "switching line technique", "switching line", "fast output", "output samples", "feedback guarantees", "state feedback"]], "multipartiterank": [["switching line approach", "mode control", "second order systems", "discrete output feedback", "phase"], ["switching line approach", "mode control", "second order systems", "discrete output feedback", "phase", "initial conditions", "output samples", "use", "sliding mode control systems", "line"]]}, {"id": "2138", "text": "Reachability sets of a class of multistep control processes: their design\nAn upper estimate and an iterative \"restriction\" algorithm for the reachability\n\tset for determining the optimal control for a class of multistep\n\tcontrol processes are designed\n", "keywords": "reachability sets; multistep control processes; discrete systems; upper\n\testimate; iterative restriction algorithm; optimal control\n", "topicrank": [["multistep control processes", "class", "reachability sets", "restriction", "iterative"], ["multistep control processes", "class", "reachability sets", "restriction", "iterative", "algorithm", "upper estimate", "multistep", "design"]], "textrank": [["reachability sets", "control", "reachability", "upper"], ["reachability sets", "control", "reachability", "upper"]], "positionrank": [["multistep control processes", "control processes", "reachability sets", "optimal control", "reachability"], ["multistep control processes", "control processes", "reachability sets", "optimal control", "reachability", "upper estimate", "multistep", "class", "design", "algorithm"]], "multipartiterank": [["reachability sets", "multistep control processes", "class", "design", "upper estimate"], ["reachability sets", "multistep control processes", "class", "design", "upper estimate", "restriction", "iterative", "algorithm", "multistep", "reachability"]]}, {"id": "1949", "text": "A new graphical user interface for fast construction of computation phantoms\n\tand MCNP calculations: application to calibration of in vivo\n\tmeasurement systems\nReports on a new utility for development of computational phantoms for Monte\n\tCarlo calculations and data analysis for in vivo measurements of\n\tradionuclides deposited in tissues. The individual properties of each\n\tworker can be acquired for a rather precise geometric representation of\n\this (her) anatomy, which is particularly important for low energy gamma\n\tray emitting sources such as thorium, uranium, plutonium and other\n\tactinides. The software enables automatic creation of an MCNP input\n\tdata file based on scanning data. The utility includes segmentation of\n\timages obtained with either computed tomography or magnetic resonance\n\timaging by distinguishing tissues according to their signal\n\t(brightness) and specification of the source and detector. In addition,\n\ta coupling of individual voxels within the tissue is used to reduce the\n\tmemory demand and to increase the calculational speed. The utility was\n\ttested for low energy emitters in plastic and biological tissues as\n\twell as for computed tomography and magnetic resonance imaging scanning\n\tinformation\n", "keywords": "computational phantoms; Monte Carlo calculations; in vivo measurements;\n\tradionuclides; tissues; worker; precise geometric representation; MCNP\n\tinput data file; scanning data; computed tomography; brightness;\n\tgraphical user interface; computation phantoms; calibration; in vivo\n\tmeasurement systems; Th; U; Pu; signal; detector; individual voxels;\n\tmemory demand; calculational speed; plastic; biological tissues;\n\tmagnetic resonance imaging scanning information; anatomy; low energy\n\tgamma ray emitting sources; actinides; software; automatic creation\n", "topicrank": [["new utility", "data analysis", "tissues", "mcnp calculations", "computation phantoms"], ["new utility", "data analysis", "tissues", "mcnp calculations", "computation phantoms", "vivo", "low energy gamma", "magnetic resonance", "individual properties", "tomography"]], "textrank": [["new graphical user", "resonance imaging", "mcnp calculations", "automatic creation", "sources such"], ["new graphical user", "resonance imaging", "mcnp calculations", "automatic creation", "sources such", "vivo measurements", "measurement systems", "fast construction", "energy", "geometric"]], "positionrank": [["new utility", "computation phantoms", "computational phantoms", "mcnp calculations", "fast construction"], ["new utility", "computation phantoms", "computational phantoms", "mcnp calculations", "fast construction", "carlo calculations", "data analysis", "mcnp input", "vivo measurements", "data file"]], "multipartiterank": [["mcnp calculations", "computation phantoms", "new utility", "data analysis", "vivo"], ["mcnp calculations", "computation phantoms", "new utility", "data analysis", "vivo", "tissues", "application", "individual properties", "measurement systems", "calibration"]]}, {"id": "2180", "text": "Standard protocol for exchange of health-checkup data based on SGML: the\n\tHealth-checkup Data Markup Language (HDML)\nThe objectives are to develop a health/medical data interchange model for\n\tefficient electronic exchange of data among health-checkup facilities.\n\tA Health-checkup Data Markup Language (HDML) was developed on the basis\n\tof the Standard Generalized Markup Language (SGML), and a feasibility\n\tstudy carried out, involving data exchange between two health checkup\n\tfacilities. The structure of HDML is described. The transfer of\n\tnumerical lab data, summary findings and health status assessment was\n\tsuccessful. HDML is an improvement to laboratory data exchange. Further\n\twork has to address the exchange of qualitative and textual data\n", "keywords": "health checkup data exchange; SGML; Health-checkup Data Markup Language; data\n\tinterchange model; numerical lab data; summary findings; health status\n\tassessment\n", "topicrank": [["health", "checkup data", "exchange", "hdml", "checkup facilities"], ["health", "checkup data", "exchange", "hdml", "checkup facilities", "sgml", "summary findings", "numerical lab data", "structure", "successful"]], "textrank": [["checkup data markup", "checkup data", "lab data", "data interchange", "data exchange"], ["checkup data markup", "checkup data", "lab data", "data interchange", "data exchange", "data", "standard generalized markup", "health checkup", "health status", "electronic exchange"]], "positionrank": [["laboratory data exchange", "checkup data", "data exchange", "health checkup", "numerical lab data"], ["laboratory data exchange", "checkup data", "data exchange", "health checkup", "numerical lab data", "health status assessment", "textual data", "data", "efficient electronic exchange", "checkup facilities"]], "multipartiterank": [["health", "checkup data", "exchange", "hdml", "sgml"], ["health", "checkup data", "exchange", "hdml", "sgml", "checkup data markup language", "checkup facilities", "standard protocol", "qualitative", "medical data interchange model"]]}, {"id": "237", "text": "International library consortia: positive starts, promising futures\nLibrary consortia have grown substantially over the past ten years, both within\n\tNorth America and globally. As this resurgent consortial movement has\n\tbegun to mature, and as publishers and vendors have begun to adapt to\n\tconsortial purchasing models, consortia have expanded their agendas for\n\taction. The movement to globalize consortia is traced (including the\n\tdevelopment and current work of the International Coalition of Library\n\tConsortia-ICOLC). A methodology is explored to classify library\n\tconsortia by articulating the key factors that affect and distinguish\n\tconsortia as organizations within three major areas: strategic,\n\ttactical, and practical (or managerial) concerns. Common consortial\n\tvalues are examined, and a list of known international library\n\tconsortia is presented\n", "keywords": "consortial purchasing models; international library consortia\n", "topicrank": [["consortia", "international library consortia", "resurgent consortial movement", "concerns", "common consortial"], ["consortia", "international library consortia", "resurgent consortial movement", "concerns", "common consortial", "major areas", "international coalition", "managerial", "strategic", "current work"]], "textrank": [["consortial purchasing", "international library", "consortial", "current work", "north america"], ["consortial purchasing", "international library", "consortial", "current work", "north america", "promising futures", "positive starts", "international", "library"]], "positionrank": [["international library consortia", "library consortia", "international library", "consortia", "library"], ["international library consortia", "library consortia", "international library", "consortia", "library", "international coalition", "positive starts", "promising futures", "resurgent consortial movement", "consortial purchasing models"]], "multipartiterank": [["international library consortia", "consortia", "positive starts", "promising futures", "resurgent consortial movement"], ["international library consortia", "consortia", "positive starts", "promising futures", "resurgent consortial movement", "past", "years", "library", "library consortia", "north america"]]}, {"id": "272", "text": "Median partitioning: a novel method for the selection of representative subsets\n\tfrom large compound pools\nA method termed median partitioning (MP) has been developed to select diverse\n\tsets of molecules from large compound pools. Unlike many other methods\n\tfor subset selection, the MP approach does not depend on pairwise\n\tcomparison of molecules and can therefore be applied to very large\n\tcompound collections. The only time limiting step is the calculation of\n\tmolecular descriptors for database compounds. MP employs arrays of\n\tproperty descriptors with little correlation to divide large compound\n\tpools into partitions from which representative molecules can be\n\tselected. In each of n subsequent steps, a population of molecules is\n\tdivided into subpopulations above and below the median value of a\n\tproperty descriptor until a desired number of 2/sup n/ partitions are\n\tobtained. For descriptor evaluation and selection, an entropy\n\tformulation was embedded in a genetic algorithm. MP has been applied to\n\tgenerate a subset of the Available Chemicals Directory, and the results\n\thave been compared with cell-based partitioning\n", "keywords": "median partitioning; large compound pools; representative subset selection;\n\tmolecules; time limiting step; molecular descriptors; database\n\tcompounds; property descriptor array; entropy formulation; genetic\n\talgorithm; Available Chemicals Directory; cell-based partitioning\n", "topicrank": [["large compound pools", "molecules", "selection", "molecular descriptors", "median"], ["large compound pools", "molecules", "selection", "molecular descriptors", "median", "property descriptor", "novel method", "pools", "little correlation", "partitions"]], "textrank": [["property descriptor", "property descriptors", "only time", "mp approach", "subset selection"], ["property descriptor", "property descriptors", "only time", "mp approach", "subset selection", "novel method", "compound", "chemicals", "n/", "other"]], "positionrank": [["large compound pools", "large compound", "median partitioning", "median value", "novel method"], ["large compound pools", "large compound", "median partitioning", "median value", "novel method", "representative molecules", "compound collections", "subset selection", "mp approach", "representative subsets"]], "multipartiterank": [["median", "large compound pools", "molecules", "selection", "novel method"], ["median", "large compound pools", "molecules", "selection", "novel method", "molecular descriptors", "representative subsets", "property descriptor", "sets", "method"]]}, {"id": "407", "text": "Generating code at run time with Reflection.Emit\nThe .NET framework SDK includes several tools that convert source code into\n\texecutable code-the C# and VB.NET compilers get most of the attention,\n\tbut there are others. The Regex class (in the\n\tSystem.Text.RegularExpressions namespace) has the ability to compile\n\tfavorite regular expressions into a .NET assembly. In fact, the NET\n\tCommon Language Runtime (CLR) contains a whole namespace full of\n\tclasses to help us build assemblies, define types, and emit their\n\timplementations, all at run time. These classes, which comprise the\n\tSystem.Reflection.Emit namespace, are known collectively as Reflection.\n\tEmit\n", "keywords": ".NET framework SDK; runtime code generation; Regex class; .NET Common Language\n\tRuntime; assemblies; types; System.Reflection.Emit namespace;\n\tReflection.Emit\n", "topicrank": [["reflection", "emit", "system", "run time", "code"], ["reflection", "emit", "system", "run time", "code", "classes", "common language runtime", "text", "regularexpressions namespace", "net"]], "textrank": [[".net framework", "namespace", "c #", "several tools", "run time"], [".net framework", "namespace", "c #", "several tools", "run time", "language", "regular", "code", ".net", "vb.net"]], "positionrank": [["source code", "executable code", ".net framework sdk", "code", "run time"], ["source code", "executable code", ".net framework sdk", "code", "run time", "emit namespace", "several tools", ".net assembly", "c #", "reflection"]], "multipartiterank": [["reflection", "code", "run time", "emit", "system"], ["reflection", "code", "run time", "emit", "system", "classes", "common language runtime", "text", "net", "regularexpressions namespace"]]}, {"id": "2025", "text": "Multispectral color image capture using a liquid crystal tunable filter\nWe describe the experimental setup of a multispectral color image acquisition\n\tsystem consisting of a professional monochrome CCD camera and a tunable\n\tfilter in which the spectral transmittance can be controlled\n\telectronically. We perform a spectral characterization of the\n\tacquisition system taking into account the acquisition noise. To\n\tconvert the camera output signals to device-independent color data, two\n\tmain approaches are proposed and evaluated. One consists in applying\n\tregression methods to convert from the K camera outputs to a\n\tdevice-independent color space such as CIEXYZ or CIELAB. Another method\n\tis based on a spectral model of the acquisition system. By inverting\n\tthe model using a principal eigenvector approach, we estimate the\n\tspectral reflectance of each pixel of the imaged surface\n", "keywords": "multispectral color image capture; liquid crystal tunable filter; multispectral\n\tcolor image acquisition system; monochrome CCD camera; tunable filter;\n\tspectral transmittance; spectral characterization; acquisition system;\n\tacquisition noise; camera output signals; device-independent color\n\tdata; regression methods; camera outputs; independent color space;\n\tCIEXYZ; CIELAB; spectral model; principal eigenvector approach;\n\tspectral reflectance; imaged surface; pixel\n", "topicrank": [["system", "spectral transmittance", "device", "multispectral color image capture", "spectral model"], ["system", "spectral transmittance", "device", "multispectral color image capture", "spectral model", "independent color data", "camera output signals", "tunable", "account", "cielab"]], "textrank": [["color image acquisition", "monochrome ccd camera", "color image", "color space", "camera output"], ["color image acquisition", "monochrome ccd camera", "color image", "color space", "camera output", "crystal tunable", "color", "spectral", "camera", "experimental setup"]], "positionrank": [["independent color space", "independent color data", "acquisition system", "camera output signals", "k camera outputs"], ["independent color space", "independent color data", "acquisition system", "camera output signals", "k camera outputs", "acquisition noise", "experimental setup", "filter", "spectral model", "system"]], "multipartiterank": [["multispectral color image capture", "system", "spectral transmittance", "liquid crystal tunable filter", "acquisition system"], ["multispectral color image capture", "system", "spectral transmittance", "liquid crystal tunable filter", "acquisition system", "device", "filter", "tunable", "professional monochrome ccd camera", "spectral model"]]}, {"id": "392", "text": "Time-varying properties of renal autoregulatory mechanisms\nIn order to assess the possible time-varying properties of renal\n\tautoregulation, time-frequency and time-scaling methods were applied to\n\trenal blood flow under broad-band forced arterial blood pressure\n\tfluctuations and single-nephron renal blood flow with spontaneous\n\toscillations obtained from normotensive (Sprague-Dawley, Wistar, and\n\tLong-Evans) rats, and spontaneously hypertensive rats. Time-frequency\n\tanalyses of normotensive and hypertensive blood flow data obtained from\n\teither the whole kidney or the single-nephron show that indeed both the\n\tmyogenic and tubuloglomerular feedback (TGF) mechanisms have\n\ttime-varying characteristics. Furthermore, we utilized the Renyi\n\tentropy to measure the complexity of blood-flow dynamics in the\n\ttime-frequency plane in an effort to discern differences between\n\tnormotensive and hypertensive recordings. We found a clear difference\n\tin Renyi entropy between normotensive and hypertensive blood flow\n\trecordings at the whole kidney level for both forced (p < 0.037) and\n\tspontaneous arterial pressure fluctuations (p < 0.033), and at the\n\tsingle-nephron level (p < 0.008). Especially at the single-nephron\n\tlevel, the mean Renyi entropy is significantly larger for hypertensive\n\tthan normotensive rats, suggesting more complex dynamics in the\n\thypertensive condition. To further evaluate whether or not the\n\tseparation of dynamics between normotensive and hypertensive rats is\n\tfound in the prescribed frequency ranges of the myogenic and TGF\n\tmechanisms, we employed multiresolution wavelet transform. Our analysis\n\trevealed that exclusively over scale ranges corresponding to the\n\tfrequency intervals of the myogenic and TGF mechanisms, the widths of\n\tthe blood flow wavelet coefficients fall into disjoint sets for\n\tnormotensive and hypertensive rats. The separation of the scales at the\n\tmyogenic and TGF frequency ranges is distinct and obtained with 100%\n\taccuracy. However, this observation remains valid only for the whole\n\tkidney blood pressure/flow data. The results suggest that understanding\n\tof the time-varying properties of the two mechanisms is required for a\n\tcomplete description of renal autoregulation\n", "keywords": "time-varying properties; Sprague-Dawley rats; Wistar rats; Long-Evans rats;\n\twhole kidney; single-nephron; Renyi entropy; spontaneous arterial\n\tpressure fluctuations; hypertensive rats; normotensive rats; renal\n\tautoregulatory mechanisms; broad-band forced arterial blood pressure\n\tfluctuations; single-nephron renal blood flow; spontaneous oscillations\n", "topicrank": [["time", "normotensive", "renal blood flow", "frequency", "rats"], ["time", "normotensive", "renal blood flow", "frequency", "rats", "myogenic", "single", "mechanisms", "arterial blood pressure", "tgf"]], "textrank": [["nephron renal blood flow", "blood flow wavelet", "hypertensive blood flow", "renal blood flow", "kidney blood pressure"], ["nephron renal blood flow", "blood flow wavelet", "hypertensive blood flow", "renal blood flow", "kidney blood pressure", "arterial blood pressure", "tgf frequency ranges", "frequency ranges", "hypertensive rats", "flow dynamics"]], "positionrank": [["renal blood flow", "hypertensive blood flow", "possible time", "renal autoregulatory mechanisms", "time"], ["renal blood flow", "hypertensive blood flow", "possible time", "renal autoregulatory mechanisms", "time", "kidney blood pressure", "arterial blood pressure", "renal autoregulation", "tgf frequency ranges", "tgf mechanisms"]], "multipartiterank": [["time", "normotensive", "renal blood flow", "frequency", "single"], ["time", "normotensive", "renal blood flow", "frequency", "single", "rats", "arterial blood pressure", "myogenic", "mechanisms", "properties"]]}, {"id": "2060", "text": "Decisions, decisions, decisions: a tale of special collections in the small\n\tacademic library\nA case study of a special collections department in a small academic library\n\tand how its collections have been acquired and developed over the years\n\tis described. It looks at the changes that have occurred in the\n\tacademic environment and what effect, if any, these changes may have\n\thad on the department and how it has adapted to them. It raises\n\tquestions about development and acquisitions policies and procedures\n", "keywords": "special collections; small academic library; case study; acquisitions policies;\n\tout-of-print books; University library\n", "topicrank": [["academic library", "special collections", "decisions", "acquisitions policies", "development"], ["academic library", "special collections", "decisions", "acquisitions policies", "development", "changes", "tale", "small", "case study", "questions"]], "textrank": [["acquisitions policies", "case study", "academic", "collections"], ["acquisitions policies", "case study", "academic", "collections"]], "positionrank": [["special collections department", "small academic library", "special collections", "academic library", "decisions"], ["special collections department", "small academic library", "special collections", "academic library", "decisions", "collections", "academic environment", "case study", "tale", "department"]], "multipartiterank": [["special collections", "academic library", "decisions", "small", "tale"], ["special collections", "academic library", "decisions", "small", "tale", "case study", "changes", "acquisitions policies", "development", "special collections department"]]}, {"id": "2018", "text": "Design and implementation of a 3-D mapping system for highly irregular shaped\n\tobjects with application to semiconductor manufacturing\nThe basic technology for a robotic system is developed to automate the packing\n\tof polycrystalline silicon nuggets into fragile fused silica crucible\n\tin Czochralski (melt pulling) semiconductor wafer production. The\n\thighly irregular shapes of the nuggets and the packing constraints make\n\tthis a difficult and challenging task. It requires the delicate\n\tmanipulation and packing of highly irregular polycrystalline silicon\n\tnuggets into a fragile fused silica crucible. For this application, a\n\tdual optical 3-D surface mapping system that uses active laser\n\ttriangulation has been developed and successfully tested. One part of\n\tthe system measures the geometry profile of a nugget being packed and\n\tthe other the profile of the nuggets already in the crucible. A\n\tresolution of 1 mm with 15-KHz sampling frequency is achieved. Data\n\tfrom the system are used by the packing algorithm, which determines\n\toptimal nugget placement. The key contribution is to describe the\n\tdesign and implementation of an efficient and robust 3-D imaging system\n\tto map highly irregular shaped objects using conventional components in\n\tcontext of real commercial manufacturing processes\n", "keywords": "3D mapping system; highly irregular shaped objects; semiconductor\n\tmanufacturing; robotic system; polycrystalline silicon nuggets; fragile\n\tfused silica crucible; sampling frequency; packing algorithm; optical\n\tnugget placement; robust 3-D imaging system; irregular shaped objects;\n\tcommercial manufacturing processes; Czochralski semiconductor wafer\n\tproduction; dual optical 3D surface mapping system; highly irregular\n\tpolycrystalline silicon nuggets; active laser triangulation\n", "topicrank": [["mapping system", "silica crucible", "nuggets", "polycrystalline silicon nuggets", "fragile"], ["mapping system", "silica crucible", "nuggets", "polycrystalline silicon nuggets", "fragile", "application", "packing", "objects", "implementation", "irregular"]], "textrank": [["irregular polycrystalline silicon", "mapping system", "commercial manufacturing", "irregular shaped", "semiconductor manufacturing"], ["irregular polycrystalline silicon", "mapping system", "commercial manufacturing", "irregular shaped", "semiconductor manufacturing", "semiconductor wafer", "polycrystalline silicon", "dual optical", "challenging task", "silica crucible"]], "positionrank": [["surface mapping system", "mapping system", "imaging system", "irregular shaped objects", "robotic system"], ["surface mapping system", "mapping system", "imaging system", "irregular shaped objects", "robotic system", "irregular polycrystalline silicon", "design", "system", "polycrystalline silicon nuggets", "irregular shapes"]], "multipartiterank": [["mapping system", "silica crucible", "irregular", "application", "nuggets"], ["mapping system", "silica crucible", "irregular", "application", "nuggets", "objects", "fragile", "implementation", "polycrystalline silicon nuggets", "packing"]]}, {"id": "2", "text": "Waiting for the wave to crest [wavelength services]\nWavelength services have been hyped ad nauseam for years. But despite their\n\tquick turn-up time and impressive margins, such services have yet to\n\tlive up to the industry's expectations. The reasons for this lukewarm\n\treception are many, not the least of which is the confusion that still\n\tsurrounds the technology, but most industry observers are still\n\tconvinced that wavelength services with ultimately flourish\n", "keywords": "wavelength services; fiber optic networks; Looking Glass Networks; PointEast\n\tResearch\n", "topicrank": [["wavelength services", "reception", "lukewarm", "many", "expectations"], ["wavelength services", "reception", "lukewarm", "many", "expectations", "reasons", "industry", "time", "ad nauseam", "impressive margins"]], "textrank": [["wavelength services", "impressive margins", "ad nauseam", "industry", "services"], ["wavelength services", "impressive margins", "ad nauseam", "industry", "services"]], "positionrank": [["wavelength services", "such services", "most industry observers", "ad nauseam", "impressive margins"], ["wavelength services", "such services", "most industry observers", "ad nauseam", "impressive margins", "wave", "industry", "years", "time", "technology"]], "multipartiterank": [["wavelength services", "reception", "lukewarm", "many", "expectations"], ["wavelength services", "reception", "lukewarm", "many", "expectations", "reasons", "industry", "time", "ad nauseam", "impressive margins"]]}, {"id": "352", "text": "An efficient retrieval selection algorithm for video servers with random\n\tduplicated assignment storage technique\nRandom duplicated assignment (RDA) is an approach in which video data is stored\n\tby assigning a number of copies of each data block to different,\n\trandomly chosen disks. It has been shown that this approach results in\n\tsmaller response times and lower disk and RAM costs compared to the\n\twell-known disk stripping techniques. Based on this storage approach,\n\tone has to determine, for each given batch of data blocks, from which\n\tdisk each of the data blocks is to be retrieved. This is to be done in\n\tsuch a way that the maximum load of the disks is minimized. The problem\n\tis called the retrieval selection problem (RSP). In this paper, we\n\tpropose a new efficient algorithm for RSP. This algorithm is based on\n\tthe breadth-first search approach and is able to guarantee optimal\n\tsolutions for RSP in O(n/sup 2/+mn), where m and n correspond to the\n\tnumber of data blocks and the number of disks, respectively. We show\n\tthat our proposed algorithm has a lower time complexity than an\n\texisting algorithm, called the MFS algorithm\n", "keywords": "efficient retrieval selection algorithm; video servers; random duplicated\n\tassignment storage technique; copies; data block; randomly chosen\n\tdisks; response times; RAM costs; disk costs; maximum load;\n\tbreadth-first search; optimal solutions; time complexity\n", "topicrank": [["video data", "approach", "rsp", "number", "disks"], ["video data", "approach", "rsp", "number", "disks", "lower disk", "algorithm", "assignment storage technique", "random", "efficient retrieval selection algorithm"]], "textrank": [["video data", "efficient algorithm", "selection algorithm", "storage approach", "search approach"], ["video data", "efficient algorithm", "selection algorithm", "storage approach", "search approach", "lower time", "disk stripping", "lower disk", "ram costs", "data"]], "positionrank": [["new efficient algorithm", "retrieval selection problem", "assignment storage technique", "video servers", "video data"], ["new efficient algorithm", "retrieval selection problem", "assignment storage technique", "video servers", "video data", "mfs algorithm", "algorithm", "storage approach", "first search approach", "data blocks"]], "multipartiterank": [["video data", "approach", "random", "assignment storage technique", "number"], ["video data", "approach", "random", "assignment storage technique", "number", "lower disk", "efficient retrieval selection algorithm", "disks", "rsp", "data blocks"]]}, {"id": "317", "text": "Relevance of Web documents: ghosts consensus method\nThe dominant method currently used to improve the quality of Internet search\n\tsystems is often called \"digital democracy.\" Such an approach implies\n\tthe utilization of the majority opinion of Internet users to determine\n\tthe most relevant documents: for example, citation index usage for\n\tsorting of search results (google.com) or an enrichment of a query with\n\tterms that are asked frequently in relation with the query's theme.\n\t\"Digital democracy\" is an effective instrument in many cases, but it\n\thas an unavoidable shortcoming, which is a matter of principle: the\n\taverage intellectual and cultural level of Internet users is very low;\n\teveryone knows what kind of information is dominant in Internet query\n\tstatistics. Therefore, when one searches the Internet by means of\n\t\"digital democracy\" systems, one gets answers that reflect an\n\tunderlying assumption that the user's mind potential is very low, and\n\tthat his cultural interests are not demanding. Thus, it is more correct\n\tto use the term \"digital ochlocracy\" to refer to Internet search\n\tsystems with \"digital democracy.\" Based on the well-known mathematical\n\tmechanism of linear programming, we propose a method to solve the\n\tindicated problem\n", "keywords": "Internet search systems; digital democracy; majority opinion; citation index\n\tusage; search results; Internet query statistics; digital ochlocracy;\n\tlinear programming; ghosts consensus method; World Wide Web\n", "topicrank": [["internet search", "digital democracy", "systems", "query", "dominant method"], ["internet search", "digital democracy", "systems", "query", "dominant method", "cultural level", "low", "web documents", "ghosts consensus method", "information"]], "textrank": [["internet search", "consensus method", "average intellectual", "unavoidable shortcoming", "many cases"], ["internet search", "consensus method", "average intellectual", "unavoidable shortcoming", "many cases", "effective instrument", "majority opinion", "internet", "cultural", "index"]], "positionrank": [["ghosts consensus method", "dominant method", "web documents", "internet search", "method"], ["ghosts consensus method", "dominant method", "web documents", "internet search", "method", "relevant documents", "internet query", "internet users", "relevance", "digital democracy"]], "multipartiterank": [["internet search", "digital democracy", "systems", "web documents", "ghosts consensus method"], ["internet search", "digital democracy", "systems", "web documents", "ghosts consensus method", "dominant method", "query", "internet users", "cultural level", "low"]]}, {"id": "1974", "text": "Real-time implementation of a new low-memory SPIHT image coding algorithm using\n\tDSP chip\nAmong all algorithms based on wavelet transform and zerotree quantization, Said\n\tand Pearlman's (1996) set partitioning in hierarchical trees (SPIHT)\n\talgorithm is well-known for its simplicity and efficiency. This paper\n\tdeals with the real-time implementation of SPIHT algorithm using DSP\n\tchip. In order to facilitate the implementation and improve the codec's\n\tperformance, some relative issues are thoroughly discussed, such as the\n\toptimization of program structure to speed up the wavelet\n\tdecomposition. SPIHT's high memory requirement is a major drawback for\n\thardware implementation. In this paper, we modify the original SPIHT\n\talgorithm by presenting two new concepts-number of error bits and\n\tabsolute zerotree. Consequently, the memory cost is significantly\n\treduced. We also introduce a new method to control the coding process\n\tby number of error bits. Our experimental results show that the\n\timplementation meets common requirement of real-time video coding and\n\tis proven to be a practical and efficient DSP solution\n", "keywords": "SPIHT algorithm; real-time implementation; wavelet transform; zerotree\n\tquantization; codec; wavelet decomposition; number of error bits;\n\tabsolute zerotree; DSP chip; set partitioning in hierarchical trees;\n\tmemory cost reduction; video coding\n", "topicrank": [["time implementation", "memory spiht image", "algorithm", "real", "new low"], ["time implementation", "memory spiht image", "algorithm", "real", "new low", "wavelet transform", "number", "dsp chip", "error bits", "dsp"]], "textrank": [["memory spiht", "time video coding", "memory requirement", "time implementation", "spiht"], ["memory spiht", "time video coding", "memory requirement", "time implementation", "spiht", "memory", "relative issues", "hierarchical trees", "wavelet transform", "dsp"]], "positionrank": [["time implementation", "memory spiht image", "spiht algorithm", "time video coding", "hardware implementation"], ["time implementation", "memory spiht image", "spiht algorithm", "time video coding", "hardware implementation", "high memory requirement", "implementation", "original spiht", "dsp chip", "spiht"]], "multipartiterank": [["time implementation", "algorithm", "memory spiht image", "new low", "real"], ["time implementation", "algorithm", "memory spiht image", "new low", "real", "dsp chip", "wavelet transform", "zerotree quantization", "spiht", "paper"]]}, {"id": "1931", "text": "Mathematical fundamentals of constructing fuzzy Bayesian inference techniques\nProblems and an associated technique for developing a Bayesian approach to\n\tdecision-making in the case of fuzzy data are presented. The concept of\n\tfuzzy and pseudofuzzy quantities is introduced and main operations with\n\tpseudofuzzy quantities are considered. The basic relationships and the\n\tprincipal concepts of the Bayesian decision procedure based on the\n\tmodus-ponens rule are proposed. Some problems concerned with the\n\tpractical realization of the fuzzy Bayesian method are considered\n", "keywords": "mathematical fundamentals; fuzzy Bayesian inference techniques; decision\n\tmaking; pseudofuzzy quantities; modus-ponens rule\n", "topicrank": [["fuzzy data", "decision", "pseudofuzzy quantities", "problems", "fuzzy bayesian inference techniques"], ["fuzzy data", "decision", "pseudofuzzy quantities", "problems", "fuzzy bayesian inference techniques", "making", "case", "bayesian approach", "concept", "main operations"]], "textrank": [["fuzzy bayesian inference", "fuzzy bayesian", "bayesian decision", "bayesian", "pseudofuzzy quantities"], ["fuzzy bayesian inference", "fuzzy bayesian", "bayesian decision", "bayesian", "pseudofuzzy quantities", "mathematical fundamentals", "fuzzy", "decision", "main"]], "positionrank": [["fuzzy bayesian method", "bayesian decision procedure", "mathematical fundamentals", "bayesian approach", "fuzzy data"], ["fuzzy bayesian method", "bayesian decision procedure", "mathematical fundamentals", "bayesian approach", "fuzzy data", "problems", "pseudofuzzy quantities", "decision", "basic relationships", "practical realization"]], "multipartiterank": [["fuzzy data", "decision", "pseudofuzzy quantities", "problems", "fuzzy bayesian inference techniques"], ["fuzzy data", "decision", "pseudofuzzy quantities", "problems", "fuzzy bayesian inference techniques", "case", "making", "bayesian approach", "concept", "technique"]]}, {"id": "2140", "text": "Strong active solution in non-cooperative games\nFor the non-cooperative games and the problems of accepting or rejecting a\n\tproposal, a new notion of equilibrium was proposed, its place among the\n\tknown basic equilibria was established, and its application to the\n\tstatic and dynamic game problems was demonstrated\n", "keywords": "strong active solution; noncooperative games; static game problems; dynamic\n\tgame problems\n", "topicrank": [["problems", "new notion", "equilibrium", "static", "proposal"], ["problems", "new notion", "equilibrium", "static", "proposal", "place", "application", "basic equilibria", "strong active solution"]], "textrank": [["- cooperative", "new notion", "game", "active"], ["- cooperative", "new notion", "game", "active"]], "positionrank": [["strong active solution", "dynamic game problems", "problems", "new notion", "application"], ["strong active solution", "dynamic game problems", "problems", "new notion", "application", "basic equilibria", "place", "proposal", "equilibrium"]], "multipartiterank": [["new notion", "problems", "equilibrium", "proposal", "static"], ["new notion", "problems", "equilibrium", "proposal", "static", "place", "basic equilibria", "application", "dynamic game problems", "strong active solution"]]}, {"id": "2105", "text": "Collective action in the age of the Internet: mass communication and online\n\tmobilization\nThis article examines how the Internet transforms collective action. Current\n\tpractices on the Web bear witness to thriving collective action ranging\n\tfrom persuasive to confrontational, individual to collective,\n\tundertakings. Even more influential than direct calls for action is the\n\tindirect mobilizing influence of the Internet's powers of mass\n\tcommunication, which is boosted by an antiauthoritarian ideology on the\n\tWeb. Theoretically, collective action through the otherwise socially\n\tisolating computer is possible because people rely on internalized\n\tgroup memberships and social identities to achieve social involvement.\n\tEmpirical evidence from an online survey among environmental activists\n\tand nonactivists confirms that online action is considered an\n\tequivalent alternative to offline action by activists and nonactivists\n\talike. However, the Internet may slightly alter the motives underlying\n\tcollective action and thereby alter the nature of collective action and\n\tsocial movements. Perhaps more fundamental is the reverse influence\n\tthat successful collective action will have on the nature and function\n\tof the Internet\n", "keywords": "Internet; mass communication; online mobilization; collective action; World\n\tWide Web; antiauthoritarian ideology; group memberships; social\n\tidentities; online survey; anonymity; politics\n", "topicrank": [["collective action", "internet", "online", "social identities", "action"], ["collective action", "internet", "online", "social identities", "action", "mass communication", "environmental activists", "web bear witness", "nonactivists", "nature"]], "textrank": [["online action", "collective action", "mobilizing influence", "group memberships", "antiauthoritarian ideology"], ["online action", "collective action", "mobilizing influence", "group memberships", "antiauthoritarian ideology", "direct calls", "mass communication", "social", "action", "bear"]], "positionrank": [["successful collective action", "collective action", "online action", "offline action", "action"], ["successful collective action", "collective action", "online action", "offline action", "action", "mass communication", "web bear witness", "internet", "indirect mobilizing influence", "online survey"]], "multipartiterank": [["collective action", "internet", "online", "mass communication", "social identities"], ["collective action", "internet", "online", "mass communication", "social identities", "web bear witness", "action", "environmental activists", "nonactivists", "mobilization"]]}, {"id": "1989", "text": "Managing system risk\nCompanies are increasingly required to provide assurance that their systems are\n\tsecure and conform to commercial security standards. Senior business\n\tmanagers are ultimately responsible for the security of their corporate\n\tsystems and for the implications in the event of a failure. Businesses\n\twill be exposed to unquantified security risks unless they have a\n\tformal risk management framework in place to enable risks to be\n\tidentified, evaluated and managed. Failure to assess and manage risks\n\tcan lead to a business suffering serious financial impacts, commercial\n\tembarrassment and fines or sanctions from regulators. This is both a\n\tkey responsibility and opportunity for Management Services\n\tPractitioners\n", "keywords": "risk management framework; commercial security standards; IT projects\n", "topicrank": [["commercial security standards", "senior business", "systems", "security", "failure"], ["commercial security standards", "senior business", "systems", "security", "failure", "risks", "fines", "embarrassment", "sanctions", "serious financial impacts"]], "textrank": [["risk management", "commercial security", "serious financial impacts", "security", "key responsibility"], ["risk management", "commercial security", "serious financial impacts", "security", "key responsibility", "senior business", "management", "risk", "business", "commercial"]], "positionrank": [["system risk", "unquantified security risks", "commercial security standards", "security", "senior business"], ["system risk", "unquantified security risks", "commercial security standards", "security", "senior business", "risks", "companies", "systems", "assurance", "serious financial impacts"]], "multipartiterank": [["senior business", "commercial security standards", "systems", "security", "failure"], ["senior business", "commercial security standards", "systems", "security", "failure", "managers", "responsible", "corporate", "risks", "secure"]]}, {"id": "350", "text": "There is no optimal routing policy for the torus\nA routing policy is the method used to select a specific output channel for a\n\tmessage from among a number of acceptable output channels. An optimal\n\trouting policy is a policy that maximizes the probability of a message\n\treaching its destination without delays. Optimal routing policies have\n\tbeen proposed for several regular networks, including the mesh and the\n\thypercube. An open problem in interconnection network research has been\n\tthe identification of an optimal routing policy for the torus. In this\n\tpaper, we show that there is no optimal routing policy for the torus.\n\tOur result is demonstrated by presenting a detailed example in which\n\tthe best choice of output channel is dependent on the probability of\n\teach channel being available. This result settles, in the negative, a\n\tconjecture by J. Wu (1996) concerning an optimal routing policy for the\n\ttorus\n", "keywords": "optimal routing policy; torus; hypercube\n", "topicrank": [["policy", "optimal", "torus", "specific output channel", "probability"], ["policy", "optimal", "torus", "specific output channel", "probability", "message", "result", "delays", "destination", "open problem"]], "textrank": [["output", "several regular", "j. wu", "best choice", "detailed example"], ["output", "several regular", "j. wu", "best choice", "detailed example", "open problem", "network"]], "positionrank": [["specific output channel", "policy", "acceptable output channels", "output channel", "torus"], ["specific output channel", "policy", "acceptable output channels", "output channel", "torus", "interconnection network research", "channel", "several regular networks", "message", "probability"]], "multipartiterank": [["policy", "optimal", "torus", "specific output channel", "message"], ["policy", "optimal", "torus", "specific output channel", "message", "probability", "result", "delays", "acceptable output channels", "destination"]]}, {"id": "315", "text": "The impact of the Internet on public library use: an analysis of the current\n\tconsumer market for library and Internet services\nThe potential impact of the Internet on the public's demand for the services\n\tand resources of public libraries is an issue of critical importance.\n\tThe research reported in this article provides baseline data concerning\n\tthe evolving relationship between the public's use of the library and\n\tits use of the Internet. The authors developed a consumer model of the\n\tAmerican adult market for information services and resources, segmented\n\tby use (or nonuse) of the public library and by access (or lack of\n\taccess) to, and use (or nonuse) of, the Internet. A national Random\n\tDigit Dialing telephone survey collected data to estimate the size of\n\teach of six market segments, and to describe their usage choices\n\tbetween the public library and the Internet. The analyses presented in\n\tthis article provide estimates of the size and demographics of each of\n\tthe market segments; describe why people are currently using the public\n\tlibrary and the Internet; identify the decision criteria people use in\n\ttheir choices of which provider to use; identify areas in which\n\tlibraries and the Internet appear to be competing and areas in which\n\tthey appear to be complementary; and identify reasons why people choose\n\tnot to use the public library and/or the Internet. The data suggest\n\tthat some differentiation between the library and the Internet is\n\ttaking place, which may very well have an impact on consumer choices\n\tbetween the two. Longitudinal research is necessary to fully reveal\n\ttrends in these usage choices, which have implications for all types of\n\tlibraries in planning and policy development\n", "keywords": "Internet; public libraries; baseline data; consumer model; American adult\n\tmarket; national Random Digit Dialing telephone survey; decision\n\tcriteria; public library; longitudinal research\n", "topicrank": [["public library use", "internet", "usage choices", "public libraries", "baseline data"], ["public library use", "internet", "usage choices", "public libraries", "baseline data", "use", "people", "impact", "services", "consumer market"]], "textrank": [["consumer market", "consumer choices", "adult market", "dialing telephone", "public library"], ["consumer market", "consumer choices", "adult market", "dialing telephone", "public library", "national random", "baseline data", "critical importance", "potential impact", "market"]], "positionrank": [["public library use", "public library", "internet services", "public libraries", "internet"], ["public library use", "public library", "internet services", "public libraries", "internet", "library", "public", "potential impact", "consumer market", "consumer choices"]], "multipartiterank": [["public library use", "internet", "impact", "library", "usage choices"], ["public library use", "internet", "impact", "library", "usage choices", "public libraries", "baseline data", "use", "consumer market", "public"]]}, {"id": "2142", "text": "Spectral characteristics of the linear systems over a bounded time interval\nConsideration was given to the spectral characteristics of the linear dynamic\n\tsystems over a bounded time interval. Singular characteristics of\n\tstandard dynamic blocks, transcendental characteristic equations, and\n\tpartial spectra of the singular functions were studied. Relationship\n\tbetween the spectra under study and the classical frequency\n\tcharacteristic was demonstrated\n", "keywords": "spectral characteristics; bounded time interval; linear dynamic systems;\n\tsingular characteristics; standard dynamic blocks; transcendental\n\tcharacteristic equations; partial spectra; singular functions;\n\tfrequency characteristic\n", "topicrank": [["time interval", "singular characteristics", "partial spectra", "transcendental characteristic equations", "linear systems"], ["time interval", "singular characteristics", "partial spectra", "transcendental characteristic equations", "linear systems", "spectral characteristics", "standard dynamic blocks", "linear dynamic", "study", "classical frequency"]], "textrank": [["linear dynamic", "singular characteristics", "dynamic", "characteristic", "singular"], ["linear dynamic", "singular characteristics", "dynamic", "characteristic", "singular", "characteristics", "linear", "time"]], "positionrank": [["spectral characteristics", "singular characteristics", "time interval", "linear systems", "standard dynamic blocks"], ["spectral characteristics", "singular characteristics", "time interval", "linear systems", "standard dynamic blocks", "transcendental characteristic equations", "systems", "singular functions", "partial spectra", "consideration"]], "multipartiterank": [["time interval", "singular characteristics", "linear systems", "spectral characteristics", "transcendental characteristic equations"], ["time interval", "singular characteristics", "linear systems", "spectral characteristics", "transcendental characteristic equations", "partial spectra", "standard dynamic blocks", "linear dynamic", "consideration", "systems"]]}, {"id": "2107", "text": "The effects of asynchronous computer-mediated group interaction on group\n\tprocesses\nThis article reports a study undertaken to investigate some of the social\n\tpsychological processes underlying computer-supported group discussion\n\tin natural computer-mediated contexts. Based on the concept of\n\tdeindividuation, it was hypothesized that personal identifiability and\n\tgroup identity would be important factors that affect the perceptions\n\tand behavior of members of computer-mediated groups. The degree of\n\tpersonal identifiability and the strength of group identity were\n\tmanipulated across groups of geographically dispersed computer users\n\twho took part in e-mail discussions during a 2-week period. The results\n\tdo not support the association between deindividuation and uninhibited\n\tbehavior cited in much previous research. Instead, the data provide\n\tsome support for a social identity perspective of computer-mediated\n\tcommunication, which explains the higher levels uninhibited in\n\tidentifiable computer-mediated groups. However, predictions based on\n\tsocial identity theory regarding group polarization and group cohesion\n\twere not supported. Possible explanations for this are discussed and\n\tfurther research is suggested to resolve these discrepancies\n", "keywords": "asynchronous computer-mediated group interaction; group processes; social\n\tissues; psychology; deindividuation; Internet; personal\n\tidentifiability; group identity; geographically dispersed computer\n\tusers; e-mail discussions; social identity theory; group polarization;\n\tgroup cohesion\n", "topicrank": [["asynchronous computer", "group interaction", "social", "groups", "behavior"], ["asynchronous computer", "group interaction", "social", "groups", "behavior", "deindividuation", "uninhibited", "processes", "personal identifiability", "members"]], "textrank": [["group identity", "computer -", "group", "previous research", "- mail"], ["group identity", "computer -", "group", "previous research", "- mail", "computer", "levels uninhibited", "identity", "possible explanations", "important factors"]], "positionrank": [["group identity", "group interaction", "group discussion", "group polarization", "group cohesion"], ["group identity", "group interaction", "group discussion", "group polarization", "group cohesion", "asynchronous computer", "group", "natural computer", "computer users", "identifiable computer"]], "multipartiterank": [["asynchronous computer", "group interaction", "processes", "effects", "social"], ["asynchronous computer", "group interaction", "processes", "effects", "social", "computer", "article", "groups", "deindividuation", "behavior"]]}, {"id": "208", "text": "Designing a new urban Internet\nThe parallel between designing a Web site and the construction of a building is\n\ta familiar one, but how often do we think of the Internet as having\n\tparks and streets? It would be absurd to say that the Internet could\n\tever take the place of real, livable communities; however, it is safe\n\tto say that the context for using the Internet is on a path of change.\n\tAs the Internet evolves beyond a simple linkage of disparate Web sites\n\tand applications, the challenge for Information Architects is\n\testablishing a process by which to structure, organize, and design\n\tnetworked environments. The principles that guide New Urbanism can\n\toffer much insight into networked electronic environment design. At the\n\tcore of every New Urbanism principle is the idea of \"wholeness\"-of\n\tmaking sure that neighborhoods and communities are knit together in a\n\tway that supports civic activities, economic development, efficient\n\tecosystems, aesthetic beauty, and human interaction\n", "keywords": "Web site; Internet; information architects; private-public sector cooperation;\n\tglobal information networks; networked environments; networked\n\telectronic environment design; communities\n", "topicrank": [["new urban internet", "livable communities", "new urbanism", "economic development", "efficient"], ["new urban internet", "livable communities", "new urbanism", "economic development", "efficient", "disparate web sites", "ecosystems", "challenge", "neighborhoods", "real"]], "textrank": [["networked electronic environment", "new urbanism", "new urban", "much insight", "information architects"], ["networked electronic environment", "new urbanism", "new urban", "much insight", "information architects", "simple linkage", "livable communities", "familiar one", "web", "networked"]], "positionrank": [["new urban internet", "new urbanism principle", "new urbanism", "disparate web sites", "web site"], ["new urban internet", "new urbanism principle", "new urbanism", "disparate web sites", "web site", "internet", "parallel", "simple linkage", "networked environments", "familiar one"]], "multipartiterank": [["new urban internet", "internet", "parallel", "livable communities", "new urbanism"], ["new urban internet", "internet", "parallel", "livable communities", "new urbanism", "web site", "construction", "building", "real", "place"]]}, {"id": "1976", "text": "Adaptive image denoising using scale and space consistency\nThis paper proposes a new method for image denoising with edge preservation,\n\tbased on image multiresolution decomposition by a redundant wavelet\n\ttransform. In our approach, edges are implicitly located and preserved\n\tin the wavelet domain, whilst image noise is filtered out. At each\n\tresolution level, the image edges are estimated by gradient magnitudes\n\t(obtained from the wavelet coefficients), which are modeled\n\tprobabilistically, and a shrinkage function is assembled based on the\n\tmodel obtained. Joint use of space and scale consistency is applied for\n\tbetter preservation of edges. The shrinkage functions are combined to\n\tpreserve edges that appear simultaneously at several resolutions, and\n\tgeometric constraints are applied to preserve edges that are not\n\tisolated. The proposed technique produces a filtered version of the\n\toriginal image, where homogeneous regions appear separated by\n\twell-defined edges. Possible applications include image\n\tpresegmentation, and image denoising\n", "keywords": "adaptive image denoising; scale consistency; space consistency; edge\n\tpreservation; image multiresolution decomposition; redundant wavelet\n\ttransform; image edges; gradient magnitudes; shrinkage function;\n\tgeometric constraints; edge enhancement\n", "topicrank": [["adaptive image", "edges", "redundant wavelet", "space consistency", "scale"], ["adaptive image", "edges", "redundant wavelet", "space consistency", "scale", "edge preservation", "shrinkage function", "joint use", "possible applications", "new method"]], "textrank": [["image multiresolution", "image", "joint use", "gradient magnitudes", "resolution level"], ["image multiresolution", "image", "joint use", "gradient magnitudes", "resolution level", "new method", "wavelet", "shrinkage", "preservation", "consistency"]], "positionrank": [["adaptive image", "image edges", "image multiresolution decomposition", "image noise", "image denoising"], ["adaptive image", "image edges", "image multiresolution decomposition", "image noise", "image denoising", "original image", "image", "scale consistency", "space consistency", "edge preservation"]], "multipartiterank": [["adaptive image", "scale", "space consistency", "edges", "redundant wavelet"], ["adaptive image", "scale", "space consistency", "edges", "redundant wavelet", "paper", "edge preservation", "new method", "image", "transform"]]}, {"id": "1933", "text": "Accelerated simulation of the steady-state availability of non-Markovian\n\tsystems\nA general accelerated simulation method for evaluation of the steady-state\n\tavailability of non-Markovian systems is proposed. It is applied to the\n\tinvestigation of a class of systems with repair. Numerical examples are\n\tgiven\n", "keywords": "accelerated simulation; steady-state availability; non-Markovian systems;\n\tgeneral accelerated simulation method; numerical examples\n", "topicrank": [["systems", "steady", "state availability", "accelerated simulation", "repair"], ["systems", "steady", "state availability", "accelerated simulation", "repair", "state", "class", "evaluation", "numerical examples", "investigation"]], "textrank": [["- markovian", "accelerated simulation", "- state"], ["- markovian", "accelerated simulation", "- state"]], "positionrank": [["accelerated simulation", "state availability", "systems", "state", "availability"], ["accelerated simulation", "state availability", "systems", "state", "availability", "evaluation", "numerical examples", "class", "repair", "investigation"]], "multipartiterank": [["accelerated simulation", "steady", "state availability", "systems", "state"], ["accelerated simulation", "steady", "state availability", "systems", "state", "evaluation", "repair", "class", "general accelerated simulation method", "availability"]]}, {"id": "2182", "text": "Organization design: The continuing influence of information technology\nDrawing from an information processing perspective, this paper examines how\n\tinformation technology (IT) has been a catalyst in the development of\n\tnew forms of organizational structures. The article draws a historical\n\tlinkage between the relative stability of an organization's task\n\tenvironment starting after the Second World War to the present\n\tenvironmental instability that now characterizes many industries.\n\tSpecifically, the authors suggest that advances in IT have enabled\n\tmanagers to adapt existing forms and create new models for\n\torganizational design that better fit requirements of an unstable\n\tenvironment. Time has seemingly borne out this hypothesis as the\n\tbureaucratic structure evolved to the matrix to the network and now to\n\tthe emerging shadow structure. IT has gone from a support mechanism to\n\ta substitute for organizational structures in the form of the shadow\n\tstructure. The article suggests that the evolving and expanding role of\n\tIT will continue for organizations that face unstable environments\n", "keywords": "organization design; information processing perspective; organizational\n\tstructures; organization task environment; environmental instability;\n\tinformation technology\n", "topicrank": [["organizational structures", "environment", "new forms", "article", "bureaucratic structure"], ["organizational structures", "environment", "new forms", "article", "bureaucratic structure", "organization design", "unstable", "shadow structure", "information technology", "task"]], "textrank": [["organizational design", "information processing", "support mechanism", "many industries", "environmental instability"], ["organizational design", "information processing", "support mechanism", "many industries", "environmental instability", "relative stability", "structure", "fit", "world", "new"]], "positionrank": [["organization design", "information processing perspective", "information technology", "organizational design", "organization"], ["organization design", "information processing perspective", "information technology", "organizational design", "organization", "organizational structures", "better fit requirements", "second world war", "new forms", "new models"]], "multipartiterank": [["organization design", "organizational structures", "information technology", "environment", "new forms"], ["organization design", "organizational structures", "information technology", "environment", "new forms", "article", "bureaucratic structure", "shadow structure", "unstable", "influence"]]}, {"id": "235", "text": "The role of CAUL (Council of Australian Libraries) in consortial purchasing\nThe Council of Australian University Librarians, constituted in 1965 for the\n\tpurposes of cooperative action and the sharing of information, assumed\n\tthe role of consortial purchasing agent in 1996 on behalf of its\n\tmembers and associate organisations in Australia and New Zealand. This\n\trole continues to grow in tandem with the burgeoning of electronic\n\tpublication and the acceptance of publishers of the advantages of\n\tdealing with consortia. The needs of the Australian university\n\tcommunity overlap significantly with consortia in North America and\n\tEurope, but important differences are highlighted\n", "keywords": "Council of Australian University Librarians; cooperative action; information\n\tsharing; consortial purchasing; Australia; New Zealand; electronic\n\tpublication; North America; Europe\n", "topicrank": [["australian libraries", "role", "consortial purchasing", "consortia", "council"], ["australian libraries", "role", "consortial purchasing", "consortia", "council", "electronic", "associate organisations", "publication", "australia", "acceptance"]], "textrank": [["australian university", "north america", "new zealand", "associate organisations", "cooperative action"], ["australian university", "north america", "new zealand", "associate organisations", "cooperative action", "consortial purchasing", "australian"]], "positionrank": [["australian university librarians", "australian libraries", "australian university", "consortial purchasing", "role"], ["australian university librarians", "australian libraries", "australian university", "consortial purchasing", "role", "council", "caul", "new zealand", "associate organisations", "north america"]], "multipartiterank": [["australian libraries", "role", "council", "consortial purchasing", "consortia"], ["australian libraries", "role", "council", "consortial purchasing", "consortia", "caul", "associate organisations", "electronic", "australia", "publication"]]}, {"id": "270", "text": "Using molecular equivalence numbers to visually explore structural features\n\tthat distinguish chemical libraries\nA molecular equivalence number (meqnum) classifies a molecule with respect to a\n\tclass of structural features or topological shapes such as its cyclic\n\tsystem or its set of functional groups. Meqnums can be used to organize\n\tmolecular structures into nonoverlapping, yet highly relatable classes.\n\tWe illustrate the construction of some different types of meqnums and\n\tpresent via examples some methods of comparing diverse chemical\n\tlibraries based on meqnums. In the examples we compare a library which\n\tis a random sample from the MDL Drug Data Report (MDDR) with a library\n\twhich is a random sample from the Available Chemical Directory (ACD).\n\tIn our analyses, we discover some interesting features of the\n\ttopological shape of a molecule and its set of functional groups that\n\tare strongly linked with compounds occurring in the MDDR but not in the\n\tACD. We also illustrate the utility of molecular equivalence indices in\n\tdelineating the structural domain over which an SAR conclusion is valid\n", "keywords": "molecular equivalence number; molecule classification; structural features;\n\ttopological shapes; cyclic system; functional groups; nonoverlapping\n\trelatable classes; chemical libraries; MDL Drug Data Report; Available\n\tChemical Directory; molecular equivalence indices\n", "topicrank": [["molecular equivalence numbers", "meqnums", "structural features", "examples", "functional groups"], ["molecular equivalence numbers", "meqnums", "structural features", "examples", "functional groups", "set", "distinguish chemical libraries", "molecule", "random sample", "mddr"]], "textrank": [["molecular equivalence", "chemical", "drug data", "topological shapes", "structural features"], ["molecular equivalence", "chemical", "drug data", "topological shapes", "structural features", "random sample", "different types", "relatable classes", "functional groups", "structural"]], "positionrank": [["molecular equivalence numbers", "molecular equivalence number", "molecular equivalence", "structural features", "distinguish chemical libraries"], ["molecular equivalence numbers", "molecular equivalence number", "molecular equivalence", "structural features", "distinguish chemical libraries", "molecular structures", "structural domain", "interesting features", "available chemical directory", "diverse chemical"]], "multipartiterank": [["molecular equivalence numbers", "structural features", "meqnums", "distinguish chemical libraries", "molecule"], ["molecular equivalence numbers", "structural features", "meqnums", "distinguish chemical libraries", "molecule", "set", "functional groups", "examples", "random sample", "library"]]}, {"id": "23", "text": "Absorption of long waves by nonresonant parametric microstructures\nUsing simple acoustical and mechanical models, we consider the conceptual\n\tpossibility of designing an active absorbing (nonreflecting) coating in\n\tthe form of a thin layer with small-scale stratification and fast time\n\tmodulation of parameters. Algorithms for space-time modulation of the\n\tcontrolled-layer structure are studied in detail for a one-dimensional\n\tboundary-value problem. These algorithms do not require wave-field\n\tmeasurements, which eliminates the self-excitation problem that is\n\tcharacteristic of active systems. The majority of the considered\n\talgorithms of parametric control transform the low-frequency incident\n\twave to high-frequency waves of the technological band for which the\n\twaveguiding medium inside the layer is assumed to be opaque\n\t(absorbing). The efficient use conditions are found for all the\n\talgorithms. It is shown that the absorbing layer can be as thin as\n\tdesired with respect to the minimum spatial scale of the incident wave\n\tand ensures efficient absorption in a wide frequency interval (starting\n\tfrom zero frequency) that is bounded from above only by a finite\n\tspace-time resolution of the parameter-control operations. The\n\tstructure of a three-dimensional parametric \"'black\" coating whose\n\tefficiency is independent of the angle of incidence of an incoming wave\n\tis developed on the basis of the studied one-dimensional problems. The\n\tgeneral solution of the problem of diffraction of incident waves from\n\tsuch a coating is obtained. This solution is analyzed in detail for the\n\tcase of a disk-shaped element\n", "keywords": "acoustical models; mechanical models; active absorbing coating; nonreflecting\n\tcoating; thin layer; small-scale stratification; fast time modulation;\n\tspace-time modulation; controlled-layer structure; one-dimensional\n\tboundary-value problem; parametric control; low-frequency incident\n\twave; high-frequency waves; waveguiding medium; absorbing layer; angle\n\tof incidence; one-dimensional problems; diffraction; disk-shaped\n\telement\n", "topicrank": [["wave", "algorithms", "frequency incident", "value problem", "dimensional"], ["wave", "algorithms", "frequency incident", "value problem", "dimensional", "layer structure", "fast time", "space", "modulation", "parametric control"]], "textrank": [["dimensional parametric", "parametric control", "frequency waves", "frequency incident", "incident waves"], ["dimensional parametric", "parametric control", "frequency waves", "frequency incident", "incident waves", "spatial scale", "efficient use", "incident wave", "absorbing layer", "thin layer"]], "positionrank": [["nonresonant parametric microstructures", "efficient absorption", "long waves", "frequency waves", "incident waves"], ["nonresonant parametric microstructures", "efficient absorption", "long waves", "frequency waves", "incident waves", "absorption", "incident wave", "frequency incident", "dimensional parametric", "parametric control"]], "multipartiterank": [["algorithms", "wave", "frequency incident", "value problem", "modulation"], ["algorithms", "wave", "frequency incident", "value problem", "modulation", "absorption", "dimensional", "long waves", "fast time", "layer structure"]]}, {"id": "2027", "text": "Motion estimation using modified dynamic programming\nA new method for computing precise estimates of the motion vector field of\n\tmoving objects in a sequence of images is proposed. Correspondence\n\tvector-field computation is formulated as a matching optimization\n\tproblem for multiple dynamic images. The proposed method is a heuristic\n\tmodification of dynamic programming applied to the 2-D optimization\n\tproblem. Motion-vector-field estimates using real movie images\n\tdemonstrate good performance of the algorithm in terms of dynamic\n\tmotion analysis\n", "keywords": "modified dynamic programming; motion estimation; precise estimates; motion\n\tvector field; moving objects; image sequence; vector-field computation;\n\tmatching optimization problem; multiple dynamic images; heuristic\n\tmodification; dynamic programming; 2-D optimization problem; motion\n\tvector field estimates; real movie images; algorithm; dynamic motion\n\tanalysis\n", "topicrank": [["images", "motion vector field", "dynamic programming", "motion estimation", "problem"], ["images", "motion vector field", "dynamic programming", "motion estimation", "problem", "field computation", "matching optimization", "new method", "modification", "heuristic"]], "textrank": [["motion vector field", "dynamic images", "field estimates", "movie images", "new method"], ["motion vector field", "dynamic images", "field estimates", "movie images", "new method", "dynamic", "motion", "field", "estimates", "images"]], "positionrank": [["motion vector field", "motion estimation", "multiple dynamic images", "motion analysis", "dynamic programming"], ["motion vector field", "motion estimation", "multiple dynamic images", "motion analysis", "dynamic programming", "motion", "field estimates", "real movie images", "new method", "precise estimates"]], "multipartiterank": [["motion estimation", "motion vector field", "dynamic programming", "images", "new method"], ["motion estimation", "motion vector field", "dynamic programming", "images", "new method", "vector", "problem", "field computation", "matching optimization", "precise estimates"]]}, {"id": "390", "text": "Automated breath detection on long-duration signals using feedforward\n\tbackpropagation artificial neural networks\nA new breath-detection algorithm is presented, intended to automate the\n\tanalysis of respiratory data acquired during sleep. The algorithm is\n\tbased on two independent artificial neural networks (ANN/sub insp/ and\n\tANN/sub expi/) that recognize, in the original signal, windows of\n\tinterest where the onset of inspiration and expiration occurs.\n\tPostprocessing consists in finding inside each of these windows of\n\tinterest minimum and maximum corresponding to each inspiration and\n\texpiration. The ANN/sub insp/ and ANN/sub expi/ correctly determine\n\trespectively 98.0% and 98.7% of the desired windows, when compared with\n\t29 820 inspirations and 29 819 expirations detected by a human expert,\n\tobtained from three entire-night recordings. Postprocessing allowed\n\tdetermination of inspiration and expiration onsets with a mean\n\tdifference with respect to the same human expert of (mean +or- SD) 34\n\t+or- 71 ms for inspiration and 5 +or- 46 ms for expiration. The method\n\tproved to be effective in detecting the onset of inspiration and\n\texpiration in full night continuous recordings. A comparison of five\n\thuman experts performing the same classification task yielded that the\n\tautomated algorithm was undifferentiable from these human experts,\n\tfailing within the distribution of human expert results. Besides being\n\tapplicable to adult respiratory volume data, the presented algorithm\n\twas also successfully applied to infant sleep data, consisting of\n\tuncalibrated rib cage and abdominal movement recordings. A comparison\n\twith two previously published algorithms for breath detection in\n\trespiratory volume signal shows that the presented algorithm has a\n\thigher specificity, while presenting similar or higher positive\n\tpredictive values\n", "keywords": "respiratory movements; automated breath detection; postprocessing; inspiration;\n\texpiration; automated algorithm; human experts; entire-night\n\trecordings; uncalibrated rib cage; abdominal movement recordings;\n\tinfant sleep data; adult respiratory volume data; long-duration\n\tsignals; feedforward backpropagation artificial neural networks; 34 ms;\n\t5 ms\n", "topicrank": [["expiration occurs", "inspiration", "detection algorithm", "human expert", "respiratory data"], ["expiration occurs", "inspiration", "detection algorithm", "human expert", "respiratory data", "ann", "breath detection", "windows", "onset", "night recordings"]], "textrank": [["same human expert", "artificial neural", "night recordings", "human expert", "volume data"], ["same human expert", "artificial neural", "night recordings", "human expert", "volume data", "breath detection", "movement recordings", "volume signal", "sleep data", "same classification"]], "positionrank": [["breath detection", "artificial neural networks", "detection algorithm", "new breath", "duration signals"], ["breath detection", "artificial neural networks", "detection algorithm", "new breath", "duration signals", "respiratory volume signal", "respiratory volume data", "sub insp/", "algorithm", "sub expi/"]], "multipartiterank": [["inspiration", "expiration occurs", "breath detection", "detection algorithm", "ann"], ["inspiration", "expiration occurs", "breath detection", "detection algorithm", "ann", "windows", "respiratory data", "algorithm", "human expert", "backpropagation artificial neural networks"]]}, {"id": "2062", "text": "Underground poetry, collecting poetry, and the librarian\nA powerful encounter with underground poetry and its important role in poetry,\n\tliterature, and culture is discussed. The acquisitions difficulties\n\tencountered in the unique publishing world of underground poetry are\n\tintroduced. Strategies for acquiring underground poetry for library\n\tcollections are proposed, including total immersion and local focus,\n\twith accompanying action\n", "keywords": "librarian; underground poetry; publishing; library collections; out-of-print\n\tbooks; special collections; literature; culture\n", "topicrank": [["underground poetry", "library", "important role", "powerful encounter", "collections"], ["underground poetry", "library", "important role", "powerful encounter", "collections", "literature", "unique publishing world", "total immersion", "culture", "strategies"]], "textrank": [["important role", "powerful encounter", "underground poetry", "publishing", "poetry"], ["important role", "powerful encounter", "underground poetry", "publishing", "poetry"]], "positionrank": [["underground poetry", "poetry", "unique publishing world", "powerful encounter", "important role"], ["underground poetry", "poetry", "unique publishing world", "powerful encounter", "important role", "acquisitions difficulties", "librarian", "total immersion", "strategies", "literature"]], "multipartiterank": [["underground poetry", "library", "collections", "unique publishing world", "powerful encounter"], ["underground poetry", "library", "collections", "unique publishing world", "powerful encounter", "important role", "strategies", "total immersion", "poetry", "local focus"]]}, {"id": "328", "text": "Personality research on the Internet: a comparison of Web-based and traditional\n\tinstruments in take-home and in-class settings\nStudents, faculty, and researchers have become increasingly comfortable with\n\tthe Internet, and many of them are interested in using the Web to\n\tcollect data. Few published studies have investigated the differences\n\tbetween Web-based data and data collected with more traditional\n\tmethods. In order to investigate these potential differences, two\n\timportant factors were crossed in this study: whether the data were\n\tcollected on line or not and whether the data were collected in a group\n\tsetting at a fixed time or individually at a time of the respondent's\n\tchoosing. The Visions of Morality scale (Shelton and McAdams, 1990) was\n\tused, and the participants were assigned to one of four conditions:\n\tin-class Web survey, in-class paper-and-pencil survey; take-home Web\n\tsurvey, and take-home paper-and-pencil survey. No significant\n\tdifferences in scores were found for any condition; however, response\n\trates were affected by the type of survey administered, with the\n\ttake-home Web-based instrument having the lowest response rate.\n\tTherefore, researchers need to be aware that different modes of\n\tadministration may affect subject attrition and may, therefore,\n\tconfound investigations of other independent variables\n", "keywords": "personality research; Internet; Web-based instruments; data collection; Visions\n\tof Morality scale; in-class Web survey; in-class paper-and-pencil\n\tsurvey; take-home Web survey; take-home paper-and-pencil survey;\n\tresponse rates; administration; subject attrition\n", "topicrank": [["web", "class web survey", "data", "differences", "take"], ["web", "class web survey", "data", "differences", "take", "traditional", "class settings", "home", "response", "internet"]], "textrank": [["class web survey", "home web", "confound investigations", "subject attrition", "different modes"], ["class web survey", "home web", "confound investigations", "subject attrition", "different modes", "morality scale", "important factors", "potential differences", "personality research", "independent"]], "positionrank": [["class web survey", "home web", "personality research", "web", "home paper"], ["class web survey", "home web", "personality research", "web", "home paper", "pencil survey", "internet", "class paper", "comparison", "class settings"]], "multipartiterank": [["web", "data", "class web survey", "differences", "take"], ["web", "data", "class web survey", "differences", "take", "class settings", "traditional", "home", "internet", "researchers"]]}, {"id": "405", "text": "Learning spatial relations using an inductive logic programming system\nThe ability to learn spatial relations is a prerequisite for performing many\n\trelevant tasks such as those associated with motion, orientation,\n\tnavigation, etc. This paper reports on using an Inductive Logic\n\tProgramming (ILP) system for learning function-free Horn-clause\n\tdescriptions of spatial knowledge. Its main contribution, however, is\n\tto show that an existing relation between two reference systems-the\n\tspeaker-relative and the absolute-can be automatically learned by an\n\tILP system, given the proper background knowledge and positive examples\n", "keywords": "spatial relations learning; inductive logic programming system; spatial\n\trelations; function-free Horn-clause descriptions\n", "topicrank": [["spatial relations", "ilp", "inductive logic programming system", "free horn", "clause"], ["spatial relations", "ilp", "inductive logic programming system", "free horn", "clause", "programming", "descriptions", "system", "function", "orientation"]], "textrank": [["logic programming system", "background knowledge", "spatial knowledge", "main contribution", "free horn"], ["logic programming system", "background knowledge", "spatial knowledge", "main contribution", "free horn", "tasks", "system", "logic", "spatial", "programming"]], "positionrank": [["spatial relations", "spatial knowledge", "inductive logic", "ilp system", "system"], ["spatial relations", "spatial knowledge", "inductive logic", "ilp system", "system", "programming", "proper background knowledge", "relevant tasks", "free horn", "ilp"]], "multipartiterank": [["spatial relations", "inductive logic programming system", "ilp", "ability", "prerequisite"], ["spatial relations", "inductive logic programming system", "ilp", "ability", "prerequisite", "programming", "system", "free horn", "orientation", "many"]]}, {"id": "1992", "text": "Geometrically invariant watermarking using feature points\nThis paper presents a new approach for watermarking of digital images providing\n\trobustness to geometrical distortions. The weaknesses of classical\n\twatermarking methods to geometrical distortions are outlined first.\n\tGeometrical distortions can be decomposed into two classes: global\n\ttransformations such as rotations and translations and local\n\ttransformations such as the StirMark attack. An overview of existing\n\tself-synchronizing schemes is then presented. Theses schemes can use\n\tperiodical properties of the mark, invariant properties of transforms,\n\ttemplate insertion, or information provided by the original image to\n\tcounter geometrical distortions. Thereafter, a new class of\n\twatermarking schemes using the image content is presented. We propose\n\tan embedding and detection scheme where the mark is bound with a\n\tcontent descriptor defined by salient points. Three different types of\n\tfeature points are studied and their robustness to geometrical\n\ttransformations is evaluated to develop an enhanced detector. The\n\tembedding of the signature is done by extracting feature points of the\n\timage and performing a Delaunay tessellation on the set of points. The\n\tmark is embedded using a classical additive scheme inside each triangle\n\tof the tessellation. The detection is done using correlation properties\n\ton the different triangles. The performance of the presented scheme is\n\tevaluated after JPEG compression, geometrical attack and\n\ttransformations. Results show that the fact that the scheme is robust\n\tto these different manipulations. Finally, in our concluding remarks,\n\twe analyze the different perspectives of such content-based\n\twatermarking scheme\n", "keywords": "geometrically invariant watermarking; feature points; digital images;\n\tgeometrical distortions; global transformations; rotations;\n\ttranslations; local transformations; StirMark attack;\n\tself-synchronizing schemes; periodical properties; invariant\n\tproperties; transforms; template insertion; image content; embedding;\n\tdetection scheme; content descriptor; feature extraction; Delaunay\n\ttessellation; additive scheme; correlation properties; JPEG\n\tcompression; geometrical attack\n", "topicrank": [["geometrical distortions", "feature points", "detection scheme", "different types", "mark"], ["geometrical distortions", "feature points", "detection scheme", "different types", "mark", "original image", "schemes", "transformations", "classical", "robustness"]], "textrank": [["geometrical attack", "watermarking scheme", "such content", "additive scheme", "image content"], ["geometrical attack", "watermarking scheme", "such content", "additive scheme", "image content", "different", "delaunay tessellation", "enhanced detector", "template insertion", "digital images"]], "positionrank": [["counter geometrical distortions", "feature points", "geometrical distortions", "invariant properties", "geometrical attack"], ["counter geometrical distortions", "feature points", "geometrical distortions", "invariant properties", "geometrical attack", "salient points", "points", "classical additive scheme", "new approach", "image content"]], "multipartiterank": [["geometrical distortions", "feature points", "invariant", "mark", "schemes"], ["geometrical distortions", "feature points", "invariant", "mark", "schemes", "robustness", "original image", "different types", "detection scheme", "classical"]]}, {"id": "211", "text": "Pervasive computing goes to work: interfacing to the enterprise\nThe paperless office is an idea whose time has come, and come, and come again.\n\tTo see how pervasive computing applications might bring some substance\n\tto this dream, the author spoke recently with key managers and\n\ttechnologists at McKesson Corporation (San Francisco), a healthcare\n\tsupplier, service, and technology company with US$50 billion in sales\n\tlast year, and also at AvantGo (Hayward, Calif.), a provider of mobile\n\tinfrastructure software and services. For the past several years,\n\tMcKesson has used mobility middleware developed by AvantGo to deploy\n\tmajor supply chain applications with thousands of pervasive clients and\n\tmultiple servers that replace existing paper-based tracking systems.\n\tAccording to McKesson's managers, their system greatly reduced errors\n\tand associated costs caused by redelivery or loss of valuable products,\n\tgiving McKesson a solid return on its investment\n", "keywords": "paperless office; pervasive clients; multiple servers; mobile workers;\n\tenterprise resource planning; data warehousing\n", "topicrank": [["mckesson corporation", "pervasive computing", "key managers", "avantgo", "infrastructure software"], ["mckesson corporation", "pervasive computing", "key managers", "avantgo", "infrastructure software", "supplier", "mobile", "service", "thousands", "loss"]], "textrank": [["supply chain applications", "pervasive computing applications", "pervasive computing", "last year", "technology company"], ["supply chain applications", "pervasive computing applications", "pervasive computing", "last year", "technology company", "san francisco", "mckesson corporation", "key managers", "paperless office", "several"]], "positionrank": [["pervasive computing applications", "pervasive computing", "pervasive clients", "paperless office", "enterprise"], ["pervasive computing applications", "pervasive computing", "pervasive clients", "paperless office", "enterprise", "multiple servers", "work", "mckesson corporation", "key managers", "mckesson"]], "multipartiterank": [["pervasive computing", "mckesson corporation", "key managers", "mckesson", "work"], ["pervasive computing", "mckesson corporation", "key managers", "mckesson", "work", "technologists", "avantgo", "san francisco", "paperless office", "enterprise"]]}, {"id": "254", "text": "What you get is what you see [Web performance monitoring]\nTo get the best possible performance from your Web infrastructure, you'll need\n\ta complete view. Don't neglect the big picture because you're too busy\n\tconcentrating on details. The increasing complexity of Web sites and\n\tthe content they provide has consequently increased the complexity of\n\tthe infrastructure that supports them. But with some knowledge of\n\tnetworking, a handful of useful tools, and the insight that those tools\n\tprovide, designing and operating for optimal performance and\n\treliability is within your grasp\n", "keywords": "Web performance; Web sites; Web infrastructure; networking; reliability\n", "topicrank": [["useful tools", "complexity", "web infrastructure", "handful", "web sites"], ["useful tools", "complexity", "web infrastructure", "handful", "web sites", "networking", "insight", "knowledge", "optimal performance", "details"]], "textrank": [["web performance", "possible performance", "performance", "big picture", "complete view"], ["web performance", "possible performance", "performance", "big picture", "complete view", "web", "useful"]], "positionrank": [["web performance monitoring", "best possible performance", "web infrastructure", "web sites", "optimal performance"], ["web performance monitoring", "best possible performance", "web infrastructure", "web sites", "optimal performance", "complete view", "useful tools", "big picture", "infrastructure", "complexity"]], "multipartiterank": [["useful tools", "complexity", "web infrastructure", "handful", "networking"], ["useful tools", "complexity", "web infrastructure", "handful", "networking", "web sites", "insight", "best possible performance", "knowledge", "details"]]}, {"id": "349", "text": "A self-adjusting quality of service control scheme\nWe propose and analyze a self-adjusting Quality of Service (QoS) control scheme\n\twith the goal of optimizing the system reward as a result of servicing\n\tdifferent priority clients with varying workload, QoS and\n\treward/penalty requirements. Our scheme is based on resource\n\tpartitioning and designated \"degrade QoS areas\" such that system\n\tresources are partitioned into priority areas each of which is reserved\n\tspecifically to serve only clients in a corresponding class with no QoS\n\tdegradation, plus one \"degraded QoS area\" into which all clients can be\n\tadmitted with QoS adjustment being applied only to the lowest priority\n\tclients. We show that the best partition is dictated by the workload\n\tand the reward/penalty characteristics of clients in difference\n\tpriority classes. The analysis results can be used by a QoS manager to\n\toptimize the system total reward dynamically in response to changing\n\tworkloads at run time. We demonstrate the validity of our scheme by\n\tmeans of simulation and comparing the proposed QoS self-adjusting\n\tscheme with those that do not use resource partitioning or designated\n\tdegraded QoS areas\n", "keywords": "self-adjusting quality of service control scheme; priority clients; resource\n\tpartitioning; simulation; multimedia systems; performance evaluation;\n\tresource reservation\n", "topicrank": [["qos", "system reward", "service control scheme", "different priority clients", "priority areas"], ["qos", "system reward", "service control scheme", "different priority clients", "priority areas", "penalty requirements", "self", "workload", "quality", "resource"]], "textrank": [["qos areas", "priority clients", "qos", "priority areas", "priority"], ["qos areas", "priority clients", "qos", "priority areas", "priority", "analysis results", "best partition", "corresponding class", "system reward", "penalty"]], "positionrank": [["proposed qos self", "service control scheme", "control scheme", "degrade qos areas", "qos areas"], ["proposed qos self", "service control scheme", "control scheme", "degrade qos areas", "qos areas", "qos manager", "qos adjustment", "qos area", "qos", "different priority clients"]], "multipartiterank": [["qos", "service control scheme", "system reward", "quality", "different priority clients"], ["qos", "service control scheme", "system reward", "quality", "different priority clients", "self", "workload", "penalty requirements", "priority areas", "servicing"]]}, {"id": "2003", "text": "Nonlinear modeling and adaptive fuzzy control of MCFC stack\nTo improve availability and performance of fuel cells, the operating\n\ttemperature of the molten carbonate fuel cells (MCFC) stack should be\n\tcontrolled within a specified range. However, most existing models of\n\tMCFC are not ready to be applied in synthesis. In the paper, a radial\n\tbasis function neural networks identification model of a MCFC stack is\n\tdeveloped based on the input-output sampled data. An adaptive fuzzy\n\tcontrol procedure for the temperature of the MCFC stack is also\n\tdeveloped. The parameters of the fuzzy control system are regulated by\n\tback-propagation algorithm, and the rule database of the fuzzy system\n\tis also adaptively adjusted by the nearest-neighbor-clustering\n\talgorithm. Finally using the neural networks model of MCFC stack, the\n\tsimulation results of the control algorithm are presented. The results\n\tshow the effectiveness of the proposed modeling and design procedures\n\tfor the MCFC stack based on neural networks identification and the\n\tnovel adaptive fuzzy control\n", "keywords": "nonlinear modeling; adaptive fuzzy control; MCFC stack; fuel cells; molten\n\tcarbonate fuel cells stack; radial basis function neural networks\n\tidentification model; input-output sampled data; backpropagation\n\talgorithm; rule database; nearest-neighbor-clustering algorithm\n", "topicrank": [["mcfc stack", "adaptive fuzzy control", "propagation algorithm", "fuel cells", "temperature"], ["mcfc stack", "adaptive fuzzy control", "propagation algorithm", "fuel cells", "temperature", "nonlinear modeling", "neural networks model", "simulation results", "output", "data"]], "textrank": [["adaptive fuzzy control", "function neural networks", "fuzzy control", "control algorithm", "carbonate fuel"], ["adaptive fuzzy control", "function neural networks", "fuzzy control", "control algorithm", "carbonate fuel", "adaptive fuzzy", "neural networks", "rule database", "mcfc stack", "nonlinear modeling"]], "positionrank": [["adaptive fuzzy control", "mcfc stack", "fuzzy control system", "nonlinear modeling", "neural networks identification"], ["adaptive fuzzy control", "mcfc stack", "fuzzy control system", "nonlinear modeling", "neural networks identification", "control algorithm", "neural networks model", "mcfc", "stack", "control procedure"]], "multipartiterank": [["mcfc stack", "adaptive fuzzy control", "nonlinear modeling", "fuel cells", "propagation algorithm"], ["mcfc stack", "adaptive fuzzy control", "nonlinear modeling", "fuel cells", "propagation algorithm", "temperature", "mcfc", "performance", "availability", "neural networks model"]]}, {"id": "2046", "text": "Designing and delivering a university course - a process (or operations)\n\tmanagement perspective\nWith over 30 years of academic experience in both engineering and management\n\tfaculties, involving trial and error experimentation in teaching as\n\twell as reading relevant literature and observing other instructors in\n\taction, the author has accumulated a number of ideas, regarding the\n\tpreparation and delivery of a university course, that should be of\n\tinterest to other instructors. This should be particularly the case for\n\tthose individuals who have had little or no teaching experience (e.g.\n\tthose whose graduate education was recently completed at\n\tresearch-oriented institutions providing little guidance with respect\n\tto teaching). A particular perspective is used to convey the ideas,\n\tnamely one of viewing the preparation and delivery of a course as two\n\tmajor processes that should provide outputs or outcomes that are of\n\tvalue to a number of customers, in particular, students\n", "keywords": "university course delivery; management perspective; academic experience;\n\tmanagement faculties; engineering faculties; search-oriented\n\tinstitutions\n", "topicrank": [["teaching", "university course", "management perspective", "number", "little"], ["teaching", "university course", "management perspective", "number", "little", "delivery", "preparation", "particular perspective", "ideas", "error experimentation"]], "textrank": [["little guidance", "graduate education", "other instructors", "relevant literature", "error experimentation"], ["little guidance", "graduate education", "other instructors", "relevant literature", "error experimentation", "university course", "experience", "perspective", "course", "little"]], "positionrank": [["university course", "course", "management perspective", "designing", "teaching experience"], ["university course", "course", "management perspective", "designing", "teaching experience", "process", "management", "particular perspective", "academic experience", "other instructors"]], "multipartiterank": [["teaching", "university course", "management perspective", "little", "delivery"], ["teaching", "university course", "management perspective", "little", "delivery", "number", "preparation", "ideas", "particular perspective", "error experimentation"]]}, {"id": "389", "text": "Bayesian nonstationary autoregressive models for biomedical signal analysis\nWe describe a variational Bayesian algorithm for the estimation of a\n\tmultivariate autoregressive model with time-varying coefficients that\n\tadapt according to a linear dynamical system. The algorithm allows for\n\ttime and frequency domain characterization of nonstationary\n\tmultivariate signals and is especially suited to the analysis of\n\tevent-related data. Results are presented on synthetic data and real\n\telectroencephalogram data recorded in event-related desynchronization\n\tand photic synchronization scenarios\n", "keywords": "photic synchronization scenarios; event-related desynchronization; frequency\n\tdomain characterization; time domain characterization; biomedical\n\tsignal analysis; Kalman smoother; EEG analysis; Bayesian nonstationary\n\tautoregressive models; linear dynamical system; variational Bayesian\n\talgorithm; time-varying coefficients\n", "topicrank": [["data", "time", "event", "biomedical signal analysis", "variational bayesian algorithm"], ["data", "time", "event", "biomedical signal analysis", "variational bayesian algorithm", "frequency domain characterization", "nonstationary", "multivariate signals", "real", "results"]], "textrank": [["bayesian nonstationary autoregressive", "multivariate autoregressive", "biomedical signal", "bayesian", "synchronization"], ["bayesian nonstationary autoregressive", "multivariate autoregressive", "biomedical signal", "bayesian", "synchronization", "data", "domain", "dynamical", "multivariate", "nonstationary"]], "positionrank": [["variational bayesian algorithm", "biomedical signal analysis", "autoregressive model", "multivariate signals", "frequency domain characterization"], ["variational bayesian algorithm", "biomedical signal analysis", "autoregressive model", "multivariate signals", "frequency domain characterization", "analysis", "algorithm", "multivariate", "time", "linear dynamical system"]], "multipartiterank": [["data", "biomedical signal analysis", "time", "variational bayesian algorithm", "event"], ["data", "biomedical signal analysis", "time", "variational bayesian algorithm", "event", "results", "bayesian nonstationary autoregressive models", "frequency domain characterization", "estimation", "multivariate autoregressive model"]]}, {"id": "374", "text": "Horizontal waypoint guidance design using optimal control\nA horizontal waypoint guidance algorithm is proposed by applying line-following\n\tguidance to waypoint line segments in sequence. The line-following\n\tguidance is designed using an LQR (linear quadratic regulator). Then,\n\tthe optimal waypoint changing points are derived by minimizing the\n\taccelerations required for changing the waypoint line segments. Also\n\tderived is a sufficient condition for the stability bound of ground\n\tspeed changes based on the Lyapunov stability theorem. Simulation\n\tresults show that the proposed algorithm can effectively guide a\n\tvehicle along the sequence of waypoint line segments\n", "keywords": "horizontal waypoint guidance algorithm; line-following guidance; waypoint line\n\tsegments; LQR; linear quadratic regulator; optimal waypoint changing\n\tpoints; stability bound; ground speed changes; Lyapunov stability\n\ttheorem; unmanned flying vehicle; threat avoidance; terrain masking;\n\tattack directions; target location arrival time\n", "topicrank": [["line", "stability", "sequence", "optimal control", "guidance"], ["line", "stability", "sequence", "optimal control", "guidance", "horizontal waypoint guidance design", "simulation", "ground", "speed changes", "results"]], "textrank": [["waypoint guidance", "optimal waypoint", "waypoint line", "sufficient condition", "guidance"], ["waypoint guidance", "optimal waypoint", "waypoint line", "sufficient condition", "guidance", "stability", "quadratic", "line", "optimal"]], "positionrank": [["waypoint line segments", "optimal waypoint", "line segments", "guidance", "optimal control"], ["waypoint line segments", "optimal waypoint", "line segments", "guidance", "optimal control", "line", "linear quadratic regulator", "algorithm", "lyapunov stability theorem", "sequence"]], "multipartiterank": [["line", "horizontal waypoint guidance design", "optimal control", "guidance", "sequence"], ["line", "horizontal waypoint guidance design", "optimal control", "guidance", "sequence", "stability", "waypoint line segments", "ground", "speed changes", "simulation"]]}, {"id": "2086", "text": "A design to cost system for innovative product development\nPresents a prototype object-oriented and rule-based system for product cost\n\tmodelling and design for automation at an early design stage. The\n\tdeveloped system comprises a computer aided design (CAD) solid\n\tmodelling system, a material selection module, a knowledge-based system\n\t(KBS), a process optimization module, a design for assembly module, a\n\tcost estimation module and a user interface. Two manufacturing\n\tprocesses, namely machining and injection moulding processes, were\n\tconsidered in the developed system. The main function of the system,\n\tbesides estimating the product cost, is to generate initial process\n\tplanning, including the generation and selection of machining\n\tprocesses, their sequence and their machining parameters, and to\n\trecommend the most economical assembly technique for a product and\n\tprovide design improvement suggestions based on a design feasibility\n\ttechnique. In addition, a feature-by-feature cost estimation report is\n\tgenerated using the proposed system to highlight the features of high\n\tmanufacturing cost. Two case studies were used to validate the\n\tdeveloped system\n", "keywords": "design to cost system; innovative product development; object-oriented\n\trule-based system; product cost modelling; design for automation;\n\tcomputer aided design solid modelling system; material selection\n\tmodule; knowledge-based system; process optimization module; design for\n\tassembly module; cost estimation module; user interface; machining;\n\tinjection moulding; process planning; feature-by-feature cost\n\testimation report; fuzzy logic; object-oriented programming; concurrent\n\tengineering\n", "topicrank": [["design", "system", "innovative product development", "modelling", "processes"], ["design", "system", "innovative product development", "modelling", "processes", "material selection module", "economical assembly technique", "cost estimation module", "cad", "solid"]], "textrank": [["cost estimation module", "process optimization module", "product cost", "design improvement", "cost system"], ["cost estimation module", "process optimization module", "product cost", "design improvement", "cost system", "assembly module", "cost estimation", "selection module", "design", "user interface"]], "positionrank": [["modelling system", "early design stage", "developed system", "design improvement suggestions", "design feasibility"], ["modelling system", "early design stage", "developed system", "design improvement suggestions", "design feasibility", "system", "design", "cost estimation module", "product cost", "innovative product development"]], "multipartiterank": [["design", "system", "innovative product development", "modelling", "product cost"], ["design", "system", "innovative product development", "modelling", "product cost", "processes", "material selection module", "developed system", "cost estimation module", "cad"]]}, {"id": "331", "text": "Multidimensional data visualization\nHistorically, data visualization has been limited primarily to two dimensions\n\t(e.g., histograms or scatter plots). Available software packages (e.g.,\n\tData Desk 6.1, MatLab 6.1, SAS-JMP 4.04, SPSS 10.0) are capable of\n\tproducing three-dimensional scatter plots with (varying degrees of)\n\tuser interactivity. We constructed our own data visualization\n\tapplication with the Visualization Toolkit (Schroeder et al., 1998) and\n\tTcl/Tk to display multivariate data through the application of glyphs\n\t(Ware, 2000). A glyph is a visual object onto which many data\n\tparameters may be mapped, each with a different visual attribute (e.g.,\n\tsize or color). We used our multi-dimensional data viewer to explore\n\tdata from several psycholinguistic experiments. The graphical interface\n\tprovides flexibility when users dynamically explore the\n\tmultidimensional image rendered from raw experimental data. We\n\thighlight advantages of multidimensional data visualization and\n\tconsider some potential limitations\n", "keywords": "multidimensional data visualization; 3D scatter plots; user interactivity;\n\tVisualization Toolkit; Tcl/Tk; multivariate data display; glyphs;\n\tvisual object; data parameters; visual attribute; multi-dimensional\n\tdata viewer; psycholinguistic experiments; graphical interface;\n\tmultidimensional image rendering\n", "topicrank": [["multidimensional data visualization", "application", "scatter plots", "sas", "jmp"], ["multidimensional data visualization", "application", "scatter plots", "sas", "jmp", "glyphs", "flexibility", "several psycholinguistic experiments", "matlab", "users"]], "textrank": [["- dimensional data", "multidimensional data visualization", "experimental data", "data visualization", "data"], ["- dimensional data", "multidimensional data visualization", "experimental data", "data visualization", "data", "- dimensional scatter", "et al", "highlight advantages", "graphical interface", "user interactivity"]], "positionrank": [["multidimensional data visualization", "own data visualization", "data visualization", "raw experimental data", "data desk"], ["multidimensional data visualization", "own data visualization", "data visualization", "raw experimental data", "data desk", "multivariate data", "many data", "data", "multidimensional image", "visualization toolkit"]], "multipartiterank": [["multidimensional data visualization", "highlight advantages", "scatter plots", "raw experimental data", "application"], ["multidimensional data visualization", "highlight advantages", "scatter plots", "raw experimental data", "application", "potential limitations", "multidimensional image", "flexibility", "users", "several psycholinguistic experiments"]]}, {"id": "1952", "text": "Comprehensive encoding and decoupling solution to problems of decoherence and\n\tdesign in solid-state quantum computing\nProposals for scalable quantum computing devices suffer not only from\n\tdecoherence due to the interaction with their environment, but also\n\tfrom severe engineering constraints. Here we introduce a practical\n\tsolution to these major concerns, addressing solid-state proposals in\n\tparticular. Decoherence is first reduced by encoding a logical qubit\n\tinto two qubits, then completely eliminated by an efficient set of\n\tdecoupling pulse sequences. The same encoding removes the need for\n\tsingle-qubit operations, which pose a difficult design constraint. We\n\tfurther show how the dominant decoherence processes can be identified\n\tempirically, in order to optimize the decoupling pulses\n", "keywords": "solid-state quantum computing; decoherence; logical qubit encoding; pulse\n\tsequence decoupling; engineering constraints; decoupling pulse\n\toptimization; scalable quantum computing devices; exchange Hamiltonian\n", "topicrank": [["decoherence", "solid", "proposals", "solution", "state quantum computing"], ["decoherence", "solid", "proposals", "solution", "state quantum computing", "design", "logical qubit", "problems", "major concerns", "particular"]], "textrank": [["state quantum computing", "quantum computing", "efficient set", "major concerns", "qubit"], ["state quantum computing", "quantum computing", "efficient set", "major concerns", "qubit", "engineering", "design", "decoherence", "encoding", "state"]], "positionrank": [["comprehensive encoding", "dominant decoherence processes", "same encoding", "state proposals", "quantum computing"], ["comprehensive encoding", "dominant decoherence processes", "same encoding", "state proposals", "quantum computing", "decoherence", "difficult design constraint", "solution", "state", "qubit operations"]], "multipartiterank": [["decoherence", "solid", "proposals", "state quantum computing", "solution"], ["decoherence", "solid", "proposals", "state quantum computing", "solution", "design", "logical qubit", "problems", "scalable quantum computing devices", "state proposals"]]}, {"id": "195", "text": "The acquisition of out-of-print music\nNon-specialist librarians are alerted to factors important in the successful\n\tacquisition of out-of-print music, both scholarly editions and\n\tperformance editions. The appropriate technical music vocabulary, the\n\tmusic publishing industry, specialized publishers and vendors, and\n\tmethods of acquisition of out-of-print printed music are introduced,\n\tand the need for familiarity with them is emphasized\n", "keywords": "out-of-print music; scholarly editions; performance editions; technical music\n\tvocabulary; music publishing industry; specialized publishers;\n\tspecialized vendors; out-of-print printed music\n", "topicrank": [["print music", "acquisition", "scholarly editions", "specialized publishers", "vendors"], ["print music", "acquisition", "scholarly editions", "specialized publishers", "vendors", "methods", "successful", "appropriate technical music vocabulary", "print", "need"]], "textrank": [["music publishing", "technical music", "- specialist", "music", "editions"], ["music publishing", "technical music", "- specialist", "music", "editions", "-", "factors"]], "positionrank": [["print music", "music publishing industry", "music", "acquisition", "print"], ["print music", "music publishing industry", "music", "acquisition", "print", "performance editions", "scholarly editions", "specialized publishers", "factors", "vendors"]], "multipartiterank": [["print music", "acquisition", "scholarly editions", "successful", "specialized publishers"], ["print music", "acquisition", "scholarly editions", "successful", "specialized publishers", "appropriate technical music vocabulary", "vendors", "methods", "factors important", "print"]]}, {"id": "269", "text": "Genetic algorithm guided selection: variable selection and subset selection\nA novel genetic algorithm guided selection method, GAS, has been described. The\n\tmethod utilizes a simple encoding scheme which can represent both\n\tcompounds and variables used to construct a QSAR/QSPR model. A genetic\n\talgorithm is then utilized to simultaneously optimize the encoded\n\tvariables that include both descriptors and compound subsets. The GAS\n\tmethod generates multiple models each applying to a subset of the\n\tcompounds. Typically the subsets represent clusters with different\n\tchemotypes. Also a procedure based on molecular similarity is presented\n\tto determine which model should be applied to a given test set\n\tcompound. The variable selection method implemented in GAS has been\n\ttested and compared using the Selwood data set (n = 31 compounds; nu =\n\t53 descriptors). The results showed that the method is comparable to\n\tother published methods. The subset selection method implemented in GAS\n\thas been first tested using an artificial data set (n = 100 points; nu\n\t= 1 descriptor) to examine its ability to subset data points and second\n\tapplied to analyze the XLOGP data set (n = 1831 compounds; nu = 126\n\tdescriptors). The method is able to correctly identify artificial data\n\tpoints belonging to various subsets. The analysis of the XLOGP data set\n\tshows that the subset selection method can be useful in improving a\n\tQSAR/QSPR model when the variable selection method fails\n", "keywords": "genetic algorithm guided selection method; encoding scheme; compounds;\n\tvariables; variable selection; subset selection; QSAR/QSPR model;\n\toptimization; descriptors; compound subsets; multiple models; clusters;\n\tchemotypes; molecular similarity; Selwood data set; XLOGP data set;\n\tartificial data points\n", "topicrank": [["selection", "method", "selwood data set", "gas", "compounds"], ["selection", "method", "selwood data set", "gas", "compounds", "genetic algorithm", "descriptors", "points", "qspr model", "subsets"]], "textrank": [["data set", "novel genetic algorithm", "data", "simple encoding", "genetic algorithm"], ["data set", "novel genetic algorithm", "data", "simple encoding", "genetic algorithm", "molecular similarity", "multiple models", "qspr model", "selection", "subsets"]], "positionrank": [["subset selection method", "variable selection method", "selection method", "novel genetic algorithm", "subset selection"], ["subset selection method", "variable selection method", "selection method", "novel genetic algorithm", "subset selection", "variable selection", "genetic algorithm", "selection", "method", "xlogp data set"]], "multipartiterank": [["genetic algorithm", "selection", "gas", "method", "compounds"], ["genetic algorithm", "selection", "gas", "method", "compounds", "selwood data set", "descriptors", "qspr model", "points", "variables"]]}, {"id": "2166", "text": "Don't always believe what you Reed [optimisation techniques for Web sites and\n\ttrade mark infringement]\nOn 20 May 2002, Mr Justice Pumfrey gave judgment in the case of (1) Reed\n\tExecutive Plc (2) Reed Solutions Plc versus (1) Reed Business\n\tInformation Limited (2) Reed Elsevier (UK) Limited (3) totaljobs.com\n\tLimited. The case explored for the first time in any detail the extent\n\tto which the use of various optimisation techniques for Web sites could\n\tgive rise to new forms of trade mark infringement and passing off. The\n\tauthor reports on the case and offers his comments\n", "keywords": "Reed Executive Plc; Reed Solutions Plc; Reed Business Information Limited; Reed\n\tElsevier (UK) Limited; totaljobs.com Limited; optimisation techniques;\n\tWeb sites; trade mark infringement; passing off\n", "topicrank": [["case", "optimisation techniques", "web sites", "trade mark infringement", "reed business"], ["case", "optimisation techniques", "web sites", "trade mark infringement", "reed business", "information limited", "new forms", "detail", "extent", "mr justice pumfrey"]], "textrank": [["reed solutions plc", "information limited", "web sites", "reed", "justice"], ["reed solutions plc", "information limited", "web sites", "reed", "justice", "mark", "optimisation", "plc", "limited"]], "positionrank": [["trade mark infringement", "various optimisation techniques", "web sites", "optimisation techniques", "reed solutions plc"], ["trade mark infringement", "various optimisation techniques", "web sites", "optimisation techniques", "reed solutions plc", "mr justice pumfrey", "reed business", "reed elsevier", "information limited", "new forms"]], "multipartiterank": [["web sites", "case", "optimisation techniques", "reed business", "information limited"], ["web sites", "case", "optimisation techniques", "reed business", "information limited", "trade mark infringement", "mr justice pumfrey", "various optimisation techniques", "judgment", "new forms"]]}, {"id": "2123", "text": "\"Hidden convexity\" of finite-dimensional stationary linear discrete-time\n\tsystems under conical constraints\nNew properties of finite-dimensional linear discrete-time systems under conical\n\tcontrol constraints that are similar to the \"hidden convexity\" of\n\tcontinuous-time systems are studied\n", "keywords": "hidden convexity; finite-dimensional stationary linear discrete-time systems;\n\tconical constraints; control constraint\n", "topicrank": [["systems", "dimensional stationary linear discrete", "conical constraints", "finite", "convexity"], ["systems", "dimensional stationary linear discrete", "conical constraints", "finite", "convexity", "new properties", "time", "control constraints", "similar", "continuous"]], "textrank": [["time systems", "linear", "constraints", "systems", "time"], ["time systems", "linear", "constraints", "systems", "time"]], "positionrank": [["time systems", "conical constraints", "control constraints", "time", "systems"], ["time systems", "conical constraints", "control constraints", "time", "systems", "new properties", "convexity"]], "multipartiterank": [["systems", "dimensional stationary linear discrete", "conical constraints", "finite", "time"], ["systems", "dimensional stationary linear discrete", "conical constraints", "finite", "time", "new properties", "time systems", "convexity", "dimensional linear discrete", "control constraints"]]}, {"id": "294", "text": "High-density remote storage: the Ohio State University Libraries depository\nThe article describes a high-density off-site book storage facility operated by\n\tthe Ohio State University Libraries. Opened in 1995, it has the\n\tcapacity to house nearly 1.5 million items in only 9000 square feet by\n\tshelving books by size on 30-foot tall shelving. A sophisticated\n\tclimate control system extends the life of stored materials up to 12\n\ttimes. An online catalog record for each item informs patrons that the\n\titem is located in a remote location. Regular courier deliveries from\n\tthe storage facility bring requested materials to patrons with minimal\n\tdelay\n", "keywords": "high-density remote storage; Ohio State University Libraries; high-density\n\toff-site book storage facility; shelving; climate control system;\n\tstored materials; patrons; circulation; online catalog record; remote\n\tlocation; courier deliveries\n", "topicrank": [["patrons", "materials", "item", "site book storage facility", "density remote storage"], ["patrons", "materials", "item", "site book storage facility", "density remote storage", "high", "ohio state university libraries depository", "climate control system", "sophisticated", "size"]], "textrank": [["state university libraries", "remote storage", "book storage", "square feet", "remote"], ["state university libraries", "remote storage", "book storage", "square feet", "remote", "storage", "courier", "catalog", "control", "tall"]], "positionrank": [["remote storage", "storage facility", "density", "remote location", "regular courier deliveries"], ["remote storage", "storage facility", "density", "remote location", "regular courier deliveries", "article", "online catalog record", "climate control system", "materials", "patrons"]], "multipartiterank": [["density remote storage", "high", "ohio state university libraries depository", "site book storage facility", "patrons"], ["density remote storage", "high", "ohio state university libraries depository", "site book storage facility", "patrons", "materials", "item", "article", "climate control system", "density"]]}, {"id": "312", "text": "Information architecture for the Web: The IA matrix approach to designing\n\tchildren's portals\nThe article presents a matrix that can serve as a tool for designing the\n\tinformation architecture of a Web portal in a logical and systematic\n\tmanner. The information architect begins by inputting the portal's\n\tobjective, target user, and target content. The matrix then determines\n\tthe most appropriate information architecture attributes for the portal\n\tby filling in the Applied Information Architecture portion of the\n\tmatrix. The article discusses how the matrix works using the example of\n\ta children's Web portal to provide access to museum information\n", "keywords": "information architecture; target user; target content; children's Web portal;\n\tmuseum information\n", "topicrank": [["information architecture", "ia matrix approach", "web portal", "children", "article"], ["information architecture", "ia matrix approach", "web portal", "children", "article", "systematic", "logical", "manner", "portals", "objective"]], "textrank": [["information architecture", "ia matrix approach", "information", "web portal", "matrix"], ["information architecture", "ia matrix approach", "information", "web portal", "matrix", "portal", "web"]], "positionrank": [["appropriate information architecture", "information architecture", "information architect", "museum information", "web portal"], ["appropriate information architecture", "information architecture", "information architect", "museum information", "web portal", "ia matrix approach", "matrix", "portal", "web", "children"]], "multipartiterank": [["information architecture", "ia matrix approach", "web portal", "matrix", "children"], ["information architecture", "ia matrix approach", "web portal", "matrix", "children", "web", "article", "portals", "logical", "portal"]]}, {"id": "357", "text": "Embedding of level-continuous fuzzy sets on Banach spaces\nIn this paper we present an extension of the Minkowski embedding theorem,\n\tshowing the existence of an isometric embedding between the classF/sub\n\tc/(X) of compact-convex and level-continuous fuzzy sets on a real\n\tseparable Banach space X and C([0, 1] * B(X*)), the Banach space of\n\treal continuous functions defined on the cartesian product between [0,\n\t1] and the unit ball B(X*) in the dual space X*. Also, by using this\n\tembedding, we give some applications to the characterization of\n\trelatively compact subsets of F/sub c/(X). In particular, an\n\tAscoli-Arzela type theorem is proved and applied to solving the Cauchy\n\tproblem x(t) = f(t, x(t)), x(t/sub 0/) = x/sub 0/ on F/sub c/(X)\n", "keywords": "isometric embedding; level-continuous fuzzy sets; compact-convex fuzzy sets;\n\treal separable Banach space; real continuous functions; cartesian\n\tproduct; unit ball; dual space; Ascoli-Arzela type theorem; Cauchy\n\tproblem\n", "topicrank": [["continuous fuzzy sets", "level", "theorem", "compact", "isometric embedding"], ["continuous fuzzy sets", "level", "theorem", "compact", "isometric embedding", "sub", "banach spaces", "real", "convex", "classf"]], "textrank": [["banach space x", "banach space", "continuous fuzzy", "space x", "sub c/(x"], ["banach space x", "banach space", "continuous fuzzy", "space x", "sub c/(x", "cartesian product", "isometric embedding", "continuous", "banach", "type"]], "positionrank": [["continuous fuzzy sets", "real continuous functions", "banach space", "banach spaces", "sub c/(x"], ["continuous fuzzy sets", "real continuous functions", "banach space", "banach spaces", "sub c/(x", "level", "unit ball b(x", "sub", "compact subsets", "arzela type theorem"]], "multipartiterank": [["continuous fuzzy sets", "level", "theorem", "compact", "banach spaces"], ["continuous fuzzy sets", "level", "theorem", "compact", "banach spaces", "sub", "isometric embedding", "convex", "real", "minkowski"]]}, {"id": "2058", "text": "Four factors influencing the fair market value of out-of-print books.1\nFour factors (edition, condition, dust jacket, and autograph) that are\n\thypothesized to influence the value of books are identified and linked\n\tto basic economic principles, which are explained. A sample of\n\tfifty-six titles is qualitatively examined to test the hypothesis\n", "keywords": "fair market value; out-of-print books; economic principles; pricing\n", "topicrank": [["factors", "fair market value", "condition", "edition", "dust jacket"], ["factors", "fair market value", "condition", "edition", "dust jacket", "books", "autograph", "print", "basic economic principles", "sample"]], "textrank": [["fair market", "dust jacket", "economic"], ["fair market", "dust jacket", "economic"]], "positionrank": [["fair market value", "factors", "dust jacket", "value", "basic economic principles"], ["fair market value", "factors", "dust jacket", "value", "basic economic principles", "print", "edition", "condition", "autograph", "books"]], "multipartiterank": [["factors", "fair market value", "edition", "condition", "dust jacket"], ["factors", "fair market value", "edition", "condition", "dust jacket", "print", "autograph", "books", "value", "basic economic principles"]]}, {"id": "2100", "text": "Optimization of planning an advertising campaign of goods and services\nA generalization of the mathematical model and operations research problems\n\tformulated on its basis, which were presented by Belenky (2001) in the\n\tframework of an approach to planning an advertising campaign of goods\n\tand services, is considered, and corresponding nonlinear programming\n\tproblems with linear constraints are formulated\n", "keywords": "optimization; advertising campaign planning; operations research; OR; nonlinear\n\tprogramming\n", "topicrank": [["goods", "operations research problems", "advertising campaign", "services", "mathematical model"], ["goods", "operations research problems", "advertising campaign", "services", "mathematical model", "generalization", "approach", "nonlinear programming", "framework", "linear constraints"]], "textrank": [["mathematical model", "advertising campaign", "research", "nonlinear"], ["mathematical model", "advertising campaign", "research", "nonlinear"]], "positionrank": [["advertising campaign", "operations research problems", "services", "goods", "optimization"], ["advertising campaign", "operations research problems", "services", "goods", "optimization", "mathematical model", "generalization", "problems", "nonlinear programming", "linear constraints"]], "multipartiterank": [["goods", "advertising campaign", "operations research problems", "services", "mathematical model"], ["goods", "advertising campaign", "operations research problems", "services", "mathematical model", "generalization", "approach", "basis", "framework", "nonlinear programming"]]}, {"id": "2145", "text": "Enterprise in focus at NetSec 2002\nNetSec 2002 took place in San Francisco, amid industry reflection on the\n\tbalance to be struck between combatting cyber-terrorism and\n\tsafeguarding civil liberties post-9.11. The author reports on the\n\tpunditry and the pedagogy at the CSI event, focusing on security in the\n\tenterprise\n", "keywords": "NetSec 2002; CSI; enterprise security\n", "topicrank": [["netsec", "enterprise", "san francisco", "place", "focus"], ["netsec", "enterprise", "san francisco", "place", "focus", "industry reflection", "cyber", "pedagogy", "terrorism", "csi event"]], "textrank": [["industry reflection", "san francisco", "liberties", "csi"], ["industry reflection", "san francisco", "liberties", "csi"]], "positionrank": [["netsec", "enterprise", "san francisco", "csi event", "industry reflection"], ["netsec", "enterprise", "san francisco", "csi event", "industry reflection", "place", "focus", "civil liberties post-9.11", "security", "balance"]], "multipartiterank": [["netsec", "enterprise", "san francisco", "place", "focus"], ["netsec", "enterprise", "san francisco", "place", "focus", "industry reflection", "cyber", "pedagogy", "terrorism", "csi event"]]}, {"id": "1934", "text": "Computational finite-element schemes for optimal control of an elliptic system\n\twith conjugation conditions\nNew optimal control problems are considered for distributed systems described\n\tby elliptic equations with conjugate conditions and a quadratic\n\tminimized function. Highly accurate computational discretization\n\tschemes are constructed for the case where a feasible control set u/sub\n\tdelta / coincides with the full Hilbert space u of controls\n", "keywords": "optimal control problems; distributed systems; elliptic equations; conjugate\n\tconditions; quadratic minimized function; computational discretization\n\tschemes\n", "topicrank": [["optimal control", "conjugation conditions", "element schemes", "elliptic system", "accurate computational discretization"], ["optimal control", "conjugation conditions", "element schemes", "elliptic system", "accurate computational discretization", "delta", "sub", "function", "quadratic", "coincides"]], "textrank": [["optimal control", "hilbert space", "element schemes", "computational", "control"], ["optimal control", "hilbert space", "element schemes", "computational", "control", "conditions", "elliptic", "schemes"]], "positionrank": [["optimal control", "accurate computational discretization", "element schemes", "elliptic system", "feasible control"], ["optimal control", "accurate computational discretization", "element schemes", "elliptic system", "feasible control", "conjugation conditions", "elliptic equations", "conjugate conditions", "schemes", "function"]], "multipartiterank": [["optimal control", "element schemes", "elliptic system", "conjugation conditions", "computational finite"], ["optimal control", "element schemes", "elliptic system", "conjugation conditions", "computational finite", "new optimal control problems", "accurate computational discretization", "conjugate conditions", "systems", "elliptic equations"]]}, {"id": "1971", "text": "Exploring developments in Web based relationship marketing within the hotel\n\tindustry\nThis paper provides a content analysis study of the application of World Wide\n\tWeb marketing by the hotel industry. There is a lack of historical\n\tperspective on industry related Web marketing applications and this\n\tpaper attempts to resolve this with a two-year follow-up case study of\n\tthe changing use of the Web to develop different types of\n\trelationships. Specifically, the aims are: (1) to identify key changes\n\tin the way hotels are using the Web; (2) to look for evidence of the\n\tadoption of a relationship marketing (RM) model as a strategy for the\n\tdevelopment of hotel Web sites and the use of new technologies; and,\n\t(3) To investigate the use of multimedia in hotel Web sites. The\n\tdevelopment and strategic exploitation of the Internet has transformed\n\tthe basis of marketing. Using the evidence from a Web content survey\n\tthis study reveals the way relationships are being created and managed\n\twithin the hotel industry by its use of the Web as a marketing tool.\n\tThe authors have collected evidence by means of a descriptive study on\n\tthe way hotels build and create relationships with their Web presence\n\tdelivering multimedia information as well as channel and interactive\n\tmeans of communication. In addition a strategic framework is offered as\n\tthe means to describe the mechanism and orientation of Web based\n\tmarketing by hotels. The study utilizes a model by Gilbert (1996) as a\n\tmeans of developing a measurement instrument to allow a content\n\tanalysis of the current approach by hotels to the development of Web\n\tsites. The results indicate hotels are aware of the new uses of Web\n\ttechnology and are promoting hotel products in the global electronic\n\tmarket in new and sophisticated ways\n", "keywords": "Web based relationship marketing; hotel industry; World Wide Web marketing;\n\thotel Web sites; multimedia; Web content survey; global electronic\n\tmarket\n", "topicrank": [["web", "way hotels", "relationship marketing", "means", "case study"], ["web", "way hotels", "relationship marketing", "means", "case study", "hotel", "use", "hotel web sites", "development", "new technologies"]], "textrank": [["web marketing", "content analysis study", "hotel web", "web content", "web"], ["web marketing", "content analysis study", "hotel web", "web content", "web", "marketing", "measurement instrument", "multimedia information", "key changes", "different types"]], "positionrank": [["web marketing applications", "hotel web sites", "web marketing", "web content survey", "web presence"], ["web marketing applications", "hotel web sites", "web marketing", "web content survey", "web presence", "web", "relationship marketing", "hotel industry", "content analysis study", "marketing tool"]], "multipartiterank": [["web", "relationship marketing", "use", "way hotels", "hotel"], ["web", "relationship marketing", "use", "way hotels", "hotel", "case study", "hotel web sites", "means", "development", "industry"]]}, {"id": "277", "text": "Improving the predicting power of partial order based QSARs through linear\n\textensions\nPartial order theory (POT) is an attractive and operationally simple method\n\tthat allows ordering of compounds, based on selected structural and/or\n\telectronic descriptors (modeled order), or based on their end points,\n\te.g., solubility (experimental order). If the modeled order resembles\n\tthe experimental order, compounds that are not experimentally\n\tinvestigated can be assigned a position in the model that eventually\n\tmight lead to a prediction of an end-point value. However, in the\n\tapplication of POT in quantitative structure-activity relationship\n\tmodeling, only the compounds directly comparable to the noninvestigated\n\tcompounds are applied. To explore the possibilities of improving the\n\tmethodology, the theory is extended by application of the so-called\n\tlinear extensions of the model order. The study show that partial\n\tordering combined with linear extensions appears as a promising tool\n\tproviding probability distribution curves in the range of possible\n\tend-point values for compounds not being experimentally investigated\n", "keywords": "quantitative structure-activity relationships; partial order theory; predicting\n\tpower improvement; linear extensions; structural descriptors;\n\telectronic descriptors; modeled order; end points; graphical\n\trepresentation; combinatorial rule; most probable linear order;\n\tpartially ordered set; Hasse diagram; solubilities; organic compounds\n", "topicrank": [["compounds", "partial order", "extensions", "end points", "order"], ["compounds", "partial order", "extensions", "end points", "order", "pot", "ordering", "point value", "application", "model"]], "textrank": [["order", "linear extensions", "quantitative structure", "end points", "electronic descriptors"], ["order", "linear extensions", "quantitative structure", "end points", "electronic descriptors", "simple method", "distribution", "point", "activity", "end"]], "positionrank": [["partial order theory", "partial order", "experimental order", "model order", "linear extensions"], ["partial order theory", "partial order", "experimental order", "model order", "linear extensions", "order", "extensions", "compounds", "end points", "probability distribution curves"]], "multipartiterank": [["partial order", "compounds", "order", "extensions", "end points"], ["partial order", "compounds", "order", "extensions", "end points", "pot", "qsars", "linear", "ordering", "end"]]}, {"id": "2185", "text": "In search of a general enterprise model\nMany organisations, particularly SMEs, are reluctant to invest time and money\n\tin models to support decision making. Such reluctance could be overcome\n\tif a model could be used for several purposes rather than using a\n\ttraditional \"single perspective\" model. This requires the development\n\tof a \"general enterprise model\" (GEM), which can be applied to a wide\n\trange of problem domains with unlimited scope. Current enterprise\n\tmodelling frameworks only deal effectively with nondynamic modelling\n\tissues whilst dynamic modelling issues have traditionally only been\n\taddressed at the operational level. Although the majority of research\n\tin this area relates to manufacturing companies, the framework for a\n\tGEM must be equally applicable to service and public sector\n\torganisations. The paper identifies five key design issues that need to\n\tbe considered when constructing a GEM. A framework for such a GEM is\n\tpresented based on a \"plug and play\" methodology and demonstrated by a\n\tsimple case study\n", "keywords": "general enterprise model; business process re-engineering; SMEs; decision\n\tmaking; single perspective model; GEM; problem domains; enterprise\n\tmodelling frameworks; operational level; dynamic modelling issues;\n\tpublic sector organisations; service sector organisations; plug and\n\tplay methodology; case study\n", "topicrank": [["general enterprise model", "gem", "issues", "many organisations", "modelling frameworks"], ["general enterprise model", "gem", "issues", "many organisations", "modelling frameworks", "framework", "problem domains", "public sector", "unlimited scope", "service"]], "textrank": [["modelling issues", "design issues", "modelling", "problem domains", "single perspective"], ["modelling issues", "design issues", "modelling", "problem domains", "single perspective", "several purposes", "such reluctance", "decision making", "many organisations", "enterprise"]], "positionrank": [["general enterprise model", "many organisations", "current enterprise", "model", "dynamic modelling issues"], ["general enterprise model", "many organisations", "current enterprise", "model", "dynamic modelling issues", "organisations", "search", "modelling frameworks", "nondynamic modelling", "key design issues"]], "multipartiterank": [["general enterprise model", "gem", "issues", "many organisations", "modelling frameworks"], ["general enterprise model", "gem", "issues", "many organisations", "modelling frameworks", "framework", "current enterprise", "model", "unlimited scope", "problem domains"]]}, {"id": "232", "text": "Library services today and tomorrow: lessons from iLumina, a digital library\n\tfor creating and sharing teaching resources\nThis article is based on the emerging experience associated with a digital\n\tlibrary of instructional resources, iLumina, in which the contributors\n\tof resources and the users of those resources are the same-an open\n\tcommunity of instructors in science, mathematics, engineering, and\n\ttechnology. Moreover, it is not the resources, most of which will be\n\tdistributed across the Internet, but metadata about the resources that\n\tis the focus of the central iLumina repository and its support services\n\tfor resource contributors and users. The distributed iLumina library is\n\ta community-sharing library for repurposing and adding value to\n\tpotentially useful, mostly non-commercial instructional resources that\n\tare typically more granular in nature than commercially developed\n\tcourse materials. The experience of developing iLumina is raising a\n\trange of issues that have nothing to do with the place and time\n\tcharacteristics of the instructional context in which iLumina\n\tinstructional resources are created or used. The issues instead have\n\ttheir locus in the democratization of both the professional roles of\n\tlibrarians and the quality assurance mechanisms associated with\n\ttraditional peer review\n", "keywords": "iLumina; digital library; teaching resource sharing; Internet; metadata;\n\tinformation resources; community-sharing library; professional roles;\n\tacademic library; librarians; quality assurance; peer review; library\n\tautomation; standards; interoperability; reusable software; distributed\n\tsystems; user issues\n", "topicrank": [["teaching resources", "ilumina", "library services today", "community", "users"], ["teaching resources", "ilumina", "library services today", "community", "users", "contributors", "experience", "digital library", "issues", "science"]], "textrank": [["- commercial instructional resources", "ilumina library", "library services", "quality assurance mechanisms", "instructional resources"], ["- commercial instructional resources", "ilumina library", "library services", "quality assurance mechanisms", "instructional resources", "traditional peer", "ilumina", "professional roles", "course materials", "resource contributors"]], "positionrank": [["distributed ilumina library", "library services today", "digital library", "central ilumina repository", "instructional resources"], ["distributed ilumina library", "library services today", "digital library", "central ilumina repository", "instructional resources", "library", "ilumina", "teaching resources", "support services", "resources"]], "multipartiterank": [["library services today", "teaching resources", "ilumina", "tomorrow", "digital library"], ["library services today", "teaching resources", "ilumina", "tomorrow", "digital library", "lessons", "resources", "experience", "instructional resources", "article"]]}, {"id": "2178", "text": "Medicine in the 21 st century: global problems, global solutions\nThe objectives are to discuss application areas of information, technology in\n\tmedicine and health care on the occasion of the opening of the Private\n\tUniversitat fur Medizinische Informatik and Technik Tirol/University\n\tfor Health Informatics and Technology Tyrol (LIMIT) at Innsbruck,\n\tTyrol, Austria. Important application areas of information technology\n\tin medicine and health are appropriate individual access to medical\n\tknowledge, new engineering developments such as new radiant imaging\n\tmethods and the implantable pacemaker/defibrillator devices,\n\tmathematical modeling for understanding the workings of the human body,\n\tthe computer-based patient record, as well as new knowledge in\n\tmolecular biology, human genetics, and biotechnology. Challenges and\n\tresponsibilities for medical informatics research include medical data\n\tprivacy and intellectual property rights inherent in the content of the\n\tinformation systems\n", "keywords": "health care; medicine; information technology; individual medical knowledge\n\taccess; engineering developments; radiant imaging methods; implantable\n\tpacemaker devices; implantable defibrillator devices; mathematical\n\tmodeling; human body; computer-based patient record; molecular biology;\n\thuman genetics; biotechnology; medical informatics research; medical\n\tdata privacy; intellectual property rights; information systems\n", "topicrank": [["health care", "medical", "medicine", "technology tyrol", "application areas"], ["health care", "medical", "medicine", "technology tyrol", "application areas", "technology", "human body", "knowledge", "information", "global problems"]], "textrank": [["new engineering developments", "medical informatics", "health informatics", "new radiant", "property rights"], ["new engineering developments", "medical informatics", "health informatics", "new radiant", "property rights", "information technology", "fur medizinische", "technik tirol", "st century", "new"]], "positionrank": [["medicine", "important application areas", "global problems", "information technology", "global solutions"], ["medicine", "important application areas", "global problems", "information technology", "global solutions", "application areas", "technology tyrol", "st century", "health informatics", "health care"]], "multipartiterank": [["health care", "medicine", "technology", "application areas", "medical"], ["health care", "medicine", "technology", "application areas", "medical", "information", "technology tyrol", "global problems", "knowledge", "human body"]]}, {"id": "24", "text": "Fuzzy modeling based on generalized conjunction operations\nAn approach to fuzzy modeling based on the tuning of parametric conjunction\n\toperations is proposed. First, some methods for the construction of\n\tparametric generalized conjunction operations simpler than the known\n\tparametric classes of conjunctions are considered and discussed.\n\tSecond, several examples of function approximation by fuzzy models,\n\tbased on the tuning of the parameters of the new conjunction\n\toperations, are given and their approximation performances are compared\n\twith the approaches based on a tuning of membership functions and other\n\tapproaches proposed in the literature. It is seen that the tuning of\n\tthe conjunction operations can be used for obtaining fuzzy models with\n\ta sufficiently good performance when the tuning of membership functions\n\tis not possible or not desirable\n", "keywords": "fuzzy modeling; generalized conjunction operations; function approximation;\n\ttuning; approximation performances; membership functions; t-norm; fuzzy\n\tinference systems\n", "topicrank": [["tuning", "generalized conjunction operations", "fuzzy modeling", "parametric conjunction", "membership functions"], ["tuning", "generalized conjunction operations", "fuzzy modeling", "parametric conjunction", "membership functions", "function approximation", "approaches", "parameters", "parametric classes", "several examples"]], "textrank": [["parametric conjunction", "conjunction operations", "membership functions", "several examples", "conjunction"], ["parametric conjunction", "conjunction operations", "membership functions", "several examples", "conjunction", "approximation", "fuzzy", "parametric", "operations"]], "positionrank": [["generalized conjunction operations", "conjunction operations", "fuzzy modeling", "parametric conjunction", "fuzzy models"], ["generalized conjunction operations", "conjunction operations", "fuzzy modeling", "parametric conjunction", "fuzzy models", "new conjunction", "operations", "parametric classes", "tuning", "function approximation"]], "multipartiterank": [["fuzzy modeling", "generalized conjunction operations", "tuning", "approach", "parametric conjunction"], ["fuzzy modeling", "generalized conjunction operations", "tuning", "approach", "parametric conjunction", "operations", "function approximation", "membership functions", "fuzzy models", "approaches"]]}, {"id": "2065", "text": "Emotion and self-control\nA biology-based model of choice is used to examine time-inconsistent\n\tpreferences and the problem of self-control. Emotion is shown to be the\n\tbiological substrate of choice, in that emotional systems assign value\n\tto 'goods' in the environment and also facilitate the learning of\n\texpectations regarding alternative options for acquiring those goods. A\n\tthird major function of the emotional choice systems is motivation.\n\tSelf-control is shown to be the result of a problem with the inhibition\n\tof the motive force of emotion, where this inhibition is necessary for\n\thigher level deliberation\n", "keywords": "choice model; inhibition; learning; time-inconsistent preferences;\n\tself-control; emotional choice systems; emotion\n", "topicrank": [["self", "control", "emotion", "problem", "emotional systems assign value"], ["self", "control", "emotion", "problem", "emotional systems assign value", "choice", "inhibition", "goods", "inconsistent", "preferences"]], "textrank": [["systems assign", "choice systems", "motive force", "alternative options", "biological substrate"], ["systems assign", "choice systems", "motive force", "alternative options", "biological substrate", "level", "major", "choice"]], "positionrank": [["emotional choice systems", "emotion", "self", "control", "choice"], ["emotional choice systems", "emotion", "self", "control", "choice", "third major function", "motive force", "biological substrate", "inhibition", "problem"]], "multipartiterank": [["self", "control", "emotion", "choice", "problem"], ["self", "control", "emotion", "choice", "problem", "emotional systems assign value", "goods", "inhibition", "inconsistent", "preferences"]]}, {"id": "2020", "text": "Restoration of broadband imagery steered with a liquid-crystal optical phased\n\tarray\nIn many imaging applications, it is highly desirable to replace mechanical\n\tbeam-steering components (i.e., mirrors and gimbals) with a\n\tnonmechanical device. One such device is a nematic liquid crystal\n\toptical phased array (LCOPA). An LCOPA can implement a blazed phase\n\tgrating to steer the incident light. However, when a phase grating is\n\tused in a broadband imaging system, two adverse effects can occur.\n\tFirst, dispersion will cause different incident wavelengths arriving at\n\tthe same angle to be steered to different output angles, causing\n\tchromatic aberrations in the image plane. Second, the device will steer\n\tenergy not only to the first diffraction order, but to others as well.\n\tThis multiple-order effect results in multiple copies of the scene\n\tappearing in the image plane. We describe a digital image restoration\n\ttechnique designed to overcome these degradations. The proposed\n\tpostprocessing technique is based on a Wiener deconvolution filter. The\n\ttechnique, however, is applicable only to scenes containing objects\n\twith approximately constant reflectivities over the spectral region of\n\tinterest. Experimental results are presented to demonstrate the\n\teffectiveness of this technique\n", "keywords": "broadband imagery; liquid-crystal optical phased array steering; imaging\n\tapplications; mechanical beam-steering components; mirrors; gimbals;\n\tnonmechanical device; nematic liquid crystal optical phased array;\n\tblazed phase grating; incident light steering; broadband imaging\n\tsystem; dispersion; incident wavelengths; output angles; chromatic\n\taberrations; image plane; optical phased array; first diffraction\n\torder; multiple-order effect; halogen lamp; multiple copies; digital\n\timage restoration technique; postprocessing technique; Wiener\n\tdeconvolution filter; approximately constant reflectivities; spectral\n\tregion of interest\n", "topicrank": [["technique", "crystal optical", "array", "multiple", "liquid"], ["technique", "crystal optical", "array", "multiple", "liquid", "first", "restoration", "lcopa", "image plane", "nonmechanical device"]], "textrank": [["order effect results", "broadband imaging", "different incident", "liquid crystal", "different output"], ["order effect results", "broadband imaging", "different incident", "liquid crystal", "different output", "diffraction order", "imaging", "chromatic aberrations", "same angle", "adverse effects"]], "positionrank": [["digital image restoration", "nematic liquid crystal", "crystal optical", "broadband imaging system", "broadband imagery"], ["digital image restoration", "nematic liquid crystal", "crystal optical", "broadband imaging system", "broadband imagery", "restoration", "many imaging applications", "image plane", "such device", "nonmechanical device"]], "multipartiterank": [["restoration", "crystal optical", "liquid", "array", "technique"], ["restoration", "crystal optical", "liquid", "array", "technique", "broadband imagery", "lcopa", "first", "nonmechanical device", "blazed phase"]]}, {"id": "397", "text": "Accurate modeling of lossy nonuniform transmission lines by using differential\n\tquadrature methods\nThis paper discusses an efficient numerical approximation technique, called the\n\tdifferential quadrature method (DQM), which has been adapted to model\n\tlossy uniform and nonuniform transmission lines. The DQM can quickly\n\tcompute the derivative of a function at any point within its bounded\n\tdomain by estimating a weighted linear sum of values of the function at\n\ta small set of points belonging to the domain. Using the DQM, the\n\tfrequency-domain Telegrapher's partial differential equations for\n\ttransmission lines can be discretized into a set of easily solvable\n\talgebraic equations. DQM reduces interconnects into multiport models\n\twhose port voltages and currents are related by rational formulas in\n\tthe frequency domain. Although the rationalization process in DQM is\n\tcomparable with the Pade approximation of asymptotic waveform\n\tevaluation (AWE) applied to transmission lines, the derivation\n\tmechanisms in these two disparate methods are significantly different.\n\tUnlike AWE, which employs a complex moment-matching process to obtain\n\trational approximation, the DQM requires no approximation of\n\ttranscendental functions, thereby avoiding the process of moment\n\tgeneration and moment matching. Due to global sampling of points in the\n\tDQM approximation, it requires far fewer grid points in order to build\n\taccurate discrete models than other numerical methods do. The DQM-based\n\ttime-domain model can be readily integrated in a circuit simulator like\n\tSPICE\n", "keywords": "lossy nonuniform transmission lines; differential quadrature method; numerical\n\tapproximation technique; frequency-domain Telegrapher PDE; partial\n\tdifferential equations; algebraic equations; interconnects; multiport\n\tmodels; multiconductor transmission lines; rationalization process;\n\ttime-domain model\n", "topicrank": [["dqm", "lossy nonuniform transmission lines", "pade approximation", "domain", "rationalization process"], ["dqm", "lossy nonuniform transmission lines", "pade approximation", "domain", "rationalization process", "complex moment", "points", "differential", "small set", "awe"]], "textrank": [["numerical approximation", "accurate discrete models", "lossy nonuniform transmission", "rational approximation", "numerical methods"], ["numerical approximation", "accurate discrete models", "lossy nonuniform transmission", "rational approximation", "numerical methods", "differential quadrature", "quadrature methods", "differential equations", "approximation", "moment matching"]], "positionrank": [["nonuniform transmission lines", "transmission lines", "accurate modeling", "accurate discrete models", "dqm approximation"], ["nonuniform transmission lines", "transmission lines", "accurate modeling", "accurate discrete models", "dqm approximation", "differential quadrature method", "other numerical methods", "partial differential equations", "quadrature methods", "dqm"]], "multipartiterank": [["dqm", "lossy nonuniform transmission lines", "differential", "domain", "pade approximation"], ["dqm", "lossy nonuniform transmission lines", "differential", "domain", "pade approximation", "quadrature methods", "rationalization process", "points", "complex moment", "function"]]}, {"id": "402", "text": "Fast frequency acquisition phase-frequency detectors for Gsamples/s\n\tphase-locked loops\nThis paper describes two techniques for designing phase-frequency detectors\n\t(PFDs) with higher operating frequencies [periods of less than 8* the\n\tdelay of a fan-out-4 inverter (FO-4)] and faster frequency acquisition.\n\tPrototypes designed in 0.25- mu m CMOS process exhibit operating\n\tfrequencies of 1.25 GHz [=1/(8.FO-4)] and 1.5 GHz [=1/(6.7.FO-4)] for\n\ttwo techniques, respectively, whereas a conventional PFD operates at\n\t<1 GHz [=1/(10.FO-4)]. The two proposed PFDs achieve a capture range\n\tof 1.7* and 1.4* the conventional design, respectively\n", "keywords": "phase-frequency detectors; fast frequency acquisition; CMOS process; clock\n\tgenerator; latch-based PFD architecture; phase-locked loop; GSamples/s\n\tPLL; pass-transistor DFF PFD architecture; 1.25 GHz; 1.5 GHz; 0.25\n\tmicron\n", "topicrank": [["frequency detectors", "phase", "higher operating frequencies", "fast frequency acquisition phase", "pfds"], ["frequency detectors", "phase", "higher operating frequencies", "fast frequency acquisition phase", "pfds", "techniques", "ghz", "out-4 inverter", "periods", "fan"]], "textrank": [["mu m cmos process exhibit operating", "frequency acquisition", "conventional pfd", "frequency", "out-4 inverter"], ["mu m cmos process exhibit operating", "frequency acquisition", "conventional pfd", "frequency", "out-4 inverter", "operating", "conventional"]], "positionrank": [["faster frequency acquisition", "frequency detectors", "higher operating frequencies", "phase", "gsamples"], ["faster frequency acquisition", "frequency detectors", "higher operating frequencies", "phase", "gsamples", "out-4 inverter", "s", "frequencies", "techniques", "pfds"]], "multipartiterank": [["fast frequency acquisition phase", "frequency detectors", "phase", "higher operating frequencies", "pfds"], ["fast frequency acquisition phase", "frequency detectors", "phase", "higher operating frequencies", "pfds", "techniques", "ghz", "gsamples", "periods", "paper"]]}, {"id": "2098", "text": "Nonlinear systems arising from nonisothermal, non-Newtonian Hele-Shaw flows in\n\tthe presence of body forces and sources\nIn this paper, we first give a formal derivation of several systems of\n\tequations for injection moulding. This is done starting from the basic\n\tequations for nonisothermal, non-Newtonian flows in a three-dimensional\n\tdomain. We derive systems for both (T/sup 0/, p/sup 0/) and (T/sup 1/,\n\tp/sup 1/) in the presence of body forces and sources. We find that body\n\tforces and sources have a nonlinear effect on the systems. We also\n\tderive a nonlinear \"Darcy law\". Our formulation includes not only the\n\tpressure gradient, but also body forces and sources, which play the\n\trole of a nonlinearity. Later, we prove the existence of weak solutions\n\tto certain boundary value problems and initial-boundary value problems\n\tassociated with the resulting equations for (T/sup 0/, p/sup 0/) but in\n\ta more general mathematical setting\n", "keywords": "injection moulding; body forces; sources; Darcy law; nonlinear systems;\n\tboundary value problems; Hele-Shaw flows\n", "topicrank": [["body forces", "sources", "nonlinear systems", "sup", "equations"], ["body forces", "sources", "nonlinear systems", "sup", "equations", "nonlinear effect", "presence", "certain boundary value problems", "nonisothermal", "forces"]], "textrank": [["- boundary value", "- newtonian", "boundary value", "nonlinear systems", "injection moulding"], ["- boundary value", "- newtonian", "boundary value", "nonlinear systems", "injection moulding", "formal derivation", "body forces", "mathematical", "nonlinear", "systems"]], "positionrank": [["nonlinear systems", "nonlinear effect", "several systems", "body forces", "systems"], ["nonlinear systems", "nonlinear effect", "several systems", "body forces", "systems", "body", "forces", "sources", "equations", "boundary value problems"]], "multipartiterank": [["nonlinear systems", "body forces", "sources", "nonisothermal", "sup"], ["nonlinear systems", "body forces", "sources", "nonisothermal", "sup", "equations", "presence", "nonlinear effect", "certain boundary value problems", "systems"]]}, {"id": "1995", "text": "A comparison of computational color constancy algorithms. I: Methodology and\n\texperiments with synthesized data\nWe introduce a context for testing computational color constancy, specify our\n\tapproach to the implementation of a number of the leading algorithms,\n\tand report the results of three experiments using synthesized data.\n\tExperiments using synthesized data are important because the ground\n\ttruth is known, possible confounds due to camera characterization and\n\tpre-processing are absent, and various factors affecting color\n\tconstancy can be efficiently investigated because they can be\n\tmanipulated individually and precisely. The algorithms chosen for close\n\tstudy include two gray world methods, a limiting case of a version of\n\tthe Retinex method, a number of variants of Forsyth's (1990)\n\tgamut-mapping method, Cardei et al.'s (2000) neural net method, and\n\tFinlayson et al.'s color by correlation method (Finlayson et al. 1997,\n\t2001; Hubel and Finlayson 2000) . We investigate the ability of these\n\talgorithms to make estimates of three different color constancy\n\tquantities: the chromaticity of the scene illuminant, the overall\n\tmagnitude of that illuminant, and a corrected, illumination invariant,\n\timage. We consider algorithm performance as a function of the number of\n\tsurfaces in scenes generated from reflectance spectra, the relative\n\teffect on the algorithms of added specularities, and the effect of\n\tsubsequent clipping of the data. All data is available on-line at\n\thttp://www.cs.sfu.ca/~color/data, and implementations for most of the\n\talgorithms are also available (http://www.cs.sfu.ca/~color/code)\n", "keywords": "computational color constancy algorithms; synthesized data; gray world methods;\n\tRetinex method; gamut-mapping method; neural net method; color by\n\tcorrelation method; chromaticity; scene illuminant; illumination\n\tinvariant image; algorithm performance; reflectance spectra;\n\tspecularities; clipping\n", "topicrank": [["computational color constancy algorithms", "data", "algorithms", "retinex method", "number"], ["computational color constancy algorithms", "data", "algorithms", "retinex method", "number", "experiments", "finlayson", "effect", "scene illuminant", "available"]], "textrank": [["net method", "color constancy", "possible confounds due", "method", "subsequent clipping"], ["net method", "color constancy", "possible confounds due", "method", "subsequent clipping", "reflectance spectra", "algorithm performance", "illumination invariant", "scene illuminant", "al ."]], "positionrank": [["computational color constancy", "different color constancy", "color", "constancy", "algorithms"], ["computational color constancy", "different color constancy", "color", "constancy", "algorithms", "data", "comparison", "al .", "neural net method", "pre - processing"]], "multipartiterank": [["computational color constancy algorithms", "data", "algorithms", "experiments", "number"], ["computational color constancy algorithms", "data", "algorithms", "experiments", "number", "retinex method", "finlayson", "comparison", "effect", "scene illuminant"]]}, {"id": "2119", "text": "Location of transport nets on a heterogeneous territory\nThe location of transport routes on a heterogeneous territory is studied. The\n\tnetwork joins a given set of terminal points and a certain number of\n\tadditional (branch) points. The problem is formulated, properties of\n\tthe optimal solution for a. tree-like network, and the number of branch\n\tpoints are studied. A stepwise optimization algorithm for a. network\n\twith given adjacency matrix based on an algorithm for constructing\n\tminimal-cost routes is designed\n", "keywords": "transport nets; heterogeneous territory; transport routes; terminal points;\n\tbranch points; tree-like network; stepwise optimization algorithm;\n\tadjacency matrix\n", "topicrank": [["terminal points", "branch", "certain number", "transport routes", "heterogeneous territory"], ["terminal points", "branch", "certain number", "transport routes", "heterogeneous territory", "network", "location", "stepwise optimization algorithm", "additional", "problem"]], "textrank": [["a. network", "transport routes", "terminal points", "heterogeneous territory", "optimization"], ["a. network", "transport routes", "terminal points", "heterogeneous territory", "optimization", "routes", "a.", "network", "transport", "points"]], "positionrank": [["heterogeneous territory", "transport nets", "transport routes", "location", "cost routes"], ["heterogeneous territory", "transport nets", "transport routes", "location", "cost routes", "a. network", "like network", "stepwise optimization algorithm", "terminal points", "network"]], "multipartiterank": [["terminal points", "certain number", "branch", "heterogeneous territory", "location"], ["terminal points", "certain number", "branch", "heterogeneous territory", "location", "network", "transport routes", "points", "set", "additional"]]}, {"id": "253", "text": "Accessible streaming content\nMake sure your Web site is offering quality service to all your users. The\n\tarticle provides some tips and tactics for making your streaming media\n\taccessible. Accessibility of streaming content for people with\n\tdisabilities is often not part of the spec for multimedia projects, but\n\tit certainly affects your quality of service. Most of the resources\n\tavailable on Web accessibility deal with HTML. Fortunately, rich media\n\tand streaming content developers have a growing number of experts to\n\tturn to for information and assistance. The essentials of providing\n\taccessible streaming content are simple: blind and visually impaired\n\tpeople need audio to discern important visual detail and interface\n\telements, while deaf and hard-of-hearing people need text to access\n\tsound effects and dialog. Actually implementing these principles is\n\tquite a challenge, though. Now due to a relatively new law in the US,\n\tknown as Section 508, dealing with accessibility issues is becoming an\n\tessential part of publishing on the Web\n", "keywords": "Web site; quality service; streaming media; content providers; United States;\n\taccessible streaming content; disabled users; multimedia projects; Web\n\taccessibility; HTML; streaming content developers; visually impaired\n\tpeople; blind people; visual detail; interface elements; deaf people;\n\thard-of-hearing people; sound effects; Section 508; accessibility\n\tissues; Web publishing\n", "topicrank": [["people", "accessible streaming content", "accessibility", "content", "streaming media"], ["people", "accessible streaming content", "accessibility", "content", "streaming media", "quality service", "part", "web site", "discern important visual detail", "audio"]], "textrank": [["discern important visual detail", "web accessibility", "streaming media", "streaming content", "essential part"], ["discern important visual detail", "web accessibility", "streaming media", "streaming content", "essential part", "new law", "sound effects", "multimedia projects", "quality service", "accessibility"]], "positionrank": [["accessible streaming content", "streaming media", "web accessibility deal", "content developers", "content"], ["accessible streaming content", "streaming media", "web accessibility deal", "content developers", "content", "web site", "quality service", "web", "rich media", "accessibility issues"]], "multipartiterank": [["accessible streaming content", "people", "accessibility", "streaming media", "content"], ["accessible streaming content", "people", "accessibility", "streaming media", "content", "quality service", "web site", "part", "simple", "blind"]]}, {"id": "216", "text": "Extinction cross sections of realistic raindrops: data-bank established using\n\tT-matrix method and nonlinear fitting technique\nA new computer program is developed based on the T-matrix method to generate a\n\tlarge number of total (extinction) cross sections (TCS) values of the\n\trealistic raindrops that are deformed due to a balance of the forces\n\tthat act on a drop failing under gravity, and were described in shape\n\tby Pruppacher and Pitter (1971). These data for various dimensions of\n\tthe raindrops (mean effective radius from 0 to 3.25 mm), frequencies\n\t(10 to 80 GHz), (horizontal and vertical) polarizations, and\n\ttemperatures (0, 10 and 20 degrees C) are stored to establish a data\n\tbank. Furthermore, a curve fitting technique, i.e., interpolation of\n\torder 3, is implemented for the TCS values in the data bank. Therefore,\n\tthe interpolated TCS results can be obtained readily from the\n\tinterpolation process with negligible or even null computational time\n\tand efforts. Error analysis is carried out to show the high accuracy of\n\tthe present analysis and applicability of the interpolation. At three\n\toperating frequencies of 15, 21.225, and 38 GHz locally used in\n\tSingapore, some new TCS values are obtained from the new fast and\n\tefficient interpolation with a good accuracy\n", "keywords": "extinction cross sections; realistic raindrops; data-bank; T-matrix method;\n\ttotal cross sections; temperature; error analysis; mean effective\n\tradius; gravity; horizontal polarization; vertical polarization;\n\tinterpolation; nonlinear curve fitting technique; operating\n\tfrequencies; Singapore; SHF; EHF; electromagnetic wave scattering; EM\n\twave scattering; computer program; 15 GHz; 21.225 GHz; 38 GHz; 10 to 80\n\tGHz; 0 to 3.25 mm; 0 C; 10 C; 20 C\n", "topicrank": [["interpolation", "data", "realistic raindrops", "values", "bank"], ["interpolation", "data", "realistic raindrops", "values", "bank", "sections", "extinction", "tcs", "error analysis", "nonlinear fitting technique"]], "textrank": [["new tcs", "new computer", "data bank", "various dimensions", "large number"], ["new tcs", "new computer", "data bank", "various dimensions", "large number", "matrix method", "realistic raindrops", "cross sections", "fitting", "tcs"]], "positionrank": [["new tcs values", "data bank", "realistic raindrops", "tcs values", "cross sections"], ["new tcs values", "data bank", "realistic raindrops", "tcs values", "cross sections", "extinction", "matrix method", "new computer program", "curve fitting technique", "sections"]], "multipartiterank": [["realistic raindrops", "sections", "data", "extinction", "bank"], ["realistic raindrops", "sections", "data", "extinction", "bank", "interpolation", "values", "tcs", "matrix method", "nonlinear fitting technique"]]}, {"id": "1968", "text": "Phase control of higher-order squeezing of a quantum field\nIn a recent experiment [Phys. Rev. Lett. 88 (2002) 023601], phase-dependent\n\tphoton statistics in a c.w. system has been observed in the mixing of a\n\tcoherent field with a two-photon source. Their system has the advantage\n\tover other atomic transition-based fluorescent systems. In this paper,\n\twe examine further the squeezing properties of higher-order quantum\n\tfluctuations in one of the quadrature components of the combined field\n\tin this system. We demonstrate that efficient and lasting higher-order\n\tsqueezing effects could be observed with proper choice of the relative\n\tphase between the pump and coherent fields. This nonclassical feature\n\tis attributed to a constructive two-photon interference. Relationship\n\tbetween the second- and higher-order squeezing of the field is\n\tdiscussed\n", "keywords": "phase control; higher-order squeezing; quantum field; phase-dependent photon\n\tstatistics; coherent field mixing; atomic transition-based fluorescent\n\tsystems; quantum fluctuations; two-photon interference\n", "topicrank": [["higher", "order squeezing", "quantum field", "photon statistics", "phase control"], ["higher", "order squeezing", "quantum field", "photon statistics", "phase control", "system", "pump", "coherent fields", "relative", "efficient"]], "textrank": [["rev. lett .", "order quantum", "coherent field", "quantum field", "recent experiment"], ["rev. lett .", "order quantum", "coherent field", "quantum field", "recent experiment", "phase control", "photon", "atomic", ".", "coherent"]], "positionrank": [["phase control", "order quantum", "order squeezing", "quantum field", "phase"], ["phase control", "order quantum", "order squeezing", "quantum field", "phase", "coherent field", "order", "field", "photon statistics", "photon source"]], "multipartiterank": [["phase control", "higher", "order squeezing", "quantum field", "photon statistics"], ["phase control", "higher", "order squeezing", "quantum field", "photon statistics", "system", "phase", "recent experiment", "field", "phys"]]}, {"id": "2041", "text": "Application of multiprocessor systems for computation of jets\nThe article describes the implementation of methods for numerical solution of\n\tgas-dynamic problems on a wide class of multiprocessor systems,\n\tconventionally characterized as \"cluster\" systems. A standard\n\tdata-transfer interface - the so-called message passing interface - is\n\tused for parallelization of application algorithms among processors.\n\tSimulation of jets escaping into a low-pressure region is chosen as a\n\tcomputational example\n", "keywords": "multiprocessor systems; computation of jets; gas-dynamic problems; cluster\n\tsystems; data-transfer interface; message passing interface;\n\tlow-pressure region\n", "topicrank": [["multiprocessor systems", "jets", "application", "transfer interface", "methods"], ["multiprocessor systems", "jets", "application", "transfer interface", "methods", "numerical solution", "data", "implementation", "dynamic problems", "standard"]], "textrank": [["wide class", "dynamic problems", "numerical solution", "multiprocessor systems", "systems"], ["wide class", "dynamic problems", "numerical solution", "multiprocessor systems", "systems", "application"]], "positionrank": [["multiprocessor systems", "application algorithms", "application", "systems", "jets"], ["multiprocessor systems", "application algorithms", "application", "systems", "jets", "dynamic problems", "transfer interface", "numerical solution", "wide class", "interface"]], "multipartiterank": [["multiprocessor systems", "application", "jets", "transfer interface", "computation"], ["multiprocessor systems", "application", "jets", "transfer interface", "computation", "methods", "numerical solution", "implementation", "wide class", "dynamic problems"]]}, {"id": "2004", "text": "New paradigms for interactive 3D volume segmentation\nWe present a new virtual reality-based interaction metaphor for semi-automatic\n\tsegmentation of medical 3D volume data. The mouse-based, manual\n\tinitialization of deformable surfaces in 3D represents a major\n\tbottleneck in interactive segmentation. In our multi-modal system we\n\tenhance this process with additional sensory feedback. A 3D haptic\n\tdevice is used to extract the centreline of a tubular structure. Based\n\ton the obtained path a cylinder with varying diameter is generated,\n\twhich in turn is used as the initial guess for a deformable surface\n", "keywords": "interactive 3D volume segmentation; virtual reality; interaction metaphor;\n\tmedical image segmentation; mouse; deformable surfaces; interactive\n\tsegmentation; multi-modal system; sensory feedback; 3D haptic device;\n\ttubular structure; varying diameter cylinder; deformable surface;\n\thaptic interaction\n", "topicrank": [["interactive 3d volume segmentation", "deformable surfaces", "initialization", "bottleneck", "cylinder"], ["interactive 3d volume segmentation", "deformable surfaces", "initialization", "bottleneck", "cylinder", "manual", "3d haptic", "additional sensory feedback", "medical 3d volume data", "major"]], "textrank": [["- modal", "3d volume", "new virtual", "-", "tubular structure"], ["- modal", "3d volume", "new virtual", "-", "tubular structure", "interaction metaphor", "3d", "sensory", "deformable", "new"]], "positionrank": [["new virtual reality", "interactive segmentation", "new paradigms", "3d", "segmentation"], ["new virtual reality", "interactive segmentation", "new paradigms", "3d", "segmentation", "interaction metaphor", "additional sensory feedback", "deformable surfaces", "deformable surface", "mouse"]], "multipartiterank": [["interactive 3d volume segmentation", "deformable surfaces", "new paradigms", "initialization", "medical 3d volume data"], ["interactive 3d volume segmentation", "deformable surfaces", "new paradigms", "initialization", "medical 3d volume data", "new virtual reality", "manual", "bottleneck", "interaction metaphor", "major"]]}, {"id": "2039", "text": "An inverse problem for a model of a hierarchical structure\nWe consider the inverse problem for the identification of the coefficient in a\n\tparabolic equation. The model is applied to describe the functioning of\n\ta hierarchical structure; it is also relevant for heat-conduction\n\ttheory. Unique solvability of the inverse problem is proved\n", "keywords": "inverse problem; hierarchical structure; parabolic equation; heat-conduction\n\ttheory; unique solvability\n", "topicrank": [["inverse problem", "hierarchical structure", "model", "conduction", "heat"], ["inverse problem", "hierarchical structure", "model", "conduction", "heat", "theory", "relevant", "unique solvability", "identification", "parabolic equation"]], "textrank": [["hierarchical structure", "inverse problem", "parabolic"], ["hierarchical structure", "inverse problem", "parabolic"]], "positionrank": [["inverse problem", "hierarchical structure", "unique solvability", "model", "parabolic equation"], ["inverse problem", "hierarchical structure", "unique solvability", "model", "parabolic equation", "conduction", "coefficient", "identification", "theory", "heat"]], "multipartiterank": [["inverse problem", "hierarchical structure", "model", "conduction", "heat"], ["inverse problem", "hierarchical structure", "model", "conduction", "heat", "theory", "relevant", "unique solvability", "identification", "parabolic equation"]]}, {"id": "2081", "text": "Three-dimensional optimum design of the cooling lines of injection moulds based\n\ton boundary element design sensitivity analysis\nA three-dimensional numerical simulation using the boundary element method is\n\tproposed, which can predict the cavity temperature distributions in the\n\tcooling stage of injection moulding. Then, choosing the radii and\n\tpositions of cooling lines as design variables, the boundary integral\n\tsensitivity formulations are deduced. For the optimum design of cooling\n\tlines, the squared difference between the objective temperature and\n\ttemperature of the cavity is taken as the objective function. Based on\n\tthe optimization techniques with design sensitivity analysis, an\n\titerative algorithm to reach the minimum value of the objective\n\tfunction is introduced, which leads to the optimum design of cooling\n\tlines at the same time\n", "keywords": "injection moulding; 3D numerical simulation; boundary element method; cavity\n\ttemperature distributions; cooling stage; boundary integral sensitivity\n\tanalysis; iterative algorithm; heat conduction; objective function;\n\toptimization\n", "topicrank": [["lines", "dimensional optimum design", "objective function", "injection moulds", "boundary element design sensitivity analysis"], ["lines", "dimensional optimum design", "objective function", "injection moulds", "boundary element design sensitivity analysis", "objective temperature", "cavity temperature distributions", "boundary integral", "positions", "sensitivity formulations"]], "textrank": [["boundary element design sensitivity", "dimensional optimum design", "design sensitivity", "objective temperature", "optimum design"], ["boundary element design sensitivity", "dimensional optimum design", "design sensitivity", "objective temperature", "optimum design", "boundary element", "dimensional numerical", "design", "temperature", "sensitivity"]], "positionrank": [["dimensional optimum design", "design sensitivity analysis", "optimum design", "design variables", "boundary element method"], ["dimensional optimum design", "design sensitivity analysis", "optimum design", "design variables", "boundary element method", "dimensional numerical simulation", "injection moulds", "sensitivity formulations", "lines", "cavity temperature distributions"]], "multipartiterank": [["lines", "dimensional optimum design", "injection moulds", "boundary element design sensitivity analysis", "cavity temperature distributions"], ["lines", "dimensional optimum design", "injection moulds", "boundary element design sensitivity analysis", "cavity temperature distributions", "objective temperature", "objective function", "dimensional numerical simulation", "optimum design", "stage"]]}, {"id": "373", "text": "Putting pen to screen on Tablet PCs\nWith the release of the first Tablet PCs produced to Microsoft Corp.'s general\n\tspecifications, handheld computers may be about to leap into the ring\n\twith today's laptops. They will be about the size of the smaller\n\tlaptops, will be at least as powerful, and maybe their biggest selling\n\tpoint-will be able to handle handwritten text. The Tablet PCs will be\n\tamply configured, general-purpose machines with more than enough power\n\tto run the full-blown Windows XP operating system. In particular, they\n\twill allow handwritten text to be entered onto a digitizing tablet and\n\trecognized, a functionality that's called pen-based computing. The\n\tTablet PC will far outpace the computing power of existing small\n\tdevices such as PDAs (personal digital assistants), including those\n\tvariants based on Microsoft's own Pocket PC operating system\n", "keywords": "Tablet PC; Microsoft; handheld computers; handwritten text; Windows XP\n\toperating system; digitizing tablet; pen-based computing\n", "topicrank": [["tablet pcs", "laptops", "general", "handwritten text", "pen"], ["tablet pcs", "laptops", "general", "handwritten text", "pen", "enough power", "smaller", "biggest selling", "specifications", "point"]], "textrank": [["pocket pc operating", "windows xp operating", "tablet pc", "handwritten text", "biggest selling"], ["pocket pc operating", "windows xp operating", "tablet pc", "handwritten text", "biggest selling", "handheld computers", "microsoft corp.", "tablet", "digital", "microsoft"]], "positionrank": [["first tablet pcs", "tablet pcs", "tablet pc", "tablet", "microsoft corp."], ["first tablet pcs", "tablet pcs", "tablet pc", "tablet", "microsoft corp.", "pen", "handwritten text", "release", "microsoft", "screen"]], "multipartiterank": [["tablet pcs", "general", "laptops", "handwritten text", "pen"], ["tablet pcs", "general", "laptops", "handwritten text", "pen", "enough power", "screen", "biggest selling", "point", "smaller"]]}, {"id": "1955", "text": "Simulation of evacuation processes using a bionics-inspired cellular automaton\n\tmodel for pedestrian dynamics\nWe present simulations of evacuation processes using a recently introduced\n\tcellular automaton model for pedestrian dynamics. This model applies a\n\tbionics approach to describe the interaction between the pedestrians\n\tusing ideas from chemotaxis. Here we study a rather simple situation,\n\tnamely the evacuation from a large room with one or two doors. It is\n\tshown that the variation of the model parameters allows to describe\n\tdifferent types of behaviour, from regular to panic. We find a\n\tnon-monotonic dependence of the evacuation times on the coupling\n\tconstants. These times depend on the strength of the herding behaviour,\n\twith minimal evacuation times for some intermediate values of the\n\tcouplings, i.e., a proper combination of herding and use of knowledge\n\tabout the shortest way to the exit\n", "keywords": "evacuation processes simulation; chemotaxis; nonmonotonic dependence; coupling\n\tconstants; herding behaviour; bionics-inspired cellular automaton\n\tmodel; pedestrian dynamics\n", "topicrank": [["model", "evacuation processes", "evacuation times", "behaviour", "pedestrian dynamics"], ["model", "evacuation processes", "evacuation times", "behaviour", "pedestrian dynamics", "cellular automaton", "bionics", "use", "herding", "constants"]], "textrank": [["- monotonic", "automaton model", "bionics -", "different types", "large room"], ["- monotonic", "automaton model", "bionics -", "different types", "large room", "simple situation", "bionics approach", "pedestrian dynamics", "evacuation", "model"]], "positionrank": [["cellular automaton model", "evacuation processes", "minimal evacuation times", "evacuation times", "cellular automaton"], ["cellular automaton model", "evacuation processes", "minimal evacuation times", "evacuation times", "cellular automaton", "evacuation", "pedestrian dynamics", "model parameters", "model", "bionics approach"]], "multipartiterank": [["evacuation processes", "model", "cellular automaton", "pedestrian dynamics", "bionics"], ["evacuation processes", "model", "cellular automaton", "pedestrian dynamics", "bionics", "evacuation times", "behaviour", "simulations", "coupling", "different types"]]}, {"id": "2124", "text": "The set of stable polynomials of linear discrete systems: its geometry\nThe multidimensional stability domain of linear discrete systems is studied.\n\tIts configuration is determined from the parameters of its intersection\n\twith coordinate axes, coordinate planes, and certain auxiliary planes.\n\tCounterexamples for the discrete variant of the Kharitonov theorem are\n\tgiven\n", "keywords": "stable polynomials; Kharitonov theorem; characteristic polynomial; linear\n\tdiscrete systems; geometry; multidimensional stability domain\n", "topicrank": [["linear discrete systems", "planes", "multidimensional stability domain", "stable polynomials", "coordinate axes"], ["linear discrete systems", "planes", "multidimensional stability domain", "stable polynomials", "coordinate axes", "intersection", "counterexamples", "geometry", "parameters", "discrete variant"]], "textrank": [["coordinate axes", "stable polynomials", "discrete", "auxiliary", "stability"], ["coordinate axes", "stable polynomials", "discrete", "auxiliary", "stability", "coordinate"]], "positionrank": [["linear discrete systems", "discrete variant", "multidimensional stability domain", "stable polynomials", "certain auxiliary planes"], ["linear discrete systems", "discrete variant", "multidimensional stability domain", "stable polynomials", "certain auxiliary planes", "geometry", "set", "coordinate axes", "planes", "kharitonov theorem"]], "multipartiterank": [["linear discrete systems", "planes", "coordinate axes", "intersection", "multidimensional stability domain"], ["linear discrete systems", "planes", "coordinate axes", "intersection", "multidimensional stability domain", "stable polynomials", "counterexamples", "parameters", "geometry", "discrete variant"]]}, {"id": "293", "text": "Theoretical and experimental investigations on coherence of traffic noise\n\ttransmission through an open window into a rectangular room in\n\thigh-rise buildings\nA method for theoretically calculating the coherence between sound pressure\n\tinside a rectangular room in a high-rise building and that outside the\n\topen window of the room is proposed. The traffic noise transmitted into\n\ta room is generally dominated by low-frequency components, to which\n\tactive noise control (ANC) technology may find an application. However,\n\tgood coherence between reference and error signals is essential for an\n\teffective noise reduction and should be checked first. Based on traffic\n\tnoise prediction methods, wave theory, and mode coupling theory, the\n\tresults of this paper enabled one to determine the potentials and\n\tlimitations of ANC used to reduce such a transmission. Experimental\n\tcoherence results are shown for two similar, empty rectangular rooms\n\tlocated on the 17th and 30th floors of a 34 floor high-rise building.\n\tThe calculated results with the proposed method are generally in good\n\tagreement with the experimental results and demonstrate the usefulness\n\tof the method for predicting the coherence\n", "keywords": "traffic noise transmission; open window; rectangular room; high-rise buildings;\n\tsound pressure; low-frequency components; active noise control\n\ttechnology; traffic noise prediction methods; mode coupling theory;\n\twave theory\n", "topicrank": [["coherence", "rectangular room", "high", "traffic noise", "rise buildings"], ["coherence", "rectangular room", "high", "traffic noise", "rise buildings", "results", "method", "anc", "wave theory", "experimental investigations"]], "textrank": [["noise prediction", "noise", "experimental results", "coherence results", "error signals"], ["noise prediction", "noise", "experimental results", "coherence results", "error signals", "frequency components", "sound pressure", "open window", "rectangular", "rise"]], "positionrank": [["traffic noise", "coherence results", "experimental results", "noise prediction methods", "experimental investigations"], ["traffic noise", "coherence results", "experimental results", "noise prediction methods", "experimental investigations", "active noise control", "good coherence", "effective noise reduction", "rectangular room", "coherence"]], "multipartiterank": [["coherence", "rectangular room", "high", "rise buildings", "traffic noise"], ["coherence", "rectangular room", "high", "rise buildings", "traffic noise", "experimental investigations", "method", "results", "open window", "transmission"]]}, {"id": "2161", "text": "On the Beth properties of some intuitionistic modal logics\nLet L be one of the intuitionistic modal logics. As in the classical modal\n\tcase, we define two different forms of the Beth property for L, which\n\tare denoted by B1 and B2; in this paper we study the relation among B1,\n\tB2 and the interpolation properties C1 and C2. It turns out that C1\n\timplies B1, but contrary to the boolean case, is not equivalent to B1.\n\tIt is shown that B2 and C2 are independent, and moreover it comes out\n\tthat, in contrast to classical case, there exists an extension of the\n\tintuitionistic modal logic of S/sub 4/-type, that has not the property\n\tB2. Finally we give two algebraic properties, that characterize\n\trespectively B1 and B2\n", "keywords": "Beth properties; interpolation properties; intuitionistic modal logics\n", "topicrank": [["case", "intuitionistic modal logics", "beth properties", "beth property", "classical modal"], ["case", "intuitionistic modal logics", "beth properties", "beth property", "classical modal", "contrast", "different forms", "extension", "sub", "relation"]], "textrank": [["classical modal", "beth properties", "classical case", "modal", "different forms"], ["classical modal", "beth properties", "classical case", "modal", "different forms", "beth property", "properties", "case", "property"]], "positionrank": [["intuitionistic modal logics", "intuitionistic modal logic", "classical modal", "beth properties", "beth property"], ["intuitionistic modal logics", "intuitionistic modal logic", "classical modal", "beth properties", "beth property", "classical case", "interpolation properties", "algebraic properties", "boolean case", "b1"]], "multipartiterank": [["intuitionistic modal logics", "case", "beth properties", "classical modal", "beth property"], ["intuitionistic modal logics", "case", "beth properties", "classical modal", "beth property", "different forms", "paper", "relation", "contrast", "classical case"]]}, {"id": "2083", "text": "Innovative manufacture of impulse turbine blades for wave energy power\n\tconversion\nAn innovative approach to the manufacture of impulse turbine blades using rapid\n\tprototyping, fused decomposition modelling (FDM), is presented. These\n\tblades were designed and manufactured by the Wave Energy Research Team\n\t(WERT) at the University of Limerick for the experimental analysis of a\n\t0.6 m impulse turbine with fixed guide vanes for wave energy power\n\tconversion. The computer aided design/manufacture (CAD/CAM) package\n\tPro-Engineer 2000i was used for three-dimensional solid modelling of\n\tthe individual blades. A detailed finite element analysis of the blades\n\tunder centrifugal loads was performed using Pro-Mechanica. based on\n\tthis analysis and FDM machine capabilities, blades were redesigned.\n\tFinally, Pro-E data were transferred to an FDM machine for the\n\tmanufacture of turbine blades. The objective of this paper is to\n\tpresent the innovative method used to design, modify and manufacture\n\tblades in a time and cost effective manner using a concurrent\n\tengineering approach\n", "keywords": "CAD/CAM; impulse turbine blades; wave energy power conversion; fused\n\tdecomposition modelling; rapid prototyping; manufacturing; concurrent\n\tengineering; University of Limerick; solid modelling; finite element\n\tanalysis\n", "topicrank": [["impulse turbine blades", "innovative manufacture", "wave energy power", "fdm", "conversion"], ["impulse turbine blades", "innovative manufacture", "wave energy power", "fdm", "conversion", "innovative approach", "experimental analysis", "design", "cad", "computer"]], "textrank": [["finite element analysis", "impulse turbine blades", "- e", "- engineer", "energy research"], ["finite element analysis", "impulse turbine blades", "- e", "- engineer", "energy research", "innovative approach", "solid modelling", "turbine blades", "impulse turbine", "-"]], "positionrank": [["impulse turbine blades", "turbine blades", "innovative manufacture", "wave energy power", "m impulse turbine"], ["impulse turbine blades", "turbine blades", "innovative manufacture", "wave energy power", "m impulse turbine", "innovative approach", "individual blades", "blades", "innovative method", "manufacture"]], "multipartiterank": [["innovative manufacture", "impulse turbine blades", "wave energy power", "conversion", "manufacture"], ["innovative manufacture", "impulse turbine blades", "wave energy power", "conversion", "manufacture", "fdm", "innovative approach", "blades", "rapid", "prototyping"]]}, {"id": "334", "text": "Capturing niche markets with copper\nFor \"last-mile access\" in niche applications, twisted copper pair may be the\n\tcable of best option to gain access and deliver desired services. The\n\tarticle discusses how operators can use network edge devices to serve\n\tnew customers. Niche market segments represent a significant\n\topportunity for cable TV delivery of television and high-speed Internet\n\tsignals. But the existing telecommunications infrastructure in those\n\tdevelopments frequently presents unique challenges for the service\n\tprovider to overcome\n", "keywords": "last-mile access; twisted copper pair; network edge devices; copper cables;\n\tniche markets\n", "topicrank": [["cable", "mile access", "copper", "niche markets", "speed internet"], ["cable", "mile access", "copper", "niche markets", "speed internet", "high", "television", "opportunity", "niche market segments", "significant"]], "textrank": [["niche market", "new customers", "best option", "mile access", "niche"], ["niche market", "new customers", "best option", "mile access", "niche", "tv", "edge", "copper", "speed", "access"]], "positionrank": [["niche market segments", "niche markets", "twisted copper pair", "niche applications", "mile access"], ["niche market segments", "niche markets", "twisted copper pair", "niche applications", "mile access", "cable tv delivery", "copper", "network edge devices", "access", "cable"]], "multipartiterank": [["niche markets", "copper", "mile access", "cable", "last"], ["niche markets", "copper", "mile access", "cable", "last", "best option", "cable tv delivery", "niche applications", "television", "speed internet"]]}, {"id": "371", "text": "A better ballot box?\nElection officials are examining technologies to address a wide range of voting\n\tissues. The problems observed in the November 2000 US election\n\taccelerated existing trends to get rid of lever machines, punch-cards,\n\tand hand-counted paper ballots and replace them with mark-sense\n\tballoting, Internet, and automatic teller machine (ATM) kiosk style\n\tcomputer-based systems. An estimated US $2-$4 billion will be spent in\n\tthe United States and Canada to update voting systems during the next\n\tdecade. Voting online might enable citizens to vote even if they are\n\tunable to get to the polls. Yet making these methods work right turns\n\tout to be considerably more difficult than originally thought. New\n\telectronic voting systems pose risks as well as solutions. As it turns\n\tout, many of the voting products currently for sale provide less\n\taccountability, poorer reliability, and greater opportunity for\n\twidespread fraud than those already in use. This paper discusses the\n\ttechnology available and how to ensure accurate ballots\n", "keywords": "ballot box; mark-sense balloting; automatic teller machine computer-based\n\tvoting system; ATM kiosk style computer-based voting systems;\n\telectronic voting; online voting\n", "topicrank": [["systems", "voting", "election officials", "paper ballots", "balloting"], ["systems", "voting", "election officials", "paper ballots", "balloting", "sense", "automatic teller machine", "kiosk style", "less", "atm"]], "textrank": [["widespread fraud", "greater opportunity", "poorer reliability", "united states", "kiosk style"], ["widespread fraud", "greater opportunity", "poorer reliability", "united states", "kiosk style", "lever machines", "wide range", "voting", "teller", "ballots"]], "positionrank": [["better ballot box", "election officials", "us election", "electronic voting systems", "voting systems"], ["better ballot box", "election officials", "us election", "electronic voting systems", "voting systems", "wide range", "technologies", "voting products", "voting", "automatic teller machine"]], "multipartiterank": [["systems", "election officials", "voting", "paper ballots", "kiosk style"], ["systems", "election officials", "voting", "paper ballots", "kiosk style", "computer", "balloting", "automatic teller machine", "atm", "sense"]]}, {"id": "2126", "text": "A nonlinear time-optimal control problem\nSufficient conditions for the existence of an optimal control in a time-optimal\n\tcontrol problem with fixed ends for a smooth nonlinear control system\n\tare formulated. The properties of this system for characterizing the\n\toptimal control switching points are studied\n", "keywords": "nonlinear time-optimal control problem; sufficient existence conditions; smooth\n\tnonlinear control system; optimal control switching points\n", "topicrank": [["optimal control problem", "nonlinear time", "fixed ends", "sufficient conditions", "existence"], ["optimal control problem", "nonlinear time", "fixed ends", "sufficient conditions", "existence", "smooth nonlinear control system", "properties", "system"]], "textrank": [["nonlinear control", "control switching", "control", "nonlinear", "sufficient"], ["nonlinear control", "control switching", "control", "nonlinear", "sufficient"]], "positionrank": [["optimal control problem", "optimal control", "control problem", "nonlinear time", "sufficient conditions"], ["optimal control problem", "optimal control", "control problem", "nonlinear time", "sufficient conditions", "time", "fixed ends", "system", "existence", "properties"]], "multipartiterank": [["optimal control problem", "nonlinear time", "sufficient conditions", "existence", "time"], ["optimal control problem", "nonlinear time", "sufficient conditions", "existence", "time", "fixed ends", "smooth nonlinear control system", "optimal control", "system", "properties"]]}, {"id": "291", "text": "Nuclear magnetic resonance molecular photography\nA procedure is described for storing a two-dimensional (2D) pattern consisting\n\tof 32*32=1024 bits in a spin state of a molecular system and then\n\tretrieving the stored information as a stack of nuclear magnetic\n\tresonance spectra. The system used is a nematic liquid crystal, the\n\tprotons of which act as spin clusters with strong intramolecular\n\tinteractions. The technique used is a programmable multifrequency\n\tirradiation with low amplitude. When it is applied to the liquid\n\tcrystal, a large number of coherent long-lived /sup 1/H response\n\tsignals can be excited, resulting in a spectrum showing many sharp\n\tpeaks with controllable frequencies and amplitudes. The spectral\n\tresolution is enhanced by using a second weak pulse with a 90 degrees\n\tphase shift, so that the 1024 bits of information can be retrieved as a\n\tset of well-resolved pseudo-2D spectra reproducing the input pattern\n", "keywords": "NMR molecular photography; 2D pattern; molecular system spin state; information\n\tstorage; nematic liquid crystal; spin clusters; strong intramolecular\n\tinteractions; programmable multifrequency irradiation; low amplitude;\n\tcoherent long-lived /sup 1/H response signals; spectral resolution;\n\tsecond weak pulse; pseudo-2D spectra; spin echoes; Hilbert spaces;\n\thigh-content molecular information processing; coupled spins;\n\tdipole-dipole interactions; spin-locking; proton spin; spin dynamics;\n\t1024 bit\n", "topicrank": [["spin state", "nematic liquid crystal", "resonance spectra", "stored information", "molecular system"], ["spin state", "nematic liquid crystal", "resonance spectra", "stored information", "molecular system", "nuclear magnetic resonance molecular photography", "bits", "controllable frequencies", "strong intramolecular", "peaks"]], "textrank": [["magnetic resonance molecular", "resonance spectra", "large number", "low amplitude", "programmable multifrequency"], ["magnetic resonance molecular", "resonance spectra", "large number", "low amplitude", "programmable multifrequency", "strong intramolecular", "stored information", "molecular", "weak", "liquid"]], "positionrank": [["nuclear magnetic resonance", "resonance spectra", "molecular system", "molecular photography", "stored information"], ["nuclear magnetic resonance", "resonance spectra", "molecular system", "molecular photography", "stored information", "nematic liquid crystal", "pseudo-2d spectra", "system", "information", "procedure"]], "multipartiterank": [["nuclear magnetic resonance molecular photography", "spin state", "molecular system", "bits", "nematic liquid crystal"], ["nuclear magnetic resonance molecular photography", "spin state", "molecular system", "bits", "nematic liquid crystal", "stored information", "resonance spectra", "procedure", "pattern", "stack"]]}, {"id": "2163", "text": "IT as a key enabler to law firm competitiveness\nProfessional services firms have traditionally been able to thrive in virtually\n\tany market conditions. They have been consistently successful for\n\tseveral decades without ever needing to reexamine or change their basic\n\toperating model. However, gradual but inexorable change in client\n\texpectations and the business environment over recent years now means\n\tthat more of the same is no longer enough. In future, law firms will\n\tincreasingly need to exploit IT more effectively in order to remain\n\tcompetitive. To do this, they will need to ensure that all their\n\tinformation systems function as an integrated whole and are available\n\tto their staff, clients and business partners. The authors set out the\n\tlessons to be learned for law firms in the light of the recent PA\n\tConsulting survey\n", "keywords": "professional services firms; client expectations; business environment;\n\tinformation systems; law firms\n", "topicrank": [["business environment", "recent years", "law firms", "inexorable change", "client"], ["business environment", "recent years", "law firms", "inexorable change", "client", "clients", "expectations", "gradual", "staff", "operating model"]], "textrank": [["services firms", "law firm", "law firms", "operating model", "several decades"], ["services firms", "law firm", "law firms", "operating model", "several decades", "market conditions", "key enabler", "systems", "recent", "business"]], "positionrank": [["law firm competitiveness", "professional services firms", "law firms", "key enabler", "it"], ["law firm competitiveness", "professional services firms", "law firms", "key enabler", "it", "recent pa", "recent years", "market conditions", "business environment", "business partners"]], "multipartiterank": [["business environment", "recent years", "client", "inexorable change", "expectations"], ["business environment", "recent years", "client", "inexorable change", "expectations", "law firms", "gradual", "operating model", "basic", "law firm competitiveness"]]}, {"id": "1957", "text": "The two populations' cellular automata model with predation based on the Penna\n\tmodel\nIn Penna's (1995) single-species asexual bit-string model of biological ageing,\n\tthe Verhulst factor has too strong a restraining effect on the\n\tdevelopment of the population. Danuta Makowiec gave an improved model\n\tbased on the lattice, where the restraining factor of the four\n\tneighbours take the place of the Verhulst factor. Here, we discuss the\n\ttwo populations' Penna model with predation on the planar lattice of\n\ttwo dimensions. A cellular automata model containing movable wolves and\n\tsheep has been built. The results show that both the quantity of the\n\twolves and the sheep fluctuate in accordance with the law that one\n\tquantity increases while the other one decreases\n", "keywords": "cellular automata model; population; Penna model; single-species asexual\n\tbit-string model; biological ageing; Verhulst factor; restraining\n\teffect; lattice; wolves; sheep; fluctuation; Lotka-Volterra model;\n\tpredation\n", "topicrank": [["cellular automata model", "penna", "verhulst factor", "predation", "movable wolves"], ["cellular automata model", "penna", "verhulst factor", "predation", "movable wolves", "sheep", "lattice", "populations", "quantity", "species asexual bit"]], "textrank": [["automata model", "model", "planar lattice", "danuta makowiec", "verhulst factor"], ["automata model", "model", "planar lattice", "danuta makowiec", "verhulst factor", "biological ageing", "asexual", "movable", "factor", "lattice"]], "positionrank": [["cellular automata model", "penna model", "string model", "improved model", "model"], ["cellular automata model", "penna model", "string model", "improved model", "model", "planar lattice", "verhulst factor", "penna", "populations", "predation"]], "multipartiterank": [["cellular automata model", "penna", "verhulst factor", "predation", "movable wolves"], ["cellular automata model", "penna", "verhulst factor", "predation", "movable wolves", "populations", "sheep", "lattice", "quantity", "dimensions"]]}, {"id": "229", "text": "Simple minds [health care IT]\nA few things done properly, and soon, is the short-term strategy for the UK NHS\n\tIT programme. Can it deliver this time?\n", "keywords": "UK NHS IT programme; health care; strategy\n", "topicrank": [["term strategy", "short", "uk nhs", "time", "simple minds"], ["term strategy", "short", "uk nhs", "time", "simple minds"]], "textrank": [["care it", "simple minds", "it"], ["care it", "simple minds", "it"]], "positionrank": [["health care it", "simple minds", "it programme", "few things", "uk nhs"], ["health care it", "simple minds", "it programme", "few things", "uk nhs", "term strategy", "time"]], "multipartiterank": [["term strategy", "short", "uk nhs", "time", "simple minds"], ["term strategy", "short", "uk nhs", "time", "simple minds"]]}, {"id": "251", "text": "Central hub for design assets: Adobe GoLive 6.0\nAdobe GoLive is a strong contender for Web authoring and publishing. Version\n\t6.0 features a flexible GUI environment combined with a comprehensive\n\tworkgroup and collaboration server, plus tight integration with leading\n\tdesign tools\n", "keywords": "Adobe GoLive 6.0; Flash; Real; Java; application servers; Web authoring; GUI;\n\tworkgroup server; collaboration server; LiveMotion 2.0; animation and\n\tscripting tool; Macromedia SWF format; workgroup environment; Web\n\tpublishing environment; design-centric dynamic content\n", "topicrank": [["adobe golive", "design assets", "workgroup", "strong contender", "web"], ["adobe golive", "design assets", "workgroup", "strong contender", "web", "publishing", "collaboration server", "comprehensive", "version", "flexible gui environment"]], "textrank": [["adobe golive", "central hub", "gui", "design"], ["adobe golive", "central hub", "gui", "design"]], "positionrank": [["adobe golive", "central hub", "design assets", "design tools", "strong contender"], ["adobe golive", "central hub", "design assets", "design tools", "strong contender", "flexible gui environment", "collaboration server", "tight integration", "publishing", "web"]], "multipartiterank": [["adobe golive", "design assets", "strong contender", "web", "publishing"], ["adobe golive", "design assets", "strong contender", "web", "publishing", "workgroup", "version", "collaboration server", "central hub", "comprehensive"]]}, {"id": "214", "text": "Evolution of the high-end computing market in the USA\nThis paper focuses on the technological change in the high-end computing\n\tmarket. The discussion combines historical analysis with strategic\n\tanalysis to provide a framework to analyse a key component of the\n\tcomputer industry. This analysis begins from the perspective of\n\tgovernment research and development spending; then examines the\n\tconfusion around the evolution of the high-end computing market in the\n\tcontext of standard theories of technology strategy and new product\n\tinnovation. Rather than the high-end market being 'dead', one should\n\tview the market as changing due to increased capability and competition\n\tfrom the low-end personal computer market. The high-end market is also\n\tresponding to new product innovation from the introduction of new\n\tparallel computing architectures. In the conclusion, key leverage\n\tpoints in the market are identified and the trends in high-end\n\tcomputing are highlighted with implications\n", "keywords": "high-end computing market evolution; USA; historical analysis; strategic\n\tanalysis; computer industry; government research; development spending;\n\ttechnology strategy; new product innovation; competition; low-end\n\tpersonal computer market; parallel computing architectures;\n\tsupercomputing\n", "topicrank": [["end computing market", "high", "historical analysis", "new product", "market"], ["end computing market", "high", "historical analysis", "new product", "market", "key component", "parallel computing architectures", "evolution", "standard theories", "technology strategy"]], "textrank": [["end computing market", "computer market", "end computing", "end market", "development spending"], ["end computing market", "computer market", "end computing", "end market", "development spending", "government research", "historical analysis", "technological change", "computing", "market"]], "positionrank": [["end computing market", "end market being", "end market", "end computing", "personal computer market"], ["end computing market", "end market being", "end market", "end computing", "personal computer market", "market", "end", "parallel computing architectures", "new product innovation", "computing"]], "multipartiterank": [["end computing market", "high", "historical analysis", "new product", "market"], ["end computing market", "high", "historical analysis", "new product", "market", "evolution", "analysis", "key component", "technology strategy", "strategic"]]}, {"id": "1997", "text": "Exact controllability of shells in minimal time\nWe prove an exact controllability result for thin cups using the Fourier method\n\tand recent improvements of Ingham (1936) type theorems\n", "keywords": "controllability; shells; minimal time; thin cups; partial differential\n\tequations; Young modulus; Hilbert space; Fourier method; Ingham type\n\ttheorems\n", "topicrank": [["exact controllability", "recent improvements", "thin cups", "shells", "fourier method"], ["exact controllability", "recent improvements", "thin cups", "shells", "fourier method", "ingham", "minimal time", "type theorems"]], "textrank": [["minimal time", "controllability", "thin"], ["minimal time", "controllability", "thin"]], "positionrank": [["exact controllability result", "exact controllability", "minimal time", "thin cups", "fourier method"], ["exact controllability result", "exact controllability", "minimal time", "thin cups", "fourier method", "recent improvements", "shells", "type theorems", "ingham"]], "multipartiterank": [["exact controllability", "shells", "minimal time", "thin cups", "recent improvements"], ["exact controllability", "shells", "minimal time", "thin cups", "recent improvements", "fourier method", "ingham", "exact controllability result", "type theorems"]]}, {"id": "2043", "text": "Limits for computational electromagnetics codes imposed by computer\n\tarchitecture\nThe algorithmic complexity of the innermost loops that determine the complexity\n\tof algorithms in computational electromagnetics (CEM) codes are\n\tanalyzed according to their operation count and the impact of the\n\tunderlying computer hardware. As memory chips are much slower than\n\tarithmetic processors, codes that involve a high data movement compared\n\tto the number of arithmetic operations are executed comparatively\n\tslower. Hence, matrix-matrix multiplications are much faster than\n\tmatrix-vector multiplications. It is seen that it is not sufficient to\n\tcompare only the complexity, but also the actual performance of\n\talgorithms to judge on faster execution. Implications involve FDTD\n\tloops, LU factorizations, and iterative solvers for dense matrices. Run\n\ttimes on two reference platforms, namely an Athlon 900 MHz and an HP PA\n\t8600 processor, verify the findings\n", "keywords": "computational electromagnetics codes; computer architecture; algorithmic\n\tcomplexity; innermost loops; CEM codes; operation count; computer\n\thardware; memory chips; data movement; matrix-matrix multiplications;\n\tmatrix-vector multiplications; FDTD loops; LU factorizations; iterative\n\tsolvers; dense matrices\n", "topicrank": [["algorithmic complexity", "matrix", "innermost loops", "faster", "computational electromagnetics codes"], ["algorithmic complexity", "matrix", "innermost loops", "faster", "computational electromagnetics codes", "algorithms", "codes", "arithmetic processors", "computer", "fdtd"]], "textrank": [["memory chips", "computer hardware", "operation count", "innermost loops", "algorithmic complexity"], ["memory chips", "computer hardware", "operation count", "innermost loops", "algorithmic complexity", "multiplications", "data", "arithmetic", "electromagnetics", "loops"]], "positionrank": [["computational electromagnetics codes", "computational electromagnetics", "algorithmic complexity", "codes", "computer hardware"], ["computational electromagnetics codes", "computational electromagnetics", "algorithmic complexity", "codes", "computer hardware", "limits", "computer", "innermost loops", "complexity", "high data movement"]], "multipartiterank": [["algorithmic complexity", "computational electromagnetics codes", "computer", "innermost loops", "matrix"], ["algorithmic complexity", "computational electromagnetics codes", "computer", "innermost loops", "matrix", "codes", "algorithms", "architecture", "faster", "arithmetic processors"]]}, {"id": "2006", "text": "Lung metastasis detection and visualization on CT images: a knowledge-based\n\tmethod\nA solution to the problem of lung metastasis detection on computed tomography\n\t(CT) scans of the thorax is presented. A knowledge-based top-down\n\tapproach for image interpretation is used. The method is inspired by\n\tthe manner in which a radiologist and radiotherapist interpret CT\n\timages before radiotherapy is planned. A two-dimensional followed by a\n\tthree-dimensional analysis is performed. The algorithm first detects\n\tthe thorax contour, the lungs and the ribs, which further help the\n\tdetection of metastases. Thus, two types of tumors are detected:\n\tnodules and metastases located at the lung extremities. A method to\n\tvisualize the anatomical structures segmented is also presented. The\n\tsystem was tested on 20 patients (988 total images) from the Oncology\n\tDepartment of La Chaux-de-Fonds Hospital and the results show that the\n\tmethod is reliable as a computer-aided diagnostic tool for clinical\n\tpurpose in an oncology department\n", "keywords": "lung metastasis detection; data visualization; CT images; computed tomography;\n\tknowledge-based top-down approach; two-dimensional analysis;\n\tthree-dimensional analysis; computer-aided diagnostic tool; oncology;\n\tmedical imaging; knowledge representation; thorax; image interpretation\n", "topicrank": [["method", "ct images", "lung metastasis detection", "metastases", "department"], ["method", "ct images", "lung metastasis detection", "metastases", "department", "thorax", "knowledge", "dimensional", "radiotherapist interpret ct", "diagnostic tool"]], "textrank": [["lung metastasis", "interpret ct", "ct images", "oncology department", "anatomical structures"], ["lung metastasis", "interpret ct", "ct images", "oncology department", "anatomical structures", "thorax contour", "dimensional analysis", "image interpretation", "computed tomography", "lung"]], "positionrank": [["lung metastasis detection", "lung extremities", "ct images", "radiotherapist interpret ct", "detection"], ["lung metastasis detection", "lung extremities", "ct images", "radiotherapist interpret ct", "detection", "ct", "total images", "computed tomography", "method", "images"]], "multipartiterank": [["lung metastasis detection", "method", "ct images", "knowledge", "thorax"], ["lung metastasis detection", "method", "ct images", "knowledge", "thorax", "visualization", "metastases", "department", "problem", "computed tomography"]]}, {"id": "309", "text": "WEXTOR: a Web-based tool for generating and visualizing experimental designs\n\tand procedures\nWEXTOR is a Javascript-based experiment generator and teaching tool on the\n\tWorld Wide Web that can be used to design laboratory and Web\n\texperiments in a guided step-by-step process. It dynamically creates\n\tthe customized Web pages and Javascripts needed for the experimental\n\tprocedure and provides experimenters with a print-ready visual display\n\tof their experimental design. WEXTOR flexibly supports complete and\n\tincomplete factorial designs with between-subjects, within-subjects,\n\tand quasi-experimental factors, as well as mixed designs. The software\n\timplements client-side response time measurement and contains a content\n\twizard for creating interactive materials, as well as dependent\n\tmeasures (graphical scales, multiple-choice items, etc.), on the\n\texperiment pages. However, it does not aim to replace a full-fledged\n\tHTML editor. Several methodological features specifically needed in Web\n\texperimental design have been implemented in the Web-based tool and are\n\tdescribed in this paper. WEXTOR is platform independent. The created\n\tWeb pages can be uploaded to any type of Web server in which data may\n\tbe recorded in logfiles or via a database. The current version of\n\tWEXTOR is freely available for educational and noncommercial purposes.\n\tIts Web address is http://www.genpsylab.unizh.ch/wextor/index.html\n", "keywords": "WEXTOR; Web-based tool; experimental design visualization; Javascript-based\n\texperiment generator; teaching tool; World Wide Web; customized Web\n\tpages; print-ready visual display; factorial designs; client-side\n\tresponse time measurement; content wizard; HTML; Web server; logfiles;\n\tdatabase; free software\n", "topicrank": [["web", "wextor", "experimental", "experimental designs", "tool"], ["web", "wextor", "experimental", "experimental designs", "tool", "experiment generator", "step", "subjects", "graphical scales", "measures"]], "textrank": [["- experimental", "wide web", "web -", "web pages", "experimental designs"], ["- experimental", "wide web", "web -", "web pages", "experimental designs", "implements client -", "- step process", "response time", "experiment pages", "factorial designs"]], "positionrank": [["web pages", "wextor", "wide web", "web server", "web address"], ["web pages", "wextor", "wide web", "web server", "web address", "experimental designs", "web", "experimental design", "incomplete factorial designs", "teaching tool"]], "multipartiterank": [["web", "wextor", "experimental", "tool", "experimental designs"], ["web", "wextor", "experimental", "tool", "experimental designs", "experimental design", "experiment generator", "step", "web pages", "procedure"]]}, {"id": "288", "text": "Complexity transitions in global algorithms for sparse linear systems over\n\tfinite fields\nWe study the computational complexity of a very basic problem, namely that of\n\tfinding solutions to a very large set of random linear equations in a\n\tfinite Galois field modulo q. Using tools from statistical mechanics we\n\tare able to identify phase transitions in the structure of the solution\n\tspace and to connect them to the changes in the performance of a global\n\talgorithm, namely Gaussian elimination. Crossing phase boundaries\n\tproduces a dramatic increase in memory and CPU requirements necessary\n\tfor the algorithms. In turn, this causes the saturation of the upper\n\tbounds for the running time. We illustrate the results on the specific\n\tproblem of integer factorization, which is of central interest for\n\tdeciphering messages encrypted with the RSA cryptosystem\n", "keywords": "complexity transitions; global algorithms; sparse linear systems; finite\n\tfields; random linear equations; finite Galois field; statistical\n\tmechanics; Gaussian elimination; phase boundaries; integer\n\tfactorization; message deciphering; encryption; RSA cryptosystem;\n\tdisordered systems\n", "topicrank": [["global algorithms", "basic problem", "complexity transitions", "memory", "global"], ["global algorithms", "basic problem", "complexity transitions", "memory", "global", "algorithm", "gaussian elimination", "cpu requirements necessary", "crossing phase boundaries", "dramatic increase"]], "textrank": [["finite galois field modulo", "phase transitions", "linear", "complexity transitions", "statistical mechanics"], ["finite galois field modulo", "phase transitions", "linear", "complexity transitions", "statistical mechanics", "large set", "basic problem", "global algorithms", "phase", "requirements"]], "positionrank": [["complexity transitions", "sparse linear systems", "computational complexity", "global algorithms", "random linear equations"], ["complexity transitions", "sparse linear systems", "computational complexity", "global algorithms", "random linear equations", "phase transitions", "finite fields", "crossing phase boundaries", "algorithms", "basic problem"]], "multipartiterank": [["complexity transitions", "global algorithms", "basic problem", "sparse linear systems", "finite fields"], ["complexity transitions", "global algorithms", "basic problem", "sparse linear systems", "finite fields", "global", "algorithm", "solution", "gaussian elimination", "phase transitions"]]}, {"id": "26", "text": "Learning weights for the quasi-weighted means\nWe study the determination of weights for quasi-weighted means (also called\n\tquasi-linear means) when a set of examples is given. We consider first\n\ta simple case, the learning of weights for weighted means, and then we\n\textend the approach to the more general case of a quasi-weighted mean.\n\tWe consider the case of a known arbitrary generator f. The paper\n\tfinishes considering the use of parametric functions that are suitable\n\twhen the values to aggregate are measure values or ratio\n", "keywords": "quasi-weighted means; quasi-linear means; learning; parametric functions;\n\tmeasure values; ratio values\n", "topicrank": [["simple case", "weights", "values", "finishes", "parametric functions"], ["simple case", "weights", "values", "finishes", "parametric functions", "use", "paper", "learning", "weighted means", "arbitrary generator"]], "textrank": [["- weighted", "parametric functions", "arbitrary generator", "case", "weighted"], ["- weighted", "parametric functions", "arbitrary generator", "case", "weighted", "-", "values"]], "positionrank": [["weighted means", "weights", "simple case", "general case", "case"], ["weighted means", "weights", "simple case", "general case", "case", "determination", "examples", "approach", "learning", "set"]], "multipartiterank": [["weights", "simple case", "learning", "values", "weighted means"], ["weights", "simple case", "learning", "values", "weighted means", "parametric functions", "use", "finishes", "paper", "suitable"]]}, {"id": "275", "text": "Prediction of ultraviolet spectral absorbance using quantitative\n\tstructure-property relationships\nHigh performance liquid chromatography (HPLC) with ultraviolet (UV)\n\tspectrophotometric detection is a common method for analyzing reaction\n\tproducts in organic chemistry. This procedure would benefit from a\n\tcomputational model for predicting the relative response of organic\n\tmolecules. Models are now reported for the prediction of the integrated\n\tUV absorbance for a diverse set of organic compounds using a\n\tquantitative structure-property relationship (QSPR) approach. A\n\tseven-descriptor linear correlation with a squared correlation\n\tcoefficient (R/sup 2/) of 0.815 is reported for a data set of\n\t521.compounds. Using the sum of ZINDO oscillator strengths in the\n\tintegration range as an additional descriptor allowed reduction in the\n\tnumber of descriptors producing a robust model for 460 compounds with\n\tfive descriptors and a squared correlation coefficient 0.857. The\n\tdescriptors used in the models are discussed with respect to the\n\tphysical nature of the UV absorption process\n", "keywords": "ultraviolet spectral absorbance prediction; quantitative structure-property\n\trelationship; high performance liquid chromatography; ultraviolet\n\tspectrophotometric detection; reaction products; organic chemistry;\n\tcomputational model; relative response; seven-descriptor linear\n\tcorrelation; squared correlation coefficient; ZINDO oscillator\n\tstrengths; combinatorial chemistry; generic quantitation; configuration\n\tinteraction calculation; CODESSA program; MOS-F package\n", "topicrank": [["descriptors", "descriptor linear correlation", "property relationships", "organic chemistry", "quantitative"], ["descriptors", "descriptor linear correlation", "property relationships", "organic chemistry", "quantitative", "organic compounds", "ultraviolet spectral absorbance", "computational model", "models", "diverse set"]], "textrank": [["descriptor linear correlation", "performance liquid", "uv absorption", "spectral absorbance", "uv absorbance"], ["descriptor linear correlation", "performance liquid", "uv absorption", "spectral absorbance", "uv absorbance", "quantitative structure", "spectrophotometric detection", "oscillator", "set", "model"]], "positionrank": [["ultraviolet spectral absorbance", "quantitative structure", "uv absorbance", "property relationships", "prediction"], ["ultraviolet spectral absorbance", "quantitative structure", "uv absorbance", "property relationships", "prediction", "organic compounds", "ultraviolet", "property relationship", "uv absorption process", "structure"]], "multipartiterank": [["ultraviolet spectral absorbance", "quantitative", "property relationships", "organic chemistry", "prediction"], ["ultraviolet spectral absorbance", "quantitative", "property relationships", "organic chemistry", "prediction", "descriptor linear correlation", "structure", "descriptors", "organic compounds", "diverse set"]]}, {"id": "2187", "text": "Variable structure intelligent control for PM synchronous servo motor drive\nThe variable structure control (VSC) of discrete time systems based on\n\tintelligent control is presented in this paper. A novel approach is\n\tproposed for the state estimation. A linear observer is firstly\n\tdesigned. Then a neural network is used for compensating uncertainty.\n\tThe parameter of the VSC scheme is adjusted online by a neural network.\n\tPractical operating results from a PM synchronous motor (PMSM)\n\tillustrate the effectiveness and practicability of the proposed\n\tapproach\n", "keywords": "PM synchronous servo motor drive; variable structure intelligent control;\n\tcontrol design; discrete time systems; state estimation; linear\n\tobserver; neural network; uncertainty compensation; control performance\n", "topicrank": [["variable structure intelligent control", "pm synchronous servo motor drive", "vsc", "neural network", "novel approach"], ["variable structure intelligent control", "pm synchronous servo motor drive", "vsc", "neural network", "novel approach", "pmsm", "practical operating results", "effectiveness", "practicability", "discrete time systems"]], "textrank": [["synchronous motor", "state estimation", "novel approach", "structure", "motor"], ["synchronous motor", "state estimation", "novel approach", "structure", "motor", "synchronous", "operating", "time", "approach", "vsc"]], "positionrank": [["variable structure control", "variable structure", "intelligent control", "synchronous motor", "discrete time systems"], ["variable structure control", "variable structure", "intelligent control", "synchronous motor", "discrete time systems", "pm", "vsc scheme", "practical operating results", "neural network", "vsc"]], "multipartiterank": [["variable structure intelligent control", "pm synchronous servo motor drive", "vsc", "novel approach", "neural network"], ["variable structure intelligent control", "pm synchronous servo motor drive", "vsc", "novel approach", "neural network", "discrete time systems", "variable structure control", "paper", "state estimation", "linear observer"]]}, {"id": "230", "text": "2002 in-house fulfillment systems report [publishing]\nCM's 13th annual survey of in-house fulfillment system suppliers brings you up\n\tto date on the current capabilities of the leading publication software\n\tpackages\n", "keywords": "survey; in-house fulfillment system; suppliers; publication software packages\n", "topicrank": [["house fulfillment systems", "publication software", "current capabilities", "packages", "date"], ["house fulfillment systems", "publication software", "current capabilities", "packages", "date", "13th annual survey", "publishing"]], "textrank": [["fulfillment system", "current capabilities", "fulfillment", "annual"], ["fulfillment system", "current capabilities", "fulfillment", "annual"]], "positionrank": [["house fulfillment systems", "13th annual survey", "cm", "publishing", "current capabilities"], ["house fulfillment systems", "13th annual survey", "cm", "publishing", "current capabilities", "publication software", "date", "packages"]], "multipartiterank": [["house fulfillment systems", "publishing", "13th annual survey", "publication software", "current capabilities"], ["house fulfillment systems", "publishing", "13th annual survey", "publication software", "current capabilities", "date", "packages", "house fulfillment system suppliers"]]}, {"id": "368", "text": "From a biological to a computational model for the autonomous behavior of an\n\tanimat\nEndowing an autonomous system like a robot with intelligent behavior is\n\tdifficult for several reasons. First, behavior is such a wide topic\n\tthat a general framework paradigm of inspiration must be chosen in\n\torder to obtain a consistent model. Such a framework can be, for\n\texample, biological modeling or an artificial intelligence approach.\n\tSecond, a general framework is not sufficient to determine a fully\n\tspecified program to be implemented in a robot. Many choices, tuning\n\tand tests must be carried out before obtaining a robust system. A\n\tbiological model is presented, based on the definition of cortex-like\n\tautomata, representing elementary functions in the perceptive, motor or\n\tassociative domain. These automata are connected in a network whose\n\tarchitecture, functioning and learning rules are described in a\n\tcortical framework. Second, the computational model derived from that\n\tbiological model is specified. The way units exchange and compute\n\tvariables through links is explained, with reference to corresponding\n\tbiological elements. It is then easier to report experiments allowing\n\tan autonomous system to learn regularities of a simple environment and\n\tto exploit them to satisfy some internal drives. Even if additional\n\tbiological hints can be added, this model allow us to better understand\n\thow a biological model can be implemented and how biological properties\n\tcan emerge from a distributed set of units\n", "keywords": "autonomous system; robot; autonomous behavior; intelligent behavior; animat;\n\ttuning; tests; robust system; biological model; cortex-like automata;\n\telementary functions; perceptive domain; associative domain; motor\n\tdomain; learning rules; architecture; computational model; variable\n\tcomputation; variable exchange; links; regularity learning; simple\n\tenvironment; internal drives\n", "topicrank": [["computational model", "biological", "general framework paradigm", "autonomous system", "autonomous behavior"], ["computational model", "biological", "general framework paradigm", "autonomous system", "autonomous behavior", "automata", "robot", "compute", "like", "variables"]], "textrank": [["biological model", "biological", "autonomous system", "autonomous behavior", "simple environment"], ["biological model", "biological", "autonomous system", "autonomous behavior", "simple environment", "learning rules", "associative domain", "elementary functions", "many choices", "wide topic"]], "positionrank": [["biological model", "computational model", "biological modeling", "biological properties", "biological hints"], ["biological model", "computational model", "biological modeling", "biological properties", "biological hints", "autonomous behavior", "biological elements", "biological", "autonomous system", "consistent model"]], "multipartiterank": [["computational model", "biological", "autonomous behavior", "general framework paradigm", "autonomous system"], ["computational model", "biological", "autonomous behavior", "general framework paradigm", "autonomous system", "robot", "automata", "biological model", "animat", "inspiration"]]}, {"id": "400", "text": "A 120-mW 3-D rendering engine with 6-Mb embedded DRAM and 3.2-GB/s runtime\n\treconfigurable bus for PDA chip\nA low-power three-dimensional (3-D) rendering engine is implemented as part of\n\ta mobile personal digital assistant (PDA) chip. Six-megabit embedded\n\tDRAM macros attached to 8-pixel-parallel rendering logic are logically\n\tlocalized with a 3.2-GB/s runtime reconfigurable bus, reducing the area\n\tby 25% compared with conventional local frame-buffer architectures. The\n\tlow power consumption is achieved by polygon-dependent access to the\n\tembedded DRAM macros with line-block mapping providing\n\tread-modify-write data transaction. The 3-D rendering engine with\n\t2.22-Mpolygons/s drawing speed was fabricated using 0.18- mu m CMOS\n\tembedded memory logic technology. Its area is 24 mm/sup 2/ and its\n\tpower consumption is 120 mW\n", "keywords": "low-power 3D rendering engine; three-dimensional rendering engine; mobile PDA\n\tchip; mobile personal digital assistant chip; embedded DRAM macros;\n\t8-pixel-parallel rendering logic; reconfigurable bus; low power\n\tconsumption; polygon-dependent access; line-block mapping;\n\tread-modify-write data transaction; CMOS embedded memory logic\n\ttechnology; 3D graphics rendering; 120 mW; 6 Mbit; 3.2 GB/s; 0.18\n\tmicron\n", "topicrank": [["dram", "power", "pda chip", "engine", "reconfigurable bus"], ["dram", "power", "pda chip", "engine", "reconfigurable bus", "area", "pda", "mobile personal digital assistant", "line", "low"]], "textrank": [["rendering logic", "mu m", "runtime reconfigurable", "personal digital", "dram macros"], ["rendering logic", "mu m", "runtime reconfigurable", "personal digital", "dram macros", "pda chip", "logic", "rendering", "local", "power"]], "positionrank": [["low power consumption", "pda chip", "dram macros", "rendering engine", "s runtime"], ["low power consumption", "pda chip", "dram macros", "rendering engine", "s runtime", "reconfigurable bus", "power consumption", "parallel rendering logic", "engine", "dram"]], "multipartiterank": [["pda chip", "power", "engine", "dram", "reconfigurable bus"], ["pda chip", "power", "engine", "dram", "reconfigurable bus", "low", "dimensional", "dram macros", "mobile personal digital assistant", "pda"]]}, {"id": "2067", "text": "A comparison of the discounted utility model and hyperbolic discounting models\n\tin the case of social and private intertemporal preferences for health\nWhilst there is substantial evidence that hyperbolic discounting models\n\tdescribe intertemporal preferences for monetary outcomes better than\n\tthe discounted utility (DU) model, there is only very limited evidence\n\tin the context of health outcomes. This study elicits private and\n\tsocial intertemporal preferences for non-fatal changes in health.\n\tSpecific functional forms of the DU model and three hyperbolic models\n\tare fitted. The results show that the stationarity axiom is violated,\n\tand that the hyperbolic models fit the data better than the DU model.\n\tIntertemporal preferences for private and social decisions are found to\n\tbe very similar\n", "keywords": "discounted utility model; hyperbolic discounting models; intertemporal\n\tpreferences; health outcomes; private decisions; social decisions\n", "topicrank": [["private intertemporal preferences", "hyperbolic", "health", "model", "models"], ["private intertemporal preferences", "hyperbolic", "health", "model", "models", "private", "social", "substantial evidence", "discounted utility model", "study"]], "textrank": [["social intertemporal", "- fatal", "utility model", "outcomes", "intertemporal"], ["social intertemporal", "- fatal", "utility model", "outcomes", "intertemporal", "functional", "evidence", "model", "utility", "social"]], "positionrank": [["social intertemporal preferences", "private intertemporal preferences", "discounted utility model", "hyperbolic models", "intertemporal preferences"], ["social intertemporal preferences", "private intertemporal preferences", "discounted utility model", "hyperbolic models", "intertemporal preferences", "du model", "discounted utility", "health outcomes", "model", "models"]], "multipartiterank": [["private intertemporal preferences", "hyperbolic", "health", "models", "discounted utility model"], ["private intertemporal preferences", "hyperbolic", "health", "models", "discounted utility model", "social", "substantial evidence", "model", "case", "intertemporal preferences"]]}, {"id": "2022", "text": "Two-step integral imaging for orthoscopic three-dimensional imaging with\n\timproved viewing resolution\nWe present a two-step integral imaging system to obtain 3-D orthoscopic real\n\timages. By adopting a nonstationary micro-optics technique, we\n\tdemonstrate experimentally the potential usefulness of two-step\n\tintegral imaging\n", "keywords": "two-step integral imaging; resolution improved viewing; two-step integral\n\timaging system; 3-D orthoscopic real images; nonstationary micro-optics\n\ttechnique; 3-D image reconstruction; liquid crystal light valve;\n\tdisplay device; LCLV; pickup lenslet array\n", "topicrank": [["step integral imaging", "orthoscopic", "improved", "nonstationary micro", "images"], ["step integral imaging", "orthoscopic", "improved", "nonstationary micro", "images", "resolution", "optics technique", "step", "potential usefulness"]], "textrank": [["integral imaging", "orthoscopic real", "imaging", "nonstationary", "orthoscopic"], ["integral imaging", "orthoscopic real", "imaging", "nonstationary", "orthoscopic"]], "positionrank": [["step integral imaging", "integral imaging system", "integral imaging", "dimensional imaging", "step"], ["step integral imaging", "integral imaging system", "integral imaging", "dimensional imaging", "step", "orthoscopic", "potential usefulness", "optics technique", "resolution", "images"]], "multipartiterank": [["step integral imaging", "orthoscopic", "improved", "resolution", "dimensional imaging"], ["step integral imaging", "orthoscopic", "improved", "resolution", "dimensional imaging", "images", "nonstationary micro", "orthoscopic real", "optics technique", "step"]]}, {"id": "395", "text": "Conformal-mapping design tools for coaxial couplers with complex cross section\nNumerical conformal mapping is exploited as a simple, accurate, and efficient\n\ttool for the analysis and design of coaxial waveguides and couplers of\n\tcomplex cross section. An implementation based on the\n\tSchwarz-Christoffel Toolbox, a public-domain MATLAB package, is applied\n\tto slotted coaxial cables and to symmetrical coaxial couplers, with\n\tcircular or polygonal inner conductors and external shields. The effect\n\tof metallic diaphragms of arbitrary thickness, partially separating the\n\tinner conductors, is also easily taken into account. The proposed\n\ttechnique is validated against the results of the finite-element\n\tmethod, showing excellent agreement at a fraction of the computational\n\tcost, and is also extended to the case of nonsymmetrical couplers,\n\tproviding the designer with important additional degrees of freedom\n", "keywords": "conformal mapping design tools; coaxial couplers; complex cross section;\n\tcoaxial waveguides; Schwarz-Christoffel Toolbox; public-domain MATLAB\n\tpackage; slotted coaxial cables; symmetrical couplers; circular inner\n\tconductors; polygonal inner conductors; external shields; metallic\n\tdiaphragms; nonsymmetrical couplers; numerical conformal\n\ttransformations\n", "topicrank": [["coaxial couplers", "coaxial waveguides", "complex cross section", "design tools", "polygonal inner conductors"], ["coaxial couplers", "coaxial waveguides", "complex cross section", "design tools", "polygonal inner conductors", "conformal", "element", "method", "finite", "analysis"]], "textrank": [["coaxial couplers", "coaxial", "arbitrary thickness", "metallic diaphragms", "external shields"], ["coaxial couplers", "coaxial", "arbitrary thickness", "metallic diaphragms", "external shields", "christoffel toolbox", "design tools", "additional", "inner", "matlab"]], "positionrank": [["symmetrical coaxial couplers", "coaxial couplers", "complex cross section", "numerical conformal mapping", "coaxial waveguides"], ["symmetrical coaxial couplers", "coaxial couplers", "complex cross section", "numerical conformal mapping", "coaxial waveguides", "coaxial cables", "conformal", "design tools", "nonsymmetrical couplers", "couplers"]], "multipartiterank": [["coaxial couplers", "conformal", "design tools", "complex cross section", "coaxial waveguides"], ["coaxial couplers", "conformal", "design tools", "complex cross section", "coaxial waveguides", "polygonal inner conductors", "analysis", "accurate", "efficient", "tool"]]}, {"id": "310", "text": "ePsych: interactive demonstrations and experiments in psychology\nePsych (http://epsych.msstate.edu), a new Web site currently under active\n\tdevelopment, is intended to teach students about the discipline of\n\tpsychology. The site presumes little prior knowledge about the field\n\tand so may be used in introductory classes, but it incorporates\n\tsufficient depth of coverage to be useful in more advanced classes as\n\twell. Numerous interactive and dynamic elements are incorporated into\n\tvarious modules, orientations, and guidebooks. These elements include\n\tJava-based experiments and demonstrations, video clips, and animated\n\tdiagrams. Rapid access to all material is provided through a\n\tlayer-based navigation system that allows users to visit various\n\t\"Worlds of the Mind.\" Active learning is encouraged, by challenging\n\tstudents with puzzles and problems and by providing the opportunity to\n\t\"dig deeper\" to learn more about the phenomena at hand\n", "keywords": "ePsych; interactive demonstrations; psychology experiments; Web site; teaching;\n\tJava-based experiments; video clips; animated diagrams; layer-based\n\tnavigation system; Worlds of the Mind; active learning\n", "topicrank": [["interactive demonstrations", "experiments", "various modules", "active", "dynamic elements"], ["interactive demonstrations", "experiments", "various modules", "active", "dynamic elements", "psychology", "students", "new web site", "introductory classes", "epsych"]], "textrank": [["navigation system", "rapid access", "video clips", "various modules", "dynamic elements"], ["navigation system", "rapid access", "video clips", "various modules", "dynamic elements", "sufficient depth", "classes", "prior", "web", "interactive"]], "positionrank": [["interactive demonstrations", "epsych", "new web site", "psychology", "demonstrations"], ["interactive demonstrations", "epsych", "new web site", "psychology", "demonstrations", "experiments", "dynamic elements", "little prior knowledge", "site", "various modules"]], "multipartiterank": [["interactive demonstrations", "experiments", "psychology", "new web site", "active"], ["interactive demonstrations", "experiments", "psychology", "new web site", "active", "epsych", "dynamic elements", "various modules", "students", "introductory classes"]]}, {"id": "355", "text": "An identity-based society oriented signature scheme with anonymous signers\nIn this paper, we propose a new society oriented scheme, based on the\n\tGuillou-Quisquater (1989) signature scheme. The scheme is\n\tidentity-based and the signatures are verified with respect to only one\n\tidentity. That is, the verifier does not have to know the identity of\n\tthe co-signers, but just that of the organization they represent\n", "keywords": "identity-based society oriented signature scheme; anonymous signers; signature\n\tverification\n", "topicrank": [["signature scheme", "identity", "society", "quisquater", "guillou"], ["signature scheme", "identity", "society", "quisquater", "guillou", "anonymous signers", "signatures", "paper", "respect", "verifier"]], "textrank": [["- signers", "signature scheme", "signers", "-", "scheme"], ["- signers", "signature scheme", "signers", "-", "scheme", "society"]], "positionrank": [["signature scheme", "identity", "scheme", "co - signers", "anonymous signers"], ["signature scheme", "identity", "scheme", "co - signers", "anonymous signers", "new society", "society", "paper", "guillou", "quisquater"]], "multipartiterank": [["signature scheme", "identity", "society", "scheme", "anonymous signers"], ["signature scheme", "identity", "society", "scheme", "anonymous signers", "quisquater", "guillou", "paper", "new society", "signatures"]]}, {"id": "248", "text": "Universal dynamic synchronous self-stabilization\nWe prove the existence of a \"universal\" synchronous self-stabilizing protocol,\n\tthat is, a protocol that allows a distributed system to stabilize to a\n\tdesired nonreactive behaviour (as long as a protocol stabilizing to\n\tthat behaviour exists). Previous proposals required drastic increases\n\tin asymmetry and knowledge to work, whereas our protocol does not use\n\tany additional knowledge, and does not require more symmetry-breaking\n\tconditions than available; thus, it is also stabilizing with respect to\n\tdynamic changes in the topology. We prove an optimal quiescence time n\n\t+ D for a synchronous network of n processors and diameter D; the\n\tprotocol can be made finite state with a negligible loss in quiescence\n\ttime. Moreover, an optimal D + 1 protocol is given for the case of\n\tunique identifiers. As a consequence, we provide an effective proof\n\ttechnique that allows one to show whether self-stabilization to a\n\tcertain behaviour is possible under a wide range of models\n", "keywords": "universal dynamic synchronous self-stabilization; synchronous self-stabilizing\n\tprotocol; distributed system; nonreactive behaviour; topology; dynamic\n\tchanges; optimal quiescence time; synchronous network; finite state;\n\tquiescence time; optimal protocol; unique identifiers; proof technique;\n\tself-stabilization; anonymous networks; graph fibrations\n", "topicrank": [["protocol", "universal dynamic synchronous self", "nonreactive behaviour", "stabilization", "knowledge"], ["protocol", "universal dynamic synchronous self", "nonreactive behaviour", "stabilization", "knowledge", "quiescence", "negligible loss", "drastic increases", "asymmetry", "previous proposals"]], "textrank": [["optimal quiescence time n", "dynamic synchronous", "optimal d", "additional knowledge", "drastic increases"], ["optimal quiescence time n", "dynamic synchronous", "optimal d", "additional knowledge", "drastic increases", "previous proposals", "distributed system", "dynamic", "synchronous", "behaviour"]], "positionrank": [["synchronous self", "synchronous network", "self", "dynamic changes", "optimal d"], ["synchronous self", "synchronous network", "self", "dynamic changes", "optimal d", "protocol", "diameter d", "stabilization", "certain behaviour", "nonreactive behaviour"]], "multipartiterank": [["universal dynamic synchronous self", "protocol", "stabilization", "nonreactive behaviour", "knowledge"], ["universal dynamic synchronous self", "protocol", "stabilization", "nonreactive behaviour", "knowledge", "asymmetry", "universal", "drastic increases", "existence", "previous proposals"]]}, {"id": "1936", "text": "A new approach to the decomposition of Boolean functions by the method of\n\tq-partitions.II. Repeated decomposition\nFor pt.I. see Upr. Sist. Mash., no. 6, p. 29-42 (1999). A new approach to the\n\tdecomposition of Boolean,functions that depend on n variables and are\n\trepresented in various forms is considered. The approach is based on\n\tthe method of q-partitioning of minterms and on the introduced concept\n\tof a decomposition clone. The theorem on simple disjunctive\n\tdecomposition of full and partial functions is formulated. The approach\n\tproposed is illustrated by examples\n", "keywords": "Boolean functions decomposition; minterms; decomposition clone; disjunctive\n\tdecomposition; partial functions; logic synthesis; q-partitions\n", "topicrank": [["decomposition", "new approach", "functions", "boolean functions", "method"], ["decomposition", "new approach", "functions", "boolean functions", "method", "simple disjunctive", "full", "theorem", "partitioning", "minterms"]], "textrank": [["decomposition clone .", "various forms", "new approach", ".", "functions"], ["decomposition clone .", "various forms", "new approach", ".", "functions", "simple", "approach", "decomposition"]], "positionrank": [["new approach", "boolean functions", "decomposition clone", "decomposition", "partial functions"], ["new approach", "boolean functions", "decomposition clone", "decomposition", "partial functions", "approach", "functions", "boolean", "mash .", "no ."]], "multipartiterank": [["decomposition", "new approach", "boolean functions", "functions", "method"], ["decomposition", "new approach", "boolean functions", "functions", "method", "boolean", "approach", "simple disjunctive", "full", "theorem"]]}, {"id": "1973", "text": "Affine invariants of convex polygons\nIn this correspondence, we prove that the affine invariants, for image\n\tregistration and object recognition, proposed recently by Yang and\n\tCohen (see ibid., vol.8, no.7, p.934-46, July 1999) are algebraically\n\tdependent. We show how to select an independent and complete set of the\n\tinvariants. The use of this new set leads to a significant reduction of\n\tthe computing complexity without decreasing the discrimination power\n", "keywords": "affine invariants; convex polygons; algebraically dependent. invariants;\n\tcomplexity reduction; image registration; object recognition; convex\n\tquadruplet; feature vector\n", "topicrank": [["affine invariants", "complete set", "registration", "image", "object recognition"], ["affine invariants", "complete set", "registration", "image", "object recognition", "cohen", "use", "yang", "independent", "convex polygons"]], "textrank": [["object recognition", "convex polygons", "affine invariants", "set", "significant"], ["object recognition", "convex polygons", "affine invariants", "set", "significant", "invariants"]], "positionrank": [["affine invariants", "invariants", "convex polygons", "object recognition", "correspondence"], ["affine invariants", "invariants", "convex polygons", "object recognition", "correspondence", "new set", "complete set", "registration", "image", "significant reduction"]], "multipartiterank": [["affine invariants", "registration", "image", "complete set", "convex polygons"], ["affine invariants", "registration", "image", "complete set", "convex polygons", "object recognition", "correspondence", "cohen", "yang", "ibid"]]}, {"id": "2102", "text": "Trust in online advice\nMany people are now influenced by the information and advice they find on the\n\tInternet, much of it of dubious quality. This article describes two\n\tstudies concerned with those factors capable of influencing people's\n\tresponse to online advice. The first study is a qualitative account of\n\ta group of house-hunters attempting to find worthwhile information\n\tonline. The second study describes a survey of more than 2,500 people\n\twho had actively sought advice over the Internet. A framework for\n\tunderstanding trust in online advice is proposed in which first\n\timpressions are distinguished from more detailed evaluations. Good Web\n\tdesign can influence the first process, but three key factors-source\n\tcredibility, personalization, and predictability-are shown to predict\n\twhether people actually follow the advice given\n", "keywords": "online advice trust; Internet; survey; online mortgage advice; Web design;\n\tsource credibility; personalization; predictability; e-commerce; house\n\tbuying advice\n", "topicrank": [["online advice", "many people", "first study", "factors capable", "internet"], ["online advice", "many people", "first study", "factors capable", "internet", "information", "house", "credibility", "source", "group"]], "textrank": [["first study", "dubious quality", "many people", "online advice", "detailed"], ["first study", "dubious quality", "many people", "online advice", "detailed", "factors", "first", "study", "online", "qualitative"]], "positionrank": [["online advice", "advice", "many people", "first study", "people"], ["online advice", "advice", "many people", "first study", "people", "first process", "worthwhile information", "more detailed evaluations", "second study", "key factors"]], "multipartiterank": [["online advice", "many people", "first study", "people", "advice"], ["online advice", "many people", "first study", "people", "advice", "information", "internet", "factors capable", "response", "qualitative account"]]}, {"id": "2147", "text": "Much ado about nothing: Win32.Perrun\nJPEG files do not contain any executable code and it is impossible to infect\n\tsuch files. The author takes a look at the details surrounding the\n\tWin32.Perrun virus and make clear exactly what it does. The main virus\n\tfeature is its ability to affect JPEG image files (compressed graphic\n\timages) and to spread via affected JPEG files. The virus affects, or\n\tmodifies, or alters JPEG files but does not \"infect\" them\n", "keywords": "Win32.Perrun; JPEG files; virus; compressed graphic images\n", "topicrank": [["jpeg files", "main virus", "feature", "graphic", "ability"], ["jpeg files", "main virus", "feature", "graphic", "ability", "images", "look", "details", "author", "executable code"]], "textrank": [["executable code", "much ado", "files", "virus"], ["executable code", "much ado", "files", "virus"]], "positionrank": [["jpeg image files", "jpeg files", "such files", "much ado", "win32.perrun virus"], ["jpeg image files", "jpeg files", "such files", "much ado", "win32.perrun virus", "main virus", "win32.perrun", "executable code", "virus", "look"]], "multipartiterank": [["jpeg files", "main virus", "feature", "ability", "graphic"], ["jpeg files", "main virus", "feature", "ability", "graphic", "images", "look", "jpeg image files", "details", "author"]]}, {"id": "2063", "text": "On emotion and bounded rationality: reply to Hanoch\nThe author refers to the comment made by Hanoch (see ibid. vol.49 (2000)) on\n\this model of bounded rationality and the role of the Yerkes-Dodson law\n\tand emotional arousal in it. The author points out that Hanoch's\n\tcomment, however, conspicuously fails to challenge - much less\n\tcontradict - the central hypothesis of his paper. In addition, several\n\tof Hanoch's criticisms are based on a wrong characterization of the\n\tpositions\n", "keywords": "emotion; bounded rationality; Yerkes-Dodson law; decision-making; psychology\n", "topicrank": [["hanoch", "rationality", "author", "comment", "addition"], ["hanoch", "rationality", "author", "comment", "addition", "several", "dodson law", "yerkes", "reply", "role"]], "textrank": [["wrong characterization", "central hypothesis", "emotional arousal", "dodson law"], ["wrong characterization", "central hypothesis", "emotional arousal", "dodson law"]], "positionrank": [["hanoch", "rationality", "dodson law", "author", "emotion"], ["hanoch", "rationality", "dodson law", "author", "emotion", "emotional arousal", "comment", "reply", "yerkes", "wrong characterization"]], "multipartiterank": [["hanoch", "rationality", "author", "comment", "addition"], ["hanoch", "rationality", "author", "comment", "addition", "several", "dodson law", "yerkes", "reply", "role"]]}, {"id": "2026", "text": "Iterative regularized least-mean mixed-norm image restoration\nWe develop a regularized mixed-norm image restoration algorithm to deal with\n\tvarious types of noise. A mixed-norm functional is introduced, which\n\tcombines the least mean square (LMS) and the least mean fourth (LMF)\n\tfunctionals, as well as a smoothing functional. Two regularization\n\tparameters are introduced: one to determine the relative importance of\n\tthe LMS and LMF functionals, which is a function of the kurtosis, and\n\tanother to determine the relative importance of the smoothing\n\tfunctional. The two parameters are chosen in such a way that the\n\tproposed functional is convex, so that a unique minimizer exists. An\n\titerative algorithm is utilized for obtaining the solution, and its\n\tconvergence is analyzed. The novelty of the proposed algorithm is that\n\tno knowledge of the noise distribution is required, and the relative\n\tcontributions of the LMS, the LMF, and the smoothing functionals are\n\tadjusted based on the partially restored image. Experimental results\n\tdemonstrate the effectiveness of the proposed algorithm\n", "keywords": "iterative regularized least-mean mixed-norm image restoration; noise;\n\tmixed-norm functional; least mean square functionals; mean fourth\n\tfunctionals; smoothing functional; regularization parameters; kurtosis;\n\tconvex functional; unique minimizer; iterative algorithm; convergence;\n\tnoise distribution; partially restored image\n", "topicrank": [["norm functional", "lms", "least", "relative importance", "mean mixed"], ["norm functional", "lms", "least", "relative importance", "mean mixed", "functionals", "norm image restoration", "iterative algorithm", "lmf", "noise"]], "textrank": [["norm image restoration algorithm", "norm image restoration", "lmf functionals", "relative importance", "various types"], ["norm image restoration algorithm", "norm image restoration", "lmf functionals", "relative importance", "various types", "mean", "algorithm", "norm", "image", "relative"]], "positionrank": [["norm image restoration", "iterative algorithm", "least mean square", "norm", "image"], ["norm image restoration", "iterative algorithm", "least mean square", "norm", "image", "lmf functionals", "algorithm", "various types", "relative importance", "noise distribution"]], "multipartiterank": [["mean mixed", "least", "norm image restoration", "norm functional", "lms"], ["mean mixed", "least", "norm image restoration", "norm functional", "lms", "functional", "functionals", "mixed", "relative importance", "noise"]]}, {"id": "391", "text": "Model selection in electromagnetic source analysis with an application to VEFs\nIn electromagnetic source analysis, it is necessary to determine how many\n\tsources are required to describe the electroencephalogram or\n\tmagnetoencephalogram adequately. Model selection procedures (MSPs) or\n\tgoodness of fit procedures give an estimate of the required number of\n\tsources. Existing and new MSPs are evaluated in different source and\n\tnoise settings: two sources which are close or distant and noise which\n\tis uncorrelated or correlated. The commonly used MSP residual variance\n\tis seen to be ineffective, that is it often selects too many sources.\n\tAlternatives like the adjusted Hotelling's test, Bayes information\n\tcriterion and the Wald test on source amplitudes are seen to be\n\teffective. The adjusted Hotelling's test is recommended if a\n\tconservative approach is taken and MSPs such as Bayes information\n\tcriterion or the Wald test on source amplitudes are recommended if a\n\tmore liberal approach is desirable. The MSPs are applied to empirical\n\tdata (visual evoked fields)\n", "keywords": "model selection; electromagnetic source analysis; noise settings; residual\n\tvariance; Wald test; adjusted Hotelling's test; empirical data; VEFs;\n\tMEG source analysis; EEG source analysis; goodness-of-fit; source\n\tlocalization; visual evoked fields\n", "topicrank": [["test", "msps", "sources", "different source", "bayes information"], ["test", "msps", "sources", "different source", "bayes information", "adjusted hotelling", "criterion", "model selection", "many", "electromagnetic source analysis"]], "textrank": [["selection procedures", "source", "adjusted hotelling", "many sources", "noise settings"], ["selection procedures", "source", "adjusted hotelling", "many sources", "noise settings", "required number", "approach", "residual", "msps", "procedures"]], "positionrank": [["electromagnetic source analysis", "model selection procedures", "model selection", "source amplitudes", "different source"], ["electromagnetic source analysis", "model selection procedures", "model selection", "source amplitudes", "different source", "new msps", "many sources", "fit procedures", "msps", "wald test"]], "multipartiterank": [["model selection", "sources", "test", "msps", "electromagnetic source analysis"], ["model selection", "sources", "test", "msps", "electromagnetic source analysis", "different source", "adjusted hotelling", "many", "bayes information", "criterion"]]}, {"id": "329", "text": "Implications of document-level literacy skills for Web site design\nThe proliferation of World Wide Web (Web) sites and the low cost of publishing\n\tinformation on the Web have placed a tremendous amount of information\n\tat the fingertips of millions of people. Although most of this\n\tinformation is at least intended to be accurate, there is much that is\n\trumor, innuendo, urban legend, and outright falsehood. This raises\n\tproblems especially for students (of all ages) trying to do research or\n\tlearn about some topic. Finding accurate, credible information requires\n\tdocument level literacy skills, such as integration, sourcing,\n\tcorroboration, and search. This paper discusses these skills and offers\n\ta list of simple ways that designers of educational Web sites can help\n\ttheir visitors utilize these skills\n", "keywords": "document-level literacy skills; rumor; innuendo; urban legend; falsehood;\n\tstudents; accurate credible information; integration; sourcing;\n\tcorroboration; search; educational Web site design\n", "topicrank": [["information", "level literacy skills", "web site design", "sites", "accurate"], ["information", "level literacy skills", "web site design", "sites", "accurate", "innuendo", "urban legend", "millions", "simple ways", "rumor"]], "textrank": [["wide web", "web site", "level literacy", "web", "credible information"], ["wide web", "web site", "level literacy", "web", "credible information", "outright falsehood", "urban legend", "tremendous amount", "low cost", "information"]], "positionrank": [["level literacy skills", "web site design", "world wide web", "educational web sites", "web"], ["level literacy skills", "web site design", "world wide web", "educational web sites", "web", "skills", "credible information", "implications", "document", "information"]], "multipartiterank": [["web site design", "level literacy skills", "information", "sites", "document"], ["web site design", "level literacy skills", "information", "sites", "document", "proliferation", "web", "accurate", "implications", "low cost"]]}, {"id": "404", "text": "A 0.8-V 128-kb four-way set-associative two-level CMOS cache memory using\n\ttwo-stage wordline/bitline-oriented tag-compare (WLOTC/BLOTC) scheme\nThis paper reports a 0.8-V 128-kb four-way set-associative two-level CMOS cache\n\tmemory using a novel two-stage wordline/bitline-oriented tag-compare\n\t(WLOTC/BLOTC) and sense wordline/bitline (SWL/SBL) tag-sense amplifiers\n\twith an eight-transistor (8-T) tag cell in Level 2 (L2) and a 10-T\n\tshrunk logic swing (SLS) memory cell. with the ground/floating (G/F)\n\tdata sense amplifier in Level 1 (L1) for high-speed operation for\n\tlow-voltage low-power VLSI system applications. Owing to the reduced\n\tloading at the SWL in the new 11-T tag cell using the WLOTC scheme, the\n\t10-T SLS memory cell with G/F sense amplifier in L1, and the split\n\tcomparison of the index signal in the 8-T tag cells with SWL/SBL tag\n\tsense amplifiers in L2, this 0.8-V cache memory implemented in a 1.8-V\n\t0.18- mu m CMOS technology has a measured L1/L2 hit time of 11.6/20.5\n\tns at the average dissipation of 0.77 mW at 50 MHz\n", "keywords": "four-way set-associative memory; two-level CMOS cache memory; cache memory\n\tarchitecture; wordline/bitline-oriented tag-compare; sense\n\twordline/bitline amplifiers; tag-sense amplifiers; eight-transistor tag\n\tcell; ten-transistor memory cell; shrunk logic swing memory cell;\n\tground/floating data sense amplifier; high-speed operation; low-voltage\n\tVLSI system applications; low-power VLSI system applications; 0.8 V;\n\t128 kbit; 50 MHz; 0.77 mW; 1.8 V; 0.18 micron; 11.6 ns; 20.5 ns\n", "topicrank": [["tag", "level cmos cache memory", "memory", "bitline", "swl"], ["tag", "level cmos cache memory", "memory", "bitline", "swl", "sense wordline", "wlotc", "blotc", "compare", "stage wordline"]], "textrank": [["cmos cache memory", "11-t tag cell", "sense wordline", "m cmos", "tag cell"], ["cmos cache memory", "11-t tag cell", "sense wordline", "m cmos", "tag cell", "cmos cache", "sense", "vlsi system", "cache memory", "memory cell"]], "positionrank": [["level cmos cache", "cache memory", "sls memory cell", "level cmos", "memory cell"], ["level cmos cache", "cache memory", "sls memory cell", "level cmos", "memory cell", "tag cell", "sense wordline", "way set", "sbl tag", "f sense amplifier"]], "multipartiterank": [["tag", "level cmos cache memory", "bitline", "sense wordline", "memory"], ["tag", "level cmos cache memory", "bitline", "sense wordline", "memory", "compare", "blotc", "swl", "wlotc", "stage wordline"]]}, {"id": "271", "text": "On the use of neural network ensembles in QSAR and QSPR\nDespite their growing popularity among neural network practitioners, ensemble\n\tmethods have not been widely adopted in structure-activity and\n\tstructure-property correlation. Neural networks are inherently\n\tunstable, in that small changes in the training set and/or training\n\tparameters can lead to large changes in their generalization\n\tperformance. Recent research has shown that by capitalizing on the\n\tdiversity of the individual models, ensemble techniques can minimize\n\tuncertainty and produce more stable and accurate predictors. In this\n\twork, we present a critical assessment of the most common ensemble\n\ttechnique known as bootstrap aggregation, or bagging, as applied to\n\tQSAR and QSPR. Although aggregation does offer definitive advantages,\n\twe demonstrate that bagging may not be the best possible choice and\n\tthat simpler techniques such as retraining with the full sample can\n\toften produce superior results. These findings are rationalized using\n\tKrogh and Vedelsby's (1995) decomposition of the generalization error\n\tinto a term that measures the average generalization performance of the\n\tindividual networks and a term that measures the diversity among them.\n\tFor networks that are designed to resist over-fitting, the benefits of\n\taggregation are clear but not overwhelming\n", "keywords": "neural network ensembles; QSAR; QSPR; training set; training parameters;\n\tgeneralization performance; uncertainty; bootstrap aggregation;\n\tbagging; retraining; generalization error decomposition;\n\tstructure-activity correlation; structure-property correlation\n", "topicrank": [["ensemble", "bootstrap aggregation", "neural networks", "neural network ensembles", "generalization"], ["ensemble", "bootstrap aggregation", "neural networks", "neural network ensembles", "generalization", "qsar", "small changes", "performance", "qspr", "structure"]], "textrank": [["ensemble techniques", "neural network", "individual networks", "neural networks", "bootstrap aggregation"], ["ensemble techniques", "neural network", "individual networks", "neural networks", "bootstrap aggregation", "critical assessment", "accurate predictors", "recent research", "property correlation", "generalization"]], "positionrank": [["neural network ensembles", "neural network practitioners", "neural networks", "qspr", "ensemble techniques"], ["neural network ensembles", "neural network practitioners", "neural networks", "qspr", "ensemble techniques", "qsar", "use", "individual networks", "average generalization performance", "bootstrap aggregation"]], "multipartiterank": [["ensemble", "neural network ensembles", "bootstrap aggregation", "qsar", "structure"], ["ensemble", "neural network ensembles", "bootstrap aggregation", "qsar", "structure", "neural networks", "small changes", "training", "qspr", "generalization"]]}, {"id": "2183", "text": "Knowledge-based structures and organisational commitment\nOrganisational commitment, the emotional attachment of an employee to the\n\temploying organisation, has attracted a substantial body of literature,\n\trelating the concept to various antecedents, including organisational\n\tstructure, and to a range of consequences, including financially\n\timportant performance factors such as productivity and staff turnover.\n\tThe new areas of knowledge management and learning organisations offer\n\tsubstantial promise as imperatives for the organisation of business\n\tenterprises. As organisations in the contemporary environment adopt\n\tknowledge-based structures to improve their competitive position, there\n\tis value in examining these structures against other performance\n\trelated factors. Theoretical knowledge-based structures put forward by\n\tR. Miles et al. (1997) and J. Quinn et al. (1996) and an existing\n\timplementation are examined to determine common features inherent in\n\tthese approaches. These features are posited as a typical form and\n\ttheir impact on organisational commitment and hence on individual and\n\torganisational performance is examined\n", "keywords": "knowledge-based structures; emotional attachment; performance factors;\n\tproductivity; staff turnover; earning organisations; organisational\n\tcommitment\n", "topicrank": [["organisational commitment", "knowledge", "structures", "learning organisations", "substantial body"], ["organisational commitment", "knowledge", "structures", "learning organisations", "substantial body", "organisation", "common features inherent", "business", "enterprises", "imperatives"]], "textrank": [["organisational performance", "performance factors", "quinn et", "miles et", "performance"], ["organisational performance", "performance factors", "quinn et", "miles et", "performance", "new areas", "staff turnover", "various antecedents", "emotional attachment", "features"]], "positionrank": [["organisational commitment", "knowledge management", "theoretical knowledge", "organisational performance", "knowledge"], ["organisational commitment", "knowledge management", "theoretical knowledge", "organisational performance", "knowledge", "important performance factors", "structures", "other performance", "emotional attachment", "learning organisations"]], "multipartiterank": [["knowledge", "organisational commitment", "structures", "substantial body", "learning organisations"], ["knowledge", "organisational commitment", "structures", "substantial body", "learning organisations", "organisation", "contemporary environment", "common features inherent", "literature", "business"]]}, {"id": "234", "text": "The UK's National Electronic Site Licensing Initiative (NESLI)\nIn 1998 the UK created the National Electronic Site Licensing Initiative\n\t(NESLI) to increase and improve access to electronic journals and to\n\tnegotiate license agreements on behalf of academic libraries. The use\n\tof a model license agreement and the success of site licensing is\n\tdiscussed. Highlights from an interim evaluation by the Joint\n\tInformation Systems Committee (JISC) are noted and key issues and\n\tquestions arising from the evaluation are identified\n", "keywords": "National Electronic Site Licensing Initiative; NESLI; electronic journals;\n\tlicense agreements; academic libraries; Joint Information Systems\n\tCommittee; usage statistics; JISC; ICOLC\n", "topicrank": [["national electronic site licensing initiative", "interim evaluation", "nesli", "information systems committee", "behalf"], ["national electronic site licensing initiative", "interim evaluation", "nesli", "information systems committee", "behalf", "academic libraries", "joint", "license agreements", "success", "model license agreement"]], "textrank": [["electronic site licensing", "site licensing", "interim evaluation", "academic libraries", "license"], ["electronic site licensing", "site licensing", "interim evaluation", "academic libraries", "license", "electronic", "systems", "evaluation"]], "positionrank": [["site licensing", "electronic journals", "uk", "model license agreement", "nesli"], ["site licensing", "electronic journals", "uk", "model license agreement", "nesli", "license agreements", "academic libraries", "interim evaluation", "information systems committee", "use"]], "multipartiterank": [["national electronic site licensing initiative", "nesli", "interim evaluation", "behalf", "academic libraries"], ["national electronic site licensing initiative", "nesli", "interim evaluation", "behalf", "academic libraries", "information systems committee", "license agreements", "joint", "electronic journals", "success"]]}, {"id": "22", "text": "Analyzing the benefits of 300 mm conveyor-based AMHS\nWhile the need for automation in 300 mm fabs is not debated, the form and\n\tperformance of such automation is still in question. Software\n\tsimulation that compares conveyor-based continuous flow transport\n\ttechnology to conventional car-based wafer-lot delivery has detailed\n\tdelivery time and throughput advantages to the former\n", "keywords": "software simulation; car-based wafer-lot delivery; conveyor-based continuous\n\tflow transport technology; automated material handling system;\n\tsemiconductor fab; throughput; wafer processing; delivery time; 300 mm\n", "topicrank": [["mm conveyor", "lot delivery", "continuous flow transport", "software", "technology"], ["mm conveyor", "lot delivery", "continuous flow transport", "software", "technology", "conventional car", "simulation", "wafer", "question", "automation"]], "textrank": [["conventional car", "such automation", "delivery", "flow", "mm"], ["conventional car", "such automation", "delivery", "flow", "mm", "throughput", "automation"]], "positionrank": [["mm conveyor", "mm fabs", "such automation", "conveyor", "continuous flow transport"], ["mm conveyor", "mm fabs", "such automation", "conveyor", "continuous flow transport", "automation", "amhs", "benefits", "lot delivery", "need"]], "multipartiterank": [["mm conveyor", "lot delivery", "need", "automation", "amhs"], ["mm conveyor", "lot delivery", "need", "automation", "amhs", "wafer", "continuous flow transport", "conventional car", "technology", "software"]]}, {"id": "2106", "text": "Explanations for the perpetration of and reactions to deception in a virtual\n\tcommunity\nCases of identity deception on the Internet are not uncommon. Several cases of\n\ta revealed identity deception have been reported in the media. The\n\tauthors examine a case of deception in an online community composed\n\tprimarily of information technology professionals. In this case, an\n\testablished community member (DF) invented a character (Nowheremom)\n\twhom he fell in love with and who was eventually killed in a tragic\n\taccident. When other members of the community eventually began to\n\tquestion Nowheremom's actual identity, DF admitted that he invented\n\ther. The discussion board was flooded with reactions to DF's\n\trevelation. The authors propose several explanations for the\n\tperpetration of identity deception, including psychiatric illness,\n\tidentity play, and expressions of true self. They also analyze the\n\treactions of community members and propose three related explanations\n\t(social identity, deviance, and norm violation) to account for their\n\treactions. It is argued that virtual communities' reactions to such\n\tthreatening events provide invaluable clues for the study of group\n\tprocesses on the Internet\n", "keywords": "virtual community; identity deception; Internet; online community; information\n\ttechnology professionals; psychiatric illness; group processes; social\n\tprocesses; Web sites; psychology; bulletin boards\n", "topicrank": [["deception", "community", "reactions", "actual identity", "explanations"], ["deception", "community", "reactions", "actual identity", "explanations", "cases", "virtual", "authors", "perpetration", "internet"]], "textrank": [["community members", "identity", "virtual communities", "norm violation", "true self"], ["community members", "identity", "virtual communities", "norm violation", "true self", "psychiatric illness", "discussion board", "community", "technology", "several"]], "positionrank": [["identity deception", "several explanations", "social identity", "identity play", "explanations"], ["identity deception", "several explanations", "social identity", "identity play", "explanations", "actual identity", "community members", "deception", "online community", "community member"]], "multipartiterank": [["deception", "community", "reactions", "explanations", "identity deception"], ["deception", "community", "reactions", "explanations", "identity deception", "actual identity", "cases", "virtual", "nowheremom", "case"]]}, {"id": "2143", "text": "Quantum computing with solids\nScience and technology could be revolutionized by quantum computers, but\n\tbuilding them from solid-state devices will not be easy. The author\n\toutlines the challenges in scaling up the technology from lab\n\texperiments to practical devices\n", "keywords": "quantum computers; solid-state devices\n", "topicrank": [["technology", "state devices", "quantum", "lab", "experiments"], ["technology", "state devices", "quantum", "lab", "experiments", "science", "solids", "author", "easy", "solid"]], "textrank": [["state devices", "quantum computers", "devices", "quantum"], ["state devices", "quantum computers", "devices", "quantum"]], "positionrank": [["quantum computers", "technology", "state devices", "practical devices", "science"], ["quantum computers", "technology", "state devices", "practical devices", "science", "solids", "author", "challenges", "lab", "experiments"]], "multipartiterank": [["quantum", "technology", "state devices", "solids", "science"], ["quantum", "technology", "state devices", "solids", "science", "solid", "lab", "experiments", "easy", "author"]]}, {"id": "209", "text": "Information interaction: providing a framework for information architecture\nInformation interaction is the process that people use in interacting with the\n\tcontent of an information system. Information architecture is a\n\tblueprint and navigational aid to the content of information-rich\n\tsystems. As such information architecture performs an important\n\tsupporting role in information interactivity. This article elaborates\n\ton a model of information interactivity that crosses the \"no-man's\n\tland\" between user and computer articulating a model that includes\n\tuser, content and system, illustrating the context for information\n\tarchitecture\n", "keywords": "information interaction; navigational aid; information-rich systems;\n\tinformation interactivity\n", "topicrank": [["information interaction", "content", "information architecture", "user", "information system"], ["information interaction", "content", "information architecture", "user", "information system", "model", "rich", "navigational aid", "computer", "systems"]], "textrank": [["such information architecture", "information system", "information architecture", "information interaction", "information"], ["such information architecture", "information system", "information architecture", "information interaction", "information", "navigational aid", "architecture", "system"]], "positionrank": [["such information architecture", "information architecture", "information interaction", "information system", "information interactivity"], ["such information architecture", "information architecture", "information interaction", "information system", "information interactivity", "information", "architecture", "content", "navigational aid", "system"]], "multipartiterank": [["information interaction", "information architecture", "content", "process", "framework"], ["information interaction", "information architecture", "content", "process", "framework", "information system", "people", "user", "information", "model"]]}, {"id": "1932", "text": "Solution of the safe problem on (0,1)-matrices\nA safe problem with mn locks is studied. It is reduced to a system of linear\n\tequations in the modulo 2 residue class. There are three possible\n\tvariants defined by the numbers m and n evenness, with only one of them\n\thaving a solution. In two other cases, correction of the initial state\n\tof the safe insuring a solution is proposed\n", "keywords": "safe problem; mn locks; linear equations; modulo 2 residue class;\n\t(0;1)-matrices; computer games; linear Diophantine equations\n", "topicrank": [["safe problem", "solution", "linear", "equations", "modulo"], ["safe problem", "solution", "linear", "equations", "modulo", "residue class", "system", "possible", "variants", "mn locks"]], "textrank": [["residue class", "mn locks", "safe problem", "safe", "numbers"], ["residue class", "mn locks", "safe problem", "safe", "numbers"]], "positionrank": [["safe problem", "solution", "initial state", "mn locks", "other cases"], ["safe problem", "solution", "initial state", "mn locks", "other cases", "0,1)-matrices", "correction", "residue class", "system", "numbers m"]], "multipartiterank": [["safe problem", "solution", "linear", "equations", "modulo"], ["safe problem", "solution", "linear", "equations", "modulo", "residue class", "system", "mn locks", "possible", "variants"]]}, {"id": "1977", "text": "Tracking nonparameterized object contours in video\nWe propose a new method for contour tracking in video. The inverted distance\n\ttransform of the edge map is used as an edge indicator function for\n\tcontour detection. Using the concept of topographical distance, the\n\twatershed segmentation can be formulated as a minimization. This new\n\tviewpoint gives a way to combine the results of the watershed algorithm\n\ton different surfaces. In particular, our algorithm determines the\n\tcontour as a combination of the current edge map and the contour,\n\tpredicted from the tracking result in the previous frame. We also show\n\tthat the problem of background clutter can be relaxed by taking the\n\tobject motion into account. The compensation with object motion allows\n\tto detect and remove spurious edges in background. The experimental\n\tresults confirm the expected advantages of the proposed method over the\n\texisting approaches\n", "keywords": "contour tracking; nonparameterized object contours; edge indicator function;\n\ttopographical distance; watershed segmentation; minimization;\n\tbackground clutter; object motion; motion analysis; video; inverted\n\tdistance transform; edge map; motion estimation; edge detection\n", "topicrank": [["contour tracking", "object contours", "inverted distance", "results", "watershed algorithm"], ["contour tracking", "object contours", "inverted distance", "results", "watershed algorithm", "background clutter", "edge map", "video", "new method", "viewpoint"]], "textrank": [["edge indicator", "contour tracking", "previous frame", "different surfaces", "new method"], ["edge indicator", "contour tracking", "previous frame", "different surfaces", "new method", "edge", "watershed", "distance", "object", "contour"]], "positionrank": [["contour tracking", "object motion", "object contours", "new method", "current edge map"], ["contour tracking", "object motion", "object contours", "new method", "current edge map", "contour detection", "edge indicator function", "edge map", "contour", "inverted distance"]], "multipartiterank": [["contour tracking", "video", "object contours", "inverted distance", "new method"], ["contour tracking", "video", "object contours", "inverted distance", "new method", "edge map", "transform", "watershed algorithm", "results", "background clutter"]]}, {"id": "314", "text": "Information architecture in JASIST: just where did we come from?\nThe emergence of Information Architecture within the information systems world\n\thas been simultaneously drawn out yet rapid. Those with an eye on\n\thistory are quick to point to Wurman's 1976 use of the term\n\t\"architecture of information,\" but it has only been in the last 2 years\n\tthat IA has become the source of sufficient interest for people to\n\tlabel themselves professionally as Information Architects. The impetus\n\tfor this recent emergence of IA can be traced to a historical summit,\n\tsupported by ASIS&T in May 2000 at Boston. It was here that several\n\thundred of us gathered to thrash out the questions of just what IA was\n\tand what this new field might become. At the time of the summit,\n\tinvited to present a short talk on my return journey from the annual\n\tACM SIGCHI conference, I entered the summit expecting little and\n\tconvinced that IA was nothing new. I left 2 days later refreshed, not\n\tjust by the enthusiasm of the attendees for this term but by IA's\n\tpotential to unify the disparate perspectives and orientations of\n\tprofessionals from a range of disciplines. It was at this summit that\n\tthe idea for the special issue took root. I proposed the idea to Don\n\tKraft, hoping he would find someone else to run with it. AS luck would\n\thave it, I ended up taking charge of it myself, with initial support\n\tfrom David Blair. From the suggestion to the finished product-has been\n\tthe best part of 2 years, and in that time more than 50 volunteers\n\treviewed over 20 submissions\n", "keywords": "information architecture; information systems; metadata fields; controlled\n\tvocabularies; Web sites; CD-ROM; qualified information architect\n", "topicrank": [["historical summit", "information systems world", "information architecture", "term", "idea"], ["historical summit", "information systems world", "information architecture", "term", "idea", "years", "emergence", "new field", "orientations", "range"]], "textrank": [["information systems", "initial support", "special issue", "disparate perspectives", "return journey"], ["information systems", "initial support", "special issue", "disparate perspectives", "return journey", "short talk", "new field", "historical summit", "recent emergence", "sufficient interest"]], "positionrank": [["information architecture", "information systems world", "information architects", "information", "architecture"], ["information architecture", "information systems world", "information architects", "information", "architecture", "recent emergence", "emergence", "ia", "historical summit", "term"]], "multipartiterank": [["information architecture", "information systems world", "historical summit", "emergence", "summit"], ["information architecture", "information systems world", "historical summit", "emergence", "summit", "term", "years", "idea", "jasist", "new field"]]}, {"id": "351", "text": "Optimal online algorithm for scheduling on two identical machines with machine\n\tavailability constraints\nThis paper considers the online scheduling on two identical machines with\n\tmachine availability constraints for minimizing makespan. We assume\n\tthat machine M/sub j/ is unavailable during period from s/sub j/ to\n\tt/sub j/ (0 <or= s/sub j/ < t/sub j/), j = 1, 2, and the\n\tunavailable periods of two machines do not overlap. We show that the\n\tcompetitive ratio of list scheduling is 3. We further give an optimal\n\talgorithm with a competitive ratio 5/2\n", "keywords": "optimal online algorithm; makespan minimisation; list scheduling; identical\n\tmachines scheduling; machine availability constraints\n", "topicrank": [["identical machines", "availability constraints", "online scheduling", "optimal online algorithm", "competitive ratio"], ["identical machines", "availability constraints", "online scheduling", "optimal online algorithm", "competitive ratio", "unavailable", "machine", "paper", "optimal", "makespan"]], "textrank": [["online scheduling", "machine availability", "identical machines", "online", "availability"], ["online scheduling", "machine availability", "identical machines", "online", "availability", "machine", "scheduling", "machines", "sub"]], "positionrank": [["optimal online algorithm", "machine availability constraints", "identical machines", "online scheduling", "availability constraints"], ["optimal online algorithm", "machine availability constraints", "identical machines", "online scheduling", "availability constraints", "sub j/", "machine m", "list scheduling", "machine", "machines"]], "multipartiterank": [["identical machines", "availability constraints", "machine", "online scheduling", "optimal online algorithm"], ["identical machines", "availability constraints", "machine", "online scheduling", "optimal online algorithm", "paper", "unavailable", "machine availability constraints", "makespan", "period"]]}, {"id": "1953", "text": "Social percolation and the influence of mass media\nIn the marketing model of Solomon and Weisbuch, people buy a product only if\n\ttheir neighbours tell them of its quality, and if this quality is\n\thigher than their own quality expectations. Now we introduce additional\n\tinformation from the mass media, which is analogous to the ghost field\n\tin percolation theory. The mass media shift the percolative phase\n\ttransition observed in the model, and decrease the time after which the\n\tstationary state is reached\n", "keywords": "social percolation; mass media influence; Solomon-Weisbuch marketing model;\n\tquality expectations; ghost field; percolative phase transition;\n\tstationary state; customers; cinema; external field\n", "topicrank": [["mass media", "marketing model", "social percolation", "quality", "weisbuch"], ["mass media", "marketing model", "social percolation", "quality", "weisbuch", "solomon", "people", "percolative phase", "information", "ghost field"]], "textrank": [["ghost field", "marketing model", "mass media", "quality", "percolation"], ["ghost field", "marketing model", "mass media", "quality", "percolation", "model", "percolative"]], "positionrank": [["mass media", "social percolation", "percolation theory", "marketing model", "ghost field"], ["mass media", "social percolation", "percolation theory", "marketing model", "ghost field", "own quality expectations", "percolative phase", "model", "influence", "solomon"]], "multipartiterank": [["mass media", "social percolation", "marketing model", "solomon", "weisbuch"], ["mass media", "social percolation", "marketing model", "solomon", "weisbuch", "influence", "quality", "people", "product", "information"]]}, {"id": "194", "text": "Books on demand: just-in-time acquisitions\nThe Purdue University Libraries Interlibrary Loan unit proposed a pilot project\n\tto purchase patrons' loan requests from Amazon. com, lend them to the\n\tpatrons, and then add the titles to the collection. Staff analyzed\n\tprevious monograph loans, developed ordering criteria, implemented the\n\tproposal as a pilot project for six months, and evaluated the resulting\n\tpatron comments, statistics, and staff perceptions. As a result of\n\tenthusiastic patron comments and a review of the project statistics,\n\tthe program was extended\n", "keywords": "Purdue University Libraries Interlibrary Loan unit; monograph loans; ordering\n\tcriteria; staff perceptions; patron comments; publication on demand\n", "topicrank": [["staff", "patron comments", "statistics", "patrons", "pilot project"], ["staff", "patron comments", "statistics", "patrons", "pilot project", "loan requests", "amazon", "collection", "previous monograph loans", "com"]], "textrank": [["university libraries interlibrary loan", "time acquisitions", "loan", "patron", "monograph"], ["university libraries interlibrary loan", "time acquisitions", "loan", "patron", "monograph", "project", "ordering", "staff"]], "positionrank": [["time acquisitions", "pilot project", "books", "loan requests", "project statistics"], ["time acquisitions", "pilot project", "books", "loan requests", "project statistics", "demand", "enthusiastic patron comments", "patron comments", "patrons", "previous monograph loans"]], "multipartiterank": [["staff", "patron comments", "statistics", "patrons", "pilot project"], ["staff", "patron comments", "statistics", "patrons", "pilot project", "collection", "previous monograph loans", "loan requests", "amazon", "titles"]]}, {"id": "268", "text": "A method for correlations analysis of coordinates: applications for molecular\n\tconformations\nWe describe a new method to analyze multiple correlations between subsets of\n\tcoordinates that represent a sample. The correlation is established\n\tonly between specific regions of interest at the coordinates. First,\n\tthe region(s) of interest are selected at each molecular coordinate.\n\tNext, a correlation matrix is constructed for the selected regions. The\n\tmatrix is subject to further analysis, illuminating the\n\tmultidimensional structural characteristics that exist in the\n\tconformational space. The method's abilities are demonstrated in\n\tseveral examples: it is used to analyze the conformational space of\n\tcomplex molecules, it is successfully applied to compare related\n\tconformational spaces, and it is used to analyze a diverse set of\n\tprotein folding trajectories\n", "keywords": "multiple correlation analysis; regions of interest; correlation matrix;\n\tmolecular coordinate; multidimensional structural characteristics;\n\tcomplex molecules; conformational spaces; protein folding trajectories;\n\tmolecular conformations\n", "topicrank": [["coordinates", "method", "conformational space", "correlations analysis", "molecular"], ["coordinates", "method", "conformational space", "correlations analysis", "molecular", "specific regions", "interest", "correlation", "applications", "subsets"]], "textrank": [["correlations analysis", "molecular coordinate", "specific regions", "new method", "folding"], ["correlations analysis", "molecular coordinate", "specific regions", "new method", "folding", "conformational", "structural", "analysis", "correlations", "regions"]], "positionrank": [["new method", "correlations analysis", "method", "multiple correlations", "coordinates"], ["new method", "correlations analysis", "method", "multiple correlations", "coordinates", "further analysis", "molecular coordinate", "conformational space", "correlation matrix", "multidimensional structural characteristics"]], "multipartiterank": [["method", "coordinates", "correlations analysis", "conformational space", "molecular"], ["method", "coordinates", "correlations analysis", "conformational space", "molecular", "specific regions", "interest", "correlation", "applications", "conformations"]]}, {"id": "2122", "text": "A fuzzy logic adaptation circuit for control systems of deformable space\n\tvehicles: its design\nA fuzzy-logic adaptation algorithm is designed for adjusting the discreteness\n\tperiod of a control system for ensuring the stability and quality of\n\tcontrol process with regard to the elastic structural vibrations of a\n\tdeformable space vehicle. Its performance is verified by digital\n\tmodeling of a discrete control system with two objects\n", "keywords": "fuzzy logic adaptation circuit; control systems; deformable space vehicles;\n\tdiscreteness period; stability; elastic structural vibrations; digital\n\tmodeling\n", "topicrank": [["control systems", "deformable space", "fuzzy logic adaptation circuit", "quality", "stability"], ["control systems", "deformable space", "fuzzy logic adaptation circuit", "quality", "stability", "regard", "period", "vehicles", "fuzzy", "design"]], "textrank": [["logic adaptation", "elastic structural vibrations", "control", "deformable space"], ["logic adaptation", "elastic structural vibrations", "control", "deformable space"]], "positionrank": [["logic adaptation algorithm", "deformable space vehicle", "discrete control system", "control systems", "deformable space"], ["logic adaptation algorithm", "deformable space vehicle", "discrete control system", "control systems", "deformable space", "control system", "control process", "elastic structural vibrations", "vehicles", "design"]], "multipartiterank": [["control systems", "fuzzy logic adaptation circuit", "deformable space", "vehicles", "design"], ["control systems", "fuzzy logic adaptation circuit", "deformable space", "vehicles", "design", "fuzzy", "logic adaptation algorithm", "period", "discreteness", "quality"]]}, {"id": "295", "text": "Hours of operation and service in academic libraries: toward a national\n\tstandard\nIn an effort toward establishing a standard for academic library hours, the\n\tarticle surveys and compares hours of operation and service for ARL\n\tlibraries and IPEDS survey respondents. The article ranks the ARL\n\t(Association for Research Libraries) libraries according to hours of\n\toperation and reference hours and then briefly discusses such issues as\n\tlibraries offering twenty-four access and factors affecting service\n\thour decisions\n", "keywords": "academic library hours; operation/service hours; ARL libraries; IPEDS survey\n\trespondents; Integrated Post Secondary Education Data System;\n\tAssociation for Research Libraries\n", "topicrank": [["academic libraries", "hours", "service", "operation", "arl"], ["academic libraries", "hours", "service", "operation", "arl", "article surveys", "standard", "ipeds survey respondents", "association", "factors"]], "textrank": [["academic library hours", "academic libraries", "article surveys", "survey", "libraries"], ["academic library hours", "academic libraries", "article surveys", "survey", "libraries", "hours", "article"]], "positionrank": [["academic library hours", "reference hours", "academic libraries", "hours", "research libraries"], ["academic library hours", "reference hours", "academic libraries", "hours", "research libraries", "libraries", "article surveys", "operation", "service", "ipeds survey respondents"]], "multipartiterank": [["hours", "academic libraries", "operation", "service", "libraries"], ["hours", "academic libraries", "operation", "service", "libraries", "standard", "arl", "article surveys", "national", "ipeds survey respondents"]]}, {"id": "2167", "text": "Finally! some sensible European legislation on software\nThe European Commission has formally tabled a draft Directive on the Protection\n\tby Patents of Computer-Implemented Inventions. The aim of this very\n\timportant Directive is to harmonise national patent laws relating to\n\tinventions using software. It follows an extensive consultation\n\tlaunched by the Commission in October 2000. The impetus behind the\n\tDirective was the recognition at EU level of a total lack of unity\n\tbetween the European Patent Office and European national courts in\n\tdeciding what was or was not deemed patentable when it came to the\n\tsubject of computer programs\n", "keywords": "European Commission; Directive on the Protection by Patents of\n\tComputer-Implemented Inventions; national patent laws; law\n\tharmonisation; EU; European Patent Office; national courts; computer\n\tprograms\n", "topicrank": [["draft directive", "inventions", "software", "european commission", "computer"], ["draft directive", "inventions", "software", "european commission", "computer", "eu level", "total lack", "recognition", "patents", "october"]], "textrank": [["european patent", "european national", "national patent", "european", "eu level"], ["european patent", "european national", "national patent", "european", "eu level", "extensive consultation", "directive", "total", "computer"]], "positionrank": [["sensible european legislation", "european patent office", "european national courts", "european commission", "national patent laws"], ["sensible european legislation", "european patent office", "european national courts", "european commission", "national patent laws", "draft directive", "important directive", "directive", "software", "commission"]], "multipartiterank": [["draft directive", "software", "inventions", "european commission", "computer"], ["draft directive", "software", "inventions", "european commission", "computer", "patents", "protection", "aim", "sensible european legislation", "national patent laws"]]}, {"id": "388", "text": "Noninvasive myocardial activation time imaging: a novel inverse algorithm\n\tapplied to clinical ECG mapping data\nLinear approaches like the minimum-norm least-square algorithm show\n\tinsufficient performance when it comes to estimating the activation\n\ttime map on the surface of the heart from electrocardiographic (ECG)\n\tmapping data. Additional regularization has to be considered leading to\n\ta nonlinear problem formulation. The Gauss-Newton approach is one of\n\tthe standard mathematical tools capable of solving this kind of\n\tproblem. To our experience, this algorithm has specific drawbacks which\n\tare caused by the applied regularization procedure. In particular,\n\tunder clinical conditions the amount of regularization cannot be\n\tdetermined clearly. For this reason, we have developed an iterative\n\talgorithm solving this nonlinear problem by a sequence of regularized\n\tlinear problems. At each step of iteration, an individual L-curve is\n\tcomputed. Subsequent iteration steps are performed with the individual\n\toptimal regularization parameter. This novel approach is compared with\n\tthe standard Gauss-Newton approach. Both methods are applied to\n\tsimulated ECG mapping data as well as to single beat sinus rhythm data\n\tfrom two patients recorded in the catheter laboratory. The proposed\n\tapproach shows excellent numerical and computational performance, even\n\tunder clinical conditions at which the Gauss-Newton approach begins to\n\tbreak down\n", "keywords": "noninvasive myocardial activation time imaging; electrodiagnostics; activation\n\ttime imaging; L-curve method; noninvasive electrocardiography; tikhonov\n\tregularization; Gauss-Newton approach; individual optimal\n\tregularization parameter; catheter laboratory; clinical conditions;\n\titeration steps; heart surface; regularization procedure; inverse\n\talgorithm; clinical ECG mapping data\n", "topicrank": [["newton approach", "novel inverse algorithm", "additional regularization", "nonlinear problem formulation", "clinical ecg mapping data"], ["newton approach", "novel inverse algorithm", "additional regularization", "nonlinear problem formulation", "clinical ecg mapping data", "gauss", "linear approaches", "iteration", "clinical conditions", "insufficient performance"]], "textrank": [["beat sinus rhythm data", "clinical ecg mapping data", "standard mathematical tools", "myocardial activation time", "novel inverse algorithm"], ["beat sinus rhythm data", "clinical ecg mapping data", "standard mathematical tools", "myocardial activation time", "novel inverse algorithm", "ecg mapping data", "regularization", "novel approach", "mapping data", "iteration"]], "positionrank": [["novel inverse algorithm", "ecg mapping data", "mapping data", "novel approach", "square algorithm"], ["novel inverse algorithm", "ecg mapping data", "mapping data", "novel approach", "square algorithm", "time map", "algorithm", "activation", "newton approach", "clinical conditions"]], "multipartiterank": [["novel inverse algorithm", "clinical ecg mapping data", "newton approach", "additional regularization", "linear approaches"], ["novel inverse algorithm", "clinical ecg mapping data", "newton approach", "additional regularization", "linear approaches", "nonlinear problem formulation", "gauss", "insufficient performance", "norm least", "minimum"]]}, {"id": "2087", "text": "Re-examining the machining frictional boundary conditions using fractals\nPresents experimental evidence for the existence of non-Euclidean contact\n\tgeometry at the tool-chip interface in the machining of aluminium\n\talloy, which challenges conventional assumptions. The geometry of\n\tcontact at the tool rake face is modelled using fractals and a\n\tdimension is computed for its description. The variation in the fractal\n\tdimension with the cutting speed is explored\n", "keywords": "machining frictional boundary conditions; fractals; nonEuclidean contact\n\tgeometry; tool-chip interface; aluminium alloy; contact geometry; tool\n\trake face; cutting speed; Al\n", "topicrank": [["tool", "geometry", "dimension", "fractals", "aluminium"], ["tool", "geometry", "dimension", "fractals", "aluminium", "machining", "chip interface", "alloy", "conventional assumptions", "fractal"]], "textrank": [["- chip interface", "- euclidean", "experimental evidence", "rake", "boundary"], ["- chip interface", "- euclidean", "experimental evidence", "rake", "boundary", "-", "conventional"]], "positionrank": [["frictional boundary conditions", "experimental evidence", "re", "fractals", "tool rake face"], ["frictional boundary conditions", "experimental evidence", "re", "fractals", "tool rake face", "contact", "geometry", "chip interface", "tool", "existence"]], "multipartiterank": [["tool", "geometry", "fractals", "dimension", "chip interface"], ["tool", "geometry", "fractals", "dimension", "chip interface", "aluminium", "machining", "alloy", "conventional assumptions", "contact"]]}, {"id": "330", "text": "Improving computer security for authentication of users: influence of proactive\n\tpassword restrictions\nEntering a user name-password combination is a widely used procedure for\n\tidentification and authentication in computer systems. However, it is a\n\tnotoriously weak method, in that the passwords adopted by many users\n\tare easy to crack. In an attempt to, improve security, proactive\n\tpassword checking may be used, in which passwords must meet several\n\tcriteria to be more resistant to cracking. In two experiments, we\n\texamined the influence of proactive password restrictions on the time\n\tthat it took to generate an acceptable password and to use it\n\tsubsequently to log in. The required length was a minimum of five\n\tcharacters in experiment I and eight characters in experiment 2. In\n\tboth experiments, one condition had only the length restriction, and\n\tthe other had additional restrictions. The additional restrictions\n\tgreatly increased the time it took to generate the password but had\n\tonly a small effect on the time it took to use it subsequently to log\n\tin. For the five-character passwords, 75% were cracked when no other\n\trestrictions were imposed, and this was reduced to 33% with the\n\tadditional restrictions. For the eight-character passwords, 17% were\n\tcracked with no other restrictions, and 12.5% with restrictions. The\n\tresults indicate that increasing the minimum character length reduces\n\tcrackability and increases security, regardless of whether additional\n\trestrictions are imposed\n", "keywords": "computer security; user authentication; proactive password checking; proactive\n\tpassword restrictions; length restriction; five-character passwords;\n\teight-character passwords\n", "topicrank": [["password restrictions", "password combination", "passwords", "computer security", "proactive"], ["password restrictions", "password combination", "passwords", "computer security", "proactive", "additional restrictions", "authentication", "users", "influence", "time"]], "textrank": [["password restrictions", "character length", "password", "small effect", "many users"], ["password restrictions", "character length", "password", "small effect", "many users", "weak method", "user name", "character", "restrictions", "computer"]], "positionrank": [["proactive password restrictions", "password restrictions", "computer security", "additional restrictions", "other restrictions"], ["proactive password restrictions", "password restrictions", "computer security", "additional restrictions", "other restrictions", "password combination", "password checking", "acceptable password", "computer systems", "restrictions"]], "multipartiterank": [["password restrictions", "computer security", "password combination", "authentication", "proactive"], ["password restrictions", "computer security", "password combination", "authentication", "proactive", "users", "influence", "passwords", "user name", "time"]]}, {"id": "375", "text": "Separation and tracking of multiple broadband sources with one electromagnetic\n\tvector sensor\nA structure for adaptively separating, enhancing and tracking uncorrelated\n\tsources with an electromagnetic vector sensor (EMVS) is presented. The\n\tstructure consists of a set of parallel spatial processors, one for\n\teach individual source. Two stages of processing are involved in each\n\tspatial processor. The first preprocessing stage rejects all other\n\tsources except the one of interest, while the second stage is an\n\tadaptive one for maximizing the signal-to-noise ratio (SNR) and\n\ttracking the desired source. The preprocessings are designed using the\n\tlatest source parameter estimates obtained from the source trackers,\n\tand a redesign is activated periodically or whenever any source has\n\tbeen detected by the source trackers to have made significant movement.\n\tCompared with conventional adaptive beamforming, the algorithm has the\n\tadvantage that no a priori information on any desired signal location\n\tis needed, the sources are separated at maximum SNR, and their\n\tlocations are available. The structure is also well suited for parallel\n\timplementation. Numerical examples are included to illustrate the\n\tcapability and performance of the algorithm\n", "keywords": "multiple broadband sources separation; multiple broadband sources tracking;\n\tuncorrelated sources; electromagnetic vector sensor; single EM vector\n\tsensor; parallel spatial processors; preprocessing stage; adaptive\n\tsecond stage; signal-to-noise ratio; SNR maximization; maximum SNR;\n\tsignal source location; parallel implementation; adaptive source\n\tenhancement\n", "topicrank": [["individual source", "multiple broadband sources", "structure", "parallel spatial processors", "vector sensor"], ["individual source", "multiple broadband sources", "structure", "parallel spatial processors", "vector sensor", "stage", "snr", "tracking", "signal", "algorithm"]], "textrank": [["source parameter", "source", "signal location", "significant movement", "noise ratio"], ["source parameter", "source", "signal location", "significant movement", "noise ratio", "second stage", "tracking uncorrelated", "adaptive", "spatial", "vector"]], "positionrank": [["electromagnetic vector sensor", "multiple broadband sources", "vector sensor", "sources", "tracking"], ["electromagnetic vector sensor", "multiple broadband sources", "vector sensor", "sources", "tracking", "separation", "structure", "parallel spatial processors", "source trackers", "individual source"]], "multipartiterank": [["multiple broadband sources", "tracking", "individual source", "structure", "vector sensor"], ["multiple broadband sources", "tracking", "individual source", "structure", "vector sensor", "sources", "parallel spatial processors", "electromagnetic", "stage", "separation"]]}, {"id": "348", "text": "Lower bounds on the information rate of secret sharing schemes with homogeneous\n\taccess structure\nWe present some new lower bounds on the optimal information rate and on the\n\toptimal average information rate of secret sharing schemes with\n\thomogeneous access structure. These bounds are found by using some\n\tcovering constructions and a new parameter, the k-degree of a\n\tparticipant, that is introduced in this paper. Our bounds improve the\n\tprevious ones in almost all cases\n", "keywords": "lower bounds; optimal information rate; optimal average information rate;\n\tk-degree; cryptography; information rate; secret sharing schemes;\n\thomogeneous access structure\n", "topicrank": [["lower bounds", "information rate", "secret sharing schemes", "access structure", "homogeneous"], ["lower bounds", "information rate", "secret sharing schemes", "access structure", "homogeneous", "new parameter", "constructions", "degree", "paper", "participant"]], "textrank": [["new lower", "previous ones", "information", "access", "sharing"], ["new lower", "previous ones", "information", "access", "sharing", "new", "lower"]], "positionrank": [["optimal information rate", "new lower bounds", "secret sharing schemes", "information rate", "lower bounds"], ["optimal information rate", "new lower bounds", "secret sharing schemes", "information rate", "lower bounds", "homogeneous access structure", "access structure", "bounds", "new parameter", "previous ones"]], "multipartiterank": [["lower bounds", "information rate", "secret sharing schemes", "access structure", "homogeneous"], ["lower bounds", "information rate", "secret sharing schemes", "access structure", "homogeneous", "bounds", "homogeneous access structure", "optimal average information rate", "new lower bounds", "optimal information rate"]]}, {"id": "2047", "text": "A generalized PERT/CPM implementation in a spreadsheet\nThis paper describes the implementation of the traditional PERT/CPM algorithm\n\tfor finding the critical path in a project network in a spreadsheet.\n\tThe problem is of importance due to the recent shift of attention to\n\tusing the spreadsheet environment as a vehicle for delivering\n\tmanagement science/operations research (MS/OR) techniques to end-users\n", "keywords": "generalized PERT/CPM implementation; spreadsheet; critical path; MS/OR\n\ttechniques\n", "topicrank": [["spreadsheet", "cpm implementation", "pert", "recent shift", "attention"], ["spreadsheet", "cpm implementation", "pert", "recent shift", "attention", "management science", "project network", "cpm algorithm", "importance", "problem"]], "textrank": [["project network", "critical path", "traditional pert", "cpm", "spreadsheet"], ["project network", "critical path", "traditional pert", "cpm", "spreadsheet", "pert"]], "positionrank": [["cpm implementation", "traditional pert", "cpm algorithm", "spreadsheet environment", "pert"], ["cpm implementation", "traditional pert", "cpm algorithm", "spreadsheet environment", "pert", "spreadsheet", "critical path", "implementation", "paper", "project network"]], "multipartiterank": [["spreadsheet", "cpm implementation", "pert", "paper", "project network"], ["spreadsheet", "cpm implementation", "pert", "paper", "project network", "cpm algorithm", "recent shift", "problem", "traditional pert", "importance"]]}, {"id": "2002", "text": "A new subspace identification approach based on principal component analysis\nPrincipal component analysis (PCA) has been widely used for monitoring complex\n\tindustrial processes with multiple variables and diagnosing process and\n\tsensor faults. The objective of this paper is to develop a new subspace\n\tidentification algorithm that gives consistent model estimates under\n\tthe errors-in-variables (EIV) situation. In this paper, we propose a\n\tnew subspace identification approach using principal component\n\tanalysis. PCA naturally falls into the category of EIV formulation,\n\twhich resembles total least squares and allows for errors in both\n\tprocess input and output. We propose to use PCA to determine the system\n\tobservability subspace, the matrices and the system order for an EIV\n\tformulation. Standard PCA is modified with instrumental variables in\n\torder to achieve consistent estimates of the system matrices. The\n\tproposed subspace identification method is demonstrated using a\n\tsimulated process and a real industrial process for model\n\tidentification and order determination. For comparison the MOESP\n\talgorithm and N4SID algorithm are used as benchmarks to demonstrate the\n\tadvantages of the proposed PCA based subspace model identification\n\t(SMI) algorithm\n", "keywords": "subspace identification approach; principal component analysis; PCA; complex\n\tindustrial process monitoring; process fault diagnosis; sensor fault\n\tdiagnosis; errors-in-variables situation; EIV situation; total\n\tleast-squares approximation; system observability subspace; consistent\n\tsystem matrix estimates; MOESP algorithm; N4SID algorithm; subspace\n\tmodel identification; SMI\n", "topicrank": [["pca", "process", "new subspace identification approach", "identification algorithm", "eiv"], ["pca", "process", "new subspace identification approach", "identification algorithm", "eiv", "multiple variables", "subspace identification method", "principal component analysis", "order", "system"]], "textrank": [["subspace model identification", "subspace identification", "industrial process", "identification algorithm", "system order"], ["subspace model identification", "subspace identification", "industrial process", "identification algorithm", "system order", "identification", "sensor faults", "subspace", "process", "industrial"]], "positionrank": [["subspace model identification", "subspace identification method", "principal component analysis", "new subspace", "identification algorithm"], ["subspace model identification", "subspace identification method", "principal component analysis", "new subspace", "identification algorithm", "principal component", "observability subspace", "identification", "consistent model estimates", "standard pca"]], "multipartiterank": [["new subspace identification approach", "pca", "multiple variables", "process", "principal component analysis"], ["new subspace identification approach", "pca", "multiple variables", "process", "principal component analysis", "eiv", "identification algorithm", "paper", "consistent model estimates", "subspace identification method"]]}, {"id": "1993", "text": "Color plane interpolation using alternating projections\nMost commercial digital cameras use color filter arrays to sample red, green,\n\tand blue colors according to a specific pattern. At the location of\n\teach pixel only one color sample is taken, and the values of the other\n\tcolors must be interpolated using neighboring samples. This color plane\n\tinterpolation is known as demosaicing; it is one of the important tasks\n\tin a digital camera pipeline. If demosaicing is not performed\n\tappropriately, images suffer from highly visible color artifacts. In\n\tthis paper we present a new demosaicing technique that uses\n\tinter-channel correlation effectively in an alternating-projections\n\tscheme. We have compared this technique with six state-of-the-art\n\tdemosaicing techniques, and it outperforms all of them, both visually\n\tand in terms of mean square error\n", "keywords": "color plane interpolation; alternating projections; digital cameras;\n\tdemosaicing; color filter arrays; color artifacts; inter-channel\n\tcorrelation\n", "topicrank": [["color plane interpolation", "blue colors", "projections", "demosaicing", "green"], ["color plane interpolation", "blue colors", "projections", "demosaicing", "green", "red", "pixel", "interpolation", "scheme", "digital camera pipeline"]], "textrank": [["color plane", "digital camera", "commercial digital", "color", "- channel"], ["color plane", "digital camera", "commercial digital", "color", "- channel", "specific pattern", "blue colors", "square", "demosaicing", "-"]], "positionrank": [["color plane interpolation", "color plane", "color filter", "visible color artifacts", "color sample"], ["color plane interpolation", "color plane", "color filter", "visible color artifacts", "color sample", "digital camera pipeline", "interpolation", "new demosaicing technique", "projections", "blue colors"]], "multipartiterank": [["color plane interpolation", "projections", "blue colors", "demosaicing", "red"], ["color plane interpolation", "projections", "blue colors", "demosaicing", "red", "green", "scheme", "specific pattern", "digital camera pipeline", "pixel"]]}, {"id": "255", "text": "The culture of usability\nNow that most of us agree that usability testing is an integral investment in\n\tsite development, it's time to recognize that the standard approach\n\tfalls short. It is possible to do less work and get better results\n\twhile spending less money. By bringing usability testing in-house and\n\tbreaking tests into more manageable sessions, you can vastly improve\n\tyour online offering without affecting your profit margin\n", "keywords": "usability testing program; Web site\n", "topicrank": [["usability", "less", "possible", "short", "standard approach"], ["usability", "less", "possible", "short", "standard approach", "site development", "integral investment", "better results", "house", "time"]], "textrank": [["site development", "integral investment", "usability testing", "manageable", "standard"], ["site development", "integral investment", "usability testing", "manageable", "standard", "usability"]], "positionrank": [["usability testing", "usability", "integral investment", "site development", "less money"], ["usability testing", "usability", "integral investment", "site development", "less money", "culture", "more manageable sessions", "better results", "standard approach", "time"]], "multipartiterank": [["usability", "culture", "less", "usability testing", "possible"], ["usability", "culture", "less", "usability testing", "possible", "integral investment", "short", "standard approach", "site development", "better results"]]}, {"id": "210", "text": "When a better interface and easy navigation aren't enough: examining the\n\tinformation architecture in a law enforcement agency\nAn information architecture that allows users to easily navigate through a\n\tsystem and quickly recover from mistakes is often defined as a highly\n\tusable system. But usability in systems design goes beyond a good\n\tinterface and efficient navigation. In this article we describe two\n\tdatabase systems in a law enforcement agency. One system is a legacy,\n\ttext-based system with cumbersome navigation (RMS); the newer system is\n\ta graphical user interface with simplified navigation (CopNet). It is\n\thypothesized that law enforcement users will evaluate CopNet higher\n\tthan RMS, but experts of the older system will evaluate it higher than\n\tothers will. We conducted two user studies. One study examined what\n\tusers thought of RMS and CopNet, and compared RMS experts' evaluations\n\twith nonexperts. We found that all users evaluated CopNet as more\n\teffective, easier to use, and easier to navigate than RMS, and this was\n\tespecially noticeable for users who were not experts with the older\n\tsystem. The second, follow-up study examined use behavior after CopNet\n\twas deployed some time later. The findings revealed that evaluations of\n\tCopNet were not associated with its use. If the newer system had a\n\tbetter interface and was easier to navigate than the older, legacy\n\tsystem, why were law enforcement personnel reluctant to switch? We\n\tdiscuss reasons why switching to a new system is difficult, especially\n\tfor those who are most adept at using the older system. Implications\n\tfor system design and usability are also discussed\n", "keywords": "information architecture; law enforcement agency; legacy text-based system;\n\tRMS; graphical user interface; simplified navigation; CopNet; law\n\tenforcement users\n", "topicrank": [["system", "copnet", "older system", "rms", "easy navigation"], ["system", "copnet", "older system", "rms", "easy navigation", "users", "better interface", "law enforcement agency", "experts", "easier"]], "textrank": [["system design", "enforcement personnel", "user interface", "system", "navigation"], ["system design", "enforcement personnel", "user interface", "system", "navigation", "enforcement", "systems design", "use behavior", "rms experts", "copnet higher"]], "positionrank": [["older system", "law enforcement users", "newer system", "system design", "law enforcement agency"], ["older system", "law enforcement users", "newer system", "system design", "law enforcement agency", "better interface", "usable system", "new system", "system", "graphical user interface"]], "multipartiterank": [["system", "better interface", "copnet", "easy navigation", "older system"], ["system", "better interface", "copnet", "easy navigation", "older system", "law enforcement agency", "rms", "users", "experts", "easier"]]}, {"id": "2045", "text": "Building a better game through dynamic programming: a Flip analysis\nFlip is a solitaire board game produced by craft woodworkers. We analyze Flip\n\tand suggest modifications to the rules to make the game more\n\tmarketable. In addition to being an interesting application of dynamic\n\tprogramming, this case shows the use of operations research in\n\tmanagerial decision making\n", "keywords": "dynamic programming; Flip analysis; operations research; managerial decision\n\tmaking; solitaire board game; craft woodworkers\n", "topicrank": [["dynamic programming", "flip analysis", "programming", "interesting application", "use"], ["dynamic programming", "flip analysis", "programming", "interesting application", "use", "case", "operations research", "solitaire board game", "addition", "modifications"]], "textrank": [["board game", "flip analysis", "dynamic programming", "game", "decision"], ["board game", "flip analysis", "dynamic programming", "game", "decision", "programming", "dynamic", "flip"]], "positionrank": [["solitaire board game", "flip analysis", "better game", "dynamic programming", "flip"], ["solitaire board game", "flip analysis", "better game", "dynamic programming", "flip", "game", "programming", "craft woodworkers", "interesting application", "managerial decision making"]], "multipartiterank": [["dynamic programming", "flip analysis", "flip", "better game", "solitaire board game"], ["dynamic programming", "flip analysis", "flip", "better game", "solitaire board game", "craft woodworkers", "programming", "interesting application", "dynamic", "modifications"]]}, {"id": "2000", "text": "Generalized predictive control for non-uniformly sampled systems\nIn this paper, we study digital control systems with non-uniform updating and\n\tsampling patterns, which include multirate sampled-data systems as\n\tspecial cases. We derive lifted models in the state-space domain. The\n\tmain obstacle for generalized predictive control (GPC) design using the\n\tlifted models is the so-called causality constraint. Taking into\n\taccount this design constraint, we propose a new GPC algorithm, which\n\tresults in optimal causal control laws for the non-uniformly sampled\n\tsystems. The solution applies immediately to multirate sampled-data\n\tsystems where rates are integer multiples of some base period\n", "keywords": "generalized predictive control design; nonuniformly sampled systems; digital\n\tcontrol systems; nonuniform updating patterns; nonuniform sampling\n\tpatterns; multirate sampled-data systems; state-space models; GPC;\n\tcausality constraint; optimal causal control laws; integer multiples\n", "topicrank": [["systems", "gpc", "design", "data systems", "models"], ["systems", "gpc", "design", "data systems", "models", "predictive control", "rates", "space domain", "state", "integer multiples"]], "textrank": [["causal control", "control systems", "- space domain", "control", "- uniform"], ["causal control", "control systems", "- space domain", "control", "- uniform", "special cases", "constraint", "gpc", "-", "systems"]], "positionrank": [["digital control systems", "predictive control", "data systems", "systems", "new gpc algorithm"], ["digital control systems", "predictive control", "data systems", "systems", "new gpc algorithm", "design constraint", "main obstacle", "space domain", "gpc", "design"]], "multipartiterank": [["systems", "gpc", "design", "data systems", "models"], ["systems", "gpc", "design", "data systems", "models", "predictive control", "space domain", "state", "main obstacle", "special cases"]]}, {"id": "257", "text": "Unsafe at any speed?\nWhile Sun prides itself on Java's secure sandbox programming model, Microsoft\n\ttakes a looser approach. Its C# language incorporates C-like concepts,\n\tincluding pointers and memory management. But is unsafe code really a\n\tboon to programmers, or is it a step backward?\n", "keywords": "Microsoft C# language; C-like concepts; pointers; memory management; Sun Java\n\tsecure sandbox programming model\n", "topicrank": [["unsafe", "secure sandbox programming model", "memory management", "java", "pointers"], ["unsafe", "secure sandbox programming model", "memory management", "java", "pointers", "microsoft", "boon", "programmers", "sun", "speed"]], "textrank": [["sandbox programming", "looser approach", "#", "like", "unsafe"], ["sandbox programming", "looser approach", "#", "like", "unsafe"]], "positionrank": [["unsafe code", "c # language", "memory management", "looser approach", "like concepts"], ["unsafe code", "c # language", "memory management", "looser approach", "like concepts", "c", "sun", "java", "pointers", "speed"]], "multipartiterank": [["unsafe", "secure sandbox programming model", "speed", "java", "sun"], ["unsafe", "secure sandbox programming model", "speed", "java", "sun", "microsoft", "memory management", "looser approach", "pointers", "boon"]]}, {"id": "212", "text": "Knowledge management-capturing the skills of key performers in the power\n\tindustry\nThe growing pressure to reduce the cost of electrical power in recent years has\n\tresulted in an enormous \"brain-drain\" within the power industry. A\n\tnovel approach has been developed by Eskom to capture these skills\n\tbefore they are lost and to incorporate these into a computer-based\n\tprogramme called \"knowledge management\"\n", "keywords": "power industry; key performers; knowledge management; skills capture;\n\tbrain-drain; Eskom; computer-based programme; South Africa; personnel\n\tmanagement\n", "topicrank": [["power", "industry", "skills", "brain", "knowledge management"], ["power", "industry", "skills", "brain", "knowledge management", "drain", "cost", "enormous", "key performers", "recent years"]], "textrank": [["key performers", "knowledge management", "power", "recent"], ["key performers", "knowledge management", "power", "recent"]], "positionrank": [["knowledge management", "power industry", "key performers", "electrical power", "power"], ["knowledge management", "power industry", "key performers", "electrical power", "power", "skills", "industry", "recent years", "novel approach", "computer"]], "multipartiterank": [["power", "industry", "skills", "key performers", "knowledge management"], ["power", "industry", "skills", "key performers", "knowledge management", "cost", "pressure", "brain", "electrical power", "recent years"]]}, {"id": "1991", "text": "A framework for evaluating the data-hiding capacity of image sources\nAn information-theoretic model for image watermarking and data hiding is\n\tpresented in this paper. Previous theoretical results are used to\n\tcharacterize the fundamental capacity limits of image watermarking and\n\tdata-hiding systems. Capacity is determined by the statistical model\n\tused for the host image, by the distortion constraints on the data\n\thider and the attacker, and by the information available to the data\n\thider, to the attacker, and to the decoder. We consider autoregressive,\n\tblock-DCT, and wavelet statistical models for images and compute\n\tdata-hiding capacity for compressed and uncompressed host-image\n\tsources. Closed-form expressions are obtained under sparse-model\n\tapproximations. Models for geometric attacks and distortion measures\n\tthat are invariant to such attacks are considered\n", "keywords": "data-hiding capacity; image sources; information-theoretic model; watermarking;\n\tcapacity limits; statistical model; distortion constraints;\n\tautoregressive statistical models; block-DCT statistical models;\n\twavelet statistical models; compressed host-image sources; uncompressed\n\thost-image sources; closed-form expressions; sparse-model\n\tapproximations; geometric attacks; distortion measures\n", "topicrank": [["data", "image watermarking", "hiding capacity", "theoretic model", "statistical models"], ["data", "image watermarking", "hiding capacity", "theoretic model", "statistical models", "image sources", "hider", "distortion constraints", "information", "attacker"]], "textrank": [["host image", "hiding capacity", "statistical model", "form expressions", "information available"], ["host image", "hiding capacity", "statistical model", "form expressions", "information available", "capacity", "image", "attacks", "distortion", "theoretical"]], "positionrank": [["data hiding", "hiding capacity", "image sources", "image watermarking", "host image"], ["data hiding", "hiding capacity", "image sources", "image watermarking", "host image", "fundamental capacity limits", "data", "image", "capacity", "theoretic model"]], "multipartiterank": [["data", "hiding capacity", "image watermarking", "theoretic model", "image sources"], ["data", "hiding capacity", "image watermarking", "theoretic model", "image sources", "information", "hider", "statistical models", "attacker", "distortion constraints"]]}, {"id": "41", "text": "Controller performance analysis with LQG benchmark obtained under closed loop\n\tconditions\nThis paper proposes a new method for obtaining a linear quadratic Gaussian\n\t(LQG) benchmark in terms of the variances of process input and output\n\tfrom closed-loop data, for assessing the controller performance. LQG\n\tbenchmark has been proposed in the literature to assess controller\n\tperformance since the LQG tradeoff curve represents the limit of\n\tperformance in terms of input and output variances. However, an\n\texplicit parametric model is required to calculate the LQG benchmark.\n\tIn this work, we propose a data driven subspace approach to calculate\n\tthe LQG benchmark under closed-loop conditions with certain external\n\texcitations. The optimal LQG-benchmark variances are obtained directly\n\tfrom the subspace matrices corresponding to the deterministic inputs\n\tand the stochastic inputs, which are identified using closed-loop data\n\twith setpoint excitation. These variances are used for assessing the\n\tcontroller performance. The method proposed in this paper is applicable\n\tto both univariate and multivariate systems. Profit analysis for the\n\timplementation of feedforward control to the existing feedback-only\n\tcontrol system is also analyzed under the optimal LQG performance\n\tframework\n", "keywords": "controller performance analysis; LQG benchmark; linear quadratic Gaussian\n\tbenchmark; closed-loop data; subspace matrices; deterministic inputs;\n\tstochastic inputs; univariate systems; multivariate systems; profit\n\tanalysis; feedforward control; state space model\n", "topicrank": [["lqg benchmark", "controller performance analysis", "closed loop", "benchmark", "variances"], ["lqg benchmark", "controller performance analysis", "closed loop", "benchmark", "variances", "loop data", "process input", "terms", "conditions", "paper"]], "textrank": [["lqg performance", "performance analysis", "lqg benchmark", "benchmark variances", "process input"], ["lqg performance", "performance analysis", "lqg benchmark", "benchmark variances", "process input", "new method", "loop", "performance", "lqg", "control"]], "positionrank": [["controller performance analysis", "optimal lqg performance", "lqg benchmark", "controller performance", "benchmark variances"], ["controller performance analysis", "optimal lqg performance", "lqg benchmark", "controller performance", "benchmark variances", "closed loop", "lqg", "loop data", "loop conditions", "performance"]], "multipartiterank": [["controller performance analysis", "lqg benchmark", "closed loop", "conditions", "closed"], ["controller performance analysis", "lqg benchmark", "closed loop", "conditions", "closed", "benchmark", "lqg", "loop data", "variances", "paper"]]}, {"id": "2158", "text": "Press shop. Industrial IT solutions for the press shop\nGlobalization of the world's markets is challenging the traditional limits of\n\tmanufacturing efficiency. The competitive advantage belongs to those\n\twho understand the new requirements and opportunities, and who commit\n\tto integrated solutions that span the value chain all the way from\n\tdemand to production. ABB's automation and IT expertise and the process\n\tknow-how gained from its long involvement with the automotive industry,\n\thave been brought together in new, state-of-the-art software solutions\n\tfor press shops. Integrated into Industrial IT architecture, they allow\n\tthe full potential of the shops to be realized, with advantages at\n\tevery step in the supply chain\n", "keywords": "press shops; industrial IT solutions; market globalisation; manufacturing\n\tefficiency; automation; state-of-the-art; software solutions; car\n\tmanufacturing business; supply chain\n", "topicrank": [["new requirements", "press shops", "production", "abb", "demand"], ["new requirements", "press shops", "production", "abb", "demand", "press shop", "automation", "world", "way", "markets"]], "textrank": [["it solutions", "software solutions", "it", "new requirements", "competitive advantage"], ["it solutions", "software solutions", "it", "new requirements", "competitive advantage", "manufacturing efficiency", "traditional limits", "solutions", "press", "new"]], "positionrank": [["industrial it solutions", "press shop", "industrial it architecture", "press shops", "art software solutions"], ["industrial it solutions", "press shop", "industrial it architecture", "press shops", "art software solutions", "it expertise", "integrated solutions", "traditional limits", "globalization", "manufacturing efficiency"]], "multipartiterank": [["new requirements", "production", "abb", "press shop", "press shops"], ["new requirements", "production", "abb", "press shop", "press shops", "demand", "opportunities", "world", "automation", "markets"]]}, {"id": "2120", "text": "Control in active systems based on criteria and motivation\nFor active systems where the principal varies the agents' goal functions by\n\tadding to them appropriately weighted goal functions of other agents or\n\ta balanced system of inter-agent transfers, the paper formulated and\n\tsolved the problems of control based on criteria and motivation. Linear\n\tactive systems were considered by way of example\n", "keywords": "goal functions; inter-agent transfers; linear active systems; criteria-based\n\tcontrol; motivation-based control\n", "topicrank": [["active systems", "motivation", "criteria", "control", "goal functions"], ["active systems", "motivation", "criteria", "control", "goal functions", "linear", "agents", "problems", "principal", "way"]], "textrank": [["- agent", "active systems", "goal", "agents"], ["- agent", "active systems", "goal", "agents"]], "positionrank": [["active systems", "control", "motivation", "criteria", "goal functions"], ["active systems", "control", "motivation", "criteria", "goal functions", "other agents", "balanced system", "agents", "linear", "principal"]], "multipartiterank": [["active systems", "motivation", "criteria", "control", "goal functions"], ["active systems", "motivation", "criteria", "control", "goal functions", "linear", "agents", "problems", "principal", "way"]]}, {"id": "39", "text": "Supervisory control design based on hybrid systems and fuzzy events detection.\n\tApplication to an oxichlorination reactor\nThis paper presents a supervisory control scheme based on hybrid systems theory\n\tand fuzzy events detection. The fuzzy event detector is a linguistic\n\tmodel, which synthesizes complex relations between process variables\n\tand process events incorporating experts' knowledge about the process\n\toperation. This kind of detection allows the anticipation of\n\tappropriate control actions, which depend upon the selected membership\n\tfunctions used to characterize the process under scrutiny. The proposed\n\tsupervisory control scheme was successfully implemented for an\n\toxichlorination reactor in a vinyl monomer plant\n", "keywords": "supervisory control design; hybrid systems; events detection. fuzzy;\n\toxichlorination reactor; linguistic model; complex relations; process\n\tvariables; process events; expert knowledge; process operation; control\n\tactions; membership functions; vinyl monomer plant; reactor stability;\n\traw material consumption; discrete events systems; reactive systems;\n\tfinite state machines\n", "topicrank": [["process variables", "fuzzy events detection", "supervisory control design", "hybrid systems", "oxichlorination reactor"], ["process variables", "fuzzy events detection", "supervisory control design", "hybrid systems", "oxichlorination reactor", "experts", "knowledge", "operation", "kind", "complex relations"]], "textrank": [["control", "process events", "fuzzy events", "fuzzy event", "complex relations"], ["control", "process events", "fuzzy events", "fuzzy event", "complex relations", "oxichlorination reactor", "monomer", "systems", "process"]], "positionrank": [["supervisory control scheme", "supervisory control design", "fuzzy events detection", "hybrid systems theory", "process events"], ["supervisory control scheme", "supervisory control design", "fuzzy events detection", "hybrid systems theory", "process events", "appropriate control actions", "hybrid systems", "fuzzy event detector", "oxichlorination reactor", "process variables"]], "multipartiterank": [["supervisory control design", "fuzzy events detection", "process variables", "hybrid systems", "oxichlorination reactor"], ["supervisory control design", "fuzzy events detection", "process variables", "hybrid systems", "oxichlorination reactor", "complex relations", "process", "supervisory control scheme", "application", "experts"]]}, {"id": "297", "text": "The service side of systems librarianship\nDescribes the role of a systems librarian at a small academic library. Although\n\tonline catalogs and the Internet are making library accessibility more\n\tconvenient, the need for library buildings and professionals has not\n\tdiminished. Typical duties of a systems librarian and the effects of\n\tnew technology on librarianship are discussed. Services provided to\n\tother constituencies on campus and the blurring relationship between\n\tthe library and computer services are also presented\n", "keywords": "systems librarianship; service side; small academic library; online catalogs;\n\tInternet\n", "topicrank": [["small academic library", "systems librarian", "systems librarianship", "services", "need"], ["small academic library", "systems librarian", "systems librarianship", "services", "need", "new technology", "convenient", "professionals", "effects", "internet"]], "textrank": [["academic library", "typical duties", "online catalogs", "service side", "library"], ["academic library", "typical duties", "online catalogs", "service side", "library", "systems"]], "positionrank": [["systems librarianship", "systems librarian", "small academic library", "service side", "library accessibility"], ["systems librarianship", "systems librarian", "small academic library", "service side", "library accessibility", "library buildings", "library", "librarianship", "role", "online catalogs"]], "multipartiterank": [["small academic library", "systems librarian", "systems librarianship", "online catalogs", "role"], ["small academic library", "systems librarian", "systems librarianship", "online catalogs", "role", "service side", "services", "internet", "need", "convenient"]]}, {"id": "2165", "text": "Naomi Campbell: drugs, distress and the Data Protection Act\nIn the first case of its kind, Naomi Campbell successfully sued Mirror Group\n\tNewspapers for damage and distress caused by breach of the Data\n\tProtection Act 1998. Partner N. Wildish and assistant M. Turle of City\n\tlaw firm Field Fisher Waterhouse discuss the case and the legal\n\timplications of which online publishers should be aware\n", "keywords": "drugs; distress; Data Protection Act; Naomi Campbell; online publishers\n", "topicrank": [["distress", "naomi campbell", "first case", "data protection act", "damage"], ["distress", "naomi campbell", "first case", "data protection act", "damage", "newspapers", "mirror group", "breach", "law firm field fisher waterhouse", "data"]], "textrank": [["firm field fisher", "first case", "naomi campbell", "m.", "n."], ["firm field fisher", "first case", "naomi campbell", "m.", "n.", "protection", "case"]], "positionrank": [["naomi campbell", "data protection act", "protection act", "first case", "mirror group"], ["naomi campbell", "data protection act", "protection act", "first case", "mirror group", "assistant m. turle", "partner n. wildish", "distress", "data", "case"]], "multipartiterank": [["distress", "naomi campbell", "data protection act", "first case", "newspapers"], ["distress", "naomi campbell", "data protection act", "first case", "newspapers", "damage", "kind", "mirror group", "drugs", "breach"]]}, {"id": "2198", "text": "Reconfigurable context-sensitive middleware for pervasive computing\nContext-sensitive applications need data from sensors, devices, and user\n\tactions, and might need ad hoc communication support to dynamically\n\tdiscover new devices and engage in spontaneous information exchange.\n\tReconfigurable Context-Sensitive Middleware facilitates the development\n\tand runtime operations of context-sensitive pervasive computing\n\tsoftware\n", "keywords": "pervasive computing; Reconfigurable Context-Sensitive Middleware;\n\tcontext-sensitive pervasive computing; middleware; context-sensitive\n\tapplications\n", "topicrank": [["reconfigurable context", "sensitive middleware", "pervasive computing", "devices", "sensors"], ["reconfigurable context", "sensitive middleware", "pervasive computing", "devices", "sensors", "data", "user", "runtime operations", "actions", "development"]], "textrank": [["sensitive pervasive", "reconfigurable context", "sensitive", "information", "pervasive"], ["sensitive pervasive", "reconfigurable context", "sensitive", "information", "pervasive", "communication", "devices", "context"]], "positionrank": [["sensitive pervasive computing", "reconfigurable context", "sensitive middleware", "sensitive applications", "context"], ["sensitive pervasive computing", "reconfigurable context", "sensitive middleware", "sensitive applications", "context", "pervasive computing", "spontaneous information exchange", "new devices", "runtime operations", "devices"]], "multipartiterank": [["reconfigurable context", "sensitive middleware", "pervasive computing", "devices", "context"], ["reconfigurable context", "sensitive middleware", "pervasive computing", "devices", "context", "sensors", "spontaneous information exchange", "data", "sensitive applications", "user"]]}, {"id": "1951", "text": "Recording quantum properties of light in a long-lived atomic spin state:\n\ttowards quantum memory\nWe report an experiment on mapping a quantum state of light onto the ground\n\tstate spin of an ensemble of Cs atoms with the lifetime of 2 ms.\n\tRecording of one of the two quadrature phase operators of light is\n\tdemonstrated with vacuum and squeezed states of light. The sensitivity\n\tof the mapping procedure at the level of approximately 1 photon/sec per\n\tHz is shown. The results pave the road towards complete (storing both\n\tquadrature phase observables) quantum memory for Gaussian states of\n\tlight. The experiment also sheds new light on fundamental limits of\n\tsensitivity of the magneto-optical resonance method\n", "keywords": "light quantum properties recording; long-lived atomic spin state; quantum\n\tmemory; ground state spin; ensemble; two quadrature phase operators;\n\tvacuum states; squeezed states; mapping procedure; magnetooptical\n\tresonance method; 2 ms; Cs\n", "topicrank": [["light", "quantum properties", "states", "sensitivity", "quadrature phase operators"], ["light", "quantum properties", "states", "sensitivity", "quadrature phase operators", "experiment", "atomic spin state", "road", "photon", "complete"]], "textrank": [["quantum state", "state spin", "spin state", "gaussian states", "mapping procedure"], ["quantum state", "state spin", "spin state", "gaussian states", "mapping procedure", "light .", "ms .", "phase", "quantum", "resonance"]], "positionrank": [["quantum state", "quantum memory", "atomic spin state", "quantum properties", "new light"], ["quantum state", "quantum memory", "atomic spin state", "quantum properties", "new light", "state spin", "light", "quadrature phase observables", "quadrature phase operators", "gaussian states"]], "multipartiterank": [["light", "quantum properties", "atomic spin state", "states", "quadrature phase operators"], ["light", "quantum properties", "atomic spin state", "states", "quadrature phase operators", "sensitivity", "experiment", "quantum memory", "vacuum", "ground"]]}, {"id": "196", "text": "On the emergence of rules in neural networks\nA simple associationist neural network learns to factor abstract rules (i.e.,\n\tgrammars) from sequences of arbitrary input symbols by inventing\n\tabstract representations that accommodate unseen symbol sets as well as\n\tunseen but similar grammars. The neural network is shown to have the\n\tability to transfer grammatical knowledge to both new symbol\n\tvocabularies and new grammars. Analysis of the state-space shows that\n\tthe network learns generalized abstract structures of the input and is\n\tnot simply memorizing the input strings. These representations are\n\tcontext sensitive, hierarchical, and based on the state variable of the\n\tfinite-state machines that the neural network has learned.\n\tGeneralization to new symbol sets or grammars arises from the spatial\n\tnature of the internal representations used by the network, allowing\n\tnew symbol sets to be encoded close to symbol sets that have already\n\tbeen learned in the hidden unit space of the network. The results are\n\tcounter to the arguments that learning algorithms based on weight\n\tadaptation after each exemplar presentation (such as the long term\n\tpotentiation found in the mammalian nervous system) cannot in principle\n\textract symbolic knowledge from positive examples as prescribed by\n\tprevailing human linguistic theory and evolutionary psychology\n", "keywords": "associationist neural network; learns; abstract rules; neural network;\n\tstate-space; symbolic knowledge; cognitive neurosciences;\n\tassociationist learning\n", "topicrank": [["simple associationist neural network", "unseen symbol sets", "grammars", "state", "abstract representations"], ["simple associationist neural network", "unseen symbol sets", "grammars", "state", "abstract representations", "arbitrary input symbols", "grammatical knowledge", "rules", "weight", "adaptation"]], "textrank": [["abstract representations", "associationist neural", "new symbol", "unit space", "new grammars"], ["abstract representations", "associationist neural", "new symbol", "unit space", "new grammars", "long term", "exemplar presentation", "context sensitive", "input", "abstract"]], "positionrank": [["neural network", "new symbol sets", "neural networks", "unseen symbol sets", "abstract rules"], ["neural network", "new symbol sets", "neural networks", "unseen symbol sets", "abstract rules", "new symbol", "new grammars", "symbol sets", "network", "abstract representations"]], "multipartiterank": [["simple associationist neural network", "grammars", "unseen symbol sets", "rules", "abstract representations"], ["simple associationist neural network", "grammars", "unseen symbol sets", "rules", "abstract representations", "arbitrary input symbols", "state", "neural networks", "network", "sequences"]]}, {"id": "2085", "text": "An intelligent fuzzy decision system for a flexible manufacturing system with\n\tmulti-decision points\nThis paper describes an intelligent fuzzy decision support system for real-time\n\tscheduling and dispatching of parts in a flexible manufacturing system\n\t(FMS), with alternative routing possibilities for all parts. A fuzzy\n\tlogic approach is developed to improve the system performance by\n\tconsidering multiple performance measures and at multiple decision\n\tpoints. The characteristics of the system status, instead of parts, are\n\tfed back to assign priority to the parts waiting to be processed. A\n\tsimulation model is developed and it is shown that the proposed\n\tintelligent fuzzy decision support system keeps all performance\n\tmeasures at a good level. The proposed intelligent system is a\n\tpromising tool for dealing with scheduling FMSs, in contrast to\n\ttraditional rules\n", "keywords": "flexible manufacturing system; FMS; fuzzy logic; multiple decision points;\n\tintelligent decision support system; real-time system; scheduling;\n\tsimulation\n", "topicrank": [["parts", "intelligent fuzzy decision system", "multiple performance measures", "system performance", "flexible manufacturing system"], ["parts", "intelligent fuzzy decision system", "multiple performance measures", "system performance", "flexible manufacturing system", "scheduling", "dispatching", "time", "real", "possibilities"]], "textrank": [["decision system", "system performance", "system", "decision", "good level"], ["decision system", "system performance", "system", "decision", "good level", "simulation model", "assign priority", "logic approach", "performance", "promising"]], "positionrank": [["intelligent system", "flexible manufacturing system", "system performance", "system status", "multiple decision"], ["intelligent system", "flexible manufacturing system", "system performance", "system status", "multiple decision", "multiple performance measures", "parts", "points", "performance", "measures"]], "multipartiterank": [["intelligent fuzzy decision system", "parts", "flexible manufacturing system", "multiple performance measures", "system performance"], ["intelligent fuzzy decision system", "parts", "flexible manufacturing system", "multiple performance measures", "system performance", "intelligent fuzzy decision support system", "dispatching", "scheduling", "time", "multiple decision"]]}, {"id": "332", "text": "Fitting mixed-effects models for repeated ordinal outcomes with the NLMIXED\n\tprocedure\nThis paper presents an analysis of repeated ordinal outcomes arising from two\n\tpsychological studies. The first case is a repeated measures analysis\n\tof variance; the second is a mixed-effects regression. in a\n\tlongitudinal design. In both, the subject-specific variation is modeled\n\tby including random effects in the linear predictor (inside a link\n\tfunction) of a generalized linear model. The NLMIXED procedure in SAS\n\tis used to fit the mixed-effects models for the categorical response\n\tdata. The presentation emphasizes the parallel between the model.\n\tspecifications and the SAS statements. The purpose of this paper is to\n\tfacilitate the use of mixed-effects models in the analysis of repeated\n\tordinal outcomes\n", "keywords": "repeated ordinal outcomes; psychological studies; repeated measures analysis of\n\tvariance; mixed-effects regression; longitudinal design;\n\tsubject-specific variation modeling; random effects; linear predictor;\n\tgeneralized linear model; NLMIXED procedure; mixed-effects model\n\tfitting; categorical response data; model specifications\n", "topicrank": [["effects models", "fitting mixed", "analysis", "ordinal outcomes", "nlmixed"], ["effects models", "fitting mixed", "analysis", "ordinal outcomes", "nlmixed", "generalized linear model", "sas", "paper", "data", "categorical response"]], "textrank": [["nlmixed procedure", "psychological studies", "ordinal outcomes", "fitting mixed", "linear"], ["nlmixed procedure", "psychological studies", "ordinal outcomes", "fitting mixed", "linear", "effects", "mixed", "first", "analysis", "procedure"]], "positionrank": [["effects models", "ordinal outcomes", "effects regression", "random effects", "measures analysis"], ["effects models", "ordinal outcomes", "effects regression", "random effects", "measures analysis", "nlmixed procedure", "generalized linear model", "analysis", "psychological studies", "nlmixed"]], "multipartiterank": [["fitting mixed", "effects models", "ordinal outcomes", "analysis", "nlmixed"], ["fitting mixed", "effects models", "ordinal outcomes", "analysis", "nlmixed", "paper", "generalized linear model", "sas", "mixed", "procedure"]]}, {"id": "377", "text": "MATLAB code for plotting ambiguity functions\nA MATLAB code capable of plotting ambiguity functions of many different radar\n\tsignals is presented. The program makes use of MATLAB's sparse matrix\n\toperations, and avoids loops. The program could be useful as a\n\tpedagogical tool in radar courses teaching pulse compression\n", "keywords": "MATLAB code; ambiguity functions plotting; radar signals; sparse matrix\n\toperations; pedagogical tool; radar courses; pulse compression;\n\tmatched-filter response; Doppler-shifted signal version\n", "topicrank": [["matlab code", "program", "ambiguity functions", "sparse matrix", "use"], ["matlab code", "program", "ambiguity functions", "sparse matrix", "use", "operations", "many different radar", "radar courses", "avoids loops", "pedagogical tool"]], "textrank": [["different radar", "sparse matrix", "ambiguity functions", "code", "radar"], ["different radar", "sparse matrix", "ambiguity functions", "code", "radar"]], "positionrank": [["matlab code", "ambiguity functions", "matlab", "many different radar", "radar courses"], ["matlab code", "ambiguity functions", "matlab", "many different radar", "radar courses", "program", "sparse matrix", "avoids loops", "pedagogical tool", "signals"]], "multipartiterank": [["matlab code", "ambiguity functions", "program", "many different radar", "sparse matrix"], ["matlab code", "ambiguity functions", "program", "many different radar", "sparse matrix", "use", "signals", "operations", "radar courses", "avoids loops"]]}, {"id": "1930", "text": "A new method of systemological analysis coordinated with the procedure of\n\tobject-oriented design. II\nFor pt.I. see Vestn. KhGPU, no.81, p.15-18 (2000). The paper presents the\n\tresults of development of an object-oriented systemological method used\n\tto design complex systems. A formal system representation, as well as\n\tan axiomatics of the calculus of systems as functional flow-type\n\tobjects based on a Node-Function-Object class hierarchy are proposed. A\n\tformalized NFO/UFO analysis algorithm and CASE tools used to support it\n\tare considered\n", "keywords": "systemological analysis; object-oriented design; complex systems design; formal\n\tsystem representation; axiomatics; functional flow-type objects;\n\tformalized NFO/UFO analysis algorithm; CASE tools\n", "topicrank": [["object", "complex systems", "new method", "functional flow", "type"], ["object", "complex systems", "new method", "functional flow", "type", "objects", "calculus", "function", "node", "development"]], "textrank": [["systemological analysis", "systemological method", "case tools", "functional flow", "complex systems"], ["systemological analysis", "systemological method", "case tools", "functional flow", "complex systems", "analysis", "class", "system", "method", "systems"]], "positionrank": [["systemological method", "new method", "systemological analysis", "object class hierarchy", "ufo analysis algorithm"], ["systemological method", "new method", "systemological analysis", "object class hierarchy", "ufo analysis algorithm", "object", "complex systems", "formal system representation", "procedure", "systems"]], "multipartiterank": [["object", "new method", "complex systems", "systemological analysis", "procedure"], ["object", "new method", "complex systems", "systemological analysis", "procedure", "development", "functional flow", "results", "type", "calculus"]]}, {"id": "1975", "text": "Efficient computation of local geometric moments\nLocal moments have attracted attention as local features in applications such\n\tas edge detection and texture segmentation. The main reason for this is\n\tthat they are inherently integral-based features, so that their use\n\treduces the effect of uncorrelated noise. The computation of local\n\tmoments, when viewed as a neighborhood operation, can be interpreted as\n\ta convolution of the image with a set of masks. Nevertheless, moments\n\tcomputed inside overlapping windows are not independent and convolution\n\tdoes not take this fact into account. By introducing a matrix\n\tformulation and the concept of accumulation moments, this paper\n\tpresents an algorithm which is computationally much more efficient than\n\tconvolving and yet as simple\n", "keywords": "local geometric moments computation; local features; edge detection; texture\n\tsegmentation; integral-based features; neighborhood operation; image\n\tconvolution; overlapping windows; matrix formulation; accumulation\n\tmoments; computationally efficient algorithm; image analysis\n", "topicrank": [["moments", "local geometric moments", "convolution", "efficient computation", "local features"], ["moments", "local geometric moments", "convolution", "efficient computation", "local features", "uncorrelated noise", "formulation", "set", "concept", "independent"]], "textrank": [["local moments", "main reason", "texture segmentation", "edge detection", "applications such"], ["local moments", "main reason", "texture segmentation", "edge detection", "applications such", "efficient computation", "moments", "local", "efficient", "computation"]], "positionrank": [["local geometric moments", "local moments", "local features", "accumulation moments", "efficient computation"], ["local geometric moments", "local moments", "local features", "accumulation moments", "efficient computation", "moments", "computation", "edge detection", "uncorrelated noise", "features"]], "multipartiterank": [["local geometric moments", "efficient computation", "moments", "local features", "attention"], ["local geometric moments", "efficient computation", "moments", "local features", "attention", "convolution", "edge detection", "texture segmentation", "local moments", "main reason"]]}, {"id": "2104", "text": "Computer-mediated communication and remote management: integration or\n\tisolation?\nThe use of intranets and e-mails to communicate with remote staff is increasing\n\trapidly within organizations. For many companies this is viewed as a\n\tspeedy and cost-effective way of keeping in contact with staff and\n\tensuring their continuing commitment to company goals. This article\n\thighlights the problems experienced by staff when managers use\n\tintranets and e-mails in an inappropriate fashion for these purposes.\n\tIssues of remoteness and isolation are discussed, along with the\n\treports of frustration and disidentification experienced. However, it\n\twill be shown that when used appropriately, communication using these\n\ttechnologies can facilitate shared understanding and help remote staff\n\tto view their company as alive and exciting. Theoretical aspects are\n\thighlighted and the implications of these findings are discussed\n", "keywords": "computer-mediated communication; remote management; intranets; e-mails; remote\n\tstaff; organizations; companies; cost-effective; managers; remoteness\n", "topicrank": [["remote staff", "company goals", "intranets", "isolation", "mails"], ["remote staff", "company goals", "intranets", "isolation", "mails", "communication", "remoteness", "issues", "cost", "managers"]], "textrank": [["remote staff", "remote management", "theoretical aspects", "inappropriate fashion", "company goals"], ["remote staff", "remote management", "theoretical aspects", "inappropriate fashion", "company goals", "effective way", "many companies", "company", "staff"]], "positionrank": [["remote staff", "remote management", "computer", "staff", "communication"], ["remote staff", "remote management", "computer", "staff", "communication", "integration", "isolation", "intranets", "e", "company goals"]], "multipartiterank": [["remote staff", "company goals", "intranets", "staff", "isolation"], ["remote staff", "company goals", "intranets", "staff", "isolation", "mails", "communication", "alive", "commitment", "remoteness"]]}, {"id": "2141", "text": "System embedding. Control with reduced observer\nTwo interrelated problems-design of the reduced observer of plant state\n\tseparately and together with its control system-were considered from\n\tthe standpoint of designing the multivariable linear systems from the\n\tdesired matrix transfer functions. The matrix equations defining the\n\tentire constructive class of solutions of the posed problems were\n\tobtained using the system embedding technology. As was demonstrated,\n\tcontrol based on the reduced observer is capable to provide the desired\n\tresponse to the control input, as well as the response to the nonzero\n\tinitial conditions, only for the directly measurable part of the\n\tcomponents of the state vector. An illustrative example was presented\n", "keywords": "system embedding; reduced observer control; reduced plant state observer\n\tdesign; multivariable linear systems; matrix transfer functions; state\n\tvector\n", "topicrank": [["reduced observer", "control", "system", "interrelated problems", "plant state"], ["reduced observer", "control", "system", "interrelated problems", "plant state", "response", "entire constructive class", "nonzero", "solutions", "design"]], "textrank": [["matrix transfer", "interrelated problems", "reduced observer", "constructive", "linear"], ["matrix transfer", "interrelated problems", "reduced observer", "constructive", "linear", "state", "control", "matrix", "initial", "problems"]], "positionrank": [["control system", "reduced observer", "control input", "interrelated problems", "system"], ["control system", "reduced observer", "control input", "interrelated problems", "system", "control", "plant state", "problems", "state vector", "matrix transfer functions"]], "multipartiterank": [["system", "reduced observer", "control", "interrelated problems", "plant state"], ["system", "reduced observer", "control", "interrelated problems", "plant state", "response", "design", "technology", "entire constructive class", "solutions"]]}, {"id": "1988", "text": "Integration is key - an introduction to enterprise application integration\n\t(EAI) technology\nOver the past few years, numerous organisations have invested in the latest\n\tsoftware applications to drive their business forward. But many are now\n\tfinding that these systems are becoming redundant on their own. The key\n\tto staying ahead of the competition in today's current climate is now\n\tto integrate all of these systems, says Justin Opie, Portfolio Director\n\tat Imark Communications\n", "keywords": "enterprise application integration; Imark Communications\n", "topicrank": [["integration", "key", "systems", "today", "software applications"], ["integration", "key", "systems", "today", "software applications", "eai", "introduction", "latest", "justin opie", "competition"]], "textrank": [["current climate", "software applications", "numerous organisations", "few", "application"], ["current climate", "software applications", "numerous organisations", "few", "application", "justin"]], "positionrank": [["enterprise application integration", "integration", "past few years", "key", "numerous organisations"], ["enterprise application integration", "integration", "past few years", "key", "numerous organisations", "introduction", "technology", "eai", "software applications", "systems"]], "multipartiterank": [["integration", "key", "systems", "introduction", "today"], ["integration", "key", "systems", "introduction", "today", "eai", "software applications", "competition", "justin opie", "current climate"]]}, {"id": "2019", "text": "Effective moving cast shadow detection for monocular color traffic image\n\tsequences\nFor an accurate scene analysis using monocular color traffic image sequences, a\n\trobust segmentation of moving vehicles from the stationary background\n\tis generally required. However, the presence of moving cast shadow may\n\tlead to an inaccurate vehicle segmentation, and as a result, may lead\n\tto further erroneous scene analysis. We propose an effective method for\n\tthe detection of moving cast shadow. By observing the characteristics\n\tof cast shadow in the luminance, chrominance, gradient density, and\n\tgeometry domains, a combined probability map, called a shadow\n\tconfidence score (SCS), is obtained. From the edge map of the input\n\timage, each edge pixel is examined to determine whether it belongs to\n\tthe vehicle region based on its neighboring SCSs. The cast shadow is\n\tidentified as those regions with high SCSs, which are outside the\n\tconvex hull of the selected vehicle edge pixels. The proposed method is\n\ttested on 100 vehicle images taken under different lighting conditions\n\t(sunny and cloudy), viewing angles (roadside and overhead), vehicle\n\tsizes (small, medium, and large), and colors (similar to the road and\n\tnot). The results indicate that an average error rate of around 14% is\n\tobtained while the lowest error rate is around 3% for large vehicles\n", "keywords": "effective moving cast shadow detection; monocular color traffic image\n\tsequences; accurate scene analysis; robust segmentation; moving\n\tvehicles; stationary background; moving cast shadow; inaccurate vehicle\n\tsegmentation; erroneous scene analysis; luminance; chrominance;\n\tgradient density; geometry domains; combined probability map; shadow\n\tconfidence score; input image; cast shadow; convex hull; selected\n\tvehicle edge pixels; lighting conditions; vehicle images; sunny;\n\tcloudy; viewing angles; vehicle sizes; average error rate; image\n\tsegmentation\n", "topicrank": [["shadow", "vehicle region", "monocular color traffic image", "neighboring scss", "edge map"], ["shadow", "vehicle region", "monocular color traffic image", "neighboring scss", "edge map", "shadow detection", "large", "small", "effective", "sizes"]], "textrank": [["vehicle edge", "vehicle segmentation", "color traffic image", "edge map", "erroneous scene"], ["vehicle edge", "vehicle segmentation", "color traffic image", "edge map", "erroneous scene", "vehicle", "edge", "geometry domains", "gradient density", "effective method"]], "positionrank": [["shadow detection", "accurate scene analysis", "cast shadow", "effective method", "shadow"], ["shadow detection", "accurate scene analysis", "cast shadow", "effective method", "shadow", "inaccurate vehicle segmentation", "image", "vehicle edge pixels", "sequences", "robust segmentation"]], "multipartiterank": [["shadow", "vehicle region", "monocular color traffic image", "effective", "shadow detection"], ["shadow", "vehicle region", "monocular color traffic image", "effective", "shadow detection", "cast shadow", "neighboring scss", "edge map", "sequences", "confidence score"]]}, {"id": "3", "text": "NuVox shows staying power with new cash, new market\nWho says you can't raise cash in today's telecom market? NuVox Communications\n\tpositions itself for the long run with $78.5 million in funding and a\n\tnew credit facility\n", "keywords": "telecom; competitive carrier market; NuVox Communications; investors\n", "topicrank": [["new market", "new cash", "nuvox", "today", "power"], ["new market", "new cash", "nuvox", "today", "power", "long run", "funding", "new credit facility"]], "textrank": [["new credit", "new market", "new", "market", "nuvox"], ["new credit", "new market", "new", "market", "nuvox"]], "positionrank": [["new cash", "new market", "nuvox communications", "new credit facility", "nuvox"], ["new cash", "new market", "nuvox communications", "new credit facility", "nuvox", "telecom market", "cash", "long run", "power", "today"]], "multipartiterank": [["new cash", "nuvox", "new market", "power", "today"], ["new cash", "nuvox", "new market", "power", "today", "telecom market", "cash", "nuvox communications", "long run", "funding"]]}, {"id": "316", "text": "Duality revisited: construction of fractional frequency distributions based on\n\ttwo dual Lotka laws\nFractional frequency distributions of, for example, authors with a certain\n\t(fractional) number of papers are very irregular, and therefore not\n\teasy to model or to explain. The article gives a first attempt to this\n\tby as suming two simple Lotka laws (with exponent 2): one for the\n\tnumber of authors with n papers (total count here) and one for the\n\tnumber of papers with n authors, n in N. Based on an earlier made\n\tconvolution model of Egghe, interpreted and reworked now for discrete\n\tscores, we are able to produce theoretical fractional frequency\n\tdistributions with only one parameter, which are in very close\n\tagreement with the practical ones as found in a large dataset produced\n\tearlier by Rao (1995). The article also shows that (irregular)\n\tfractional frequency distributions are a consequence of Lotka's law,\n\tand are not examples of breakdowns of this famous historical law\n", "keywords": "dual Lotka laws; convolution model; discrete scores; irregular fractional\n\tfrequency distributions\n", "topicrank": [["fractional frequency distributions", "number", "dual lotka laws", "authors", "papers"], ["fractional frequency distributions", "number", "dual lotka laws", "authors", "papers", "irregular", "law", "article", "agreement", "scores"]], "textrank": [["fractional frequency", "practical ones", "convolution model", "total count", "n papers"], ["fractional frequency", "practical ones", "convolution model", "total count", "n papers", "first attempt", "lotka", "historical", "fractional", "n"]], "positionrank": [["fractional frequency distributions", "theoretical fractional frequency", "dual lotka laws", "simple lotka laws", "distributions"], ["fractional frequency distributions", "theoretical fractional frequency", "dual lotka laws", "simple lotka laws", "distributions", "duality", "lotka", "construction", "n papers", "authors"]], "multipartiterank": [["fractional frequency distributions", "dual lotka laws", "number", "authors", "papers"], ["fractional frequency distributions", "dual lotka laws", "number", "authors", "papers", "irregular", "law", "article", "construction", "example"]]}, {"id": "353", "text": "Edit distance of run-length encoded strings\nLet X and Y be two run-length encoded strings, of encoded lengths k and l,\n\trespectively. We present a simple O(|X|l+|Y|k) time algorithm that\n\tcomputes their edit distance\n", "keywords": "run-length encoded strings; encoded lengths; algorithm; edit distance;\n\tcomputation time\n", "topicrank": [["run", "length encoded strings", "edit distance", "time algorithm"], ["run", "length encoded strings", "edit distance", "time algorithm"]], "textrank": [["encoded lengths", "edit distance", "encoded"], ["encoded lengths", "edit distance", "encoded"]], "positionrank": [["encoded strings", "edit distance", "encoded lengths k", "run", "length"], ["encoded strings", "edit distance", "encoded lengths k", "run", "length", "simple o(|x|l+|y|k", "time algorithm", "x", "l"]], "multipartiterank": [["run", "length encoded strings", "edit distance", "time algorithm"], ["run", "length encoded strings", "edit distance", "time algorithm"]]}, {"id": "406", "text": "Windows XP fast user switching\nThe Windows NT family of operating systems has always supported the concept of\n\tmultiple user accounts, but they've taken the concept a step further\n\twith Windows XP's Fast User Switching feature. Fast User Switching is a\n\tnew feature of Windows XP that allows multiple users to log on to the\n\tsame machine and quickly switch between the logged on accounts. Fast\n\tUser Switching is implemented using some of the built-in capabilities\n\tof Terminal Services. Terminal Server has been around for a while but\n\tis much more feature rich and integrated in Windows XP. A machine with\n\tthe terminal services (Remote Desktop) client can log on to and run\n\tapplications on a remote machine running the terminal server\n", "keywords": "Windows XP Fast User Switching; multiple user logon access; operating systems;\n\tmultiple user accounts; Terminal Services; Terminal Server; Remote\n\tDesktop\n", "topicrank": [["windows xp fast user switching", "windows xp", "terminal services", "multiple user accounts", "concept"], ["windows xp fast user switching", "windows xp", "terminal services", "multiple user accounts", "concept", "machine", "remote desktop", "fast", "new feature", "step"]], "textrank": [["multiple user", "remote machine", "windows nt", "windows xp", "feature"], ["multiple user", "remote machine", "windows nt", "windows xp", "feature", "user", "terminal", "remote", "machine", "multiple"]], "positionrank": [["fast user switching", "windows xp", "windows nt family", "user switching", "multiple user accounts"], ["fast user switching", "windows xp", "windows nt family", "user switching", "multiple user accounts", "new feature", "more feature", "operating systems", "multiple users", "terminal services"]], "multipartiterank": [["windows xp fast user switching", "windows nt family", "windows xp", "concept", "terminal services"], ["windows xp fast user switching", "windows nt family", "windows xp", "concept", "terminal services", "operating systems", "multiple user accounts", "machine", "step", "remote desktop"]]}, {"id": "2061", "text": "Acquisitions in the James Ford Bell Library\nThis article presents basic acquisitions philosophy and approaches in a noted\n\tspecial collection, with commentary on \"just saying no\" and on how the\n\telectronic revolution has changed the acquisition of special\n\tcollections materials\n", "keywords": "James Ford Bell Library; library acquisitions philosophy; out-of-print books;\n\tUniversity library; special collections; electronic revolution\n", "topicrank": [["special collection", "acquisitions", "article", "approaches", "acquisition"], ["special collection", "acquisitions", "article", "approaches", "acquisition", "james ford bell library", "collections materials", "commentary", "electronic revolution"]], "textrank": [["ford bell", "special collection", "acquisitions", "special"], ["ford bell", "special collection", "acquisitions", "special"]], "positionrank": [["basic acquisitions philosophy", "acquisitions", "special collection", "article", "approaches"], ["basic acquisitions philosophy", "acquisitions", "special collection", "article", "approaches", "electronic revolution", "collections materials", "acquisition", "commentary"]], "multipartiterank": [["acquisitions", "james ford bell library", "special collection", "article", "approaches"], ["acquisitions", "james ford bell library", "special collection", "article", "approaches", "basic acquisitions philosophy", "commentary", "acquisition", "special", "collections materials"]]}, {"id": "2024", "text": "Binocular model for figure-ground segmentation in translucent and occluding\n\timages\nA Fourier-based solution to the problem of figure-ground segmentation in short\n\tbaseline binocular image pairs is presented. Each image is modeled as\n\tan additive composite of two component images that exhibit a spatial\n\tshift due to the binocular parallax. The segmentation is accomplished\n\tby decoupling each Fourier component in one of the resultant additive\n\timages into its two constituent phasors, allocating each to its\n\tappropriate object-specific spectrum, and then reconstructing the\n\tforeground and background using the inverse Fourier transform. It is\n\tshown that the foreground and background shifts can be computed from\n\tthe differences of the magnitudes and phases of the Fourier transform\n\tof the binocular image pair. While the model is based on translucent\n\tobjects, it also works with occluding objects\n", "keywords": "binocular model; figure-ground segmentation; translucent images; occluding\n\timages; images; image segmentation; Fourier-based solution; short\n\tbaseline binocular image pairs; component images; spatial shift;\n\tbinocular parallax; Fourier component decoupling; phasors;\n\tobject-specific spectrum; foreground; background; inverse Fourier\n\ttransform; binocular image pair; translucent objects; occluding objects\n", "topicrank": [["ground segmentation", "images", "fourier component", "baseline binocular image pairs", "figure"], ["ground segmentation", "images", "fourier component", "baseline binocular image pairs", "figure", "background", "additive composite", "translucent", "foreground", "binocular model"]], "textrank": [["binocular image", "fourier component", "binocular", "appropriate object", "constituent phasors"], ["binocular image", "fourier component", "binocular", "appropriate object", "constituent phasors", "ground segmentation", "fourier", "image", "additive", "component"]], "positionrank": [["binocular image pair", "binocular model", "ground segmentation", "binocular parallax", "segmentation"], ["binocular image pair", "binocular model", "ground segmentation", "binocular parallax", "segmentation", "component images", "image", "fourier transform", "figure", "fourier component"]], "multipartiterank": [["ground segmentation", "images", "figure", "baseline binocular image pairs", "binocular model"], ["ground segmentation", "images", "figure", "baseline binocular image pairs", "binocular model", "fourier component", "additive composite", "translucent", "short", "foreground"]]}, {"id": "393", "text": "The use of the SPSA method in ECG analysis\nThe classification, monitoring, and compression of electrocardiogram (ECG)\n\tsignals recorded of a single patient over a relatively long period of\n\ttime is considered. The particular application we have in mind is\n\thigh-resolution ECG analysis, such as late potential analysis,\n\tmorphology changes in QRS during arrythmias, T-wave alternants, or the\n\tstudy of drug effects on ventricular activation. We propose to apply a\n\tmodification of a classical method of cluster analysis or vector\n\tquantization. The novelty of our approach is that we use a new\n\tdistortion measure to quantify the distance of two ECG cycles, and the\n\tclass-distortion measure is defined using a min-max criterion. The new\n\tclass-distortion-measure is much more sensitive to outliers than the\n\tusual distortion measures using average-distance. The price of this\n\tpractical advantage is that computational complexity is significantly\n\tincreased. The resulting nonsmooth optimization problem is solved by an\n\tadapted version of the simultaneous perturbation stochastic\n\tapproximation (SPSA) method of J. Spall (IEEE Trans. Automat. Contr.,\n\tvol. 37, p. 332-41, Mar. 1992). The main idea is to generate a smooth\n\tapproximation by a randomization procedure. The viability of the method\n\tis demonstrated on both simulated and real data. An experimental\n\tcomparison with the widely used correlation method is given on real\n\tdata\n", "keywords": "class-distortion-measure; nonsmooth optimization problem; simultaneous\n\tperturbation stochastic approximation method; cluster analysis;\n\trandomization procedure; correlation method; electrodiagnostics; ECG\n\tsignals compression; distortion measure; ECG cycles\n", "topicrank": [["distortion measure", "ecg analysis", "classical method", "class", "new"], ["distortion measure", "ecg analysis", "classical method", "class", "new", "approximation", "distance", "spsa method", "real data", "cluster analysis"]], "textrank": [["ecg analysis", "potential analysis", "j. spall", "computational complexity", "practical advantage"], ["ecg analysis", "potential analysis", "j. spall", "computational complexity", "practical advantage", "max criterion", "ventricular activation", "drug effects", "wave alternants", "morphology changes"]], "positionrank": [["resolution ecg analysis", "ecg analysis", "spsa method", "late potential analysis", "ecg cycles"], ["resolution ecg analysis", "ecg analysis", "spsa method", "late potential analysis", "ecg cycles", "cluster analysis", "classical method", "correlation method", "ecg", "method"]], "multipartiterank": [["ecg analysis", "distortion measure", "classical method", "spsa method", "class"], ["ecg analysis", "distortion measure", "classical method", "spsa method", "class", "new", "distance", "classification", "monitoring", "cluster analysis"]]}, {"id": "20", "text": "Adaptive state feedback control for a class of linear systems with unknown\n\tbounds of uncertainties\nThe problem of adaptive robust stabilization for a class of linear time-varying\n\tsystems with disturbance and nonlinear uncertainties is considered. The\n\tbounds of the disturbance and uncertainties are assumed to be unknown,\n\tbeing even arbitrary. For such uncertain dynamical systems, the\n\tadaptive robust state feedback controller is obtained. And the\n\tresulting closed-loop systems are asymptotically stable in theory.\n\tMoreover, an adaptive robust state feedback control scheme is given.\n\tThe scheme ensures the closed-loop systems exponentially practically\n\tstable and can be used in practical engineering. Finally, simulations\n\tshow that the control scheme is effective\n", "keywords": "robust stabilization; adaptive stabilization; linear time-varying systems;\n\tnonlinear uncertainties; closed-loop systems; uncertain dynamical\n\tsystems; state feedback; adaptive controller; robust control; uncertain\n\tsystems\n", "topicrank": [["linear systems", "uncertainties", "bounds", "disturbance", "class"], ["linear systems", "uncertainties", "bounds", "disturbance", "class", "unknown", "closed", "stable", "scheme", "adaptive state feedback control"]], "textrank": [["robust state feedback control", "robust state feedback", "state feedback control", "uncertain dynamical systems", "linear systems"], ["robust state feedback control", "robust state feedback", "state feedback control", "uncertain dynamical systems", "linear systems", "systems", "robust", "linear", "control", "uncertainties"]], "positionrank": [["adaptive robust stabilization", "linear systems", "loop systems", "control scheme", "systems"], ["adaptive robust stabilization", "linear systems", "loop systems", "control scheme", "systems", "linear time", "nonlinear uncertainties", "class", "uncertainties", "scheme"]], "multipartiterank": [["linear systems", "uncertainties", "class", "unknown", "bounds"], ["linear systems", "uncertainties", "class", "unknown", "bounds", "adaptive state feedback control", "disturbance", "adaptive robust stabilization", "problem", "closed"]]}, {"id": "2139", "text": "Generalized confidence sets for a statistically indeterminate random vector\nA problem is considered for the construction of confidence sets for a random\n\tvector, the information on distribution parameters of which is\n\tincomplete. To obtain exact estimates and a detailed analysis of the\n\tproblem, the notion is introduced of a generalized confidence set for a\n\tstatistically indeterminate random vector. Properties of generalized\n\tconfidence sets are studied. It is shown that the standard method of\n\testimation, which relies on the unification of confidence sets, leads\n\tin many cases to wider confidence estimates. For a normally distributed\n\trandom vector with an inaccurately known mean value, generalized\n\tconfidence sets are built tip and the dependence of sizes of a\n\tgeneralized confidence set on the forms and parameters of a set of\n\tpossible mean values is examined\n", "keywords": "generalized confidence sets; statistically indeterminate random vector;\n\tdistribution parameters; normally distributed random vector\n", "topicrank": [["confidence sets", "indeterminate random vector", "distribution parameters", "problem", "information"], ["confidence sets", "indeterminate random vector", "distribution parameters", "problem", "information", "dependence", "sizes", "forms", "tip", "exact estimates"]], "textrank": [["confidence estimates", "standard method", "detailed analysis", "distribution parameters", "mean"], ["confidence estimates", "standard method", "detailed analysis", "distribution parameters", "mean", "confidence", "random", "estimates", "parameters"]], "positionrank": [["confidence sets", "wider confidence estimates", "indeterminate random vector", "random vector", "confidence"], ["confidence sets", "wider confidence estimates", "indeterminate random vector", "random vector", "confidence", "vector", "possible mean values", "exact estimates", "distribution parameters", "mean value"]], "multipartiterank": [["confidence sets", "indeterminate random vector", "problem", "distribution parameters", "properties"], ["confidence sets", "indeterminate random vector", "problem", "distribution parameters", "properties", "information", "confidence", "construction", "unification", "exact estimates"]]}, {"id": "1948", "text": "Estimating populations for collective dose calculations\nThe collective dose provides an estimate of the effects of facility operations\n\ton the public based on an estimate of the population in the area.\n\tGeographic information system software, electronic population data\n\tresources, and a personal computer were used to develop estimates of\n\tpopulation within 80 km radii of two sites\n", "keywords": "collective dose calculations; facility operations; public; geographic\n\tinformation system software; electronic population data resources;\n\tpersonal computer\n", "topicrank": [["population", "estimate", "collective dose calculations", "geographic information system software", "facility operations"], ["population", "estimate", "collective dose calculations", "geographic information system software", "facility operations", "effects", "resources", "area", "public", "km radii"]], "textrank": [["information system", "facility operations", "population", "dose", "personal"], ["information system", "facility operations", "population", "dose", "personal"]], "positionrank": [["collective dose calculations", "collective dose", "estimate", "electronic population data", "facility operations"], ["collective dose calculations", "collective dose", "estimate", "electronic population data", "facility operations", "populations", "population", "effects", "public", "personal computer"]], "multipartiterank": [["population", "estimate", "collective dose calculations", "geographic information system software", "effects"], ["population", "estimate", "collective dose calculations", "geographic information system software", "effects", "facility operations", "populations", "area", "resources", "electronic population data"]]}, {"id": "273", "text": "Chemical information based scaling of molecular descriptors: a universal\n\tchemical scale for library design and analysis\nScaling is a difficult issue for any analysis of chemical properties or\n\tmolecular topology when disparate descriptors are involved. To compare\n\tproperties across different data sets, a common scale must be defined.\n\tUsing several publicly available databases (ACD, CMC, MDDR, and NCI) as\n\ta basis, we propose to define chemically meaningful scales for a number\n\tof molecular properties and topology descriptors. These chemically\n\tderived scaling functions have several advantages. First, it is\n\tpossible to define chemically relevant scales, greatly simplifying\n\tsimilarity and diversity analyses across data sets. Second, this\n\tapproach provides a convenient method for setting descriptor boundaries\n\tthat define chemically reasonable topology spaces. For example,\n\tdescriptors can be scaled so that compounds with little potential for\n\tbiological activity, bioavailability, or other drug-like\n\tcharacteristics are easily identified as outliers. We have compiled\n\tscaling values for 314 molecular descriptors. In addition the 10th and\n\t90th percentile values for each descriptor have been calculated for use\n\tin outlier filtering\n", "keywords": "universal chemical scale; library design; library analysis; chemical\n\tinformation based scaling; molecular descriptors; molecular topology;\n\tchemical properties; databases; diversity analyses; similarity\n\tanalyses; data sets; descriptor boundaries; drug-like characteristics;\n\tbiological activity; bioavailability; outliers\n", "topicrank": [["molecular descriptors", "chemical properties", "scaling", "analysis", "different data sets"], ["molecular descriptors", "chemical properties", "scaling", "analysis", "different data sets", "several", "descriptor boundaries", "chemical information", "meaningful scales", "values"]], "textrank": [["topology descriptors", "molecular topology", "molecular descriptors", "chemical scale", "diversity analyses"], ["topology descriptors", "molecular topology", "molecular descriptors", "chemical scale", "diversity analyses", "several advantages", "scaling functions", "available databases", "difficult issue", "library design"]], "positionrank": [["chemical properties", "molecular descriptors", "chemical scale", "chemical information", "topology descriptors"], ["chemical properties", "molecular descriptors", "chemical scale", "chemical information", "topology descriptors", "molecular properties", "molecular topology", "disparate descriptors", "scaling functions", "descriptors"]], "multipartiterank": [["molecular descriptors", "chemical information", "scaling", "chemical properties", "analysis"], ["molecular descriptors", "chemical information", "scaling", "chemical properties", "analysis", "different data sets", "values", "several", "descriptor boundaries", "universal"]]}, {"id": "2181", "text": "Development of a health guidance support system for lifestyle improvement\nThe objective is to provide automated advice for lifestyle adjustment based on\n\tan assessment of the results of a questionnaire and medical examination\n\tor health checkup data. A system was developed that gathers data based\n\ton questions regarding weight gain, exercise, smoking, sleep, eating\n\thabits, salt intake, animal fat intake, snacks, alcohol, and oral\n\thygiene, body mass index, resting blood pressure, fasting blood sugar,\n\ttotal cholesterol, triglycerides, uric acid and liver function tests.\n\tBased on the relationships between the lifestyle data and the health\n\tcheckup data, a health assessment sheet was generated for persons being\n\tallocated to a multiple-risk factor syndrome group. Health assessment\n\tand useful advice for lifestyle improvement were automatically\n\textracted with the system, toward the high risk group for life style\n\trelated diseases. The system is operational. In comparison with\n\tconventional, limited advice methods, we developed a practical system\n\tthat defined the necessity for lifestyle improvement more clearly, and\n\tmade giving advice easier\n", "keywords": "health guidance support system; lifestyle improvement; questionnaire; medical\n\texamination; health checkup data; weight gain; smoking; exercise;\n\tsleep; eating habits; salt intake; animal fat intake; snacks; alcohol;\n\toral hygiene; body mass index; resting blood pressure; fasting blood\n\tsugar; total cholesterol; triglycerides; uric acid; liver function\n\ttests\n", "topicrank": [["health checkup data", "assessment", "lifestyle improvement", "system", "advice"], ["health checkup data", "assessment", "lifestyle improvement", "system", "advice", "risk factor syndrome group", "blood pressure", "animal fat intake", "smoking", "salt intake"]], "textrank": [["health guidance support system", "health checkup data", "lifestyle data", "fat intake", "health assessment"], ["health guidance support system", "health checkup data", "lifestyle data", "fat intake", "health assessment", "advice", "checkup data", "total cholesterol", "weight gain", "medical examination"]], "positionrank": [["health checkup data", "health assessment sheet", "lifestyle improvement", "health assessment", "lifestyle data"], ["health checkup data", "health assessment sheet", "lifestyle improvement", "health assessment", "lifestyle data", "practical system", "lifestyle adjustment", "health", "system", "development"]], "multipartiterank": [["lifestyle improvement", "health checkup data", "assessment", "advice", "system"], ["lifestyle improvement", "health checkup data", "assessment", "advice", "system", "risk factor syndrome group", "blood pressure", "medical examination", "results", "questionnaire"]]}, {"id": "236", "text": "Licensing experiences in the Netherlands\nThe licensing strategy of university libraries in the Netherlands is closely\n\tconnected with university policies to develop document servers and to\n\tmake research publications available on the Web. National agreements\n\thave been made with major publishers, such as Elsevier Science and\n\tKluwer Academic, to provide access to a wide range of scientific\n\tinformation and to experiment with new ways of providing information\n\tand new business models\n", "keywords": "licensing strategy; university libraries; Netherlands; university policies;\n\tdocument servers; research publications; Web; Elsevier Science; Kluwer\n\tAcademic; scientific information; business models\n", "topicrank": [["information", "university libraries", "netherlands", "licensing experiences", "scientific"], ["information", "university libraries", "netherlands", "licensing experiences", "scientific", "wide range", "web", "national agreements", "access", "kluwer academic"]], "textrank": [["new business", "national agreements", "document servers", "publications", "university"], ["new business", "national agreements", "document servers", "publications", "university", "licensing", "new", "major"]], "positionrank": [["licensing strategy", "licensing experiences", "university libraries", "netherlands", "university policies"], ["licensing strategy", "licensing experiences", "university libraries", "netherlands", "university policies", "document servers", "research publications", "national agreements", "major publishers", "new business models"]], "multipartiterank": [["licensing experiences", "netherlands", "university libraries", "information", "scientific"], ["licensing experiences", "netherlands", "university libraries", "information", "scientific", "wide range", "web", "national agreements", "access", "kluwer academic"]]}, {"id": "362", "text": "On batch-constructing B/sup +/-trees: algorithm and its performance evaluation\nEfficient construction of indexes is very important in bulk-loading a database\n\tor adding a new index to an existing database since both of them should\n\thandle an enormous volume of data. In this paper, we propose an\n\talgorithm for batch-constructing the B/sup +/-tree, the most widely\n\tused index structure in database systems. The main characteristic of\n\tour algorithm is to simultaneously process all the key values to be\n\tplaced on each B+-tree page when accessing the page. This avoids the\n\toverhead due to accessing the same page multiple times, which results\n\tfrom applying the B+-tree insertion algorithm repeatedly. For\n\tperformance evaluation, we have analyzed our algorithm in terms of the\n\tnumber of disk accesses. The results show that the number of disk\n\taccesses excluding those in the relocation process is identical to the\n\tnumber of pages belonging to the B/sup +/-tree. Considering that the\n\trelocation process is an unavoidable preprocessing step for\n\tbatch-constructing of B/sup +/-trees, our algorithm requires just one\n\tdisk access per B+-tree page, and therefore turns out to be optimal. We\n\talso present the performance tendency in relation with different\n\tparameter values via simulation. Finally, we show the performance\n\tenhancement effect of our algorithm, compared with the one using\n\trepeated insertions through experiments\n", "keywords": "B+-tree batch construction; algorithm performance evaluation; database bulk\n\tloading; index structure; B+-tree page; page access; B+-tree insertion\n\talgorithm; disk accesses; relocation process; simulation\n", "topicrank": [["algorithm", "performance evaluation", "number", "sup", "database"], ["algorithm", "performance evaluation", "number", "sup", "database", "batch", "disk accesses", "relocation process", "disk", "key values"]], "textrank": [["page multiple", "b+-tree page", "enhancement effect", "relocation process", "main characteristic"], ["page multiple", "b+-tree page", "enhancement effect", "relocation process", "main characteristic", "database systems", "enormous volume", "efficient construction", "page", "disk"]], "positionrank": [["algorithm", "batch", "performance evaluation", "sup", "b"], ["algorithm", "batch", "performance evaluation", "sup", "b", "performance tendency", "database systems", "performance", "disk accesses", "relocation process"]], "multipartiterank": [["algorithm", "performance evaluation", "number", "database", "sup"], ["algorithm", "performance evaluation", "number", "database", "sup", "batch", "disk accesses", "new index", "relocation process", "disk"]]}, {"id": "2090", "text": "All-optical logic NOR gate using two-cascaded semiconductor optical amplifiers\nThe authors present a novel all-optical logic NOR gate using two-cascaded\n\tsemiconductor optical. amplifiers (SOAs) in a counterpropagating\n\tfeedback configuration. This configuration accentuates the gain\n\tnonlinearity due to the mutual gain modulation of the two SOAs. The\n\tall-optical NOR gate feasibility has been demonstrated delivering an\n\textinction ratio higher than 12 dB over a wide range of wavelength\n", "keywords": "all-optical logic NOR gate; two-cascaded semiconductor optical amplifiers; SOA;\n\tcounterpropagating feedback configuration; gain nonlinearity; mutual\n\tgain modulation; extinction ratio; wide wavelength range\n", "topicrank": [["optical logic", "gate", "feedback configuration", "soas", "gain"], ["optical logic", "gate", "feedback configuration", "soas", "gain", "amplifiers", "counterpropagating", "nonlinearity", "novel", "authors"]], "textrank": [["gate feasibility", "feedback configuration", "optical", "ratio", "gain"], ["gate feasibility", "feedback configuration", "optical", "ratio", "gain", "configuration", "gate"]], "positionrank": [["semiconductor optical", "optical logic", "optical amplifiers", "gate feasibility", "gate"], ["semiconductor optical", "optical logic", "optical amplifiers", "gate feasibility", "gate", "semiconductor", "amplifiers", "mutual gain modulation", "feedback configuration", "soas"]], "multipartiterank": [["optical logic", "gate", "feedback configuration", "soas", "gain"], ["optical logic", "gate", "feedback configuration", "soas", "gain", "novel", "amplifiers", "counterpropagating", "authors", "nonlinearity"]]}, {"id": "327", "text": "Using latent semantic analysis to assess reader strategies\nWe tested a computer-based procedure for assessing reader strategies that was\n\tbased on verbal protocols that utilized latent semantic analysis (LSA).\n\tStudents were given self-explanation-reading training (SERT), which\n\tteaches strategies that facilitate self-explanation during reading,\n\tsuch as elaboration based on world knowledge and bridging between text\n\tsentences. During a computerized version of SERT practice, students\n\tread texts and typed self-explanations into a computer after each\n\tsentence. The use of SERT strategies during this practice was assessed\n\tby determining the extent to which students used the information in the\n\tcurrent sentence versus the prior text or world knowledge in their\n\tself-explanations. This assessment was made on the basis of human\n\tjudgments and LSA. Both human judgments and LSA were remarkably similar\n\tand indicated that students who were not complying with SERT tended to\n\tparaphrase the text sentences, whereas students who were compliant with\n\tSERT tended to explain the sentences in terms of what they knew about\n\tthe world and of information provided in the prior text context. The\n\tsimilarity between human judgments and LSA indicates that LSA will be\n\tuseful in accounting for reading strategies in a Web-based version of\n\tSERT\n", "keywords": "latent semantic analysis; reader strategy assessment; computer-based procedure;\n\tverbal protocols; self-explanation-reading training; elaboration; world\n\tknowledge; text sentence bridging; human judgments\n", "topicrank": [["students", "lsa", "self", "sert", "text"], ["students", "lsa", "self", "sert", "text", "human", "reader strategies", "world knowledge", "explanations", "explanation"]], "textrank": [["sert strategies", "human judgments", "current sentence", "computerized version", "world knowledge"], ["sert strategies", "human judgments", "current sentence", "computerized version", "world knowledge", "verbal protocols", "text", "semantic", "sert", "strategies"]], "positionrank": [["latent semantic analysis", "reader strategies", "sert strategies", "strategies", "sert practice"], ["latent semantic analysis", "reader strategies", "sert strategies", "strategies", "sert practice", "verbal protocols", "prior text context", "lsa", "text sentences", "human judgments"]], "multipartiterank": [["students", "self", "lsa", "sert", "text"], ["students", "self", "lsa", "sert", "text", "reader strategies", "human", "world knowledge", "sentences", "sert practice"]]}, {"id": "2028", "text": "Centroid detection based on optical correlation\nWe propose three correlation-based methods to simultaneously detect the\n\tcentroids of multiple objects in an input scene. The first method is\n\tbased on the modulus of the moment function, the second method is based\n\ton squaring the moment function, and the third method works with a\n\tsingle intensity filter. These methods are invariant to changes in the\n\tposition, orientation, and scale of the object and result in good\n\tnoise-smoothing performance. We use spatial light modulators (SLMs) to\n\tdirectly implement the input of the image and filter information for\n\tthe purpose of these approaches. We present results showing simulations\n\tfrom different approaches and provide comparisons between\n\toptical-correlation- and digital-moment-based methods. Experimental\n\tresults corresponding to an optical correlator using SLMs for the\n\tcentroid detection are also presented\n", "keywords": "optical correlation; centroid detection; correlation-based methods; centroids;\n\tmultiple objects; input scene; moment function modulus; moment function\n\tsquaring; single intensity filter; position; orientation; scale;\n\tnoise-smoothing performance; spatial light modulators;\n\tdigital-moment-based methods; optical correlator\n", "topicrank": [["methods", "moment function", "first method", "results", "optical"], ["methods", "moment function", "first method", "results", "optical", "approaches", "slms", "input scene", "correlation-", "digital"]], "textrank": [["intensity filter", "moment function", "input scene", "multiple objects", "centroid detection"], ["intensity filter", "moment function", "input scene", "multiple objects", "centroid detection", "method", "light", "optical", "filter", "moment"]], "positionrank": [["centroid detection", "optical correlation", "optical correlator", "methods", "correlation"], ["centroid detection", "optical correlation", "optical correlator", "methods", "correlation", "moment function", "first method", "second method", "third method", "single intensity filter"]], "multipartiterank": [["methods", "moment function", "first method", "input scene", "results"], ["methods", "moment function", "first method", "input scene", "results", "approaches", "optical", "slms", "optical correlation", "centroid detection"]]}, {"id": "2170", "text": "Evolution of litigation support systems\nFor original paper see ibid., vol. 12, no. 6: \"The E-mail of the Species\". The\n\tauthor responds to that paper and argues that printing, scanning and\n\timaging E-mails or other electronic (rather than paper) documents prior\n\tto listing and disclosure seems to be unnecessary, not 'proportionate'\n\t(from a costs point of view) and not particularly helpful, to either\n\tside. He asks how litigation support systems might evolve to help and\n\tsupport the legal team in their task\n", "keywords": "litigation support systems; E-mail; legal team\n", "topicrank": [["original paper", "litigation support systems", "listing", "disclosure", "documents"], ["original paper", "litigation support systems", "listing", "disclosure", "documents", "printing", "costs point", "scanning", "view", "unnecessary"]], "textrank": [["costs point", "other electronic", "original paper", "-", "."], ["costs point", "other electronic", "original paper", "-", ".", "support", "legal", "paper"]], "positionrank": [["litigation support systems", "original paper", "paper", "vol .", "no ."], ["litigation support systems", "original paper", "paper", "vol .", "no .", "evolution", "e - mail", "ibid", "e", "side"]], "multipartiterank": [["original paper", "litigation support systems", "paper", "ibid", "evolution"], ["original paper", "litigation support systems", "paper", "ibid", "evolution", "listing", "disclosure", "documents", "costs point", "view"]]}, {"id": "2135", "text": "A new approach to the problem of structural identification. II\nThe subject under discussion is a new approach to the problem of structural\n\tidentification, which relies on the recognition of a decisive role of\n\tthe human factor in the process of structural identification. Potential\n\tpossibilities of the suggested approach are illustrated by the\n\tstatement of a new mathematical problem of structural identification\n", "keywords": "structural identification; human factor; mathematical equations; decision-maker\n", "topicrank": [["structural identification", "problem", "new approach", "potential", "structural"], ["structural identification", "problem", "new approach", "potential", "structural", "process", "possibilities", "discussion", "human factor", "subject"]], "textrank": [["new mathematical", "new approach", "structural identification", "approach", "decisive"], ["new mathematical", "new approach", "structural identification", "approach", "decisive", "identification", "structural"]], "positionrank": [["structural identification", "new mathematical problem", "new approach", "suggested approach", "identification"], ["structural identification", "new mathematical problem", "new approach", "suggested approach", "identification", "problem", "human factor", "ii", "subject", "discussion"]], "multipartiterank": [["structural identification", "problem", "new approach", "structural", "discussion"], ["structural identification", "problem", "new approach", "structural", "discussion", "subject", "potential", "process", "identification", "possibilities"]]}, {"id": "282", "text": "Recommendations for implementing Internet inquiry projects\nThe purpose of the study presented was to provide recommendations to teachers\n\twho are interested in implementing Internet inquiry projects. Four\n\tclasses of ninth- and tenth-grade honors students (N = 100)\n\tparticipated in an Internet inquiry project in which they were\n\tpresented with an ecology question that required them to make a\n\tdecision based on information that they gathered, analyzed, and\n\tsynthesized from the Internet and their textbook. Students then\n\tcomposed papers with a rationale for their decision. Students in one\n\tgroup had access to pre-selected relevant Web sites, access to the\n\tentire Internet, and were provided with less online support. Students\n\tin the other group had access to only pre-selected relevant Web sites,\n\tbut were provided with more online support. Two of the most important\n\trecommendations were: 1) to provide students with more online support;\n\tand 2) to provide students with pre-selected relevant Web sites and\n\tallow them to search the Internet for information\n", "keywords": "Internet inquiry projects; teachers; honors students; ecology question;\n\tpre-selected relevant Web sites; online support\n", "topicrank": [["grade honors students", "internet inquiry projects", "access", "recommendations", "decision"], ["grade honors students", "internet inquiry projects", "access", "recommendations", "decision", "selected relevant web sites", "pre", "ninth-", "group", "information"]], "textrank": [["- selected relevant web", "internet inquiry", "other group", "ecology question", "online"], ["- selected relevant web", "internet inquiry", "other group", "ecology question", "online", "honors", "internet", "-", "group"]], "positionrank": [["internet inquiry projects", "internet inquiry project", "entire internet", "recommendations", "internet"], ["internet inquiry projects", "internet inquiry project", "entire internet", "recommendations", "internet", "grade honors students", "more online support", "less online support", "students", "other group"]], "multipartiterank": [["internet inquiry projects", "grade honors students", "recommendations", "students", "tenth"], ["internet inquiry projects", "grade honors students", "recommendations", "students", "tenth", "ninth-", "access", "classes", "interested", "decision"]]}, {"id": "1944", "text": "A framework of electronic tendering for government procurement: a lesson\n\tlearned in Taiwan\nTo render government procurement efficient, transparent, nondiscriminating, and\n\taccountable, an electronic government procurement system is required.\n\tAccordingly, Taiwan government procurement law (TGPL) states that\n\tsuppliers may employ electronic devices to forward a tender. This\n\tinvestigation demonstrates how the electronic government procurement\n\tsystem functions and reengineers internal procurement processes, which\n\tin turn benefits both government bodies and vendors. The system\n\tfeatures explored herein include posting/receiving bids via the\n\tInternet, vendor registration, certificate authorization, contract\n\tdevelopment tools, bid/request for proposal (RFP) development, online\n\tbidding, and online payment, all of which can be integrated easily\n\twithin most existing information infrastructures\n", "keywords": "electronic tendering; electronic government procurement system; Taiwan\n\tgovernment procurement law; reengineering; internal procurement\n\tprocesses; Internet bids; vendor registration; certificate\n\tauthorization; contract development tools; request for proposal\n\tdevelopment; RFP development; online bidding; online payment;\n\tcertification authority; payment gateway; public key infrastructure\n", "topicrank": [["government procurement", "development tools", "system functions", "online", "electronic tendering"], ["government procurement", "development tools", "system functions", "online", "electronic tendering", "request", "proposal", "bid", "certificate authorization", "rfp"]], "textrank": [["electronic government procurement system", "electronic government procurement", "government procurement", "procurement", "government"], ["electronic government procurement system", "electronic government procurement", "government procurement", "procurement", "government", "online payment", "development tools", "certificate authorization", "vendor registration", "turn benefits"]], "positionrank": [["electronic government procurement", "government procurement", "internal procurement processes", "government bodies", "electronic tendering"], ["electronic government procurement", "government procurement", "internal procurement processes", "government bodies", "electronic tendering", "electronic devices", "system functions", "system", "framework", "taiwan"]], "multipartiterank": [["government procurement", "electronic tendering", "development tools", "system functions", "lesson"], ["government procurement", "electronic tendering", "development tools", "system functions", "lesson", "online", "framework", "bid", "contract", "taiwan"]]}, {"id": "207", "text": "Information architecture for bilingual Web sites\nCreating an information architecture for a bilingual Web site presents\n\tparticular challenges beyond those that exist for single and\n\tmultilanguage sites. This article reports work in progress on the\n\tdevelopment of a content-based bilingual Web site to facilitate the\n\tsharing of resources and information between Speech and Language\n\tTherapists. The development of the information architecture is based on\n\ta combination of two aspects: an abstract structural analysis of\n\texisting bilingual Web designs focusing on the presentation of\n\tbilingual material, and a bilingual card-sorting activity conducted\n\twith potential users. Issues for bilingual developments are discussed,\n\tand some observations are made regarding the use of card-sorting\n\tactivities\n", "keywords": "information architecture; content-based bilingual Web site; speech therapists;\n\tlanguage therapists; bilingual card-sorting activity; bilingual\n\tdevelopments; World Wide Web\n", "topicrank": [["information architecture", "bilingual web sites", "development", "bilingual material", "bilingual card"], ["information architecture", "bilingual web sites", "development", "bilingual material", "bilingual card", "speech", "language", "resources", "therapists", "sharing"]], "textrank": [["bilingual web sites", "bilingual web", "bilingual", "potential users", "sorting activity"], ["bilingual web sites", "bilingual web", "bilingual", "potential users", "sorting activity", "particular challenges", "information architecture", "structural", "sites", "sorting"]], "positionrank": [["bilingual web sites", "bilingual web site", "bilingual web designs", "information architecture", "bilingual card"], ["bilingual web sites", "bilingual web site", "bilingual web designs", "information architecture", "bilingual card", "bilingual material", "bilingual developments", "information", "multilanguage sites", "abstract structural analysis"]], "multipartiterank": [["information architecture", "bilingual web sites", "development", "bilingual material", "bilingual web site"], ["information architecture", "bilingual web sites", "development", "bilingual material", "bilingual web site", "bilingual card", "speech", "language", "therapists", "resources"]]}, {"id": "242", "text": "The California Digital Library and the eScholarship program\nThe eScholarship program was launched in 2000 to foster faculty-led innovation\n\tin scholarly publishing. An initiative of the University of California\n\t(UC) and a program of the California Digital Library, the eScholarship\n\tprogram has stimulated significant interest in its short life. Its\n\tmodest but visible accomplishments garner praise from many quarters,\n\twithin and beyond the University of California. In perhaps the best\n\tindication of its timeliness and momentum, there are more proposals\n\tsubmitted to eScholarship today than the CDL can manage. This early\n\tsuccess is due in part to the sheer power of an idea whose time has\n\tcome, but also to the unique approach on which CDL was founded and the\n\teScholarship initiative was first launched\n", "keywords": "eScholarship program; faculty-led innovation; California Digital Library;\n\tscholarly publishing; University of California\n", "topicrank": [["california digital library", "escholarship program", "escholarship", "university", "cdl"], ["california digital library", "escholarship program", "escholarship", "university", "cdl", "due", "visible accomplishments", "success", "praise", "part"]], "textrank": [["many quarters", "visible accomplishments", "short life", "significant interest", "scholarly publishing"], ["many quarters", "visible accomplishments", "short life", "significant interest", "scholarly publishing", "escholarship", "digital", "more"]], "positionrank": [["california digital library", "escholarship program", "escholarship initiative", "escholarship today", "escholarship"], ["california digital library", "escholarship program", "escholarship initiative", "escholarship today", "escholarship", "program", "california", "significant interest", "scholarly publishing", "short life"]], "multipartiterank": [["california digital library", "escholarship program", "escholarship", "program", "university"], ["california digital library", "escholarship program", "escholarship", "program", "university", "california", "cdl", "visible accomplishments", "significant interest", "scholarly publishing"]]}, {"id": "1979", "text": "Combining spatial and scale-space techniques for edge detection to provide a\n\tspatially adaptive wavelet-based noise filtering algorithm\nNew methods for detecting edges in an image using spatial and scale-space\n\tdomains are proposed. A priori knowledge about geometrical\n\tcharacteristics of edges is used to assign a probability factor to the\n\tchance of any pixel being on an edge. An improved double thresholding\n\ttechnique is introduced for spatial domain filtering. Probabilities\n\tthat pixels belong to a given edge are assigned based on pixel\n\tsimilarity across gradient amplitudes, gradient phases and edge\n\tconnectivity. The scale-space approach uses dynamic range compression\n\tto allow wavelet correlation over a wider range of scales. A\n\tprobabilistic formulation is used to combine the results obtained from\n\tfiltering in each domain to provide a final edge probability image\n\twhich has the advantages of both spatial and scale-space domain\n\tmethods. Decomposing this edge probability image with the same wavelet\n\tas the original image permits the generation of adaptive filters that\n\tcan recognize the characteristics of the edges in all wavelet detail\n\tand approximation images regardless of scale. These matched filters\n\tpermit significant reduction in image noise without contributing to\n\tedge distortion. The spatially adaptive wavelet noise-filtering\n\talgorithm is qualitatively and quantitatively compared to a frequency\n\tdomain and two wavelet based noise suppression algorithms using both\n\tnatural and computer generated noisy images\n", "keywords": "spatial techniques; scale-space techniques; edge detection; spatially adaptive\n\twavelet-based noise filtering algorithm; a priori knowledge;\n\tgeometrical characteristics; probability factor; double thresholding\n\ttechnique; spatial domain filtering; pixel similarity; gradient\n\tamplitudes; gradient phases; edge connectivity; dynamic range\n\tcompression; wavelet correlation; probabilistic formulation; final edge\n\tprobability image; adaptive filters; approximation images; matched\n\tfilters; image noise; spatially adaptive wavelet noise-filtering\n\talgorithm; noise suppression\n", "topicrank": [["scale", "edge detection", "adaptive wavelet", "spatial", "space techniques"], ["scale", "edge detection", "adaptive wavelet", "spatial", "space techniques", "edges", "image", "domain", "gradient amplitudes", "new methods"]], "textrank": [["edge probability image", "adaptive wavelet noise", "adaptive wavelet", "space domain", "image noise"], ["edge probability image", "adaptive wavelet noise", "adaptive wavelet", "space domain", "image noise", "noise suppression", "wavelet", "edge", "significant reduction", "probabilistic formulation"]], "positionrank": [["edge probability image", "spatial domain filtering", "adaptive wavelet noise", "space domain", "edge detection"], ["edge probability image", "spatial domain filtering", "adaptive wavelet noise", "space domain", "edge detection", "edge distortion", "adaptive wavelet", "image noise", "space techniques", "edge"]], "multipartiterank": [["scale", "edge detection", "spatial", "space techniques", "adaptive wavelet"], ["scale", "edge detection", "spatial", "space techniques", "adaptive wavelet", "edges", "image", "noise", "new methods", "algorithm"]]}, {"id": "1984", "text": "Deriving model parameters from field test measurements [generator control\n\tsimulation]\nA major component of any power system simulation is the generating plant. The\n\tpurpose of DeriveAssist is to speed up the parameter derivation process\n\tand to allow engineers less versed in parameter matching and\n\tidentification to get involved in the process of power plant electric\n\tgenerator modelling\n", "keywords": "DeriveAssist; parameter derivation process; parameter matching; parameter\n\tidentification; power system simulation; turbine/governor; power system\n\tstability analysis; computer simulation; generator parameter derivation\n\tprocess; steady-state parameters derivation; control simulation\n", "topicrank": [["generator control", "simulation", "parameter derivation process", "field test measurements", "purpose"], ["generator control", "simulation", "parameter derivation process", "field test measurements", "purpose", "power plant electric", "deriveassist", "generating plant", "major component", "parameter matching"]], "textrank": [["power plant", "parameter derivation", "power system", "plant", "generator"], ["power plant", "parameter derivation", "power system", "plant", "generator", "test", "parameter"]], "positionrank": [["field test measurements", "power system simulation", "generator control", "model parameters", "power plant electric"], ["field test measurements", "power system simulation", "generator control", "model parameters", "power plant electric", "generator modelling", "simulation", "major component", "parameter derivation process", "generating plant"]], "multipartiterank": [["simulation", "generator control", "field test measurements", "parameter derivation process", "major component"], ["simulation", "generator control", "field test measurements", "parameter derivation process", "major component", "purpose", "generating plant", "deriveassist", "model parameters", "power system simulation"]]}, {"id": "2108", "text": "Online longitudinal survey research: viability and participation\nThis article explores the viability of conducting longitudinal survey research\n\tusing the Internet in samples exposed to trauma. A questionnaire\n\tbattery assessing psychological adjustment following adverse life\n\texperiences was posted online. Participants who signed up to take part\n\tin the longitudinal aspect of the study were contacted 3 and 6 months\n\tafter initial participation to complete the second and third waves of\n\tthe research. Issues of data screening and sample attrition rates are\n\tconsidered and the demographic profiles and questionnaire scores of\n\tthose who did and did not take part in the study during successive time\n\tpoints are compared. The results demonstrate that it is possible to\n\tconduct repeated measures survey research online and that the\n\tsimilarity in characteristics between those who do and do not take part\n\tduring successive time points mirrors that found in traditional\n\tpencil-and-paper trauma surveys\n", "keywords": "online longitudinal survey research; Internet; trauma; questionnaire;\n\tpsychological adjustment; data screening; sample attrition rates;\n\tdemographic profiles; World Wide Web; psychology research\n", "topicrank": [["online longitudinal survey research", "part", "questionnaire", "successive time", "participation"], ["online longitudinal survey research", "part", "questionnaire", "successive time", "participation", "study", "viability", "trauma", "psychological adjustment", "battery"]], "textrank": [["longitudinal survey", "data screening", "third waves", "initial participation", "adverse life"], ["longitudinal survey", "data screening", "third waves", "initial participation", "adverse life", "psychological adjustment", "survey", "longitudinal", "attrition", "trauma"]], "positionrank": [["longitudinal survey research", "measures survey research", "research", "longitudinal aspect", "initial participation"], ["longitudinal survey research", "measures survey research", "research", "longitudinal aspect", "initial participation", "viability", "participation", "sample attrition rates", "article", "third waves"]], "multipartiterank": [["online longitudinal survey research", "viability", "participation", "questionnaire", "part"], ["online longitudinal survey research", "viability", "participation", "questionnaire", "part", "article", "trauma", "battery", "study", "successive time"]]}, {"id": "2015", "text": "Optical recognition of three-dimensional objects with scale invariance using a\n\tclassical convergent correlator\nWe present a real-time method for recognizing three-dimensional (3-D) objects\n\twith scale invariance. The 3-D information of the objects is codified\n\tin deformed fringe patterns using the Fourier transform profilometry\n\ttechnique and is correlated using a classical convergent correlator.\n\tThe scale invariance property is achieved using two different\n\tapproaches: the Mellin radial harmonic decomposition and the\n\tlogarithmic radial harmonic filter. Thus, the method is invariant for\n\tchanges in the scale of the 3-D target within a defined interval of\n\tscale factors. Experimental results show the utility of the proposed\n\tmethod\n", "keywords": "optical recognition; 3D object recognition; scale invariance; classical\n\tconvergent correlator; real-time method; 3-D information; deformed\n\tfringe patterns; Fourier transform profilometry technique; scale\n\tinvariance property; Mellin radial harmonic decomposition; logarithmic\n\tradial harmonic filter; invariant; scale factors\n", "topicrank": [["scale invariance", "time method", "mellin radial harmonic decomposition", "classical convergent correlator", "dimensional objects"], ["scale invariance", "time method", "mellin radial harmonic decomposition", "classical convergent correlator", "dimensional objects", "invariant", "fourier transform profilometry", "approaches", "changes", "experimental results"]], "textrank": [["radial harmonic", "scale invariance", "dimensional objects", "optical recognition", "transform"], ["radial harmonic", "scale invariance", "dimensional objects", "optical recognition", "transform", "convergent", "scale", "objects", "dimensional", "time"]], "positionrank": [["scale invariance property", "scale invariance", "classical convergent correlator", "optical recognition", "dimensional objects"], ["scale invariance property", "scale invariance", "classical convergent correlator", "optical recognition", "dimensional objects", "scale factors", "scale", "objects", "radial harmonic decomposition", "time method"]], "multipartiterank": [["scale invariance", "dimensional objects", "time method", "classical convergent correlator", "real"], ["scale invariance", "dimensional objects", "time method", "classical convergent correlator", "real", "mellin radial harmonic decomposition", "information", "fourier transform profilometry", "method", "objects"]]}, {"id": "2050", "text": "Who Wants To Be A Millionaire(R): The classroom edition\nThis paper introduces a version of the internationally popular television game\n\tshow Who Wants To Be A Millionaire(R) that has been created for use in\n\tthe classroom using Microsoft PowerPoint(R). A suggested framework for\n\tits classroom use is presented, instructions on operating and editing\n\tthe classroom version of Who Wants To Be A Millionaire(R) are provided,\n\tand sample feedback from students who have played the classroom version\n\tof Who Wants To Be A Millionaire(R) is offered\n", "keywords": "classroom; Who Wants To Be A Millionaire(R); classroom version; undergraduate\n\tbusiness students; student contestants\n", "topicrank": [["version", "use", "classroom edition", "popular television game", "show"], ["version", "use", "classroom edition", "popular television game", "show", "paper", "students", "sample feedback", "framework", "instructions"]], "textrank": [["microsoft powerpoint(r", "classroom", "television", "sample"], ["microsoft powerpoint(r", "classroom", "television", "sample"]], "positionrank": [["classroom version", "classroom use", "classroom edition", "classroom", "popular television game"], ["classroom version", "classroom use", "classroom edition", "classroom", "popular television game", "millionaire(r", "version", "sample feedback", "microsoft powerpoint(r", "paper"]], "multipartiterank": [["version", "classroom edition", "paper", "popular television game", "use"], ["version", "classroom edition", "paper", "popular television game", "use", "show", "classroom version", "classroom", "framework", "instructions"]]}, {"id": "35", "text": "Fusion of qualitative bond graph and genetic algorithms: A fault diagnosis\n\tapplication\nIn this paper, the problem of fault diagnosis via integration of genetic\n\talgorithms (GA's) and qualitative bond graphs (QBG's) is addressed. We\n\tsuggest that GA's can be used to search for possible fault components\n\tamong a system of qualitative equations. The QBG is adopted as the\n\tmodeling scheme to generate a set of qualitative equations. The\n\tqualitative bond graph provides a unified approach for modeling\n\tengineering systems, in particular, mechatronic systems. In order to\n\tdemonstrate the performance of the proposed algorithm, we have tested\n\tthe proposed algorithm on an in-house designed and built floating disc\n\texperimental setup. Results from fault diagnosis in the floating disc\n\tsystem are presented and discussed. Additional measurements will be\n\trequired to localize the fault when more than one fault candidate is\n\tinferred. Fault diagnosis is activated by a fault detection mechanism\n\twhen a discrepancy between measured abnormal behavior and predicted\n\tsystem behavior is observed. The fault detection mechanism is not\n\tpresented here\n", "keywords": "qualitative bond graph; genetic algorithms; fault diagnosis; fault components;\n\tqualitative equations; engineering systems; mechatronic systems;\n\tfloating disc; measured abnormal behavior; predicted system behavior\n", "topicrank": [["fault diagnosis", "qualitative bond graph", "system", "qualitative equations", "engineering systems"], ["fault diagnosis", "qualitative bond graph", "system", "qualitative equations", "engineering systems", "genetic algorithms", "disc", "qbg", "algorithm", "experimental setup"]], "textrank": [["fault detection", "qualitative bond", "fault", "abnormal behavior", "proposed algorithm"], ["fault detection", "qualitative bond", "fault", "abnormal behavior", "proposed algorithm", "unified approach", "modeling scheme", "genetic algorithms", "systems", "behavior"]], "positionrank": [["qualitative bond graph", "qualitative bond graphs", "fault diagnosis", "qualitative equations", "fault detection mechanism"], ["qualitative bond graph", "qualitative bond graphs", "fault diagnosis", "qualitative equations", "fault detection mechanism", "possible fault components", "genetic algorithms", "fault candidate", "fault", "fusion"]], "multipartiterank": [["fault diagnosis", "qualitative bond graph", "genetic algorithms", "system", "qualitative equations"], ["fault diagnosis", "qualitative bond graph", "genetic algorithms", "system", "qualitative equations", "engineering systems", "disc", "qbg", "algorithm", "particular"]]}, {"id": "2169", "text": "E-government\nThe author provides an introduction to the main issues surrounding E-government\n\tmodernisation and electronic delivery of all public services by 2005.\n\tThe author makes it clear that E-government is about transformation,\n\tnot computers and hints at the special legal issues which may arise\n", "keywords": "E-government; modernisation; electronic delivery; public services; legal issues\n", "topicrank": [["author", "electronic delivery", "hints", "computers", "modernisation"], ["author", "electronic delivery", "hints", "computers", "modernisation", "public services", "introduction", "main issues", "clear", "transformation"]], "textrank": [["legal issues", "electronic delivery", "-", "issues"], ["legal issues", "electronic delivery", "-", "issues"]], "positionrank": [["e - government", "main issues", "special legal issues", "electronic delivery", "author"], ["e - government", "main issues", "special legal issues", "electronic delivery", "author", "public services", "introduction", "modernisation", "computers", "transformation"]], "multipartiterank": [["author", "electronic delivery", "hints", "computers", "modernisation"], ["author", "electronic delivery", "hints", "computers", "modernisation", "public services", "introduction", "main issues", "clear", "transformation"]]}, {"id": "2194", "text": "Data management in location-dependent information services\nLocation-dependent information services have great promise for mobile and\n\tpervasive computing environments. They can provide local and nonlocal\n\tnews, weather, and traffic reports as well as directory services.\n\tBefore they can be implemented on a large scale, however, several\n\tresearch issues must be addressed\n", "keywords": "location-dependent information services; wireless networks; pervasive\n\tcomputing; mobile computing; news; weather; traffic reports; data\n\tmanagement; directory services\n", "topicrank": [["dependent information services", "location", "news", "nonlocal", "great promise"], ["dependent information services", "location", "news", "nonlocal", "great promise", "weather", "local", "mobile", "pervasive computing environments", "traffic reports"]], "textrank": [["information services", "great promise", "data management", "computing", "services"], ["information services", "great promise", "data management", "computing", "services"]], "positionrank": [["dependent information services", "data management", "directory services", "location", "great promise"], ["dependent information services", "data management", "directory services", "location", "great promise", "pervasive computing environments", "mobile", "traffic reports", "weather", "news"]], "multipartiterank": [["dependent information services", "location", "news", "nonlocal", "great promise"], ["dependent information services", "location", "news", "nonlocal", "great promise", "weather", "local", "mobile", "pervasive computing environments", "traffic reports"]]}, {"id": "223", "text": "Broadcasts keep staff in picture [intranets]\nMark Hawkins, chief operating officer at UK-based streaming media specialist\n\tTwofourtv, explains how firms can benefit by linking their corporate\n\tintranets to broadcasting technology\n", "keywords": "corporate intranets; Twofourtv; streaming media; broadcasting technology\n", "topicrank": [["intranets", "picture", "staff", "mark hawkins", "chief operating officer"], ["intranets", "picture", "staff", "mark hawkins", "chief operating officer", "streaming media specialist", "twofourtv", "corporate", "broadcasts", "broadcasting technology"]], "textrank": [["mark hawkins", "media", "operating", "broadcasting"], ["mark hawkins", "media", "operating", "broadcasting"]], "positionrank": [["chief operating officer", "mark hawkins", "streaming media specialist", "intranets", "broadcasts"], ["chief operating officer", "mark hawkins", "streaming media specialist", "intranets", "broadcasts", "picture", "staff", "uk", "broadcasting technology", "firms"]], "multipartiterank": [["intranets", "picture", "staff", "mark hawkins", "chief operating officer"], ["intranets", "picture", "staff", "mark hawkins", "chief operating officer", "streaming media specialist", "twofourtv", "corporate", "broadcasts", "broadcasting technology"]]}, {"id": "266", "text": "Pattern recognition strategies for molecular surfaces. I. Pattern generation\n\tusing fuzzy set theory\nA new method for the characterization of molecules based on the model approach\n\tof molecular surfaces is presented. We use the topographical properties\n\tof the surface as well as the electrostatic potential, the local\n\tlipophilicity/hydrophilicity, and the hydrogen bond density on the\n\tsurface for characterization. The definition and the calculation method\n\tfor these properties are reviewed. The surface is segmented into\n\toverlapping patches with similar molecular properties. These patches\n\tcan be used to represent the characteristic local features of the\n\tmolecule in a way that is beyond the atomistic resolution but can\n\tnevertheless be applied for the analysis of partial similarities of\n\tdifferent molecules as well as for the identification of molecular\n\tcomplementarity in a very general sense. The patch representation can\n\tbe used for different applications, which will be demonstrated in\n\tsubsequent articles\n", "keywords": "pattern recognition strategies; molecular surfaces; pattern generation; fuzzy\n\tset theory; model approach; topographical properties; electrostatic\n\tpotential; local lipophilicity/hydrophilicity; hydrogen bond density;\n\tsegmented surface; overlapping patches; molecular properties; local\n\tfeatures; atomistic resolution; partial similarities; molecular\n\tcomplementarity; patch representation; lipophilicity; hydrophilicity\n", "topicrank": [["molecular surfaces", "surface", "characterization", "local", "new method"], ["molecular surfaces", "surface", "characterization", "local", "new method", "molecules", "topographical properties", "patches", "lipophilicity", "hydrophilicity"]], "textrank": [["molecular properties", "pattern recognition", "atomistic resolution", "electrostatic potential", "model approach"], ["molecular properties", "pattern recognition", "atomistic resolution", "electrostatic potential", "model approach", "pattern", "molecular", "different", "bond", "local"]], "positionrank": [["i. pattern generation", "pattern recognition strategies", "molecular surfaces", "similar molecular properties", "fuzzy set theory"], ["i. pattern generation", "pattern recognition strategies", "molecular surfaces", "similar molecular properties", "fuzzy set theory", "new method", "different molecules", "calculation method", "topographical properties", "characterization"]], "multipartiterank": [["molecular surfaces", "surface", "characterization", "new method", "molecules"], ["molecular surfaces", "surface", "characterization", "new method", "molecules", "local", "topographical properties", "lipophilicity", "model approach", "patches"]]}, {"id": "413", "text": "Effects of white space in learning via the Web\nThis study measured the effect of specific white space features on learning\n\tfrom instructional Web materials. The study also measured learners'\n\tbeliefs regarding Web-based instruction. Prior research indicated that\n\tsmall changes in the handling of presentation elements can affect\n\tlearning. Achievement results from this study indicated that in on-line\n\tmaterials, when content and overall structure are sound, minor\n\tdifferences regarding table borders and vertical spacing in text do not\n\thinder learning. Beliefs regarding Web-based instruction and\n\tinstructors who use it did not differ significantly between treatment\n\tgroups. Implications of the study and cautions regarding generalizing\n\tfrom the results are discussed\n", "keywords": "white space features; Web-based instruction; presentation; online educational\n\tmaterials; table borders; text vertical spacing; Internet\n", "topicrank": [["study", "web", "beliefs", "learning", "instruction"], ["study", "web", "beliefs", "learning", "instruction", "instructional web materials", "white space", "overall structure", "minor", "table borders"]], "textrank": [["white space", "overall structure", "presentation elements", "small changes", "prior research"], ["white space", "overall structure", "presentation elements", "small changes", "prior research", "web", "table", "learning"]], "positionrank": [["instructional web materials", "white space", "web", "study", "effects"], ["instructional web materials", "white space", "web", "study", "effects", "materials", "hinder learning", "beliefs", "prior research", "effect"]], "multipartiterank": [["study", "web", "white space", "beliefs", "learning"], ["study", "web", "white space", "beliefs", "learning", "instructional web materials", "instruction", "overall structure", "minor", "sound"]]}, {"id": "2089", "text": "World's biggest battery helps to stabilise Alaska\nIn this paper, the author describes a battery energy storage system which is\n\tunder construction to provide voltage compensation in support of\n\tAlaska's 138 kV Northern Intertie\n", "keywords": "power system stabilisation; battery energy storage system; voltage\n\tcompensation; USA; interconnected power systems; 138 kV; 77 MW\n", "topicrank": [["alaska", "voltage compensation", "support", "author", "battery energy storage system"], ["alaska", "voltage compensation", "support", "author", "battery energy storage system", "biggest battery", "paper", "construction", "world", "kv northern intertie"]], "textrank": [["battery energy storage", "northern", "battery", "voltage"], ["battery energy storage", "northern", "battery", "voltage"]], "positionrank": [["biggest battery", "alaska", "world", "kv northern intertie", "voltage compensation"], ["biggest battery", "alaska", "world", "kv northern intertie", "voltage compensation", "paper", "construction", "author", "support"]], "multipartiterank": [["alaska", "voltage compensation", "support", "author", "battery energy storage system"], ["alaska", "voltage compensation", "support", "author", "battery energy storage system", "biggest battery", "paper", "construction", "world", "kv northern intertie"]]}, {"id": "2031", "text": "Efficient two-level image thresholding method based on Bayesian formulation and\n\tthe maximum entropy principle\nAn efficient method for two-level thresholding is proposed based on the Bayes\n\tformula and the maximum entropy principle, in which no assumptions of\n\tthe image histogram are made. An alternative criterion is derived based\n\ton maximizing entropy and used for speeding up the searching algorithm.\n\tFive forms of conditional probability distributions-simple, linear,\n\tparabola concave, parabola convex, and S-function-are employed and\n\tcompared to each other for optimal threshold determination. The effect\n\tof precision on optimal threshold determination is discussed and a\n\ttrade-off precision epsilon =0.001 is selected experimentally. Our\n\texperiments demonstrate that the proposed method achieves a significant\n\timprovement in speed from 26 to 57 times faster than the exhaustive\n\tsearch method\n", "keywords": "two-level image thresholding method; Bayesian formulation; maximum entropy\n\tprinciple; image histogram; entropy; searching algorithm; conditional\n\tprobability distributions; parabola concave; parabola convex;\n\tS-function; optimal threshold determination; trade-off precision; image\n\tsegmentation; image thresholding\n", "topicrank": [["maximum entropy principle", "precision", "optimal threshold determination", "parabola concave", "method"], ["maximum entropy principle", "precision", "optimal threshold determination", "parabola concave", "method", "level image thresholding method", "conditional probability distributions", "efficient", "simple", "linear"]], "textrank": [["level image thresholding method", "level thresholding", "precision epsilon", "alternative criterion", "bayesian formulation"], ["level image thresholding method", "level thresholding", "precision epsilon", "alternative criterion", "bayesian formulation", "method", "threshold", "parabola", "probability", "entropy"]], "positionrank": [["efficient method", "maximum entropy principle", "level thresholding", "search method", "method"], ["efficient method", "maximum entropy principle", "level thresholding", "search method", "method", "bayesian formulation", "image histogram", "alternative criterion", "bayes", "formula"]], "multipartiterank": [["efficient", "maximum entropy principle", "level image thresholding method", "optimal threshold determination", "precision"], ["efficient", "maximum entropy principle", "level image thresholding method", "optimal threshold determination", "precision", "parabola concave", "method", "conditional probability distributions", "simple", "linear"]]}, {"id": "386", "text": "Matched-filter template generation via spatial filtering: application to fetal\n\tbiomagnetic recordings\nWe have developed a two-step procedure for signal processing of fetal\n\tbiomagnetic recordings that removes cardiac interference and noise.\n\tFirst, a modified matched filter (MF) is applied to remove maternal\n\tcardiac interference; then, a simple signal space projection (SSP) is\n\tapplied to remove noise. The key difference between our MF and a\n\tconventional one is that the interference template and the template\n\tscaling are derived from a signal that has been spatially filtered to\n\tisolate the interference, rather than from the raw signal. Unlike\n\tconventional MFs, ours is able to separate maternal and fetal cardiac\n\tcomplexes, even when they have similar morphology and overlap strongly.\n\tWhen followed by a SSP that preserves only the signal subspace, the\n\tnoise is reduced to a low level\n", "keywords": "maternal cardiac interference removal; simple signal space projection; noise\n\tremoval; signal subspace preservation; fetal magnetocardiography;\n\tspatial filtering; interference template; raw signal; template scaling;\n\tmodified matched filter; maternal cardiac interference\n", "topicrank": [["fetal", "signal processing", "cardiac interference", "noise", "biomagnetic recordings"], ["fetal", "signal processing", "cardiac interference", "noise", "biomagnetic recordings", "maternal", "ssp", "conventional", "interference template", "filter template generation"]], "textrank": [["signal space", "interference template", "signal", "cardiac interference", "step procedure"], ["signal space", "interference template", "signal", "cardiac interference", "step procedure", "biomagnetic recordings", "spatial filtering", "template", "cardiac", "interference"]], "positionrank": [["filter template generation", "interference template", "biomagnetic recordings", "cardiac interference", "signal processing"], ["filter template generation", "interference template", "biomagnetic recordings", "cardiac interference", "signal processing", "spatial filtering", "raw signal", "signal subspace", "signal", "template"]], "multipartiterank": [["fetal", "signal processing", "biomagnetic recordings", "cardiac interference", "noise"], ["fetal", "signal processing", "biomagnetic recordings", "cardiac interference", "noise", "filter template generation", "spatial filtering", "maternal", "application", "step procedure"]]}, {"id": "2049", "text": "The maximum possible EVPI\nIn this paper we calculate the maximum expected value of perfect information\n\t(EVPI) for any probability distribution for the states of the world.\n\tThis maximum EVPI is an upper bound for the EVPI with given\n\tprobabilities and thus an upper bound for any partial information about\n\tthe states of the world\n", "keywords": "decision analysis; expected value of perfect information; operations research;\n\tmanagement science; probability distribution; optimisation\n", "topicrank": [["maximum possible evpi", "perfect information", "upper bound", "states", "world"], ["maximum possible evpi", "perfect information", "upper bound", "states", "world", "value", "probability distribution", "probabilities", "paper"]], "textrank": [["maximum possible evpi", "maximum evpi", "information", "evpi", "maximum"], ["maximum possible evpi", "maximum evpi", "information", "evpi", "maximum"]], "positionrank": [["maximum possible evpi", "maximum evpi", "evpi", "upper bound", "perfect information"], ["maximum possible evpi", "maximum evpi", "evpi", "upper bound", "perfect information", "partial information", "probability distribution", "states", "paper", "world"]], "multipartiterank": [["maximum possible evpi", "perfect information", "paper", "value", "upper bound"], ["maximum possible evpi", "perfect information", "paper", "value", "upper bound", "states", "world", "evpi", "probability distribution", "maximum"]]}, {"id": "346", "text": "Baseball, optimization, and the World Wide Web\nThe competition for baseball play-off spots-the fabled pennant race-is one of\n\tthe most closely watched American sports traditions. While play-off\n\trace statistics, such as games back and magic number, are informative,\n\tthey are overly conservative and do not account for the remaining\n\tschedule of games. Using optimization techniques, one can model\n\tschedule effects explicitly and determine precisely when a team has\n\tsecured a play-off spot or has been eliminated from contention. The\n\tRIOT Baseball Play-off Races Web site developed at the University of\n\tCalifornia, Berkeley, provides automatic updates of new,\n\toptimization-based play-off race statistics each day of the major\n\tleague baseball season. In developing the site, we found that we could\n\tdetermine the first-place elimination status of all teams in a division\n\tusing a single linear-programming formulation, since a minimum win\n\tthreshold for teams finishing in first place applies to all teams in a\n\tdivision. We identified a similar (but weaker) result for the problem\n\tof play-off elimination with wildcard teams\n", "keywords": "baseball play-off spot competition; optimization; World Wide Web; pennant race;\n\tplay-off race statistics; games back; magic number; game schedule; RIOT\n\tBaseball Play-off Races Web site; linear programming; LP; minimum win\n\tthreshold\n", "topicrank": [["baseball", "teams", "optimization", "race statistics", "place elimination status"], ["baseball", "teams", "optimization", "race statistics", "place elimination status", "first", "games", "races web site", "division", "schedule"]], "textrank": [["wide web", "place elimination", "pennant race", "baseball", "automatic updates"], ["wide web", "place elimination", "pennant race", "baseball", "automatic updates", "schedule effects", "optimization techniques", "magic number", "web", "sports"]], "positionrank": [["riot baseball play", "baseball play", "league baseball season", "baseball", "world wide web"], ["riot baseball play", "baseball play", "league baseball season", "baseball", "world wide web", "races web site", "fabled pennant race", "race statistics", "play", "optimization techniques"]], "multipartiterank": [["baseball", "optimization", "teams", "play", "world wide web"], ["baseball", "optimization", "teams", "play", "world wide web", "race statistics", "games", "first", "competition", "place elimination status"]]}, {"id": "303", "text": "Visual-word identification thresholds for the 260 fragmented words of the\n\tSnodgrass and Vanderwart pictures in Spanish\nWord difficulty varies from language to language; therefore, normative data of\n\tverbal stimuli cannot be imported directly from another language. We\n\tpresent mean identification thresholds for the 260 screen-fragmented\n\twords corresponding to the total set of Snodgrass and Vanderwart (1980)\n\tpictures. Individual words were fragmented in eight levels using Turbo\n\tPascal, and the resulting program was implemented on a PC\n\tmicrocomputer. The words were presented individually to a group of 40\n\tSpanish observers, using a controlled time procedure. An unspecific\n\tlearning effect was found showing that performance improved due to\n\tpractice with the task. Finally, of the 11 psycholinguistic variables\n\tthat previous researchers have shown to affect word identification,\n\tonly imagery accounted for a significant amount of variance in the\n\tthreshold values\n", "keywords": "visual-word identification thresholds; fragmented words; Snodgrass and\n\tVanderwart pictures; Spanish; word difficulty; verbal stimuli; mean\n\tidentification thresholds; screen-fragmented words; Turbo Pascal; PC\n\tmicrocomputer; controlled time procedure; unspecific learning effect;\n\tpsycholinguistic variables; word identification\n", "topicrank": [["words", "word identification thresholds", "language", "vanderwart pictures", "snodgrass"], ["words", "word identification thresholds", "language", "vanderwart pictures", "snodgrass", "spanish", "turbo", "due", "word difficulty", "performance"]], "textrank": [["mean identification", "word identification", "spanish observers", "individual words", "total set"], ["mean identification", "word identification", "spanish observers", "individual words", "total set", "verbal stimuli", "normative data", "vanderwart pictures", "word", "pictures"]], "positionrank": [["word identification thresholds", "word identification", "word difficulty", "individual words", "words"], ["word identification thresholds", "word identification", "word difficulty", "individual words", "words", "vanderwart pictures", "language", "vanderwart", "snodgrass", "spanish observers"]], "multipartiterank": [["words", "word identification thresholds", "language", "vanderwart pictures", "snodgrass"], ["words", "word identification thresholds", "language", "vanderwart pictures", "snodgrass", "spanish", "word difficulty", "visual", "total set", "normative data"]]}, {"id": "1960", "text": "Streaming, disruptive interference and power-law behavior in the exit dynamics\n\tof confined pedestrians\nWe analyze the exit dynamics of pedestrians who are initially confined in a\n\troom. Pedestrians are modeled as cellular automata and compete to\n\tescape via a known exit at the soonest possible time. A pedestrian\n\tcould move forward, backward, left or right within each iteration time\n\tdepending on adjacent cell vacancy and in accordance with simple rules\n\tthat determine the compulsion to move and physical capability relative\n\tto his neighbors. The arching signatures of jamming were observed and\n\tthe pedestrians exited in bursts of various sizes. Power-law behavior\n\tis found in the burst-size frequency distribution for exit widths w\n\tgreater than one cell dimension (w > 1). The slope of the power-law\n\tcurve varies with w from -1.3092 (w = 2) to -1.0720 (w = 20). Streaming\n\twhich is a diffusive behavior, arises in large burst sizes and is more\n\tlikely in a single-exit room with w = 1 and leads to a counterintuitive\n\tresult wherein an average exit throughput Q is obtained that is higher\n\tthan with w = 2, 3, or 4. For a two-exit room (w = 1), Q is not greater\n\tthan twice the yield of a single-exit room. If the doors are not\n\tseparated far enough (< 4w), Q becomes even significantly less due\n\tto a collective slow-down that emerges among pedestrians crossing in\n\teach other's path (disruptive interference effect). For the same w and\n\tdoor number, Q is also higher with relaxed pedestrians than with\n\tanxious ones\n", "keywords": "streaming; cellular automata; iteration time; adjacent cell vacancy; arching\n\tsignatures; jamming; burst-size frequency distribution; collective\n\tslow-down; self-organised criticality; disruptive interference;\n\tpower-law behavior; exit dynamics; confined pedestrians\n", "topicrank": [["pedestrians", "exit dynamics", "power", "law behavior", "room"], ["pedestrians", "exit dynamics", "power", "law behavior", "room", "single", "burst", "disruptive interference", "greater", "streaming"]], "textrank": [["exit throughput", "exit", "burst sizes", "possible time", "relaxed pedestrians"], ["exit throughput", "exit", "burst sizes", "possible time", "relaxed pedestrians", "door number", "curve varies", "simple rules", "cellular automata", "cell"]], "positionrank": [["law behavior", "disruptive interference effect", "disruptive interference", "exit dynamics", "exit room"], ["law behavior", "disruptive interference effect", "disruptive interference", "exit dynamics", "exit room", "exit widths", "same w", "streaming", "diffusive behavior", "w >"]], "multipartiterank": [["pedestrians", "exit dynamics", "power", "law behavior", "room"], ["pedestrians", "exit dynamics", "power", "law behavior", "room", "disruptive interference", "burst", "streaming", "exit room", "greater"]]}, {"id": "2154", "text": "Optimize/sup IT/ robot condition monitoring tool\nAs robots have gained more and more 'humanlike' capability, users have looked\n\tincreasingly to their builders for ways to measure the critical\n\tvariables-the robotic equivalent of a physical check-up-in order to\n\tmonitor their condition and schedule maintenance more effectively. This\n\tis all the more essential considering the tremendous pressure there is\n\tto improve productivity in today's global markets. Developed for ABB\n\trobots with an S4-family controller and based on the company's broad\n\tprocess know-how, Optimize/sup IT/ robot condition monitoring offers\n\tmaintenance routines with embedded checklists that give a clear\n\tindication of a robot's operating condition. It performs semi-automatic\n\tmeasurements that support engineers during trouble-shooting and enable\n\taction to be taken to prevent unplanned stops. By comparing these\n\tmeasurements with reference data, negative trends can be detected early\n\tand potential breakdowns predicted. Armed with all these features,\n\tOptimize/sup IT/ robot condition monitoring provides the ideal basis\n\tfor reliability-centered maintenance (RCM) for robots\n", "keywords": "Optimize/sup IT/ robot condition monitoring tool; maintenance scheduling;\n\tcondition monitoring; ABB robots; S4-family controller; semi-automatic\n\tmeasurements; reliability-centered maintenance\n", "topicrank": [["robot condition monitoring tool", "sup", "schedule maintenance", "optimize", "robots"], ["robot condition monitoring tool", "sup", "schedule maintenance", "optimize", "robots", "condition", "measurements", "broad", "trouble", "today"]], "textrank": [["process know -", "physical check -", "condition monitoring", "reference data", "unplanned stops"], ["process know -", "physical check -", "condition monitoring", "reference data", "unplanned stops", "s4-family controller", "global markets", "tremendous pressure", "robotic equivalent", "condition"]], "positionrank": [["robot condition monitoring", "optimize", "operating condition", "condition", "robot"], ["robot condition monitoring", "optimize", "operating condition", "condition", "robot", "sup", "maintenance routines", "schedule maintenance", "robots", "process know"]], "multipartiterank": [["robot condition monitoring tool", "sup", "schedule maintenance", "robots", "optimize"], ["robot condition monitoring tool", "sup", "schedule maintenance", "robots", "optimize", "condition", "robot condition monitoring", "measurements", "capability", "variables"]]}, {"id": "2111", "text": "Extended depth-of-focus imaging of chlorophyll fluorescence from intact leaves\nImaging dynamic changes in chlorophyll a fluorescence provides a valuable means\n\twith which to examine localised changes in photosynthetic function.\n\tMicroscope-based systems provide excellent spatial resolution which\n\tallows the response of individual cells to be measured. However, such\n\tsystems have a restricted depth of focus and, as leaves are inherently\n\tuneven, only a small proportion of each image at any given focal plane\n\tis in focus. In this report we describe the development of algorithms,\n\tspecifically adapted for imaging chlorophyll fluorescence and\n\tphotosynthetic function in living plant cells, which allow\n\textended-focus images to be reconstructed from images taken in\n\tdifferent focal planes. We describe how these procedures can be used to\n\treconstruct images of chlorophyll fluorescence and calculated\n\tphotosynthetic parameters, as well as producing a map of leaf topology.\n\tThe robustness of this procedure is demonstrated using leaves from a\n\tnumber of different plant species\n", "keywords": "chlorophyll fluorescence; intact leaves; extended depth-of-focus imaging; leaf\n\ttopology map; plant species; calculated photosynthetic parameters;\n\tindividual cells response; microscope-based systems; charge-coupled\n\tdevice; maximum fluorescence yield; minimum fluorescence yield;\n\tvariable fluorescence; numerical aperture; primary quinone acceptor;\n\tspatial resolution; algorithms development; extended-focus images\n\treconstruction; biophysical research technique\n", "topicrank": [["chlorophyll fluorescence", "focus imaging", "photosynthetic function", "intact leaves", "dynamic changes"], ["chlorophyll fluorescence", "focus imaging", "photosynthetic function", "intact leaves", "dynamic changes", "systems", "images", "extended depth", "excellent spatial resolution", "fluorescence"]], "textrank": [["plant cells", "different plant", "different focal", "focus images", "intact leaves"], ["plant cells", "different plant", "different focal", "focus images", "intact leaves", "chlorophyll fluorescence", "extended depth", "focal", "spatial", "photosynthetic"]], "positionrank": [["chlorophyll fluorescence", "extended depth", "focus images", "focus imaging", "living plant cells"], ["chlorophyll fluorescence", "extended depth", "focus images", "focus imaging", "living plant cells", "chlorophyll", "fluorescence", "intact leaves", "focus", "photosynthetic function"]], "multipartiterank": [["chlorophyll fluorescence", "focus imaging", "extended depth", "intact leaves", "photosynthetic function"], ["chlorophyll fluorescence", "focus imaging", "extended depth", "intact leaves", "photosynthetic function", "dynamic changes", "systems", "images", "chlorophyll", "fluorescence"]]}, {"id": "344", "text": "Student consulting projects benefit faculty and industry\nStudent consulting projects require students to apply OR/MS tools to obtain\n\tinsight into the activities of firms in the community. These projects\n\tbenefit faculty by providing clear feedback on the real capabilities of\n\tstudents, a broad connection to local industry, and material for case\n\tstudies and research. They benefit companies by stimulating new\n\tthinking regarding their activities and delivering results they can\n\tuse. Projects provide insights into the end-user modeling mode of OR/MS\n\tpractice. Projects support continuous improvement as the lessons gained\n\tfrom a crop of projects enable better teaching during the next course\n\toffering, which in turn leads to better projects and further insights\n\tinto teaching\n", "keywords": "student consulting projects; OR/MS tools; student placements; student\n\tcapability feedback; case study material\n", "topicrank": [["projects", "activities", "industry", "students", "student consulting projects benefit faculty"], ["projects", "activities", "industry", "students", "student consulting projects benefit faculty", "better teaching", "case", "studies", "material", "research"]], "textrank": [["consulting projects benefit", "better projects", "consulting projects", "local industry", "broad connection"], ["consulting projects benefit", "better projects", "consulting projects", "local industry", "broad connection", "real capabilities", "clear feedback", "ms tools", "projects", "modeling"]], "positionrank": [["student consulting projects", "better projects", "projects", "benefit faculty", "local industry"], ["student consulting projects", "better projects", "projects", "benefit faculty", "local industry", "ms tools", "industry", "user modeling mode", "students", "or"]], "multipartiterank": [["projects", "student consulting projects benefit faculty", "industry", "activities", "students"], ["projects", "student consulting projects benefit faculty", "industry", "activities", "students", "better teaching", "studies", "case", "material", "benefit faculty"]]}, {"id": "301", "text": "Academic libraries and community: making the connection\nI explore the theme of academic libraries serving and reaching out to the\n\tbroader community. I highlight interesting projects reported on in the\n\tliterature (such as the Through Our Parents' Eyes project) and report\n\ton others. I look at challenges to community partnerships and\n\trecommendations for making them succeed. Although I focus on links with\n\tthe broader community, I also took at methods for increasing\n\tcooperation among various units on campus, so that the needs of campus\n\tcommunity groups-such as distance education students or disabled\n\tstudents-are effectively addressed. Though academic libraries are my\n\tfocus, we can learn a lot from the community building efforts of public\n\tlibraries\n", "keywords": "academic libraries; community partnerships; campus community groups; distance\n\teducation students; disabled students; public libraries\n", "topicrank": [["community", "academic libraries", "campus", "distance education students", "various units"], ["community", "academic libraries", "campus", "distance education students", "various units", "disabled", "efforts", "needs", "cooperation", "public"]], "textrank": [["various units", "eyes project", "interesting projects", "academic libraries", "community"], ["various units", "eyes project", "interesting projects", "academic libraries", "community", "education", "libraries"]], "positionrank": [["academic libraries", "broader community", "community groups", "community partnerships", "community"], ["academic libraries", "broader community", "community groups", "community partnerships", "community", "libraries", "distance education students", "connection", "students", "interesting projects"]], "multipartiterank": [["community", "academic libraries", "campus", "distance education students", "efforts"], ["community", "academic libraries", "campus", "distance education students", "efforts", "public", "disabled", "broader community", "theme", "lot"]]}, {"id": "2156", "text": "Pane relief. Robotic solutions for car windshield assembly\nJust looking through a car's windshield doesn't give us much reason to wonder\n\tabout how it's made. The idea that special manufacturing expertise\n\tmight be required can hardly occur to anyone, but that's exactly what\n\tis needed to ensure crystal-clear visibility, not to mention a perfect\n\tfit every time one is pressed into place on a car production line.\n\tComprising two thin glass sheets joined by a vinyl interlayer,\n\twindshields are assembled-usually manually-to very precise product and\n\tenvironmental specifications. To make sure this is done as perfectly as\n\tpossible, the industry invests heavily in the equipment used for their\n\tfabrication. ABB has now developed a robot-based Compact Assembling\n\tSystem for the automatic assembly of laminated windshields that speeds\n\tup production and increases cost efficiency\n", "keywords": "car windshield assembly robots; manufacturing expertise; car production line;\n\tCompact Assembling System; laminated windshields assembly automation;\n\tproduction; cost efficiency; ABB\n", "topicrank": [["windshields", "car production line", "car windshield", "abb", "fabrication"], ["windshields", "car production line", "car windshield", "abb", "fabrication", "compact", "system", "automatic assembly", "robot", "robotic solutions"]], "textrank": [["car production", "time one", "clear visibility", "much reason", "robotic solutions"], ["car production", "time one", "clear visibility", "much reason", "robotic solutions", "pane relief", "glass", "manufacturing", "production", "car"]], "positionrank": [["car windshield", "pane relief", "car production line", "robotic solutions", "car"], ["car windshield", "pane relief", "car production line", "robotic solutions", "car", "windshield", "thin glass sheets", "much reason", "time one", "production"]], "multipartiterank": [["car windshield", "car production line", "windshields", "robotic solutions", "place"], ["car windshield", "car production line", "windshields", "robotic solutions", "place", "abb", "fabrication", "time one", "compact", "system"]]}, {"id": "2113", "text": "Ideal sliding mode in the problems of convex optimization\nThe characteristics of the sliding mode that appears with using continuous\n\tconvex-programming algorithms based on the exact penalty functions were\n\tdiscussed. For the case under study, the ideal sliding mode was shown\n\tto occur in the absence of infinite number of switchings\n", "keywords": "ideal sliding mode; convex optimization; continuous convex-programming\n\talgorithms; exact penalty functions\n", "topicrank": [["mode", "convex optimization", "ideal", "study", "infinite number"], ["mode", "convex optimization", "ideal", "study", "infinite number", "problems", "continuous", "case", "characteristics", "algorithms"]], "textrank": [["convex optimization", "sliding mode", "penalty", "convex"], ["convex optimization", "sliding mode", "penalty", "convex"]], "positionrank": [["sliding mode", "convex optimization", "mode", "ideal", "convex"], ["sliding mode", "convex optimization", "mode", "ideal", "convex", "exact penalty functions", "problems", "characteristics", "case", "study"]], "multipartiterank": [["mode", "ideal", "convex optimization", "problems", "study"], ["mode", "ideal", "convex optimization", "problems", "study", "characteristics", "infinite number", "case", "continuous", "absence"]]}, {"id": "259", "text": "Nuts and bolts: implementing descriptive standards to enable virtual\n\tcollections\nTo date, online archival information systems have relied heavily on legacy\n\tfinding aids for data to encode and provide to end users, despite\n\tfairly strong indications in the archival literature that such legacy\n\tdata is problematic even as a mediated access tool. Archivists have\n\tonly just begun to study the utility of archival descriptive data for\n\tend users in unmediated settings such as via the Web. The ability of\n\tfuture archival information systems to respond to the expectations and\n\tneeds of end users is inextricably linked to archivists getting their\n\tcollective data house in order. The General International Standard\n\tArchival Description (ISAD(G)) offers the profession a place from which\n\tto start extricating ourselves from the idiosyncracies of our legacy\n\tdata and description practices\n", "keywords": "descriptive standards; virtual collections; online archival information\n\tsystems; end users; archival literature; legacy data; mediated access\n\ttool; archivists; archival descriptive data; archival information\n\tsystems; collective data house; General International Standard Archival\n\tDescription; ISAD; Online Archive of California; OAC\n", "topicrank": [["data", "users", "online archival information systems", "legacy", "archival literature"], ["data", "users", "online archival information systems", "legacy", "archival literature", "archivists", "collections", "virtual", "date", "general international standard"]], "textrank": [["archival descriptive data", "archival description", "archival information", "archival", "settings such"], ["archival descriptive data", "archival description", "archival information", "archival", "settings such", "access tool", "strong indications", "end users", "data", "descriptive"]], "positionrank": [["descriptive standards", "descriptive data", "archival description", "archival literature", "nuts"], ["descriptive standards", "descriptive data", "archival description", "archival literature", "nuts", "archival", "collective data house", "such legacy", "end users", "bolts"]], "multipartiterank": [["data", "users", "legacy", "online archival information systems", "archival literature"], ["data", "users", "legacy", "online archival information systems", "archival literature", "archivists", "date", "end users", "aids", "collections"]]}, {"id": "1962", "text": "The Bagsik Oscillator without complex numbers\nWe argue that the analysis of the so-called Bagsik Oscillator, recently\n\tpublished by Piotrowski and Sladkowski (2001), is erroneous due to: (1)\n\tthe incorrect banking data used and (2) the application of statistical\n\tmechanism apparatus to processes that are totally deterministic\n", "keywords": "Bagsik oscillator; noncomplex numbers; incorrect banking data; statistical\n\tmechanism apparatus; game theory; deterministic processes\n", "topicrank": [["bagsik oscillator", "mechanism apparatus", "statistical", "application", "processes"], ["bagsik oscillator", "mechanism apparatus", "statistical", "application", "processes", "sladkowski", "piotrowski", "complex numbers", "erroneous due", "incorrect banking data"]], "textrank": [["complex numbers", "bagsik oscillator", "banking"], ["complex numbers", "bagsik oscillator", "banking"]], "positionrank": [["bagsik oscillator", "complex numbers", "analysis", "piotrowski", "sladkowski"], ["bagsik oscillator", "complex numbers", "analysis", "piotrowski", "sladkowski", "incorrect banking data", "mechanism apparatus", "application", "processes"]], "multipartiterank": [["bagsik oscillator", "mechanism apparatus", "statistical", "application", "processes"], ["bagsik oscillator", "mechanism apparatus", "statistical", "application", "processes", "sladkowski", "piotrowski", "complex numbers", "erroneous due", "incorrect banking data"]]}, {"id": "2196", "text": "ConChat: a context-aware chat program\nConChat is a context-aware chat program that enriches electronic communication\n\tby providing contextual information and resolving potential semantic\n\tconflicts between users.ConChat uses contextual information to improve\n\telectronic communication. Using contextual cues, users can infer during\n\ta conversation what the other person is doing and what is happening in\n\this or her immediate surroundings. For example, if a user learns that\n\tthe other person is talking with somebody else or is involved in some\n\turgent activity, he or she knows to expect a slower response.\n\tConversely, if the user learns that the other person is sitting in a\n\tmeeting directly related to the conversation, he or she then knows to\n\trespond more quickly. Also, by informing users about the other person's\n\tcontext and tagging potentially ambiguous chat messages, ConChat\n\texplores how context can improve electronic communication by reducing\n\tsemantic conflicts\n", "keywords": "context-aware chat program; ConChat; contextual information; semantic\n\tconflicts; contextual cues\n", "topicrank": [["conchat", "context", "contextual information", "users", "electronic communication"], ["conchat", "context", "contextual information", "users", "electronic communication", "aware chat program", "conflicts", "conversation", "user", "potential semantic"]], "textrank": [["chat", "immediate surroundings", "other person", "electronic communication", "semantic"], ["chat", "immediate surroundings", "other person", "electronic communication", "semantic", "contextual"]], "positionrank": [["aware chat program", "conchat", "electronic communication", "ambiguous chat messages", "context"], ["aware chat program", "conchat", "electronic communication", "ambiguous chat messages", "context", "contextual information", "contextual cues", "semantic conflicts", "other person", "users"]], "multipartiterank": [["conchat", "context", "contextual information", "users", "electronic communication"], ["conchat", "context", "contextual information", "users", "electronic communication", "aware chat program", "conflicts", "potential semantic", "conversation", "user"]]}, {"id": "264", "text": "The archival imagination of David Bearman, revisited\nMany archivists regard the archival imagination evidenced in the writings of\n\tDavid Bearman as avant-garde. Archivist L. Henry (1998) has sharply\n\tcriticized Bearman for being irreverent toward the archival theory and\n\tpractice outlined by classical American archivist T. R. Schellenberg.\n\tAlthough Bearman is sometimes credited (and sometimes berated) for\n\testablishing \"a new paradigm\" centered on the archival management of\n\telectronic records, his methods and strategies are intended to\n\tencompass all forms of record keeping. The article provides general\n\tobservations on Bearman's archival imagination, lists some of its\n\tcomponents, and addresses elements of Henry's critique. Although the\n\tlong lasting impact of Bearman's imagination upon the archival\n\tprofession might be questioned, it nonetheless deserves continued\n\tconsideration by archivists and inclusion as a component of graduate\n\tarchival education\n", "keywords": "archival imagination; David Bearman; archival theory; classical American\n\tarchivist; Schellenberg; archival management; electronic records;\n\trecord keeping; archival profession; graduate archival education\n", "topicrank": [["david bearman", "archival theory", "archival imagination", "many archivists", "general"], ["david bearman", "archival theory", "archival imagination", "many archivists", "general", "observations", "article", "henry", "consideration", "record keeping"]], "textrank": [["american archivist t. r.", "archivist l.", "archival", "new paradigm", "many archivists"], ["american archivist t. r.", "archivist l.", "archival", "new paradigm", "many archivists", "david bearman", "lasting", "archivists", "electronic", "bearman"]], "positionrank": [["archival imagination", "david bearman", "archival theory", "archival management", "archival education"], ["archival imagination", "david bearman", "archival theory", "archival management", "archival education", "archival", "bearman", "imagination", "archivist l. henry", "many archivists"]], "multipartiterank": [["david bearman", "archival imagination", "bearman", "archival theory", "many archivists"], ["david bearman", "archival imagination", "bearman", "archival theory", "many archivists", "writings", "irreverent", "observations", "general", "practice"]]}, {"id": "198", "text": "Computational capacity of an odorant discriminator: the linear separability of\n\tcurves\nWe introduce and study an artificial neural network inspired by the\n\tprobabilistic receptor affinity distribution model of olfaction. Our\n\tsystem consists of N sensory neurons whose outputs converge on a single\n\tprocessing linear threshold element. The system's aim is to model\n\tdiscrimination of a single target odorant from a large number p of\n\tbackground odorants within a range of odorant concentrations. We show\n\tthat this is possible provided p does not exceed a critical value p/sub\n\tc/ and calculate the critical capacity alpha c=p/sub c//N. The critical\n\tcapacity depends on the range of concentrations in which the\n\tdiscrimination is to be accomplished. If the olfactory bulb may be\n\tthought of as a collection of such processing elements, each\n\tresponsible for the discrimination of a single odorant, our study\n\tprovides a quantitative analysis of the potential computational\n\tproperties of the olfactory bulb. The mathematical formulation of the\n\tproblem we consider is one of determining the capacity for linear\n\tseparability of continuous curves, embedded in a large-dimensional\n\tspace. This is accomplished here by a numerical study, using a method\n\tthat signals whether the discrimination task is realizable, together\n\twith a finite-size scaling analysis\n", "keywords": "artificial neural network; receptor affinity distribution; olfaction; linear\n\tthreshold element; sensory neurons; linear separability; odorant\n\tdiscriminator\n", "topicrank": [["discrimination", "single", "computational capacity", "linear separability", "range"], ["discrimination", "single", "computational capacity", "linear separability", "range", "olfactory bulb", "odorant concentrations", "curves", "system", "study"]], "textrank": [["processing linear threshold", "critical capacity alpha", "receptor affinity distribution", "critical value p", "computational capacity"], ["processing linear threshold", "critical capacity alpha", "receptor affinity distribution", "critical value p", "computational capacity", "scaling analysis", "number p", "odorant", "processing", "linear"]], "positionrank": [["computational capacity", "single odorant", "odorant discriminator", "critical value p", "linear separability"], ["computational capacity", "single odorant", "odorant discriminator", "critical value p", "linear separability", "large number p", "capacity", "odorant concentrations", "linear threshold element", "olfactory bulb"]], "multipartiterank": [["computational capacity", "single", "discrimination", "linear separability", "system"], ["computational capacity", "single", "discrimination", "linear separability", "system", "odorant discriminator", "curves", "range", "processing linear threshold element", "odorant concentrations"]]}, {"id": "37", "text": "Design PID controllers for desired time-domain or frequency-domain response\nPractical requirements on the design of control systems, especially process\n\tcontrol systems, are usually specified in terms of time-domain\n\tresponse, such as overshoot and rise time, or frequency-domain\n\tresponse, such as resonance peak and stability margin. Although\n\tnumerous methods have been developed for the design of the\n\tproportional-integral-derivative (PID) controller, little work has been\n\tdone in relation to the quantitative time-domain and frequency-domain\n\tresponses. In this paper, we study the following problem: Given a\n\tnominal stable process with time delay, we design a suboptimal PID\n\tcontroller to achieve the required time-domain response or\n\tfrequency-domain response for the nominal system or the uncertain\n\tsystem. An H/sub infinity / PID controller is developed based on\n\toptimal control theory and the parameters are derived analytically. Its\n\tproperties are investigated and compared with that of two developed\n\tsuboptimal controllers: an H/sub 2/ PID controller and a Maclaurin PID\n\tcontroller\n", "keywords": "time-domain response; frequency-domain response; process control systems;\n\tovershoot; rise time; resonance peak; stability margin;\n\tproportional-integral derivative controller; nominal stable process;\n\tsuboptimal controller; H/sub infinity / PID controller; H/sub 2/ PID\n\tcontroller; optimal control; Maclaurin PID controller\n", "topicrank": [["domain", "time", "frequency", "controller", "pid"], ["domain", "time", "frequency", "controller", "pid", "design pid controllers", "response", "nominal system", "sub infinity", "control systems"]], "textrank": [["nominal stable", "pid", "numerous methods", "stability margin", "resonance peak"], ["nominal stable", "pid", "numerous methods", "stability margin", "resonance peak", "practical requirements", "domain response", "control", "time", "nominal"]], "positionrank": [["design pid controllers", "domain response", "pid controller", "suboptimal pid", "domain"], ["design pid controllers", "domain response", "pid controller", "suboptimal pid", "domain", "quantitative time", "maclaurin pid", "time delay", "pid", "design"]], "multipartiterank": [["domain", "time", "design pid controllers", "frequency", "controller"], ["domain", "time", "design pid controllers", "frequency", "controller", "pid", "domain response", "response", "control systems", "design"]]}, {"id": "299", "text": "Customer in-reach and library strategic systems: the case of ILLiad\nLibraries have walls. Recognizing this fact, the Interlibrary Loan Department\n\tat Virginia Tech is creating systems and services that enable our\n\tcustomers to reach past our walls at anytime from anywhere. Customer\n\tin-reach enables Virginia Tech faculty, students, and staff anywhere in\n\tthe world to obtain information and services heretofore available only\n\tto our on-campus customers. ILLiad, Virginia Tech's interlibrary\n\tborrowing system, is the library strategic system that attains this\n\tgoal. The principles that guided development of ILLiad are widely\n\tapplicable\n", "keywords": "library strategic systems; Interlibrary Loan Department; Virginia Tech;\n\tcustomer in-reach; ILLiad; interlibrary borrowing system\n", "topicrank": [["illiad", "virginia tech", "services", "interlibrary loan department", "library strategic systems"], ["illiad", "virginia tech", "services", "interlibrary loan department", "library strategic systems", "customers", "walls", "customer", "libraries", "information"]], "textrank": [["enables virginia tech", "strategic system", "interlibrary loan department", "virginia tech", "campus customers"], ["enables virginia tech", "strategic system", "interlibrary loan department", "virginia tech", "campus customers", "strategic", "system", "customers", "interlibrary"]], "positionrank": [["library strategic systems", "library strategic system", "virginia tech", "interlibrary loan department", "customer"], ["library strategic systems", "library strategic system", "virginia tech", "interlibrary loan department", "customer", "reach", "borrowing system", "illiad", "systems", "campus customers"]], "multipartiterank": [["virginia tech", "illiad", "interlibrary loan department", "services", "library strategic systems"], ["virginia tech", "illiad", "interlibrary loan department", "services", "library strategic systems", "walls", "customers", "customer", "libraries", "case"]]}, {"id": "2033", "text": "Optical encoding of color three-dimensional correlation\nThree-dimensional (3D) correlation of color images, considering the color\n\tdistribution as the third dimension, has been shown to be useful for\n\tcolor pattern recognition tasks. Nevertheless, 3D correlation cannot be\n\tdirectly performed on an optical correlator, that can only process\n\ttwo-dimensional (2D) signals. We propose a method to encode 3D\n\tfunctions onto 2D ones in such a way that the Fourier transform and\n\tcorrelation of these signals, that can be optically performed, encode\n\tthe 3D Fourier transform and correlation of the 3D signals. The theory\n\tfor the encoding is given and experimental results obtained in an\n\toptical correlator are shown\n", "keywords": "optical encoding; color three-dimensional correlation; 3D correlation; color\n\timages; color distribution; color pattern recognition tasks; optical\n\tcorrelator; 3D function encoding; Fourier transform; 3D Fourier\n\ttransform\n", "topicrank": [["correlation", "color", "signals", "dimensional correlation", "fourier transform"], ["correlation", "color", "signals", "dimensional correlation", "fourier transform", "optical encoding", "optical correlator", "distribution", "ones", "way"]], "textrank": [["color pattern recognition", "3d fourier", "3d correlation", "3d", "optical"], ["color pattern recognition", "3d fourier", "3d correlation", "3d", "optical", "color", "fourier", "correlation", "third"]], "positionrank": [["3d correlation", "dimensional correlation", "optical encoding", "3d fourier transform", "3d signals"], ["3d correlation", "dimensional correlation", "optical encoding", "3d fourier transform", "3d signals", "optical correlator", "color images", "correlation", "color", "3d"]], "multipartiterank": [["color", "correlation", "dimensional correlation", "optical encoding", "signals"], ["color", "correlation", "dimensional correlation", "optical encoding", "signals", "fourier transform", "dimensional", "distribution", "third dimension", "optical correlator"]]}, {"id": "384", "text": "Brightness-independent start-up routine for star trackers\nInitial attitude acquisition by a modern star tracker is investigated here.\n\tCriteria for efficient organization of the on-board database are\n\tdiscussed with reference to a brightness-independent initial\n\tacquisition algorithm. Star catalog generation preprocessing is\n\tdescribed, with emphasis on the identification of minimum star\n\tbrightness for detection by a sensor based on a charge coupled device\n\t(CCD) photodetector. This is a crucial step for proper evaluation of\n\tthe attainable sky coverage when selecting the stars to be included in\n\tthe on-board catalog. Test results are also reported, both for\n\treliability and accuracy, even if the former is considered to be the\n\tprimary target. Probability of erroneous solution is 0.2% in the case\n\tof single runs of the procedure, while attitude determination accuracy\n\tis in the order of 0.02 degrees in the average for the computation of\n\tthe inertial pointing of the boresight axis\n", "keywords": "brightness-independent start-up routine; star trackers; initial attitude\n\tacquisition; on-board database; star catalog generation preprocessing;\n\tgyroless spacecraft; minimum star brightness; charge coupled device\n\tphotodetector; reliability; boresight axis\n", "topicrank": [["brightness", "star trackers", "accuracy", "independent", "board database"], ["brightness", "star trackers", "accuracy", "independent", "board database", "detection", "device", "ccd", "charge", "acquisition algorithm"]], "textrank": [["star catalog generation", "initial attitude acquisition", "attitude determination", "board catalog", "star"], ["star catalog generation", "initial attitude acquisition", "attitude determination", "board catalog", "star", "test results", "proper evaluation", "crucial step", "efficient organization", "up routine"]], "positionrank": [["initial attitude acquisition", "modern star tracker", "star trackers", "minimum star", "brightness"], ["initial attitude acquisition", "modern star tracker", "star trackers", "minimum star", "brightness", "acquisition algorithm", "up routine", "board catalog", "attitude determination accuracy", "board database"]], "multipartiterank": [["brightness", "star trackers", "independent", "board database", "accuracy"], ["brightness", "star trackers", "independent", "board database", "accuracy", "initial attitude acquisition", "minimum star", "acquisition algorithm", "detection", "efficient organization"]]}, {"id": "379", "text": "Feedforward maximum power point tracking of PV systems using fuzzy controller\nA feedforward maximum power (MP) point tracking scheme is developed for the\n\tinterleaved dual boost (IDB) converter fed photovoltaic (PV) system\n\tusing fuzzy controller. The tracking algorithm changes the duty ratio\n\tof the converter such that the solar cell array (SCA) voltage equals\n\tthe voltage corresponding to the MP point at that solar insolation.\n\tThis is done by the feedforward loop, which generates an error signal\n\tby comparing the instantaneous array voltage and reference voltage. The\n\treference voltage for the feedforward loop, corresponding to the MP\n\tpoint, is obtained by an off-line trained neural network. Experimental\n\tdata is used for off-line training of the neural network, which employs\n\tback-propagation algorithm. The proposed fuzzy feedforward peak power\n\ttracking effectiveness is demonstrated through the simulation and\n\texperimental results, and compared with the conventional proportional\n\tplus integral (PI) controller based system. Finally, a comparative\n\tstudy of interleaved boost and conventional boost converter for the PV\n\tapplications is given and their suitability is discussed\n", "keywords": "feedforward maximum power point tracking; PV systems; fuzzy controller;\n\tinterleaved dual boost converter feed; photovoltaic system; tracking\n\talgorithm; duty ratio; solar cell array voltage; solar insolation;\n\tfeedforward loop; error signal; instantaneous array voltage; reference\n\tvoltage; off-line trained neural network; back-propagation algorithm;\n\tfuzzy feedforward peak power tracking effectiveness\n", "topicrank": [["voltage", "fuzzy controller", "feedforward maximum power point tracking", "point tracking scheme", "dual boost"], ["voltage", "fuzzy controller", "feedforward maximum power point tracking", "point tracking scheme", "dual boost", "experimental", "neural network", "system", "algorithm", "line"]], "textrank": [["conventional boost converter", "solar cell array", "power point tracking", "fuzzy feedforward", "array voltage"], ["conventional boost converter", "solar cell array", "power point tracking", "fuzzy feedforward", "array voltage", "converter fed", "point tracking", "boost", "tracking algorithm", "duty ratio"]], "positionrank": [["feedforward loop", "point tracking scheme", "maximum power", "feedforward", "fuzzy controller"], ["feedforward loop", "point tracking scheme", "maximum power", "feedforward", "fuzzy controller", "mp point", "pv systems", "conventional boost converter", "instantaneous array voltage", "reference voltage"]], "multipartiterank": [["feedforward maximum power point tracking", "fuzzy controller", "voltage", "point tracking scheme", "pv systems"], ["feedforward maximum power point tracking", "fuzzy controller", "voltage", "point tracking scheme", "pv systems", "dual boost", "system", "algorithm", "neural network", "idb"]]}, {"id": "411", "text": "CAD/CAE software aids converter design [DC/DC power conversion]\nTypically, power supply design involves electronic and magnetic components. In\n\tthis paper, the authors describe, using a flyback converter example,\n\thow CAD/CAE tools can aid the power supply engineer in both areas,\n\treducing prototyping costs and providing insights into system\n\tperformance\n", "keywords": "DC/DC power convertor design; power supply design; electronic components;\n\tmagnetic components; CAD/CAE software; flyback power convertor\n\ttopology; prototyping costs\n", "topicrank": [["cae software", "power supply design", "cad", "electronic", "system"], ["cae software", "power supply design", "cad", "electronic", "system", "insights", "magnetic components", "prototyping costs", "converter design", "paper"]], "textrank": [["power supply design", "power supply", "converter design", "magnetic components", "converter"], ["power supply design", "power supply", "converter design", "magnetic components", "converter", "power", "cae"]], "positionrank": [["power supply design", "dc power conversion", "power supply engineer", "converter design", "flyback converter example"], ["power supply design", "dc power conversion", "power supply engineer", "converter design", "flyback converter example", "cae software", "cae tools", "cad", "dc", "magnetic components"]], "multipartiterank": [["cae software", "cad", "power supply design", "electronic", "converter design"], ["cae software", "cad", "power supply design", "electronic", "converter design", "magnetic components", "dc power conversion", "paper", "system", "authors"]]}, {"id": "1986", "text": "Control centers are here to stay\nDespite changes with different structures, market rules, and uncertainties, a\n\tcontrol center must always be in place to maintain the security,\n\treliability, and quality of electric service. This article focuses on\n\tthe energy management system (EMS) control center, identifying the\n\tmajor functions that have become standard components of every\n\tapplication software package. The two most important control center\n\tfunctions, security control and load-following control, guarantee the\n\tcontinuity of electric service, which after all, is the end-product of\n\tthe utility business. New technology trends in the design of control\n\tcenter infrastructures are emerging in the liberalized environment of\n\tthe energy market. An example of a control center infrastructure is\n\tdescribed. The article ends with a concern for the security of the\n\tcontrol center itself\n", "keywords": "EMS control centers; energy management system; standard components; application\n\tsoftware package; security control; load-following control; electric\n\tservice continuity; control center infrastructures; liberalized\n\tenvironment; energy market\n", "topicrank": [["control centers", "security", "electric service", "major functions", "market rules"], ["control centers", "security", "electric service", "major functions", "market rules", "article", "new technology trends", "design", "ems", "load"]], "textrank": [["control center", "energy market", "energy management", "control", "major functions"], ["control center", "energy market", "energy management", "control", "major functions", "electric service", "different structures", "center", "technology", "software"]], "positionrank": [["important control center", "control center infrastructure", "control center", "control centers", "security control"], ["important control center", "control center infrastructure", "control center", "control centers", "security control", "control", "center infrastructures", "energy market", "market rules", "energy management system"]], "multipartiterank": [["control centers", "market rules", "different structures", "changes", "security"], ["control centers", "market rules", "different structures", "changes", "security", "electric service", "control center", "uncertainties", "major functions", "article"]]}, {"id": "205", "text": "Geotensity: combining motion and lighting for 3D surface reconstruction\nThis paper is about automatically reconstructing the full 3D surface of an\n\tobject observed in motion by a single static camera. Based on the two\n\tparadigms, structure from motion and linear intensity subspaces, we\n\tintroduce the geotensity constraint that governs the relationship\n\tbetween four or more images of a moving object. We show that it is\n\tpossible in theory to solve for 3D Lambertian surface structure for the\n\tcase of a single point light source and propose that a solution exists\n\tfor an arbitrary number point light sources. The surface may or may not\n\tbe textured. We then give an example of automatic surface\n\treconstruction of a face under a point light source using arbitrary\n\tunknown object motion and a single fixed camera\n", "keywords": "full 3D surface; single static camera; linear intensity subspaces; geotensity\n\tconstraint; 3D Lambertian surface structure; single point light source;\n\tarbitrary number point light sources; automatic surface reconstruction;\n\tpoint light source; linear image subspaces; structure-from-motion\n", "topicrank": [["3d surface reconstruction", "motion", "single point light source", "single static camera", "object"], ["3d surface reconstruction", "motion", "single point light source", "single static camera", "object", "geotensity", "structure", "arbitrary", "reconstruction", "linear intensity subspaces"]], "textrank": [["number point light", "single point light", "3d surface", "point light", "surface"], ["number point light", "single point light", "3d surface", "point light", "surface", "single static", "geotensity constraint", "intensity", "object", "3d"]], "positionrank": [["3d surface reconstruction", "full 3d surface", "unknown object motion", "geotensity constraint", "automatic surface"], ["3d surface reconstruction", "full 3d surface", "unknown object motion", "geotensity constraint", "automatic surface", "geotensity", "motion", "single point", "surface", "arbitrary number point"]], "multipartiterank": [["motion", "3d surface reconstruction", "geotensity", "lighting", "single point light source"], ["motion", "3d surface reconstruction", "geotensity", "lighting", "single point light source", "object", "paper", "single static camera", "structure", "linear intensity subspaces"]]}, {"id": "240", "text": "Project Euclid and the role of research libraries in scholarly publishing\nProject Euclid, a joint electronic journal publishing initiative of Cornell\n\tUniversity Library and Duke University Press is discussed in the\n\tbroader contexts of the changing patterns of scholarly communication\n\tand the publishing scene of mathematics. Specific aspects of the\n\tproject such as partnerships and the creation of an economic model are\n\tpresented as well as what it takes to be a publisher. Libraries have\n\tgained important and relevant experience through the creation and\n\tmanagement of digital libraries, but they need to develop further\n\tskills if they want to adopt a new role in the life cycle of scholarly\n\tcommunication\n", "keywords": "Project Euclid; joint electronic journal publishing initiative; Cornell\n\tUniversity Library; Duke University Press; scholarly communication;\n\tmathematics; partnerships; economic model; scholarly publishing;\n\tresearch libraries\n", "topicrank": [["research libraries", "scholarly publishing", "creation", "scholarly communication", "role"], ["research libraries", "scholarly publishing", "creation", "scholarly communication", "role", "project euclid", "university library", "mathematics", "joint electronic journal publishing initiative", "cornell"]], "textrank": [["electronic journal publishing", "scholarly publishing", "publishing", "specific aspects", "broader contexts"], ["electronic journal publishing", "scholarly publishing", "publishing", "specific aspects", "broader contexts", "university", "libraries", "project", "scholarly", "economic"]], "positionrank": [["project euclid", "scholarly publishing", "project", "publishing scene", "scholarly communication"], ["project euclid", "scholarly publishing", "project", "publishing scene", "scholarly communication", "research libraries", "duke university press", "digital libraries", "scholarly", "new role"]], "multipartiterank": [["research libraries", "project euclid", "scholarly publishing", "role", "scholarly communication"], ["research libraries", "project euclid", "scholarly publishing", "role", "scholarly communication", "joint electronic journal publishing initiative", "creation", "university library", "cornell", "duke university press"]]}, {"id": "318", "text": "Note on \"Deterministic inventory lot-size models under inflation with shortages\n\tand deterioration for fluctuating demand\" by Yang et al\nFor original paper see H.-L. Yang et al., ibid., vol.48, p.144-58 (2001). Yang\n\tet al. extended the lot-size models to allow for inflation and\n\tfluctuating demand. For this model they proved that the optimal\n\treplenishment schedule exists and is unique. They also proposed an\n\talgorithm to find the optimal policy. The present paper provides\n\texamples, which show that the optimal replenishment schedule and\n\tconsequently the overall optimal policy may not exist\n", "keywords": "deterministic inventory lot-size models; inflation; fluctuating demand; optimal\n\treplenishment schedule; optimal policy algorithm; optimal scheduling\n\tparameters\n", "topicrank": [["optimal", "size models", "inflation", "demand", "deterministic inventory lot"], ["optimal", "size models", "inflation", "demand", "deterministic inventory lot", "replenishment schedule", "original paper", "yang", "shortages", "deterioration"]], "textrank": [["optimal replenishment", "h.-l. yang", "size models", "optimal", "paper"], ["optimal replenishment", "h.-l. yang", "size models", "optimal", "paper", "inventory", "replenishment", "al", "yang"]], "positionrank": [["deterministic inventory lot", "size models", "al .", "h.-l. yang", "optimal replenishment schedule"], ["deterministic inventory lot", "size models", "al .", "h.-l. yang", "optimal replenishment schedule", "yang", "lot", "al", "inflation", "original paper"]], "multipartiterank": [["size models", "inflation", "optimal", "deterministic inventory lot", "demand"], ["size models", "inflation", "optimal", "deterministic inventory lot", "demand", "replenishment schedule", "yang", "original paper", "shortages", "deterioration"]]}, {"id": "2017", "text": "Autofocus system for microscope\nA technique is developed for microscope autofocusing, which is called the\n\teccentric light beam approach with high resolution, wide focusing\n\trange, and compact construction. The principle is described. The\n\ttheoretical formula of the eccentric light beam approach deduced can be\n\tapplied not only to an object lens whose objective plane is just at the\n\tfocal plane, but also to an object lens whose objective plane is not at\n\tthe focal plane. The experimental setup uses a semiconductor laser\n\tdevice as the light source. The laser beam that enters into the\n\tmicroscope is eccentric with the main light axis. A defocused signal is\n\tacquired by a symmetrical silicon photocell for the change of the\n\treflected light position caused by differential amplification and\n\tprocessed by a microprocessor. Then the electric signal is\n\tpower-amplified and drives a dc motor, which moves a fine working\n\tplatform to an automatic focus of the microscope. The result of the\n\texperiments shows a +or-0.1- mu m precision of autofocusing for a range\n\tof +or-500- mu m defocusing. The system has high reliability and can\n\tmeet the requirements of various accurate micro measurement systems\n", "keywords": "autofocus system; microscope autofocusing; eccentric light beam approach;\n\tobject lens; objective plane; semiconductor laser; main light axis;\n\tdefocused signal; symmetrical silicon photocell; reflected light\n\tposition; differential amplification; microprocessor; power-amplified\n\telectric signal; dc motor; fine working platform; high reliability;\n\tmicro measurement systems\n", "topicrank": [["microscope", "light source", "objective plane", "semiconductor laser", "high resolution"], ["microscope", "light source", "objective plane", "semiconductor laser", "high resolution", "defocused signal", "eccentric light beam approach", "object lens", "range", "autofocus system"]], "textrank": [["light beam", "or-0.1- mu m", "accurate micro measurement", "mu m", "laser beam"], ["light beam", "or-0.1- mu m", "accurate micro measurement", "mu m", "laser beam", "light", "theoretical formula", "compact construction", "autofocus system", "silicon"]], "positionrank": [["autofocus system", "microscope", "system", "mu m defocusing", "main light"], ["autofocus system", "microscope", "system", "mu m defocusing", "main light", "light source", "light position", "laser beam", "high reliability", "high resolution"]], "multipartiterank": [["microscope", "objective plane", "light source", "semiconductor laser", "object lens"], ["microscope", "objective plane", "light source", "semiconductor laser", "object lens", "autofocus system", "eccentric light beam approach", "high resolution", "defocused signal", "range"]]}, {"id": "2052", "text": "Blitzograms - interactive histograms\nAs computers become ever faster, more and more procedures that were once viewed\n\tas iterative will continue to become instantaneous. The blitzogram is\n\tthe application of this trend to histograms, which the author hopes\n\twill lead to a better tacit understanding of probability distributions\n\tamong both students and managers. And this is not just an academic\n\texercise. Commercial Monte Carlo simulation packages like @RISK and\n\tCrystal Ball, and my INSIGHT.xla are widely available\n", "keywords": "blitzogram; histograms; probability distributions; MBA; operations research;\n\tmanagement science; statistics\n", "topicrank": [["interactive histograms", "trend", "exercise", "probability distributions", "students"], ["interactive histograms", "trend", "exercise", "probability distributions", "students", "commercial monte carlo simulation packages", "better tacit understanding", "application", "academic", "managers"]], "textrank": [["monte carlo simulation", "more procedures", "interactive histograms", "tacit", "probability"], ["monte carlo simulation", "more procedures", "interactive histograms", "tacit", "probability", "histograms", "more"]], "positionrank": [["interactive histograms", "more procedures", "histograms", "blitzograms", "computers"], ["interactive histograms", "more procedures", "histograms", "blitzograms", "computers", "better tacit understanding", "blitzogram", "application", "author", "trend"]], "multipartiterank": [["interactive histograms", "blitzograms", "computers", "exercise", "trend"], ["interactive histograms", "blitzograms", "computers", "exercise", "trend", "probability distributions", "commercial monte carlo simulation packages", "students", "academic", "better tacit understanding"]]}, {"id": "408", "text": ".NET obfuscation and intellectual property\nThe author considers obfuscation options for protecting .NET code. Many\n\tprograms won't need obfuscation because the loss caused by reverse\n\tengineering will be nonexistent. Numerous obfuscators are already\n\tavailable for the .NET platform, ranging from a basic renaming\n\tobfuscator to a fully functional obfuscator that handles mixed\n\tIL/native code assemblies created in any managed language, including\n\tMicrosoft's C++ with Managed Extensions. An obfuscator simply makes\n\tyour application harder to reverse engineer. It does not prevent\n\treverse engineering. However, the cost of obfuscation is insignificant\n\twhen compared to the cost of a typical software development project. If\n\tyou feel like an obfuscator provides you any benefit at all, it's\n\tprobably worth the price\n", "keywords": ".NET obfuscation; intellectual property; reverse engineering\n", "topicrank": [["obfuscator", "obfuscation options", "engineering", "cost", "reverse"], ["obfuscator", "obfuscation options", "engineering", "cost", "reverse", "nonexistent", "numerous obfuscators", "loss", "programs", "many"]], "textrank": [[".net code", ".net obfuscation", "software development", "reverse engineering", "basic renaming"], [".net code", ".net obfuscation", "software development", "reverse engineering", "basic renaming", "numerous obfuscators", "intellectual property", "code", ".net", "obfuscation"]], "positionrank": [[".net obfuscation", "obfuscation options", ".net code", ".net platform", "obfuscation"], [".net obfuscation", "obfuscation options", ".net code", ".net platform", "obfuscation", "intellectual property", "native code assemblies", "functional obfuscator", "reverse engineering", "obfuscator"]], "multipartiterank": [["obfuscation options", "obfuscator", "engineering", "obfuscation", "author"], ["obfuscation options", "obfuscator", "engineering", "obfuscation", "author", "cost", "reverse", "nonexistent", "programs", "many"]]}, {"id": "360", "text": "Numerical representation of binary relations with a multiplicative error\n\tfunction\nThis paper studies the case of the representation of a binary relation via a\n\tnumerical function with threshold (error) depending on both compared\n\talternatives. The error is considered to be multiplicative, its value\n\tbeing either directly or inversely proportional to the values of the\n\tnumerical function. For the first case, it is proved that a binary\n\trelation is a semiorder. Moreover, any semiorder can be represented in\n\tthis form. In the second case, the corresponding binary relation is an\n\tinterval order\n", "keywords": "numerical representation; binary relations; multiplicative error function;\n\tnumerical function; threshold; error; semiorder; interval order\n", "topicrank": [["binary relations", "function", "multiplicative error", "case", "numerical representation"], ["binary relations", "function", "multiplicative error", "case", "numerical representation", "semiorder", "threshold", "paper", "relation", "multiplicative"]], "textrank": [["multiplicative error", "case", "binary", "numerical", "interval"], ["multiplicative error", "case", "binary", "numerical", "interval", "multiplicative", "error"]], "positionrank": [["numerical function", "numerical representation", "binary relation", "binary relations", "multiplicative error"], ["numerical function", "numerical representation", "binary relation", "binary relations", "multiplicative error", "binary", "first case", "function", "second case", "representation"]], "multipartiterank": [["binary relations", "numerical representation", "multiplicative error", "function", "case"], ["binary relations", "numerical representation", "multiplicative error", "function", "case", "paper", "numerical function", "error", "binary relation", "representation"]]}, {"id": "2092", "text": "Matching PET and CT scans of the head and neck area: Development of method and\n\tvalidation\nPositron emission tomography (PET) provides important information on tumor\n\tbiology, but lacks detailed anatomical information. Our aim in the\n\tpresent study was to develop and validate an automatic registration\n\tmethod for matching PET and CT scans of the head and neck. Three\n\tdifficulties in achieving this goal are (1) nonrigid motions of the\n\tneck can hamper the use of automatic ridged body transformations; (2)\n\temission scans contain too little anatomical information to apply\n\tstandard image fusion methods; and (3) no objective way exists to\n\tquantify the quality of the match results. These problems are solved as\n\tfollows: accurate and reproducible positioning of the patient was\n\tachieved by using a radiotherapy treatment mask. The proposed method\n\tmakes use of the transmission rather than the emission scan. To obtain\n\tsufficient (anatomical) information for matching, two bed positions for\n\tthe transmission scan were included in the protocol. A mutual\n\tinformation-based algorithm was used as a registration technique. PET\n\tand CT data were obtained in seven patients. Each patient had two CT\n\tscans and one PET scan. The datasets were used to estimate the\n\tconsistency by matching PET to CT/sub 1/, CT/sub 1/ to CT/sub 2/, and\n\tCT/sub 2/ to PET using the full circle consistency test. It was found\n\tthat using our method, consistency could be obtained of 4 mm and 1.3\n\tdegrees on average. The PET voxels used for registration were 5.15 mm,\n\tso the errors compared quite favorably with the voxel size. Cropping\n\tthe images (removing the scanner bed from images) did not improve the\n\tconsistency of the algorithm. The transmission scan, however, could\n\tpotentially be reduced to a single position using this approach. In\n\tconclusion, the represented algorithm and validation technique has\n\tseveral features that are attractive from both theoretical and\n\tpractical point of view, it is a user-independent, automatic validation\n\ttechnique for matching CT and PET scans of the head and neck, which\n\tgives the opportunity to compare different image enhancements\n", "keywords": "positron emission tomography scans; tumor biology; anatomical information;\n\tautomatic registration method; computerised tomography scans; head;\n\tneck; nonrigid motions; automatic ridged body transformations; standard\n\timage fusion methods; radiotherapy treatment mask; bed positions;\n\ttransmission scan; mutual information-based algorithm; registration\n\ttechnique; patients; full circle consistency test; errors; scanner bed;\n\tuser-independent automatic validation technique; image enhancements\n", "topicrank": [["pet", "method", "neck area", "ct scans", "important information"], ["pet", "method", "neck area", "ct scans", "important information", "detailed anatomical information", "algorithm", "head", "transmission", "sub"]], "textrank": [["image fusion", "emission scan", "emission scans", "anatomical information", "pet scan"], ["image fusion", "emission scan", "emission scans", "anatomical information", "pet scan", "pet scans", "circle consistency", "ct scans", "image", "automatic validation"]], "positionrank": [["pet scans", "ct scans", "pet scan", "pet voxels", "pet"], ["pet scans", "ct scans", "pet scan", "pet voxels", "pet", "ct data", "emission scans", "ct", "detailed anatomical information", "little anatomical information"]], "multipartiterank": [["pet", "method", "ct scans", "neck area", "important information"], ["pet", "method", "ct scans", "neck area", "important information", "head", "detailed anatomical information", "neck", "validation", "transmission"]]}, {"id": "325", "text": "Open courseware and shared knowledge in higher education\nMost college and university campuses in the United States and much of the\n\tdeveloped world today maintain one, two, or several learning management\n\tsystems (LMSs), which are courseware products that provide students and\n\tfaculty with Web-based tools to manage course-related applications.\n\tSince the mid-1990s, two predominant models of Web courseware\n\tmanagement systems have emerged: commercial and noncommercial. Some of\n\tthe commercial products available today were created in academia as\n\tnoncommercial but have since become commercially encumbered. Other\n\tproducts remain noncommercial but are struggling to survive in a world\n\tof fierce commercial competition. This article argues for an ethics of\n\tpedagogy in higher education that would be based on the guiding\n\tassumptions of the non-proprietary, peer-to-peer, open-source software\n\tmovement\n", "keywords": "open courseware; shared knowledge; higher education; learning management\n\tsystems; college; university; Web courseware management systems;\n\tcommercial products; ethics; Internet; open-source software\n", "topicrank": [["noncommercial", "web", "management", "courseware products", "commercial"], ["noncommercial", "web", "management", "courseware products", "commercial", "higher education", "open courseware", "world today", "peer", "systems"]], "textrank": [["commercial products available today", "courseware products", "united states", "university campuses", "most college"], ["commercial products available today", "courseware products", "united states", "university campuses", "most college", "higher education", "commercial", "courseware", "products", "-"]], "positionrank": [["open courseware", "courseware products", "web courseware", "higher education", "most college"], ["open courseware", "courseware products", "web courseware", "higher education", "most college", "university campuses", "commercial products", "management systems", "united states", "peer"]], "multipartiterank": [["management", "web", "open courseware", "noncommercial", "courseware products"], ["management", "web", "open courseware", "noncommercial", "courseware products", "higher education", "systems", "world today", "commercial", "faculty"]]}, {"id": "1946", "text": "Integrating building management system and facilities management on the\n\tInternet\nRecently, it is of great interest to adopt the Internet/intranet to develop\n\tbuilding management systems (BMS) and facilities management systems\n\t(FMS). This paper addresses two technical issues: the Web-based access\n\t(including database integration) and the integration of BMS and FMS.\n\tThese should be addressed for accessing BMS remotely via the Internet,\n\tintegrating control networks using the Internet protocols and\n\tinfrastructures, and using Internet/intranet for building facilities\n\tmanagement. An experimental Internet-enabled system that integrates\n\tbuilding and facilities management systems has been developed and\n\ttested. This system integrated open control networks with the Internet\n\tand is developed utilizing the embedded Web server, the PC Web server\n\tand the Distributed Component Object Model (DCOM) software development\n\ttechnology on the platform of an open control network. Three strategies\n\tfor interconnecting BMS local networks via Internet/intranet are\n\tpresented and analyzed\n", "keywords": "intranet; building management systems; BMS; facilities management systems; FMS;\n\tWeb-based access; database integration; Internet protocols; embedded\n\tWeb server; PC Web server; Distributed Component Object Model; DCOM;\n\tsoftware development technology; open control network; local network\n\tinterconnection\n", "topicrank": [["internet", "facilities management", "bms", "control networks", "intranet"], ["internet", "facilities management", "bms", "control networks", "intranet", "building management system", "web", "fms", "database integration", "system"]], "textrank": [["control networks", "component object", "management", "local networks", "technical issues"], ["control networks", "component object", "management", "local networks", "technical issues", "great interest", "control", "web", "internet"]], "positionrank": [["building management system", "building management systems", "facilities management systems", "facilities management", "experimental internet"], ["building management system", "building management systems", "facilities management systems", "facilities management", "experimental internet", "internet protocols", "management", "internet", "building", "facilities"]], "multipartiterank": [["internet", "facilities management", "building management system", "bms", "intranet"], ["internet", "facilities management", "building management system", "bms", "intranet", "control networks", "web", "fms", "database integration", "facilities management systems"]]}, {"id": "238", "text": "The Open Archives Initiative: realizing simple and effective digital library\n\tinteroperability\nThe Open Archives Initiative (OAI) is dedicated to solving problems of digital\n\tlibrary interoperability. Its focus has been on defining simple\n\tprotocols, most recently for the exchange of metadata from archives.\n\tThe OAI evolved out of a need to increase access to scholarly\n\tpublications by supporting the creation of interoperable digital\n\tlibraries. As a first step towards such interoperability, a metadata\n\tharvesting protocol was developed to support the streaming of metadata\n\tfrom one repository to another, ultimately to a provider of user\n\tservices such as browsing, searching, or annotation. This article\n\tprovides an overview of the mission, philosophy, and technical\n\tframework of the OAI\n", "keywords": "Open Archives Initiative; digital library interoperability; protocols; exchange\n\tmetadata; scholarly publications; metadata harvesting protocol;\n\tstreaming metadata; annotation; searching; browsing; user services\n", "topicrank": [["effective digital library", "metadata", "oai", "open archives initiative", "interoperability"], ["effective digital library", "metadata", "oai", "open archives initiative", "interoperability", "simple", "scholarly", "access", "publications", "creation"]], "textrank": [["effective digital library", "open archives initiative", "such interoperability", "library interoperability", "harvesting protocol"], ["effective digital library", "open archives initiative", "such interoperability", "library interoperability", "harvesting protocol", "first step", "services such", "digital", "archives", "interoperability"]], "positionrank": [["open archives initiative", "effective digital library", "library interoperability", "such interoperability", "archives"], ["open archives initiative", "effective digital library", "library interoperability", "such interoperability", "archives", "interoperability", "oai", "first step", "metadata", "harvesting protocol"]], "multipartiterank": [["effective digital library", "open archives initiative", "oai", "interoperability", "metadata"], ["effective digital library", "open archives initiative", "oai", "interoperability", "metadata", "simple", "problems", "dedicated", "digital", "scholarly"]]}, {"id": "2172", "text": "Electronic data exchange for real estate\nWith HM Land Registry's consultation now underway, no one denies that the\n\tproperty industry is facing a period of unprecedented change. PISCES\n\t(Property Information Systems Common Exchange) is a property-focused\n\telectronic data exchange standard. The standard is a set of definitions\n\tand rules to facilitate electronic transfer of data between key\n\tbusiness areas and between different types of software packages that\n\tare used regularly by the property industry. It is not itself a piece\n\tof software but an enabling technology that allows software providers\n\tto prepare solutions within their own packages to transfer data between\n\tdatabases. This provides the attractive prospect of seamless transfer\n\tof data within and between systems and organisations\n", "keywords": "HM Land Registry; property industry; PISCES; Property Information Systems\n\tCommon Exchange; electronic data exchange; standard; software packages;\n\tdatabases; seamless transfer\n", "topicrank": [["electronic data exchange", "software packages", "property industry", "electronic transfer", "key"], ["electronic data exchange", "software packages", "property industry", "electronic transfer", "key", "business areas", "definitions", "unprecedented change", "set", "rules"]], "textrank": [["property information systems common exchange", "electronic data exchange", "software packages", "electronic transfer", "transfer data"], ["property information systems common exchange", "electronic data exchange", "software packages", "electronic transfer", "transfer data", "real estate", "land", "packages", "software", "transfer"]], "positionrank": [["electronic data exchange", "electronic transfer", "data", "hm land registry", "property industry"], ["electronic data exchange", "electronic transfer", "data", "hm land registry", "property industry", "real estate", "property", "software packages", "seamless transfer", "unprecedented change"]], "multipartiterank": [["electronic data exchange", "real estate", "property industry", "hm land registry", "software packages"], ["electronic data exchange", "real estate", "property industry", "hm land registry", "software packages", "consultation", "data", "electronic transfer", "unprecedented change", "one"]]}, {"id": "2137", "text": "Stabilization of a linear object by frequency-modulated pulsed signals\nA control system consisting of an unstable continuous linear part and a\n\tpulse-frequency modulator in the feedback circuit is studied.\n\tConditions for the boundedness of the solutions of the system under any\n\tinitial data are determined\n", "keywords": "discrete systems; stabilization; frequency-modulated pulsed signals; linear\n\tstationary object; control system; feedback circuit; solution\n\tboundedness\n", "topicrank": [["frequency", "control system", "pulse", "linear object", "boundedness"], ["frequency", "control system", "pulse", "linear object", "boundedness", "solutions", "feedback circuit", "conditions", "unstable continuous linear part", "signals"]], "textrank": [["continuous linear", "frequency modulator", "control system", "linear", "system"], ["continuous linear", "frequency modulator", "control system", "linear", "system", "frequency"]], "positionrank": [["linear object", "frequency modulator", "control system", "frequency", "stabilization"], ["linear object", "frequency modulator", "control system", "frequency", "stabilization", "system", "feedback circuit", "signals", "pulse", "conditions"]], "multipartiterank": [["frequency", "control system", "linear object", "signals", "unstable continuous linear part"], ["frequency", "control system", "linear object", "signals", "unstable continuous linear part", "pulse", "stabilization", "frequency modulator", "feedback circuit", "boundedness"]]}, {"id": "280", "text": "Entrepreneurs in Action: a Web-case model\nMuch of the traditional schooling in America is built around systems of\n\tcompliance and control, characteristics which stifle the creative and\n\tentrepreneurial instincts of the children who are subjected to these\n\ttactics. The article explores a different approach to education, one\n\tthat involves capturing the interest of the student through the use of\n\tproblem and project-based instruction delivered via the Internet.\n\tCalled Entrepreneurs in Action, this program seeks to involve students\n\tin a problem at the outset and to promote the learning of traditional\n\tsubject areas as a process of the problem-solving activities that are\n\tundertaken. The program's details are explained, from elementary school\n\tthrough university level courses, and the authors outline their plans\n\tto test the efficacy of the program at each level\n", "keywords": "Entrepreneurs in Action; Web-case model; traditional schooling; America;\n\tentrepreneurial instincts; project-based instruction; Internet;\n\ttraditional subject areas; problem-solving activities; elementary\n\tschool; university level courses\n", "topicrank": [["problem", "program", "traditional schooling", "action", "entrepreneurs"], ["problem", "program", "traditional schooling", "action", "entrepreneurs", "university level courses", "control", "compliance", "project", "subject areas"]], "textrank": [["university level courses", "elementary school", "subject areas", "different approach", "entrepreneurial instincts"], ["university level courses", "elementary school", "subject areas", "different approach", "entrepreneurial instincts", "traditional schooling", "case model", "level", "traditional"]], "positionrank": [["entrepreneurs", "case model", "traditional schooling", "action", "web"], ["entrepreneurs", "case model", "traditional schooling", "action", "web", "problem", "program", "america", "university level courses", "subject areas"]], "multipartiterank": [["problem", "program", "traditional schooling", "action", "entrepreneurs"], ["problem", "program", "traditional schooling", "action", "entrepreneurs", "university level courses", "america", "control", "case model", "much"]]}, {"id": "2013", "text": "Novel denoising algorithm for obtaining a superresolved position estimation\nWe present a new algorithm that uses the randomness of the noise pattern to\n\tachieve high positioning accuracy by applying a modified averaging\n\toperation. Using the suggested approach, noise sensitivity of the\n\tpositioning accuracy can be significantly reduced. This new improved\n\talgorithm can improve the performances of tracking systems used for\n\tmilitary as well as civil applications. The concept is demonstrated\n\ttheoretically as well as by optical experiment\n", "keywords": "denoising algorithm; superresolved position estimation; noise pattern\n\trandomness; high positioning accuracy; modified averaging operation;\n\tnoise sensitivity; tracking systems; military applications; civil\n\tapplications; optical experiment\n", "topicrank": [["algorithm", "noise pattern", "accuracy", "suggested approach", "high"], ["algorithm", "noise pattern", "accuracy", "suggested approach", "high", "performances", "systems", "civil applications", "military", "randomness"]], "textrank": [["suggested approach", "new algorithm", "noise", "position", "civil"], ["suggested approach", "new algorithm", "noise", "position", "civil", "new", "algorithm"]], "positionrank": [["new algorithm", "superresolved position estimation", "algorithm", "noise pattern", "noise sensitivity"], ["new algorithm", "superresolved position estimation", "algorithm", "noise pattern", "noise sensitivity", "accuracy", "suggested approach", "randomness", "civil applications", "systems"]], "multipartiterank": [["algorithm", "noise pattern", "accuracy", "high", "randomness"], ["algorithm", "noise pattern", "accuracy", "high", "randomness", "performances", "suggested approach", "systems", "new", "novel"]]}, {"id": "2056", "text": "Gifts to a science academic librarian\nGifts, by their altruistic nature, perfectly fit into the environment of\n\tuniversities and academic libraries. As a university's community and\n\tgeneral public continue to donate materials, libraries accept donations\n\twillingly, both in-kind and monetary. Eight steps of gift processing\n\tare listed in the paper. Positive and negative aspects of gift\n\tacceptance are discussed. Gifts bring value for academic libraries.\n\tGifts can be considered additional routes to contribute to library\n\tcollections without direct purchases, options to add money to the\n\tlibrary budget, and the cement of social relationships. But,\n\tunfortunately, large donations are time-consuming, labor-intensive and\n\tcostly to process. Great amounts of staff time and processing space are\n\ttwo main negative aspects that cause concern and put the value of gift\n\tacceptance under consideration by librarians. Some strategies in\n\thandling gifts are recommended. To be effective, academic science\n\tlibrarians need to approach gifts as an investment. Librarians are not\n\tto be forced by moral and public notions and should be able to make\n\tprofessional decisions in evaluating proposed collections\n", "keywords": "science academic librarian; academic libraries; donations; gift processing;\n\tlibrary collections; budget; staff time; professional decisions;\n\tresearch libraries; acquisitions; gift books\n", "topicrank": [["gifts", "gift processing", "academic libraries", "librarians", "acceptance"], ["gifts", "gift processing", "academic libraries", "librarians", "acceptance", "negative aspects", "value", "time", "library", "donations"]], "textrank": [["staff time", "great amounts", "large donations", "social relationships", "library budget"], ["staff time", "great amounts", "large donations", "social relationships", "library budget", "direct purchases", "additional routes", "altruistic nature", "academic", "negative"]], "positionrank": [["gifts", "academic science", "academic libraries", "academic librarian", "altruistic nature"], ["gifts", "academic science", "academic libraries", "academic librarian", "altruistic nature", "science", "main negative aspects", "gift processing", "libraries", "negative aspects"]], "multipartiterank": [["gifts", "academic libraries", "gift processing", "donations", "librarians"], ["gifts", "academic libraries", "gift processing", "donations", "librarians", "negative aspects", "value", "acceptance", "gift", "library"]]}, {"id": "359", "text": "Neighborhood operator systems and approximations\nThis paper presents a framework for the study of generalizing the standard\n\tnotion of equivalence relation in rough set approximation space with\n\tvarious categories of k-step neighborhood systems. Based on a binary\n\trelation on a finite universe, six families of binary relations are\n\tobtained, and the corresponding six classes of k-step neighborhood\n\tsystems are derived. Extensions of Pawlak's (1982) rough set\n\tapproximation operators based on such neighborhood systems are\n\tproposed. Properties of neighborhood operator systems and rough set\n\tapproximation operators are investigated, and their connections are\n\texamined\n", "keywords": "neighborhood operator systems; equivalence relation; rough set approximation\n\tspace; k-step neighborhood systems; binary relation; finite universe\n", "topicrank": [["neighborhood operator systems", "rough set approximation space", "equivalence relation", "binary", "approximation operators"], ["neighborhood operator systems", "rough set approximation space", "equivalence relation", "binary", "approximation operators", "notion", "standard", "families", "finite universe", "systems"]], "textrank": [["set approximation", "finite universe", "various categories", "equivalence relation", "neighborhood"], ["set approximation", "finite universe", "various categories", "equivalence relation", "neighborhood", "approximation", "set", "relation", "binary"]], "positionrank": [["neighborhood operator systems", "step neighborhood systems", "such neighborhood systems", "step neighborhood", "rough set"], ["neighborhood operator systems", "step neighborhood systems", "such neighborhood systems", "step neighborhood", "rough set", "systems", "approximation operators", "equivalence relation", "various categories", "binary relations"]], "multipartiterank": [["neighborhood operator systems", "rough set approximation space", "equivalence relation", "rough set", "binary"], ["neighborhood operator systems", "rough set approximation space", "equivalence relation", "rough set", "binary", "approximation operators", "notion", "approximations", "standard", "paper"]]}, {"id": "201", "text": "Correction to construction of panoramic image mosaics with global and local\n\talignment\nFor original paper see ibid., vol. 36, no. 2, p. 101-30 (2000). The authors had\n\tgiven a method for the construction of panoramic image mosaics with\n\tglobal and local alignment. Unfortunately a mistake had led to an\n\tincorrect equation which whilst making little difference in many cases,\n\tfor faster (and assured) convergence, the correct formulae given here\n\tshould be used\n", "keywords": "panoramic image mosaics; global alignment; local alignment; resampled image\n", "topicrank": [["panoramic image mosaics", "global", "alignment", "construction", "local"], ["panoramic image mosaics", "global", "alignment", "construction", "local", "original paper", "little difference", "many cases", "ibid", "method"]], "textrank": [["local alignment .", "incorrect equation", "original paper", ".", "image"], ["local alignment .", "incorrect equation", "original paper", ".", "image", "alignment", "local"]], "positionrank": [["panoramic image mosaics", "local alignment", "construction", "correction", "alignment"], ["panoramic image mosaics", "local alignment", "construction", "correction", "alignment", "original paper", "vol .", "no .", "ibid", "method"]], "multipartiterank": [["panoramic image mosaics", "global", "alignment", "construction", "local"], ["panoramic image mosaics", "global", "alignment", "construction", "local", "original paper", "ibid", "local alignment", "little difference", "correction"]]}, {"id": "244", "text": "Symbiosis or alienation: advancing the university press/research library\n\trelationship through electronic scholarly communication\nUniversity presses and research libraries have a long tradition of\n\tcollaboration. The rapidly expanding electronic scholarly communication\n\tenvironment offers important new opportunities for cooperation and for\n\tinnovative new models of publishing. The economics of libraries and\n\tscholarly publishers have strained the working relationship and\n\tpromoted debates on important information policy issues. This article\n\texplores the context for advancing the partnership, cites examples of\n\tjoint efforts in electronic publishing, and presents an action plan for\n\tworking together\n", "keywords": "university press/research library relationship; electronic scholarly\n\tcommunication; economics; information policy; electronic publishing\n", "topicrank": [["electronic scholarly communication", "research libraries", "university press", "publishing", "relationship"], ["electronic scholarly communication", "research libraries", "university press", "publishing", "relationship", "important new opportunities", "environment", "innovative new models", "economics", "important information policy issues"]], "textrank": [["important information policy", "important new", "electronic scholarly", "new", "joint efforts"], ["important information policy", "important new", "electronic scholarly", "new", "joint efforts", "long tradition", "scholarly", "research", "university", "electronic"]], "positionrank": [["electronic scholarly communication", "university press", "research library", "research libraries", "university presses"], ["electronic scholarly communication", "university press", "research library", "research libraries", "university presses", "electronic publishing", "important new opportunities", "scholarly publishers", "symbiosis", "innovative new models"]], "multipartiterank": [["university press", "electronic scholarly communication", "research libraries", "relationship", "publishing"], ["university press", "electronic scholarly communication", "research libraries", "relationship", "publishing", "research library", "important new opportunities", "university presses", "innovative new models", "economics"]]}, {"id": "1982", "text": "Verifying resonant grounding in distribution systems\nThe authors describe RESFAL, a software tool that can check on the behavior of\n\tdistribution network resonant grounding systems with regard to\n\tcompensation coil tuning and to fault detection\n", "keywords": "RESFAL software tool; resonant grounding systems; compensation coil tuning;\n\tfault detection; computer simulation; power distribution systems\n", "topicrank": [["distribution systems", "distribution network resonant", "regard", "resfal", "authors"], ["distribution systems", "distribution network resonant", "regard", "resfal", "authors", "software tool", "compensation coil tuning", "behavior", "resonant grounding", "detection"]], "textrank": [["distribution network resonant", "coil", "distribution", "resonant"], ["distribution network resonant", "coil", "distribution", "resonant"]], "positionrank": [["distribution network resonant", "distribution systems", "resonant grounding", "compensation coil tuning", "systems"], ["distribution network resonant", "distribution systems", "resonant grounding", "compensation coil tuning", "systems", "software tool", "authors", "resfal", "regard", "behavior"]], "multipartiterank": [["distribution systems", "authors", "resfal", "resonant grounding", "distribution network resonant"], ["distribution systems", "authors", "resfal", "resonant grounding", "distribution network resonant", "software tool", "regard", "systems", "behavior", "compensation coil tuning"]]}, {"id": "2176", "text": "Why your Web strategy is, err, wrong\nAn awkward look at a few standard views from the author, who thinks that most\n\tpeople have got it, err, wrong. Like every other investment, when the\n\ttime comes to sign the contract, the question that should be asked is\n\tnot whether it is a good investment, but whether it is the best\n\tinvestment the firm can make with the money. the author argues that he\n\twould be surprised if any law firm Web site he has seen yet would jump\n\tthat particular hurdle\n", "keywords": "Web strategy; law firm Web site\n", "topicrank": [["good investment", "wrong", "author", "firm", "best"], ["good investment", "wrong", "author", "firm", "best", "err", "money", "contract", "awkward look", "surprised"]], "textrank": [["firm web", "particular hurdle", "awkward look", "web", "investment"], ["firm web", "particular hurdle", "awkward look", "web", "investment", "standard", "firm"]], "positionrank": [["few standard views", "web strategy", "awkward look", "wrong", "author"], ["few standard views", "web strategy", "awkward look", "wrong", "author", "other investment", "err", "good investment", "firm", "investment"]], "multipartiterank": [["good investment", "wrong", "author", "best", "firm"], ["good investment", "wrong", "author", "best", "firm", "err", "investment", "money", "contract", "question"]]}, {"id": "2133", "text": "Nonlockability in multirings and hypercubes at serial transmission of data\n\tblocks\nFor the multiring and hypercube, a method of conflictless realization of an\n\tarbitrary permutation of \"large\" data items that can be divided into\n\tmany \"smaller\" data blocks was considered, and its high efficiency was\n\tdemonstrated\n", "keywords": "nonlockability; multirings; hypercubes; data block serial transmission;\n\tmultiprocessor computer systems\n", "topicrank": [["data", "blocks", "serial transmission", "hypercubes", "hypercube"], ["data", "blocks", "serial transmission", "hypercubes", "hypercube", "method", "multirings", "multiring", "conflictless realization", "smaller"]], "textrank": [["conflictless realization", "serial transmission", "data", "arbitrary"], ["conflictless realization", "serial transmission", "data", "arbitrary"]], "positionrank": [["data blocks", "data items", "serial transmission", "data", "nonlockability"], ["data blocks", "data items", "serial transmission", "data", "nonlockability", "blocks", "multirings", "hypercubes", "conflictless realization", "arbitrary permutation"]], "multipartiterank": [["data", "blocks", "serial transmission", "hypercubes", "multirings"], ["data", "blocks", "serial transmission", "hypercubes", "multirings", "multiring", "hypercube", "method", "conflictless realization", "nonlockability"]]}, {"id": "284", "text": "Project-based learning: teachers learning and using high-tech to preserve Cajun\n\tculture\nUsing project-based learning pedagogy in EdTc 658 Advances in Educational\n\tTechnology, the author has trained inservice teachers in Southwestern\n\tLouisiana with an advanced computer multimedia program called\n\tDirector(R) (Macromedia, Inc.). The content of this course focused on\n\tmodeling the project-based learning pedagogy and researching Acadian's\n\ttraditions and legacy. With the multi-functions of microcomputers, new\n\ttechnologies were used to preserve and celebrate the local culture with\n\tsuperiority of text, graphics, animation, sound, and video. The article\n\tdescribes how several groups of school teachers in the surrounding\n\tareas of a regional state university of Louisiana learned computer\n\tmultimedia using project-based learning and integrated their learning\n\tinto local cultural heritage\n", "keywords": "project-based learning; teachers; Cajun culture; project-based learning\n\tpedagogy; EdTc 658 Advances in Educational Technology; inservice\n\tteachers; advanced computer multimedia program; Director; Acadian\n\ttraditions; Macromedia; new technologies; local culture; school\n\tteachers; regional state university; computer multimedia; local\n\tcultural heritage\n", "topicrank": [["project", "teachers", "learning", "louisiana", "culture"], ["project", "teachers", "learning", "louisiana", "culture", "pedagogy", "graphics", "animation", "advances", "text"]], "textrank": [["regional state university", "multi - functions", "local cultural", "computer multimedia", "school teachers"], ["regional state university", "multi - functions", "local cultural", "computer multimedia", "school teachers", "inservice teachers", "several groups", "local culture", "teachers", "-"]], "positionrank": [["project", "inservice teachers", "school teachers", "learning", "teachers"], ["project", "inservice teachers", "school teachers", "learning", "teachers", "local culture", "regional state university", "local cultural heritage", "multimedia", "louisiana"]], "multipartiterank": [["project", "teachers", "learning", "culture", "pedagogy"], ["project", "teachers", "learning", "culture", "pedagogy", "louisiana", "cajun", "tech", "high", "advances"]]}, {"id": "1942", "text": "Precoded OFDM with adaptive vector channel allocation for scalable video\n\ttransmission over frequency-selective fading channels\nOrthogonal frequency division multiplexing (OFDM) has been applied in broadband\n\twireline and wireless systems for high data rate transmission where\n\tsevere intersymbol interference (ISI) always occurs. The conventional\n\tOFDM system provides advantages through conversion of an ISI channel\n\tinto ISI-free subchannels at multiple frequency bands. However, it may\n\tsuffer from channel spectral nulls and heavy data rate overhead due to\n\tcyclic prefix insertion. Previously, a new OFDM framework, the precoded\n\tOFDM, has been proposed to mitigate the above two problems through\n\tprecoding and conversion of an ISI channel into ISI-free vector\n\tchannels. In this paper, we consider the application of the precoded\n\tOFDM system to efficient scalable video transmission. We propose to\n\tenhance the precoded OFDM system with adaptive vector channel\n\tallocation to provide stronger protection against errors to more\n\timportant layers in the layered bit stream structure of scalable video.\n\tThe more critical layers, or equivalently, the lower layers, are\n\tallocated vector channels of higher transmission quality. The channel\n\tquality is characterized by Frobenius norm metrics; based on channel\n\testimation at the receiver. The channel allocation information is fed\n\tback periodically to the transmitter through a control channel.\n\tSimulation results have demonstrated the robustness of the proposed\n\tscheme to noise and fading inherent in wireless channels\n", "keywords": "precoded OFDM; scalable video transmission; frequency-selective fading\n\tchannels; orthogonal frequency division multiplexing; channel spectral\n\tnulls; heavy data rate overhead; ISI channel; ISI-free vector channels;\n\tadaptive vector channel allocation; layered bit stream structure; lower\n\tlayers; critical layers; channel quality; Frobenius norm metrics;\n\tchannel estimation; channel allocation information; control channel;\n\trobustness\n", "topicrank": [["ofdm", "isi", "channels", "channel spectral nulls", "scalable video"], ["ofdm", "isi", "channels", "channel spectral nulls", "scalable video", "free subchannels", "important layers", "conversion", "transmission", "adaptive vector channel allocation"]], "textrank": [["vector channel allocation", "data rate transmission", "vector channel", "scalable video transmission", "channel allocation"], ["vector channel allocation", "data rate transmission", "vector channel", "scalable video transmission", "channel allocation", "channel spectral", "frequency division", "free vector", "vector channels", "data rate"]], "positionrank": [["adaptive vector channel", "isi channel", "channel allocation information", "ofdm system", "new ofdm framework"], ["adaptive vector channel", "isi channel", "channel allocation information", "ofdm system", "new ofdm framework", "channel spectral nulls", "control channel", "vector channels", "ofdm", "channel"]], "multipartiterank": [["ofdm", "isi", "channels", "scalable video", "frequency"], ["ofdm", "isi", "channels", "scalable video", "frequency", "adaptive vector channel allocation", "channel spectral nulls", "transmission", "high data rate transmission", "free subchannels"]]}, {"id": "279", "text": "Computer mediated communication and university international students\nThe design for the preliminary study presented was based on the experiences of\n\tthe international students and faculty members of a small southwest\n\tuniversity being surveyed and interviewed. The data collection\n\tprocedure blends qualitative and quantitative data. A strong consensus\n\twas found that supports the study's premise that there is an\n\tassociation between the use of computer mediated communication (CMC)\n\tand teaching and learning performance of international students. Both\n\tgroups believe CMC to be an effective teaching and learning tool by:\n\tincreasing the frequency and quality of communication between students\n\tand instructors; improving language skills through increased writing\n\tand communication opportunities; allowing students and instructors to\n\tstay current and to compete effectively; providing alternative teaching\n\tand learning methods to increase students' confidence in their ability\n\tto communicate effectively with peers and instructors; and improving\n\tthe instructors' pedagogical focus and questioning techniques\n", "keywords": "computer mediated communication; university international students; faculty\n\tmembers; small southwest university; data collection procedure;\n\tquantitative data; qualitative data; CMC; teaching; learning\n\tperformance; language skills; communication opportunities; instructors;\n\tstudent confidence; peers; pedagogical focus; questioning techniques\n", "topicrank": [["university international students", "communication", "instructors", "teaching", "cmc"], ["university international students", "communication", "instructors", "teaching", "cmc", "computer", "data collection", "preliminary study", "quality", "use"]], "textrank": [["language skills", "strong consensus", "small southwest", "faculty members", "preliminary study"], ["language skills", "strong consensus", "small southwest", "faculty members", "preliminary study", "teaching", "blends", "data", "international", "study"]], "positionrank": [["international students", "students", "communication opportunities", "computer", "communication"], ["international students", "students", "communication opportunities", "computer", "communication", "preliminary study", "university", "effective teaching", "alternative teaching", "teaching"]], "multipartiterank": [["university international students", "communication", "computer", "instructors", "teaching"], ["university international students", "communication", "computer", "instructors", "teaching", "preliminary study", "students", "cmc", "international students", "data collection"]]}, {"id": "364", "text": "MACLP: multi agent constraint logic programming\nMulti agent systems (MAS) have become the key technology for decomposing\n\tcomplex problems in order to solve them more efficiently, or for\n\tproblems distributed in nature. However, many industrial applications,\n\tbesides their distributed nature, also involve a large number of\n\tparameters and constraints, i.e. they are combinatorial. Solving such\n\tparticularly hard problems efficiently requires programming tools that\n\tcombine MAS technology with a programming schema that facilitates the\n\tmodeling and solution of constraints. This paper presents MACLP (multi\n\tagent constraint logic programming), a logic programming platform for\n\tbuilding, in a declarative way, multi agent systems with\n\tconstraint-solving capabilities. MACLP extends CSPCONS, a logic\n\tprogramming system that permits distributed program execution through\n\tcommunicating sequential Prolog processes with constraints, by\n\tproviding all the necessary facilities for communication between\n\tagents. These facilities abstract from the programmer all the low-level\n\tdetails of the communication and allow him to focus on the development\n\tof the agent itself\n", "keywords": "multi agent constraint logic programming; multi agent systems; parameters;\n\tcombinatorial problems; hard problems; constraint solving; distributed\n\tprogram execution; communicating sequential Prolog processes\n", "topicrank": [["multi agent constraint logic programming", "maclp", "constraints", "programming tools", "multi agent systems"], ["multi agent constraint logic programming", "maclp", "constraints", "programming tools", "multi agent systems", "complex problems", "necessary facilities", "communication", "mas", "nature"]], "textrank": [["agent constraint logic programming", "logic programming", "programming", "mas technology", "program execution"], ["agent constraint logic programming", "logic programming", "programming", "mas technology", "program execution", "declarative way", "large number", "agent", "facilities", "prolog"]], "positionrank": [["multi agent systems", "logic programming platform", "programming tools", "programming system", "programming schema"], ["multi agent systems", "logic programming platform", "programming tools", "programming system", "programming schema", "maclp", "agent", "logic", "constraint", "mas technology"]], "multipartiterank": [["multi agent constraint logic programming", "multi agent systems", "maclp", "complex problems", "constraints"], ["multi agent constraint logic programming", "multi agent systems", "maclp", "complex problems", "constraints", "programming tools", "mas", "nature", "communication", "necessary facilities"]]}, {"id": "2096", "text": "A spatial rainfall simulator for crop production modeling in Southern Africa\nThis paper describes a methodology for simulating rainfall in dekads across a\n\tset of spatial units in areas where long-term meteorological records\n\tare available for a small number of sites only. The work forms part of\n\ta larger simulation model of the food system in a district of Zimbabwe,\n\twhich includes a crop production component for yields of maize, small\n\tgrains and groundnuts. Only a limited number of meteorological stations\n\tare available within or surrounding the district that have long time\n\tseries of rainfall records. Preliminary analysis of rainfall data for\n\tthese stations suggested that intra-seasonal temporal correlation was\n\tnegligible, but that rainfall at any given station was correlated with\n\trainfall at neighbouring stations. This spatial correlation structure\n\tcan be modeled using a multivariate normal distribution consisting of\n\t30 related variables, representing dekadly rainfall in each of the 30\n\twards. For each ward, log-transformed rainfall for each of the 36\n\tdekads in the year was characterized by a mean and standard deviation,\n\twhich were interpolated from surrounding meteorological stations. A\n\tcovariance matrix derived from a distance measure was then used to\n\trepresent the spatial correlation between wards. Sets of random numbers\n\twere then drawn from this distribution to simulate rainfall across the\n\twards in any given dekad. Cross-validation of estimated rainfall\n\tparameters against observed parameters for the one meteorological\n\tstation within the district suggests that the interpolation process\n\tworks well. The methodology developed is useful in situations where\n\tlong-term climatic records are scarce and where rainfall shows\n\tpronounced spatial correlation, but negligible temporal correlation\n", "keywords": "simulating rainfall; crop production modeling; Zimbabwe; covariance matrix;\n\trainfall records; rainfall data; spatial correlation; multivariate\n\tnormal distribution; parameter estimation; Southern Africa\n", "topicrank": [["spatial rainfall simulator", "spatial units", "long", "district", "meteorological stations"], ["spatial rainfall simulator", "spatial units", "long", "district", "meteorological stations", "wards", "small number", "term meteorological records", "crop production modeling", "available"]], "textrank": [["- seasonal temporal correlation", "spatial rainfall", "rainfall records", "spatial correlation", "long -"], ["- seasonal temporal correlation", "spatial rainfall", "rainfall records", "spatial correlation", "long -", "temporal correlation", "meteorological records", "meteorological stations", "rainfall", "-"]], "positionrank": [["spatial rainfall simulator", "rainfall records", "pronounced spatial correlation", "spatial correlation structure", "rainfall shows"], ["spatial rainfall simulator", "rainfall records", "pronounced spatial correlation", "spatial correlation structure", "rainfall shows", "rainfall data", "spatial correlation", "rainfall", "crop production modeling", "spatial units"]], "multipartiterank": [["spatial rainfall simulator", "crop production modeling", "rainfall", "spatial units", "long"], ["spatial rainfall simulator", "crop production modeling", "rainfall", "spatial units", "long", "southern africa", "small number", "term meteorological records", "district", "methodology"]]}, {"id": "321", "text": "A multimodal data collection tool using REALbasic and Mac OS X\nThis project uses REALbasic 3.5 in the Mac OS X environment for development of\n\ta configuration tool that builds a data collection procedure for\n\tinvestigating the effectiveness of sonified graphs. The advantage of\n\tusing REALbasic with the Mac OS X system is that it provides rapid\n\tdevelopment of stimulus presentation, direct recording of data to\n\tfiles, and control over other procedural issues. The program can be\n\tmade to run natively on the new Mac OS X system, older Mac OS systems,\n\tand Windows (98SE, ME, 2000 PRO). With modification, similar programs\n\tcould be used to present any number of visual/auditory stimulus\n\tcombinations, complete with questions for each stimulus\n", "keywords": "multimodal data collection tool; REALbasic; Mac OS X environment; configuration\n\ttool; data collection; sonified graphs; visual data comprehension;\n\tpsychology; visual stimulus; auditory stimulus; stimulus presentation;\n\tdirect data recording; Windows\n", "topicrank": [["stimulus presentation", "multimodal data collection tool", "realbasic", "development", "direct recording"], ["stimulus presentation", "multimodal data collection tool", "realbasic", "development", "direct recording", "combinations", "complete", "visual", "questions", "number"]], "textrank": [["mac os x", "data collection tool", "mac os", "data collection", "other procedural"], ["mac os x", "data collection tool", "mac os", "data collection", "other procedural", "stimulus presentation", "similar programs", "direct recording", "stimulus", "data"]], "positionrank": [["mac os x", "data collection procedure", "configuration tool", "data", "realbasic"], ["mac os x", "data collection procedure", "configuration tool", "data", "realbasic", "development", "stimulus presentation", "auditory stimulus", "other procedural issues", "direct recording"]], "multipartiterank": [["multimodal data collection tool", "realbasic", "stimulus presentation", "development", "direct recording"], ["multimodal data collection tool", "realbasic", "stimulus presentation", "development", "direct recording", "project", "rapid", "data", "graphs", "files"]]}, {"id": "399", "text": "Low-voltage DRAM sensing scheme with offset-cancellation sense amplifier\nA novel bitline sensing scheme is proposed for low-voltage DRAM to achieve low\n\tpower dissipation and compatibility with low-voltage CMOS. One of the\n\tmajor obstacles in low-voltage DRAM is the degradation of\n\tdata-retention time due to low signal level at the memory cell, which\n\trequires power-consuming refresh operations more frequently. This paper\n\tproposes an offset-cancellation sense-amplifier scheme (OCSA) that\n\timproves data-retention time significantly even at low supply voltage.\n\tIt also improves die efficiency, because the proposed scheme reduces\n\tthe number of sense amplifiers by supporting more cells in each sense\n\tamplifier. Measurements show that the data-retention time of the\n\tproposed scheme at 1.5-V supply voltage is 2.4 times of the\n\tconventional scheme at 2.0 V\n", "keywords": "LV DRAM sensing scheme; low-voltage sensing scheme; offset-cancellation sense\n\tamplifier scheme; bitline sensing scheme; low power dissipation;\n\tlow-voltage CMOS compatibility; data-retention time; memory cell;\n\tdifferential amplifier configuration; power-consuming refresh\n\toperations; sensing margin; 1.5 V\n", "topicrank": [["low", "cancellation sense amplifier", "voltage dram sensing scheme", "data", "retention time"], ["low", "cancellation sense amplifier", "voltage dram sensing scheme", "data", "retention time", "voltage cmos", "amplifier scheme", "power dissipation", "scheme", "offset"]], "textrank": [["bitline sensing scheme", "low supply voltage", "sensing scheme", "sense amplifier", "supply voltage"], ["bitline sensing scheme", "low supply voltage", "sensing scheme", "sense amplifier", "supply voltage", "amplifier scheme", "low signal", "power dissipation", "sense", "voltage"]], "positionrank": [["low supply voltage", "voltage dram", "low signal level", "cancellation sense amplifier", "amplifier scheme"], ["low supply voltage", "voltage dram", "low signal level", "cancellation sense amplifier", "amplifier scheme", "supply voltage", "voltage cmos", "conventional scheme", "cancellation sense", "scheme"]], "multipartiterank": [["low", "voltage dram sensing scheme", "cancellation sense amplifier", "offset", "voltage cmos"], ["low", "voltage dram sensing scheme", "cancellation sense amplifier", "offset", "voltage cmos", "voltage dram", "power dissipation", "retention time", "data", "amplifier scheme"]]}, {"id": "218", "text": "ISCSI poised to lower SAN costs\nIT managers building storage area networks or expanding their capacity may be\n\table to save money by using iSCSI and IP systems rather than Fibre\n\tChannel technologies\n", "keywords": "SAN costs; storage area networks; iSCSI; IP systems\n", "topicrank": [["iscsi", "ip systems", "money", "fibre", "able"], ["iscsi", "ip systems", "money", "fibre", "able", "channel technologies", "capacity", "storage area networks", "lower san costs"]], "textrank": [["it managers", "area", "san", "ip"], ["it managers", "area", "san", "ip"]], "positionrank": [["lower san costs", "storage area networks", "iscsi", "it managers", "ip systems"], ["lower san costs", "storage area networks", "iscsi", "it managers", "ip systems", "channel technologies", "capacity", "money", "fibre"]], "multipartiterank": [["iscsi", "ip systems", "money", "fibre", "able"], ["iscsi", "ip systems", "money", "fibre", "able", "channel technologies", "capacity", "storage area networks", "lower san costs"]]}, {"id": "1966", "text": "Application of nonlinear time series analysis techniques to high-frequency\n\tcurrency exchange data\nIn this work we have applied nonlinear time series analysis to high-frequency\n\tcurrency exchange data. The time series studied are the exchange rates\n\tbetween the US Dollar and 18 other foreign currencies from within and\n\twithout the Euro zone. Our goal was to determine if their dynamical\n\tbehaviours were in some way correlated. The nonexistence of\n\tstationarity called for the application of recurrence quantification\n\tanalysis as a tool for this analysis, and is based on the definition of\n\tseveral parameters that allow for the quantification of recurrence\n\tplots. The method was checked using the European Monetary System\n\tcurrency exchanges. The results show, as expected, the high correlation\n\tbetween the currencies that are part of the Euro, but also a strong\n\tcorrelation between the Japanese Yen, the Canadian Dollar and the\n\tBritish Pound. Singularities of the series are also demonstrated taking\n\tinto account historical events, in 1996, in the Euro zone\n", "keywords": "nonlinear time series; high-frequency currency exchange data; exchange rates;\n\tUS Dollar; foreign currencies; Euro zone; stationarity; recurrence\n\tquantification analysis; recurrence plots; European Monetary System;\n\tJapanese Yen; Canadian Dollar; British Pound; historical events;\n\teconophysics; nonlinear dynamics\n", "topicrank": [["nonlinear time series analysis techniques", "recurrence quantification", "euro zone", "frequency", "analysis"], ["nonlinear time series analysis techniques", "recurrence quantification", "euro zone", "frequency", "analysis", "high", "high correlation", "currency exchange data", "application", "us dollar"]], "textrank": [["time series analysis", "currency exchange", "time series", "several parameters", "recurrence quantification"], ["time series analysis", "currency exchange", "time series", "several parameters", "recurrence quantification", "euro zone", "exchange", "historical", "monetary", "foreign"]], "positionrank": [["currency exchange data", "time series", "series", "analysis", "application"], ["currency exchange data", "time series", "series", "analysis", "application", "high correlation", "exchange rates", "currency exchanges", "recurrence quantification", "frequency"]], "multipartiterank": [["nonlinear time series analysis techniques", "high", "application", "frequency", "recurrence quantification"], ["nonlinear time series analysis techniques", "high", "application", "frequency", "recurrence quantification", "currency exchange data", "analysis", "euro zone", "high correlation", "us dollar"]]}, {"id": "2152", "text": "Virtual engineering office: a state-of-the-art platform for engineering\n\tcollaboration\nA sales force in Latin America, the design department in Europe, and production\n\tin Asia? Arrangements of this kind are the new business reality for\n\ttoday's global manufacturing companies. But how are such global\n\toperations to be effectively coordinated? ABB's answer was to develop\n\tand implement a new platform for high-performance, real-time\n\tcollaboration. Globally distributed engineering teams can now work\n\ttogether, regardless of time, location or the CAD system they use,\n\tmaking ABB easier to do business with, for customers as well as\n\tsuppliers\n", "keywords": "virtual engineering office; state-of-the-art; engineering collaboration\n\tplatform; business; global manufacturing companies; ABB; CAD system;\n\tglobally distributed engineering teams\n", "topicrank": [["virtual engineering office", "collaboration", "time", "art platform", "new business reality"], ["virtual engineering office", "collaboration", "time", "art platform", "new business reality", "abb", "performance", "real", "high", "asia"]], "textrank": [["global manufacturing", "new platform", "new business", "design department", "latin america"], ["global manufacturing", "new platform", "new business", "design department", "latin america", "sales force", "engineering", "global", "business", "platform"]], "positionrank": [["virtual engineering office", "engineering teams", "engineering", "art platform", "new platform"], ["virtual engineering office", "engineering teams", "engineering", "art platform", "new platform", "sales force", "state", "latin america", "new business reality", "collaboration"]], "multipartiterank": [["virtual engineering office", "art platform", "collaboration", "state", "new business reality"], ["virtual engineering office", "art platform", "collaboration", "state", "new business reality", "time", "abb", "sales force", "design department", "latin america"]]}, {"id": "2117", "text": "The p-p rearrangement and failure-tolerance of double p-ary multirings and\n\tgeneralized hypercubes\nIt is shown that an arbitrary grouped p-element permutation can be implemented\n\tin a conflict-free way through the commutation of channels on the\n\tdouble p-ary multiring or the double p-ary hypercube. It is revealed\n\tthat in arbitrary single-element permutations, these commutators\n\tdisplay the property of the (p-1)-nodal failure-tolerance and the\n\tgeneralized hypercube displays in addition the property of the\n\t(p-1)-channel failure-tolerance\n", "keywords": "p-p rearrangement; failure-tolerance; double p-ary multirings; generalized\n\thypercubes; p-element permutation; conflict-free implementation;\n\tsingle-element permutations; commutators\n", "topicrank": [["failure", "tolerance", "ary multirings", "element permutation", "property"], ["failure", "tolerance", "ary multirings", "element permutation", "property", "arbitrary", "free way", "addition", "commutation", "hypercube displays"]], "textrank": [["ary hypercube", "free way", "ary", "element", "p"], ["ary hypercube", "free way", "ary", "element", "p", "hypercube", "arbitrary"]], "positionrank": [["double p", "p rearrangement", "p", "ary hypercube", "ary multiring"], ["double p", "p rearrangement", "p", "ary hypercube", "ary multiring", "ary multirings", "failure", "tolerance", "hypercube displays", "element permutation"]], "multipartiterank": [["tolerance", "failure", "ary multirings", "element permutation", "arbitrary"], ["tolerance", "failure", "ary multirings", "element permutation", "arbitrary", "property", "free way", "commutation", "conflict", "hypercubes"]]}, {"id": "340", "text": "Temelin casts its shadow [nuclear power plant]\nReservations about Temelin nuclear plant in the Czech Republic are political\n\trather than technical. This paper discusses the problems of\n\tturbogenerator vibrations and how they were diagnosed. The paper also\n\tdiscusses some of the other problems of commissioning the power plant.\n\tThe simulator used for training new staff is also mentioned\n", "keywords": "Temelin nuclear plant; Czech Republic; turbogenerator vibrations; power plant\n\tcommissioning; training simulator\n", "topicrank": [["nuclear power plant", "paper", "czech republic", "political", "reservations"], ["nuclear power plant", "paper", "czech republic", "political", "reservations", "technical", "problems", "shadow", "turbogenerator vibrations", "temelin"]], "textrank": [["turbogenerator vibrations", "czech republic", "nuclear", "problems"], ["turbogenerator vibrations", "czech republic", "nuclear", "problems"]], "positionrank": [["nuclear power plant", "nuclear plant", "power plant", "temelin", "czech republic"], ["nuclear power plant", "nuclear plant", "power plant", "temelin", "czech republic", "other problems", "reservations", "shadow", "paper", "problems"]], "multipartiterank": [["nuclear power plant", "paper", "shadow", "reservations", "czech republic"], ["nuclear power plant", "paper", "shadow", "reservations", "czech republic", "political", "technical", "temelin", "temelin nuclear plant", "problems"]]}, {"id": "305", "text": "Full-screen ultrafast video modes over-clocked by simple VESA routines and\n\tregisters reprogramming under MS-DOS\nFast full-screen presentation of stimuli is necessary in psychological\n\tresearch. Although Spitczok von Brisinski (1994) introduced a method\n\tthat achieved ultrafast display by reprogramming the registers, he\n\tcould not produce an acceptable full-screen display. In this report,\n\tthe author introduces a new method combining VESA routine calling with\n\tregister reprogramming that can yield a display at 640 * 480\n\tresolution, with a refresh rate of about 150 Hz\n", "keywords": "full-screen ultrafast video modes; fast full-screen stimuli presentation;\n\tpsychological research; VESA routine calling; MS-DOS; register\n\treprogramming\n", "topicrank": [["full", "ultrafast display", "method", "registers", "necessary"], ["full", "ultrafast display", "method", "registers", "necessary", "stimuli", "screen presentation", "psychological", "research", "vesa routine calling"]], "textrank": [["screen ultrafast video", "vesa routine", "new method", "vesa", "von"], ["screen ultrafast video", "vesa routine", "new method", "vesa", "von", "full", "screen", "ultrafast", "refresh", "method"]], "positionrank": [["screen display", "screen presentation", "simple vesa routines", "ultrafast display", "vesa routine calling"], ["screen display", "screen presentation", "simple vesa routines", "ultrafast display", "vesa routine calling", "new method", "spitczok von brisinski", "registers", "display", "method"]], "multipartiterank": [["full", "screen ultrafast video modes", "ultrafast display", "registers", "method"], ["full", "screen ultrafast video modes", "ultrafast display", "registers", "method", "screen presentation", "necessary", "simple vesa routines", "psychological", "stimuli"]]}, {"id": "338", "text": "Down up [IT projects]\nDespite the second quarter's gloomy GDP report, savvy CIOs are forging ahead\n\twith big IT projects that will position their companies to succeed when\n\tthe economy soars again\n", "keywords": "strategic technology projects; Walgreen; Ford; Caterpillar; Victoria's Secret;\n\tMorgan Stanley; Staples\n", "topicrank": [["gloomy gdp report", "savvy cios", "second quarter", "companies", "economy"], ["gloomy gdp report", "savvy cios", "second quarter", "companies", "economy"]], "textrank": [["gdp", "it", "second"], ["gdp", "it", "second"]], "positionrank": [["big it projects", "it projects", "gloomy gdp report", "savvy cios", "second quarter"], ["big it projects", "it projects", "gloomy gdp report", "savvy cios", "second quarter", "companies", "economy"]], "multipartiterank": [["gloomy gdp report", "savvy cios", "second quarter", "companies", "economy"], ["gloomy gdp report", "savvy cios", "second quarter", "companies", "economy"]]}, {"id": "2037", "text": "Regularization of linear regression problems\nThe study considers robust estimation of linear regression parameters by the\n\tregularization method, the pseudoinverse method, and the Bayesian\n\tmethod allowing for correlations and errors in the data. Regularizing\n\talgorithms are constructed and their relationship with pseudoinversion,\n\tthe Bayesian approach, and BLUE is investigated\n", "keywords": "linear regression problems regularization; robust estimation; linear regression\n\tparameters; pseudoinverse method; Bayesian method; pseudoinversion;\n\tBayesian approach; BLUE\n", "topicrank": [["pseudoinverse method", "bayesian", "linear regression problems", "regularization", "correlations"], ["pseudoinverse method", "bayesian", "linear regression problems", "regularization", "correlations", "errors", "robust estimation", "data", "relationship", "study"]], "textrank": [["bayesian approach", "robust estimation", "regression", "method", "bayesian"], ["bayesian approach", "robust estimation", "regression", "method", "bayesian"]], "positionrank": [["linear regression problems", "linear regression parameters", "regularization method", "robust estimation", "regularization"], ["linear regression problems", "linear regression parameters", "regularization method", "robust estimation", "regularization", "pseudoinverse method", "method", "study", "bayesian approach", "correlations"]], "multipartiterank": [["regularization", "linear regression problems", "pseudoinverse method", "bayesian", "study"], ["regularization", "linear regression problems", "pseudoinverse method", "bayesian", "study", "robust estimation", "correlations", "errors", "linear regression parameters", "method"]]}, {"id": "380", "text": "Quantitative speed control for SRM drive using fuzzy adapted inverse model\nQuantitative and robust speed control for a switched reluctance motor (SRM)\n\tdrive is considered to be rather difficult and challenging owing to its\n\thighly nonlinear dynamic behavior. A speed control scheme having\n\ttwo-degree-of-freedom (2DOF) structure is developed here to improve the\n\tspeed dynamic response of an SRM drive. In the proposed control scheme,\n\tthe feedback controller is quantitatively designed to meet the desired\n\tregulation control requirements first. Then a reference model and a\n\tcommand feedforward controller based on an inverse plant model are\n\temployed to yield the desired tracking response at nominal case. As the\n\tvariations of system parameters and operating conditions occur, the\n\tprescribed control specifications may not be satisfied any more. To\n\timprove this, the inverse model is adaptively tuned by a fuzzy control\n\tscheme so that the model-following tracking error is significantly\n\treduced. In addition, a simple disturbance cancellation robust\n\tcontroller is added to improve the tracking and regulation control\n\tperformances further\n", "keywords": "quantitative speed control; SRM drive; fuzzy adapted inverse model; switched\n\treluctance motor; nonlinear dynamic behavior; two-degree-of-freedom\n\tstructure; speed dynamic response; regulation control requirements;\n\treference model; command feedforward controller; inverse plant model;\n\ttracking response; system parameters; operating conditions; control\n\tspecifications; fuzzy control scheme; model-following tracking error;\n\tdisturbance cancellation controller\n", "topicrank": [["inverse model", "srm drive", "speed control scheme", "tracking response", "feedback controller"], ["inverse model", "srm drive", "speed control scheme", "tracking response", "feedback controller", "fuzzy", "quantitative speed control", "regulation control requirements", "2dof", "system parameters"]], "textrank": [["robust speed control", "speed control", "speed dynamic response", "control", "disturbance cancellation robust"], ["robust speed control", "speed control", "speed dynamic response", "control", "disturbance cancellation robust", "feedforward controller", "tracking response", "reluctance motor", "srm drive", "dynamic"]], "positionrank": [["quantitative speed control", "robust speed control", "speed control scheme", "fuzzy control", "control scheme"], ["quantitative speed control", "robust speed control", "speed control scheme", "fuzzy control", "control scheme", "regulation control requirements", "prescribed control specifications", "regulation control", "inverse plant model", "srm drive"]], "multipartiterank": [["quantitative speed control", "srm drive", "inverse model", "speed control scheme", "fuzzy"], ["quantitative speed control", "srm drive", "inverse model", "speed control scheme", "fuzzy", "feedback controller", "tracking response", "quantitative", "regulation control requirements", "2dof"]]}, {"id": "33", "text": "Fuzzy control of multivariable process by modified error decoupling\nIn this paper, a control concept for the squared (equal number of inputs and\n\toutputs) multivariable process systems is given. The proposed control\n\tsystem consists of two parts, single loop fuzzy controllers in each\n\tloop and a centralized decoupling unit. The fuzzy control system uses\n\tfeedback control to minimize the error in the loop and the decoupler\n\tuses an adaptive technique to mitigate loop interactions. The decoupler\n\tpredicts the interacting loop changes and modifies the input (error) of\n\tthe loop controller. The controller was tested on the simulation model\n\tof \"single component vaporizer\" process\n", "keywords": "multivariable process; modified error decoupling; squared multivariable process\n\tsystems; square multivariable process systems; single-loop fuzzy\n\tcontrollers; centralized decoupling unit; feedback control; error\n\tminimization; loop interaction mitigation; single component vaporizer\n\tprocess; set point changes; load changes\n", "topicrank": [["fuzzy control", "loop", "modified error decoupling", "multivariable process", "decoupler"], ["fuzzy control", "loop", "modified error decoupling", "multivariable process", "decoupler", "equal number", "loop controller", "inputs", "single loop fuzzy controllers", "centralized"]], "textrank": [["single loop fuzzy", "fuzzy control", "loop", "single component", "control"], ["single loop fuzzy", "fuzzy control", "loop", "single component", "control", "adaptive technique", "equal number", "error", "process"]], "positionrank": [["fuzzy control system", "fuzzy control", "control concept", "feedback control", "multivariable process systems"], ["fuzzy control system", "fuzzy control", "control concept", "feedback control", "multivariable process systems", "modified error decoupling", "control", "fuzzy controllers", "multivariable process", "single loop"]], "multipartiterank": [["fuzzy control", "multivariable process", "modified error decoupling", "loop", "paper"], ["fuzzy control", "multivariable process", "modified error decoupling", "loop", "paper", "equal number", "squared", "error", "decoupler", "inputs"]]}, {"id": "2192", "text": "The ubiquitous provisioning of internet services to portable devices\nAdvances in mobile telecommunications and device miniaturization call for\n\tproviding both standard and novel location- and context-dependent\n\tInternet services to mobile clients. Mobile agents are dynamic,\n\tasynchronous, and autonomous, making the MA programming paradigm\n\tsuitable for developing novel middleware for mobility-enabled services\n", "keywords": "mobile telecommunications; device miniaturization; Internet services; mobile\n\tclients; mobile agents; mobility-enabled services; middleware\n", "topicrank": [["internet services", "mobile telecommunications", "novel location-", "dependent", "context"], ["internet services", "mobile telecommunications", "novel location-", "dependent", "context", "clients", "portable devices", "advances", "dynamic", "standard"]], "textrank": [["internet services", "ubiquitous provisioning", "programming", "novel", "mobile"], ["internet services", "ubiquitous provisioning", "programming", "novel", "mobile", "services", "portable"]], "positionrank": [["internet services", "ubiquitous provisioning", "portable devices", "mobile telecommunications", "services"], ["internet services", "ubiquitous provisioning", "portable devices", "mobile telecommunications", "services", "mobile agents", "novel location-", "device miniaturization", "novel middleware", "ma programming paradigm"]], "multipartiterank": [["internet services", "mobile telecommunications", "novel location-", "advances", "context"], ["internet services", "mobile telecommunications", "novel location-", "advances", "context", "portable devices", "dependent", "device miniaturization", "standard", "clients"]]}, {"id": "225", "text": "The eyes have it [hotel security]\nCCTV systems can help lodging establishments accomplish a range of objectives,\n\tfrom deterring criminals to observing staff interactions with\n\tclientele. But pitfalls can arise if the CCTV system has not been\n\tproperly integrated into the overall hotel security plan. CCTV system\n\tdesigns at new hotel properties are often too sophisticated, too\n\tcomplicated, and too costly, and do not take into consideration the\n\tsecurity realities of site management. These problems arise when the\n\tprofessionals designing or installing the system, including architects,\n\tconstruction engineers, integrators, and consultants, are not familiar\n\twith a hotel's operating strategies or security standards\n", "keywords": "hotel security; CCTV system; site management; operating strategies\n", "topicrank": [["cctv system", "hotel security", "security realities", "construction engineers", "designs"], ["cctv system", "hotel security", "security realities", "construction engineers", "designs", "integrators", "site management", "range", "new hotel properties", "objectives"]], "textrank": [["hotel security", "security", "hotel", "operating strategies", "construction engineers"], ["hotel security", "security", "hotel", "operating strategies", "construction engineers", "site management", "staff interactions", "cctv"]], "positionrank": [["hotel security", "new hotel properties", "cctv system", "cctv systems", "security realities"], ["hotel security", "new hotel properties", "cctv system", "cctv systems", "security realities", "security standards", "hotel", "eyes", "system", "staff interactions"]], "multipartiterank": [["hotel security", "cctv system", "security realities", "cctv systems", "range"], ["hotel security", "cctv system", "security realities", "cctv systems", "range", "objectives", "establishments", "designs", "staff interactions", "criminals"]]}, {"id": "260", "text": "Prospecting virtual collections\nVirtual collections are a distinct sub-species of digital collections and\n\tdigital archives. Archivists and curators as archivists and curators do\n\tnot construct virtual collections; rather they enable virtual\n\tcollections through the application of descriptive and other standards.\n\tVirtual collections are constructed by end users\n", "keywords": "virtual collections; digital collections; digital archives; archivists;\n\tcurators; descriptive standards; end users; digitization\n", "topicrank": [["virtual collections", "archivists", "curators", "digital collections", "digital archives"], ["virtual collections", "archivists", "curators", "digital collections", "digital archives", "application", "descriptive", "end users"]], "textrank": [["digital collections", "sub -", "digital", "collections", "other"], ["digital collections", "sub -", "digital", "collections", "other"]], "positionrank": [["virtual collections", "digital collections", "collections", "digital archives", "other standards"], ["virtual collections", "digital collections", "collections", "digital archives", "other standards", "curators", "archivists", "end users", "application"]], "multipartiterank": [["virtual collections", "archivists", "curators", "digital collections", "digital archives"], ["virtual collections", "archivists", "curators", "digital collections", "digital archives", "application", "collections", "descriptive", "virtual", "end users"]]}, {"id": "2035", "text": "Search for efficient solutions of multi-criterion problems by target-level\n\tmethod\nThe target-level method is considered for solving continuous multi-criterion\n\tmaximization problems. In the first step, the decision-maker specifies\n\ta target-level point (the desired criterion values); then in the set of\n\tvector evaluations we seek points that are closest to the target point\n\tin the Chebyshev metric. The vector evaluations obtained in this way\n\tare in general weakly efficient. To identify the efficient evaluations,\n\tthe second step maximizes the sum of the criteria on the set generated\n\tin step 1. We prove the relationship between the evaluations and\n\tdecisions obtained by the proposed procedure, on the one hand, and the\n\tefficient (weakly efficient) evaluations and decisions, on the other\n\thand. If the Edgeworth-Pareto hull of the set of vector evaluations is\n\tconvex, the set of efficient vector evaluations can be approximated by\n\tthe proposed method\n", "keywords": "multi-criterion problems; target-level method; continuous multi-criterion\n\tmaximization problems; target-level point; Chebyshev metric;\n\tEdgeworth-Pareto hull\n", "topicrank": [["vector evaluations", "set", "target", "efficient solutions", "first step"], ["vector evaluations", "set", "target", "efficient solutions", "first step", "level", "decisions", "hand", "method", "pareto hull"]], "textrank": [["multi - criterion problems", "multi - criterion", "- level point", "- pareto hull", "- level"], ["multi - criterion problems", "multi - criterion", "- level point", "- pareto hull", "- level", "chebyshev metric", "criterion", "step", "efficient", "point"]], "positionrank": [["efficient vector evaluations", "efficient evaluations", "level method", "vector evaluations", "efficient solutions"], ["efficient vector evaluations", "efficient evaluations", "level method", "vector evaluations", "efficient solutions", "target point", "level point", "target", "criterion values", "maximization problems"]], "multipartiterank": [["target", "vector evaluations", "level", "efficient solutions", "set"], ["target", "vector evaluations", "level", "efficient solutions", "set", "first step", "method", "efficient", "decision", "maker"]]}, {"id": "382", "text": "Robust wavelet neuro control for linear brushless motors\nDesign, simulation and experimental implementation of a wavelet basis function\n\tnetwork learning controller for linear brushless dc motors (LBDCM) are\n\tconsidered. Stability robustness with position tracking is the primary\n\tconcern. The proposed controller deals mainly with external\n\tdisturbances, e.g. nonlinear friction force and payload variation in\n\tmotion control of linear motors. It consists of two parts, one is a\n\tstate feedback component, and the other one is a learning feedback\n\tcomponent. The state feedback controller is designed on the basis of a\n\tsimple linear model, and the learning feedback component is a wavelet\n\tneural controller. The attenuation effect of wavelet neural networks on\n\tfriction force is first verified by the numerical method. The learning\n\teffect of wavelet neural networks on friction force is also shown in\n\tthe numerical results. Then, a wavelet neural network is applied on a\n\treal LBDCM to on-line suppress the friction force, which may be\n\tvariable due to the different lubrication. The effectiveness of the\n\tproposed control schemes is demonstrated by simulated and experimental\n\tresults\n", "keywords": "robust wavelet neuro control; linear brushless motors; wavelet basis function\n\tnetwork; LBDCM; stability robustness; position tracking; external\n\tdisturbances; nonlinear friction force; payload variation; motion\n\tcontrol; state feedback component; learning feedback component;\n\tattenuation effect; friction force; lubrication\n", "topicrank": [["nonlinear friction force", "wavelet", "linear brushless motors", "state feedback component", "experimental implementation"], ["nonlinear friction force", "wavelet", "linear brushless motors", "state feedback component", "experimental implementation", "wavelet basis function", "attenuation effect", "motion control", "lbdcm", "numerical results"]], "textrank": [["linear brushless motors", "neural controller", "feedback controller", "wavelet neural", "linear motors"], ["linear brushless motors", "neural controller", "feedback controller", "wavelet neural", "linear motors", "linear brushless", "wavelet basis", "controller", "position tracking", "stability robustness"]], "positionrank": [["linear brushless motors", "wavelet basis function", "wavelet neural networks", "linear motors", "network learning controller"], ["linear brushless motors", "wavelet basis function", "wavelet neural networks", "linear motors", "network learning controller", "wavelet", "simple linear model", "nonlinear friction force", "state feedback controller", "neural controller"]], "multipartiterank": [["linear brushless motors", "nonlinear friction force", "state feedback component", "wavelet", "wavelet basis function"], ["linear brushless motors", "nonlinear friction force", "state feedback component", "wavelet", "wavelet basis function", "experimental implementation", "design", "simulation", "motion control", "friction force"]]}, {"id": "2070", "text": "Modularity in technology and organization\nThe paper is an attempt to raid both the literature on modular design and the\n\tliterature on property rights to create the outlines of a modularity\n\ttheory of the firm. Such a theory will look at firms, and other\n\torganizations, in terms of the partitioning of rights-understood as\n\tprotected spheres of authority-among cooperating parties. It will\n\tassert that organizations reflect nonmodular structures, that is,\n\tstructures in which decision rights, rights of alienation, and residual\n\tclaims to income do not all reside in the same hands\n", "keywords": "modularity; technology; organization; property rights; partitioning of rights;\n\tauthority; cooperating parties; nonmodular structures; decision rights;\n\trights of alienation; transaction costs\n", "topicrank": [["property rights", "modularity", "theory", "literature", "organizations"], ["property rights", "modularity", "theory", "literature", "organizations", "nonmodular structures", "partitioning", "alienation", "claims", "residual"]], "textrank": [["decision rights", "property rights", "same hands", "nonmodular structures", "modular design"], ["decision rights", "property rights", "same hands", "nonmodular structures", "modular design", "rights", "structures"]], "positionrank": [["property rights", "modularity", "decision rights", "rights", "modular design"], ["property rights", "modularity", "decision rights", "rights", "modular design", "literature", "technology", "paper", "theory", "attempt"]], "multipartiterank": [["property rights", "literature", "modularity", "theory", "organizations"], ["property rights", "literature", "modularity", "theory", "organizations", "rights", "nonmodular structures", "modular design", "outlines", "organization"]]}, {"id": "1959", "text": "Quantum market games\nWe propose a quantum-like description of markets and economics. The approach\n\thas roots in the recently developed quantum game theory\n", "keywords": "quantum market games; economics; quantum game theory; quantum strategies;\n\tfinancial markets\n", "topicrank": [["quantum market games", "markets", "like description", "economics", "approach"], ["quantum market games", "markets", "like description", "economics", "approach", "roots"]], "textrank": [["quantum game", "quantum market", "quantum"], ["quantum game", "quantum market", "quantum"]], "positionrank": [["quantum market games", "quantum game theory", "quantum", "like description", "approach"], ["quantum market games", "quantum game theory", "quantum", "like description", "approach", "markets", "economics", "roots"]], "multipartiterank": [["quantum market games", "like description", "markets", "economics", "approach"], ["quantum market games", "like description", "markets", "economics", "approach", "roots", "quantum", "quantum game theory"]]}, {"id": "2190", "text": "Standards for service discovery and delivery\nFor the past five years, competing industries and standards developers have\n\tbeen hotly pursuing automatic configuration, now coined the broader\n\tterm service discovery. Jini, Universal Plug and Play (UPnP),\n\tSalutation, and Service Location Protocol are among the front-runners\n\tin this new race. However, choosing service discovery as the topic of\n\tthe hour goes beyond the need for plug-and-play solutions or support\n\tfor the SOHO (small office/home office) user. Service discovery's\n\tpotential in mobile and pervasive computing environments motivated my\n\tchoice\n", "keywords": "service discovery; Jini; Universal Plug and Play; Salutation; Service Location\n\tProtocol; mobile computing; pervasive computing\n", "topicrank": [["service discovery", "universal plug", "play", "small office", "standards"], ["service discovery", "universal plug", "play", "small office", "standards", "jini", "user", "upnp", "mobile", "soho"]], "textrank": [["service location", "new race", "universal plug", "automatic configuration", "standards developers"], ["service location", "new race", "universal plug", "automatic configuration", "standards developers", "service", "computing", "office", "plug", "play"]], "positionrank": [["term service discovery", "service discovery", "service location protocol", "standards developers", "standards"], ["term service discovery", "service discovery", "service location protocol", "standards developers", "standards", "automatic configuration", "universal plug", "small office", "home office", "play solutions"]], "multipartiterank": [["service discovery", "standards", "universal plug", "play", "small office"], ["service discovery", "standards", "universal plug", "play", "small office", "jini", "user", "upnp", "delivery", "soho"]]}, {"id": "227", "text": "Relativistic constraints on the distinguishability of orthogonal quantum states\nThe constraints imposed by special relativity on the distinguishability of\n\tquantum states are discussed. An explicit expression relating the\n\tprobability of an error in distinguishing two orthogonal single-photon\n\tstates to their structure, the time t at which a measurement starts,\n\tand the interval of time T elapsed from the start of the measurement\n\tuntil the time at which the outcome is obtained by an observer is given\n\tas an example\n", "keywords": "relativistic constraints; orthogonal quantum states; special relativity;\n\torthogonal single-photon states; time interval; observer;\n\tnonrelativistic quantum information theory; quantum communication\n\tchannels; quantum-state distinguishability\n", "topicrank": [["orthogonal quantum states", "distinguishability", "measurement", "relativistic constraints", "photon"], ["orthogonal quantum states", "distinguishability", "measurement", "relativistic constraints", "photon", "orthogonal single", "error", "probability", "special relativity", "structure"]], "textrank": [["orthogonal quantum", "special relativity", "relativistic constraints", "orthogonal", "quantum"], ["orthogonal quantum", "special relativity", "relativistic constraints", "orthogonal", "quantum", "explicit", "constraints"]], "positionrank": [["orthogonal quantum states", "quantum states", "relativistic constraints", "states", "constraints"], ["orthogonal quantum states", "quantum states", "relativistic constraints", "states", "constraints", "special relativity", "distinguishability", "time t", "explicit expression", "time"]], "multipartiterank": [["relativistic constraints", "orthogonal quantum states", "distinguishability", "measurement", "special relativity"], ["relativistic constraints", "orthogonal quantum states", "distinguishability", "measurement", "special relativity", "photon", "orthogonal single", "constraints", "states", "error"]]}, {"id": "262", "text": "The impact of EAD adoption on archival programs: a pilot survey of early\n\timplementers\nThe article reports the results of a survey conducted to assess the impact that\n\tthe implementation of Encoded Archival Description (EAD) has on\n\tarchival programs. By gathering data related to the funding, staffing,\n\tand evaluation of EAD programs and about institutional goals for EAD\n\timplementation, the study explored how EAD has affected the operations\n\tof the institutions which are utilizing it and the extent to which EAD\n\thas become a part of regular repository functions\n", "keywords": "EAD adoption; archival programs; Encoded Archival Description; funding;\n\tstaffing; EAD programs; institutional goals; EAD implementation;\n\tregular repository functions; archival descriptive standards; diffusion\n\tof innovation\n", "topicrank": [["ead adoption", "implementation", "pilot survey", "archival programs", "impact"], ["ead adoption", "implementation", "pilot survey", "archival programs", "impact", "institutional goals", "early", "encoded archival description", "implementers", "staffing"]], "textrank": [["archival programs", "ead programs", "regular repository", "institutional goals", "pilot survey"], ["archival programs", "ead programs", "regular repository", "institutional goals", "pilot survey", "archival", "ead", "survey"]], "positionrank": [["ead programs", "archival programs", "ead adoption", "encoded archival description", "ead"], ["ead programs", "archival programs", "ead adoption", "encoded archival description", "ead", "pilot survey", "impact", "survey", "implementation", "institutional goals"]], "multipartiterank": [["ead adoption", "archival programs", "impact", "pilot survey", "ead"], ["ead adoption", "archival programs", "impact", "pilot survey", "ead", "implementation", "early", "implementers", "article", "results"]]}, {"id": "31", "text": "Adaptive neural/fuzzy control for interpolated nonlinear systems\nAdaptive control for nonlinear time-varying systems is of both theoretical and\n\tpractical importance. We propose an adaptive control methodology for a\n\tclass of nonlinear systems with a time-varying structure. This class of\n\tsystems is composed of interpolations of nonlinear subsystems which are\n\tinput-output feedback linearizable. Both indirect and direct adaptive\n\tcontrol methods are developed, where the spatially localized models (in\n\tthe form of Takagi-Sugeno fuzzy systems or radial basis function neural\n\tnetworks) are used as online approximators to learn the unknown\n\tdynamics of the system. Without assumptions on rate of change of system\n\tdynamics, the proposed adaptive control methods guarantee that all\n\tinternal signals of the system are bounded and the tracking error is\n\tasymptotically stable. The performance of the adaptive controller is\n\tdemonstrated using a jet engine control problem\n", "keywords": "adaptive neural/fuzzy control; interpolated nonlinear systems; time-varying\n\tsystems; input-output feedback linearizable systems; indirect control;\n\tdirect control; spatially localized models; Takagi-Sugeno fuzzy\n\tsystems; radial basis function neural networks; online approximators;\n\tunknown dynamics; tracking error; jet engine control; stability\n\tanalysis\n", "topicrank": [["nonlinear systems", "fuzzy control", "system", "adaptive neural", "dynamics"], ["nonlinear systems", "fuzzy control", "system", "adaptive neural", "dynamics", "nonlinear time", "class", "rate", "change", "assumptions"]], "textrank": [["adaptive control", "fuzzy control", "engine control", "basis function neural", "adaptive neural"], ["adaptive control", "fuzzy control", "engine control", "basis function neural", "adaptive neural", "control", "nonlinear systems", "fuzzy systems", "online approximators", "practical importance"]], "positionrank": [["adaptive control methods", "adaptive control methodology", "adaptive control", "adaptive neural", "nonlinear systems"], ["adaptive control methods", "adaptive control methodology", "adaptive control", "adaptive neural", "nonlinear systems", "adaptive controller", "fuzzy control", "fuzzy systems", "control methods", "nonlinear time"]], "multipartiterank": [["fuzzy control", "nonlinear systems", "adaptive neural", "nonlinear time", "class"], ["fuzzy control", "nonlinear systems", "adaptive neural", "nonlinear time", "class", "system", "systems", "adaptive control", "dynamics", "theoretical"]]}, {"id": "2128", "text": "An optimal control algorithm based on reachability set approximation and\n\tlinearization\nThe terminal functional of a general control system is refined by studying an\n\tanalogous problem for a variational system and regularization. A\n\tsequential refinement method is designed by combining the local\n\tapproximation of the reachability set and reduction. The corresponding\n\talgorithm has relaxation properties. An illustrative example is given\n", "keywords": "determinate systems; optimal control algorithm; reachability set approximation;\n\tlinearization; terminal functional; variational system; regularization;\n\tsequential refinement method; local approximation; relaxation\n\tproperties\n", "topicrank": [["reachability", "approximation", "optimal control algorithm", "corresponding", "reduction"], ["reachability", "approximation", "optimal control algorithm", "corresponding", "reduction", "variational system", "relaxation properties", "regularization", "local", "terminal functional"]], "textrank": [["control system", "control", "analogous problem", "terminal functional", "refinement"], ["control system", "control", "analogous problem", "terminal functional", "refinement", "system", "reachability"]], "positionrank": [["optimal control algorithm", "general control system", "reachability set", "variational system", "algorithm"], ["optimal control algorithm", "general control system", "reachability set", "variational system", "algorithm", "reachability", "approximation", "terminal functional", "sequential refinement method", "analogous problem"]], "multipartiterank": [["approximation", "reachability", "optimal control algorithm", "linearization", "terminal functional"], ["approximation", "reachability", "optimal control algorithm", "linearization", "terminal functional", "variational system", "general control system", "regularization", "local", "reachability set"]]}, {"id": "2150", "text": "Data storage: re-format. Closely tracking a fast-moving sector\nIn the past few years the data center market has changed dramatically, forcing\n\tmany companies into consolidation or bankruptcy. Gone are the days when\n\tcompanies raised millions of dollars to acquire large industrial\n\tbuildings and transform them into glittering, high-tech palaces filled\n\twith the latest telecommunication and data technology. Whereas\n\tmanufacturers of communication technology deliver the racked equipment\n\tin these, often mission-critical, facilities, ABB focuses mainly on the\n\tbuilding infrastructure. Besides the very important redundant power\n\tsupply, ABB also provides the redundant air conditioning and the\n\tsecurity system\n", "keywords": "building management; data centers; building infrastructure; mission-critical\n\tfacilities; ABB; engineering management; project management;\n\tinstallation; commissioning; redundant power supply; redundant air\n\tconditioning; security system\n", "topicrank": [["many companies", "data technology", "abb", "millions", "critical"], ["many companies", "data technology", "abb", "millions", "critical", "facilities", "dollars", "large industrial", "consolidation", "mission"]], "textrank": [["- tech palaces", "redundant air", "data technology", "data center", "large industrial"], ["- tech palaces", "redundant air", "data technology", "data center", "large industrial", "many companies", "redundant", "data", "few", "-"]], "positionrank": [["data center market", "data storage", "data technology", "re - format", "past few years"], ["data center market", "data storage", "data technology", "re - format", "past few years", "communication technology", "many companies", "latest telecommunication", "sector", "tech palaces"]], "multipartiterank": [["many companies", "data technology", "abb", "consolidation", "millions"], ["many companies", "data technology", "abb", "consolidation", "millions", "latest telecommunication", "bankruptcy", "critical", "dollars", "facilities"]]}, {"id": "2115", "text": "Control of combustion processes in an internal combustion engine by\n\tlow-temperature plasma\nA new method of operation of internal combustion engines enhances power and\n\treduces fuel consumption and exhaust toxicity. Low-temperature plasma\n\tcontrol combines working processes of thermal engines and steam\n\tmachines into a single process\n", "keywords": "combustion processes; internal combustion engine; low-temperature plasma; fuel\n\tconsumption; exhaust toxicity; working processes; thermal engines;\n\tsteam machines\n", "topicrank": [["temperature plasma", "low", "internal combustion engine", "combustion processes", "control"], ["temperature plasma", "low", "internal combustion engine", "combustion processes", "control", "exhaust toxicity", "thermal engines", "steam", "operation", "fuel consumption"]], "textrank": [["combustion engines", "combustion processes", "combustion", "new method", "temperature plasma"], ["combustion engines", "combustion processes", "combustion", "new method", "temperature plasma", "engines", "processes"]], "positionrank": [["internal combustion engines", "internal combustion engine", "combustion processes", "temperature plasma", "control"], ["internal combustion engines", "internal combustion engine", "combustion processes", "temperature plasma", "control", "working processes", "thermal engines", "new method", "fuel consumption", "exhaust toxicity"]], "multipartiterank": [["combustion processes", "internal combustion engine", "temperature plasma", "control", "low"], ["combustion processes", "internal combustion engine", "temperature plasma", "control", "low", "exhaust toxicity", "operation", "new method", "thermal engines", "working processes"]]}, {"id": "1999", "text": "Performance comparison between PID and dead-time compensating controllers\nThis paper is intended to answer the question: \"When can a simple dead-time\n\tcompensator be expected to perform better than a PID?\". The performance\n\tcriterion used is the integrated absolute error (IAE). It is compared\n\tfor PI and PID controllers and a simple dead-time compensator (DTC)\n\twhen a step load disturbance is applied at the plant input. Both stable\n\tand integrating processes are considered. For a fair comparison the\n\tcontrollers should provide equal robustness in some sense. Here, as a\n\tmeasure of robustness, the H/sub infinity / norm of the sum of the\n\tabsolute values of the sensitivity function and the complementary\n\tsensitivity function is used. Performance of the DTC's is given also as\n\ta function of dead-time margin (D/sub M/)\n", "keywords": "performance comparison; PID controllers; dead-time compensating controllers;\n\tperformance criterion; integrated absolute error; IAE; PI controllers;\n\tdead-time compensator; DTC; step load disturbance; stable processes;\n\tintegrating processes; equal robustness; complementary sensitivity\n\tfunction; dead-time margin; absolute value sum H/sub infinity / norm\n", "topicrank": [["dead", "time", "controllers", "performance comparison", "sensitivity function"], ["dead", "time", "controllers", "performance comparison", "sensitivity function", "compensator", "equal robustness", "pid", "dtc", "norm"]], "textrank": [["integrating processes", "plant input", "pid controllers", "simple dead", "absolute"], ["integrating processes", "plant input", "pid controllers", "simple dead", "absolute", "sub", "load", "time", "comparison", "equal"]], "positionrank": [["performance comparison", "pid controllers", "time compensator", "performance", "time margin"], ["performance comparison", "pid controllers", "time compensator", "performance", "time margin", "time", "fair comparison", "pid", "sensitivity function", "integrated absolute error"]], "multipartiterank": [["performance comparison", "dead", "time", "controllers", "pid"], ["performance comparison", "dead", "time", "controllers", "pid", "sensitivity function", "compensator", "simple dead", "equal robustness", "performance"]]}, {"id": "1964", "text": "Antipersistent Markov behavior in foreign exchange markets\nA quantitative check of efficiency in US dollar/Deutsche mark exchange rates is\n\tdeveloped using high-frequency (tick by tick) data. The antipersistent\n\tMarkov behavior of log-price fluctuations of given size implies, in\n\tprinciple, the possibility of a statistical forecast. We introduce and\n\tmeasure the available information of the quote sequence, and we show\n\thow it can be profitable following a particular trading rule\n", "keywords": "antipersistent Markov behavior; foreign exchange markets; efficiency; US\n\tdollar; Deutsche mark; exchange rates; high-frequency data; log-price\n\tfluctuations; statistical forecast; quote sequence; trading rule;\n\tShannon entropy; forecasting\n", "topicrank": [["antipersistent markov behavior", "log", "antipersistent", "price fluctuations", "data"], ["antipersistent markov behavior", "log", "antipersistent", "price fluctuations", "data", "us dollar", "tick", "efficiency", "frequency", "deutsche mark exchange rates"]], "textrank": [["mark exchange", "exchange", "price fluctuations", "us dollar", "quantitative check"], ["mark exchange", "exchange", "price fluctuations", "us dollar", "quantitative check", "trading", "markov", "size"]], "positionrank": [["antipersistent markov behavior", "markov behavior", "foreign exchange markets", "antipersistent", "quantitative check"], ["antipersistent markov behavior", "markov behavior", "foreign exchange markets", "antipersistent", "quantitative check", "us dollar", "price fluctuations", "size implies", "efficiency", "log"]], "multipartiterank": [["antipersistent markov behavior", "foreign exchange markets", "quantitative check", "efficiency", "us dollar"], ["antipersistent markov behavior", "foreign exchange markets", "quantitative check", "efficiency", "us dollar", "deutsche mark exchange rates", "frequency", "antipersistent", "log", "high"]]}, {"id": "342", "text": "Mount Sinai Hospital uses integer programming to allocate operating room time\nAn integer-programming model and a post-solution heuristic allocates operating\n\troom time to the five surgical divisions at Toronto's Mount Sinai\n\tHospital. The hospital has used this approach for several years and\n\tcredits it with both administrative savings and the ability to produce\n\tquickly an equitable master surgical schedule\n", "keywords": "Mount Sinai Hospital; integer programming; operating room time allocation;\n\tToronto; Ontario; Canada; post-solution heuristic\n", "topicrank": [["mount sinai hospital", "hospital", "operating room time", "integer programming", "toronto"], ["mount sinai hospital", "hospital", "operating room time", "integer programming", "toronto", "surgical divisions", "approach", "several years", "administrative savings", "model"]], "textrank": [["- solution heuristic", "master surgical", "integer -", "surgical", "room"], ["- solution heuristic", "master surgical", "integer -", "surgical", "room", "sinai", "integer"]], "positionrank": [["mount sinai hospital", "operating room time", "mount sinai", "room time", "integer programming"], ["mount sinai hospital", "operating room time", "mount sinai", "room time", "integer programming", "hospital", "surgical divisions", "integer", "surgical schedule", "several years"]], "multipartiterank": [["mount sinai hospital", "integer programming", "operating room time", "hospital", "model"], ["mount sinai hospital", "integer programming", "operating room time", "hospital", "model", "integer", "toronto", "surgical divisions", "mount sinai", "approach"]]}, {"id": "307", "text": "Computer program to generate operant schedules\nA computer program for programming schedules of reinforcement is described.\n\tStudents can use the program to experience schedules of reinforcement\n\tthat are typically used with nonhuman subjects. Accumulative recording\n\tof a student's response can be shown on the screen and/or printed with\n\tthe computer's printer. The program can also be used to program operant\n\tschedules for animal subjects. The program was tested with human\n\tsubjects experiencing fixed ratio, variable ratio, fixed interval, and\n\tvariable interval schedules. Performance for human subjects on a given\n\tschedule was similar to performance for nonhuman subjects on the same\n\tschedule\n", "keywords": "operant schedule generation; computer program; reinforcement schedule\n\tprogramming; nonhuman subjects; cumulative student response recording;\n\tanimal subjects; fixed ratio schedules; variable ratio schedules; fixed\n\tinterval schedules; variable interval schedules; human subjects\n", "topicrank": [["nonhuman subjects", "programming schedules", "program", "computer program", "performance"], ["nonhuman subjects", "programming schedules", "program", "computer program", "performance", "human", "interval", "operant schedules", "ratio", "reinforcement"]], "textrank": [["variable interval schedules", "computer program", "subjects", "schedules", "variable"], ["variable interval schedules", "computer program", "subjects", "schedules", "variable", "interval", "computer", "accumulative", "program"]], "positionrank": [["computer program", "operant schedules", "variable interval schedules", "programming schedules", "program"], ["computer program", "operant schedules", "variable interval schedules", "programming schedules", "program", "schedules", "computer", "human subjects", "nonhuman subjects", "animal subjects"]], "multipartiterank": [["computer program", "programming schedules", "nonhuman subjects", "reinforcement", "program"], ["computer program", "programming schedules", "nonhuman subjects", "reinforcement", "program", "operant schedules", "performance", "schedules", "human", "ratio"]]}, {"id": "2008", "text": "Building 3D anatomical scenes on the Web\nWe propose a new service for building user-defined 3D anatomical structures on\n\tthe Web. The Web server is connected to a database storing more than\n\t1000 3D anatomical models reconstructed from the Visible Human. Users\n\tmay combine existing models as well as planar oblique slices in order\n\tto create their own structured anatomical scenes. Furthermore, they may\n\trecord sequences of scene construction and visualization actions. These\n\tactions enable the server to construct high-quality video animations,\n\tdownloadable by the user. Professionals and students in anatomy,\n\tmedicine and related disciplines are invited to use the server and\n\tcreate their own anatomical scenes\n", "keywords": "3D anatomical scenes; World Wide Web; user-defined 3D anatomical structures;\n\tWeb server; database; 3D anatomical models; Visible Human; planar\n\toblique slices; structured anatomical scenes; volume visualization;\n\tsurface reconstruction; applet-based rendering engine; Java;\n\tvisualization; scene construction; high-quality video animation\n", "topicrank": [["web server", "building user", "3d anatomical scenes", "visualization actions", "web"], ["web server", "building user", "3d anatomical scenes", "visualization actions", "web", "professionals", "students", "quality video animations", "anatomy", "high"]], "textrank": [["anatomical models", "anatomical", "visible human", "web server", "building user"], ["anatomical models", "anatomical", "visible human", "web server", "building user", "new service", "video", "oblique", "models", "user"]], "positionrank": [["3d anatomical scenes", "3d anatomical models", "3d anatomical structures", "own anatomical scenes", "web server"], ["3d anatomical scenes", "3d anatomical models", "3d anatomical structures", "own anatomical scenes", "web server", "web", "building user", "new service", "existing models", "planar oblique slices"]], "multipartiterank": [["3d anatomical scenes", "web", "building user", "web server", "new service"], ["3d anatomical scenes", "web", "building user", "web server", "new service", "visualization actions", "server", "scene construction", "3d anatomical structures", "visible human"]]}, {"id": "2189", "text": "Mobile computing \"Killer app\" competition\nDesign competitions offer students an excellent way to gain hands-on experience\n\tin engineering and computer science courses. The University of Florida,\n\tin partnership with Motorola, has held two mobile computing design\n\tcompetitions. In Spring and Fall 2001, students in Abdelsalam Helal's\n\tMobile Computing class designed killer apps for a Motorola smart phone\n", "keywords": "mobile computing; smart phone; Motorola; design competitions\n", "topicrank": [["mobile", "design competitions", "students", "killer app", "motorola"], ["mobile", "design competitions", "students", "killer app", "motorola", "computer science courses", "excellent way", "engineering", "university", "florida"]], "textrank": [["computing design", "abdelsalam helal", "excellent way", "computing", "smart"], ["computing design", "abdelsalam helal", "excellent way", "computing", "smart", "science", "killer", "design"]], "positionrank": [["mobile computing design", "mobile computing class", "design competitions", "killer app", "killer apps"], ["mobile computing design", "mobile computing class", "design competitions", "killer app", "killer apps", "competitions", "students", "abdelsalam helal", "excellent way", "computer science courses"]], "multipartiterank": [["mobile", "killer app", "design competitions", "students", "competition"], ["mobile", "killer app", "design competitions", "students", "competition", "excellent way", "motorola", "hands", "computer science courses", "experience"]]}, {"id": "1940", "text": "New lower bounds of the size of error-correcting codes for the Z-channel\nOptimization problems on graphs are formulated to obtain new lower bounds of\n\tthe size of error-correcting codes for the Z-channel\n", "keywords": "lower bounds; error-correcting codes; Z-channel; optimization problems; graphs\n", "topicrank": [["error", "size", "codes", "channel", "new lower bounds"], ["error", "size", "codes", "channel", "new lower bounds", "optimization problems", "graphs"]], "textrank": [["optimization problems", "lower"], ["optimization problems", "lower"]], "positionrank": [["new lower bounds", "optimization problems", "error", "size", "codes"], ["new lower bounds", "optimization problems", "error", "size", "codes", "z", "channel", "graphs"]], "multipartiterank": [["error", "size", "codes", "channel", "new lower bounds"], ["error", "size", "codes", "channel", "new lower bounds", "optimization problems", "graphs"]]}, {"id": "2174", "text": "Spam solution?\nThe author describes a solution to spam E-mails: disposable E-mail addresses\n\t(DEA). Mailshell's free trial Web-based E-mail service allows you, if\n\tyou start getting spammed on that DEA, just to delete the DEA in\n\tMailshell, and all E-mail thereafter sent to that address will\n\tautomatically be junked (though you can later restore that address if\n\tyou want). Mailshell allows any number of DEA\n", "keywords": "spam E-mails; disposable E-mail addresses; Mailshell; Web-based E-mail\n", "topicrank": [["dea", "mailshell", "solution", "free trial web", "number"], ["dea", "mailshell", "solution", "free trial web", "number", "author", "address", "mails"]], "textrank": [["e - mail", "e -", "free trial", "-"], ["e - mail", "e -", "free trial", "-"]], "positionrank": [["e - mail", "e", "free trial web", "solution", "mailshell"], ["e - mail", "e", "free trial web", "solution", "mailshell", "dea", "mails", "author", "address", "number"]], "multipartiterank": [["dea", "mailshell", "solution", "free trial web", "number"], ["dea", "mailshell", "solution", "free trial web", "number", "author", "address", "mails"]]}, {"id": "2131", "text": "Diagnosis of the technical state of heat systems\nA step-by-step approach to the diagnosis of the technical state of heat systems\n\tis stated. The class of physical defects is supplemented by the\n\tbehavioral defects of objects, which are related to the disturbance of\n\tthe modes of their operation. The implementation of the approach is\n\tillustrated by an example of the solution of a specific problem of the\n\tdiagnosis of a closed heat consumption system\n", "keywords": "heat system technical state diagnosis; step-by-step diagnosis; operational mode\n\tdisturbance; closed heat consumption system diagnosis\n", "topicrank": [["diagnosis", "technical state", "heat systems", "step approach", "physical defects"], ["diagnosis", "technical state", "heat systems", "step approach", "physical defects", "operation", "implementation", "modes", "solution", "objects"]], "textrank": [["heat consumption", "step approach", "technical state", "heat", "defects"], ["heat consumption", "step approach", "technical state", "heat", "defects", "approach", "step"]], "positionrank": [["heat systems", "technical state", "diagnosis", "step approach", "step"], ["heat systems", "technical state", "diagnosis", "step approach", "step", "approach", "specific problem", "physical defects", "behavioral defects", "class"]], "multipartiterank": [["diagnosis", "heat systems", "technical state", "step approach", "physical defects"], ["diagnosis", "heat systems", "technical state", "step approach", "physical defects", "class", "step", "objects", "implementation", "operation"]]}, {"id": "286", "text": "Real-time tissue characterization on the basis of in vivo Raman spectra\nThe application of in vivo Raman spectroscopy for clinical diagnosis demands\n\tdedicated software that can perform the necessary signal processing and\n\tsubsequent (multivariate) data analysis, enabling clinically relevant\n\tparameters to be extracted and made available in real time. Here we\n\tdescribe the design and implementation of a software package that\n\tallows for real-time signal processing and data analysis of Raman\n\tspectra. The design is based on automatic data exchange between Grams,\n\ta spectroscopic data acquisition and analysis program, and Matlab, a\n\tprogram designed for array-based calculations. The data analysis\n\tsoftware has a modular design providing great flexibility in developing\n\tcustom data analysis routines for different applications. The\n\timplementation is illustrated by a computationally demanding\n\tapplication for the classification of skin spectra using principal\n\tcomponent analysis and linear discriminant analysis\n", "keywords": "real-time tissue characterization; clinically relevant parameters extraction;\n\tarray-based calculations; computationally demanding application;\n\tmodular design; data analysis software; clinical diagnosis; dedicated\n\tsoftware; multivariate data analysis; automatic data exchange; Grams;\n\tMatlab; linear discriminant analysis; skin spectra classification\n", "topicrank": [["data analysis", "design", "vivo raman spectra", "dedicated software", "real"], ["data analysis", "design", "vivo raman spectra", "dedicated software", "real", "spectra", "necessary signal processing", "analysis program", "implementation", "application"]], "textrank": [["data analysis", "discriminant analysis", "time signal", "data", "raman spectra"], ["data analysis", "discriminant analysis", "time signal", "data", "raman spectra", "time tissue", "analysis", "great flexibility", "modular design", "clinical diagnosis"]], "positionrank": [["vivo raman spectra", "real time", "data analysis", "time tissue characterization", "time signal processing"], ["vivo raman spectra", "real time", "data analysis", "time tissue characterization", "time signal processing", "vivo raman spectroscopy", "automatic data exchange", "spectroscopic data acquisition", "linear discriminant analysis", "analysis program"]], "multipartiterank": [["data analysis", "real", "vivo raman spectra", "dedicated software", "design"], ["data analysis", "real", "vivo raman spectra", "dedicated software", "design", "necessary signal processing", "application", "spectra", "analysis program", "implementation"]]}, {"id": "28", "text": "Uncertainty bounds and their use in the design of interval type-2 fuzzy logic\n\tsystems\nWe derive inner- and outer-bound sets for the type-reduced set of an interval\n\ttype-2 fuzzy logic system (FLS), based on a new mathematical\n\tinterpretation of the Karnik-Mendel iterative procedure for computing\n\tthe type-reduced set. The bound sets can not only provide estimates\n\tabout the uncertainty contained in the output of an interval type-2\n\tFLS, but can also be used to design an interval type-2 FLS. We\n\tdemonstrate, by means of a simulation experiment, that the resulting\n\tsystem can operate without type-reduction and can achieve similar\n\tperformance to one that uses type-reduction. Therefore, our new design\n\tmethod, based on the bound sets, can relieve the computation burden of\n\tan interval type-2 FLS during its operation, which makes an interval\n\ttype-2 FLS useful for real-time applications\n", "keywords": "uncertainty bounds; interval type-2 fuzzy logic systems; inner-bound sets;\n\touter-bound sets; type-reduced set; Karnik-Mendel iterative procedure;\n\treal-time applications; time-series forecasting\n", "topicrank": [["interval", "type", "fls", "sets", "interval type-2 fuzzy logic"], ["interval", "type", "fls", "sets", "interval type-2 fuzzy logic", "reduction", "design", "set", "uncertainty bounds", "interpretation"]], "textrank": [["type-2 fuzzy logic", "type-2 fls", "computation burden", "simulation experiment", "uncertainty bounds"], ["type-2 fuzzy logic", "type-2 fls", "computation burden", "simulation experiment", "uncertainty bounds", "type-2", "iterative", "new", "fls", "uncertainty"]], "positionrank": [["interval type-2 fls", "interval type-2", "type-2 fls", "uncertainty bounds", "interval"], ["interval type-2 fls", "interval type-2", "type-2 fls", "uncertainty bounds", "interval", "fuzzy logic system", "type-2", "uncertainty", "fuzzy logic", "new design"]], "multipartiterank": [["interval", "type", "interval type-2 fuzzy logic", "uncertainty bounds", "fls"], ["interval", "type", "interval type-2 fuzzy logic", "uncertainty bounds", "fls", "design", "sets", "set", "use", "systems"]]}, {"id": "2069", "text": "The ultimate control group\nEmpirical research on the organization of firms requires that firms be\n\tclassified on the basis of their control structures. This should be\n\tdone in a way that can potentially be made operational. It is easy to\n\tidentify the ultimate controller of a hierarchical organization, and\n\tthe literature has largely focused on this case. However, many\n\torganizational structures mix hierarchy with collective choice\n\tprocedures such as voting, or use circular structures under which\n\tsuperiors are accountable to their subordinates. The author develops\n\tsome analytic machinery that can be used to map the authority\n\tstructures of such organizations, and show that under mild restrictions\n\tthere is a well-defined ultimate control group. The results are\n\tconsistent with intuitions about the nature of control in familiar\n\teconomic settings\n", "keywords": "ultimate control group; hierarchical organization; organizational structures;\n\tauthority structures; committees; control rights; firm organization\n", "topicrank": [["ultimate control group", "organizational structures", "organization", "firms", "hierarchy"], ["ultimate control group", "organizational structures", "organization", "firms", "hierarchy", "accountable", "collective choice", "nature", "intuitions", "superiors"]], "textrank": [["control structures", "ultimate control", "analytic machinery", "collective choice", "hierarchical organization"], ["control structures", "ultimate control", "analytic machinery", "collective choice", "hierarchical organization", "empirical research", "structures", "control", "such", "ultimate"]], "positionrank": [["ultimate control group", "control structures", "ultimate controller", "control", "empirical research"], ["ultimate control group", "control structures", "ultimate controller", "control", "empirical research", "hierarchical organization", "firms", "organization", "organizational structures", "circular structures"]], "multipartiterank": [["ultimate control group", "organizational structures", "organization", "firms", "hierarchy"], ["ultimate control group", "organizational structures", "organization", "firms", "hierarchy", "empirical research", "many", "collective choice", "results", "consistent"]]}, {"id": "366", "text": "Selecting rail grade crossing investments with a decision support system\nThe Federal Railroad Administration (FRA) has developed a series of rail and\n\trail-related analysis tools that assist FRA officials, Metropolitan\n\tPlanning Organizations (MPOs), state Department of Transportation\n\t(DOT), and other constituents in evaluating the cost and benefits of\n\tpotential infrastructure projects. To meet agency objectives, the FRA\n\twants to add a high-speed rail grade crossing analysis tool to its\n\tpackage of rail and rail-related intermodal software products. This\n\tpaper presents a conceptual decision support system (DSS) that can\n\tassist officials in achieving this goal. The paper first introduces the\n\tFRA's objectives and the role of cost benefit analysis in achieving\n\tthese objectives. Next, there is a discussion of the models needed to\n\tassess the feasibility of proposed high-speed rail grade crossing\n\tinvestments and the presentation of a decision support system (DSS)\n\tthat can deliver these models transparently to users. Then, the paper\n\tillustrates a system session and examines the potential benefits from\n\tsystem use\n", "keywords": "rail grade crossing investment selection; decision support system; Federal\n\tRailroad Administration; Metropolitan Planning Organizations;\n\tDepartment of Transportation; infrastructure projects; high-speed rail\n\tgrade crossing analysis tool; rail-related intermodal software\n\tproducts; rail intermodal software products; cost benefit analysis\n", "topicrank": [["fra", "rail", "decision support system", "agency objectives", "paper"], ["fra", "rail", "decision support system", "agency objectives", "paper", "cost", "dss", "rail grade crossing investments", "high", "benefits"]], "textrank": [["rail grade crossing analysis", "decision support system", "rail grade crossing", "benefit analysis", "potential infrastructure"], ["rail grade crossing analysis", "decision support system", "rail grade crossing", "benefit analysis", "potential infrastructure", "analysis", "planning organizations", "fra officials", "system", "software"]], "positionrank": [["decision support system", "rail", "fra officials", "cost benefit analysis", "system session"], ["decision support system", "rail", "fra officials", "cost benefit analysis", "system session", "system use", "federal railroad administration", "analysis tools", "fra", "investments"]], "multipartiterank": [["fra", "rail", "decision support system", "agency objectives", "rail grade crossing investments"], ["fra", "rail", "decision support system", "agency objectives", "rail grade crossing investments", "paper", "cost", "benefits", "dss", "high"]]}, {"id": "2094", "text": "Statistical inference with partial prior information based on a Gauss-type\n\tinequality\nPotter and Anderson (1983) have developed a Bayesian decision procedure\n\trequiring the specification of a class of prior distributions\n\trestricted to have a minimal probability content for a given subset of\n\tthe parameter space. They do not, however, provide a method for the\n\tselection of that subset. We show how a generalization of Gauss'\n\tinequality can be used to determine the relevant parameter subset\n", "keywords": "Bayesian decision procedure; prior distributions; minimal probability content;\n\tparameter space; Gauss inequality; prior-to-posterior sensitivity;\n\tpartial prior information\n", "topicrank": [["gauss", "inequality", "subset", "potter", "type"], ["gauss", "inequality", "subset", "potter", "type", "class", "anderson", "prior distributions", "partial prior information", "specification"]], "textrank": [["bayesian decision procedure", "statistical inference", "parameter", "prior", "probability"], ["bayesian decision procedure", "statistical inference", "parameter", "prior", "probability"]], "positionrank": [["partial prior information", "statistical inference", "prior distributions", "gauss", "relevant parameter subset"], ["partial prior information", "statistical inference", "prior distributions", "gauss", "relevant parameter subset", "minimal probability content", "bayesian decision procedure", "inequality", "type", "subset"]], "multipartiterank": [["inequality", "gauss", "subset", "potter", "type"], ["inequality", "gauss", "subset", "potter", "type", "class", "anderson", "prior distributions", "specification", "partial prior information"]]}, {"id": "323", "text": "A server-side program for delivering experiments with animations\nA server-side program for animation experiments is presented. The program is\n\tcapable of delivering an experiment composed of discrete animation\n\tsequences in various file formats, collecting a discrete or continuous\n\tresponse from the observer, evaluating the appropriateness of the\n\tresponse, and ensuring that the user is not proceeding at an\n\tunreasonable rate. Most parameters of the program are controllable by\n\texperimenter-edited text files or simple switches in the program code,\n\tthereby minimizing the need for programming to create new experiments.\n\tA simple demonstration experiment is discussed and is freely available\n", "keywords": "server-side program; animation experiment delivery; discrete animation\n\tsequences; file formats; Web based psychological experiments; Internet;\n\texperimenter-edited text files\n", "topicrank": [["side program", "experiments", "discrete animation", "response", "server"], ["side program", "experiments", "discrete animation", "response", "server", "experiment", "continuous", "sequences", "various file formats", "text files"]], "textrank": [["simple demonstration", "animation experiments", "most parameters", "unreasonable rate", "file"], ["simple demonstration", "animation experiments", "most parameters", "unreasonable rate", "file", "program", "simple", "animation", "experiments", "text"]], "positionrank": [["side program", "program code", "animation experiments", "program", "new experiments"], ["side program", "program code", "animation experiments", "program", "new experiments", "experiments", "server", "discrete animation", "simple demonstration experiment", "various file formats"]], "multipartiterank": [["side program", "experiments", "server", "discrete animation", "animations"], ["side program", "experiments", "server", "discrete animation", "animations", "response", "experiment", "program", "sequences", "animation experiments"]]}, {"id": "2011", "text": "Innovative phase unwrapping algorithm: hybrid approach\nWe present a novel algorithm based on a hybrid of the global and local\n\ttreatment of a wrapped map. The proposed algorithm is especially\n\teffective for the unwrapping of speckle-coded interferogram contour\n\tmaps. In contrast to earlier unwrapping algorithms by region, we\n\tpropose a local discontinuity-restoring criterion to serve as the\n\tpreprocessor or postprocessor of our hybrid algorithm, which makes the\n\tunwrapping by region much easier and more efficient. With this hybrid\n\talgorithm, a robust, stable, and especially time effective phase\n\tunwrapping can be achieved. Additionally, the criterion and limitation\n\tof this hybrid algorithm are fully described. The robustness,\n\tstability, and speed of this hybrid algorithm are also studied. The\n\tproposed algorithm can be easily upgraded with minor modifications to\n\tsolve the unwrapping problem of maps with phase inconsistency. Both\n\tnumerical simulation and experimental applications demonstrate the\n\teffectiveness of the proposed algorithm\n", "keywords": "phase unwrapping algorithm; global treatment; local treatment; wrapped map;\n\tspeckle-coded interferogram contour maps; unwrapping algorithms; local\n\tdiscontinuity-restoring criterion; postprocessor; hybrid algorithm;\n\trobust stable time effective phase unwrapping; unwrapping problem;\n\tphase inconsistency; numerical simulation; interferogram analysis;\n\tlight interferometry\n", "topicrank": [["novel algorithm", "unwrapping", "hybrid approach", "region", "maps"], ["novel algorithm", "unwrapping", "hybrid approach", "region", "maps", "local", "effective", "criterion", "interferogram contour", "easier"]], "textrank": [["phase unwrapping algorithm", "effective phase", "hybrid algorithm", "phase", "algorithm"], ["phase unwrapping algorithm", "effective phase", "hybrid algorithm", "phase", "algorithm", "numerical simulation", "minor modifications", "local discontinuity", "interferogram contour", "unwrapping"]], "positionrank": [["hybrid algorithm", "unwrapping algorithm", "novel algorithm", "proposed algorithm", "innovative phase"], ["hybrid algorithm", "unwrapping algorithm", "novel algorithm", "proposed algorithm", "innovative phase", "hybrid approach", "algorithm", "unwrapping problem", "effective phase", "hybrid"]], "multipartiterank": [["novel algorithm", "hybrid approach", "unwrapping", "local", "hybrid"], ["novel algorithm", "hybrid approach", "unwrapping", "local", "hybrid", "effective", "innovative phase unwrapping algorithm", "region", "maps", "global"]]}, {"id": "2054", "text": "Teaching modeling in management science\nThis essay discusses how we can most effectively teach Management Science to\n\tstudents in MBA or similar programs who will be, at best, part-time\n\tpractitioners of these arts. I take as a working hypothesis the radical\n\tproposition that the heart of Management Science itself is not the\n\timpressive array of tools that have been built up over the years\n\t(optimization, simulation, decision analysis, queuing, and so on) but\n\trather the art of reasoning logically with formal models. I believe it\n\tis necessary with this group of students to teach basic modeling\n\tskills, and in fact it is only when such students have these basic\n\tskills as a foundation that they are prepared to acquire the more\n\tsophisticated skills needed to employ Management Science. In this paper\n\tI present a hierarchy of modeling skills, from numeracy skills through\n\tsophisticated Management Science skills, as a framework within which to\n\tplan courses for the occasional practitioner\n", "keywords": "management science; modeling; numeracy skills; formal models; decision analysis\n", "topicrank": [["skills", "management science", "students", "basic modeling", "time"], ["skills", "management science", "students", "basic modeling", "time", "decision analysis", "part", "simulation", "radical", "proposition"]], "textrank": [["modeling skills", "sophisticated skills", "sophisticated management", "such students", "formal models"], ["modeling skills", "sophisticated skills", "sophisticated management", "such students", "formal models", "decision analysis", "impressive array", "similar programs", "skills", "management"]], "positionrank": [["sophisticated management science", "management science", "sophisticated skills", "modeling skills", "numeracy skills"], ["sophisticated management science", "management science", "sophisticated skills", "modeling skills", "numeracy skills", "skills", "such students", "basic modeling", "similar programs", "students"]], "multipartiterank": [["skills", "management science", "basic modeling", "students", "time"], ["skills", "management science", "basic modeling", "students", "time", "group", "decision analysis", "radical", "part", "simulation"]]}, {"id": "1980", "text": "Lossy to lossless object-based coding of 3-D MRI data\nWe propose a fully three-dimensional (3-D) object-based coding system\n\texploiting the diagnostic relevance of the different regions of the\n\tvolumetric data for rate allocation. The data are first decorrelated\n\tvia a 3-D discrete wavelet transform. The implementation via the\n\tlifting steps scheme allows to map integer-to-integer values, enabling\n\tlossless coding, and facilitates the definition of the object-based\n\tinverse transform. The coding process assigns disjoint segments of the\n\tbitstream to the different objects, which can be independently accessed\n\tand reconstructed at any up-to-lossless quality. Two fully 3-D coding\n\tstrategies are considered: embedded zerotree coding (EZW-3D) and\n\tmultidimensional layered zero coding (MLZC), both generalized for\n\tregion of interest (ROI)-based processing. In order to avoid artifacts\n\talong region boundaries, some extra coefficients must be encoded for\n\teach object. This gives rise to an overheading of the bitstream with\n\trespect to the case where the volume is encoded as a whole. The amount\n\tof such extra information depends on both the filter length and the\n\tdecomposition depth. The system is characterized on a set of head\n\tmagnetic resonance images. Results show that MLZC and EZW-3D have\n\tcompetitive performances. In particular, the best MLZC mode outperforms\n\tthe others state-of-the-art techniques on one of the datasets for which\n\tresults are available in the literature\n", "keywords": "lossy object-based coding; lossless object-based coding; 3-D MRI data;\n\tdiagnostic relevance; volumetric data; rate allocation; 3-D discrete\n\twavelet transform; lifting steps scheme; integer-to-integer values;\n\tobject-based inverse transform; disjoint segments; bitstream; embedded\n\tzerotree coding; EZW-3D; multidimensional layered zero coding; NMZQ;\n\tregion of interest-based processing; ROI-based processing; region\n\tboundaries; filter length; decomposition depth; head magnetic resonance\n\timages\n", "topicrank": [["object", "mlzc", "coding", "mri data", "ezw-3d"], ["object", "mlzc", "coding", "mri data", "ezw-3d", "results", "region", "bitstream", "system", "different regions"]], "textrank": [["lossless coding", "wavelet transform", "filter length", "region boundaries", "disjoint segments"], ["lossless coding", "wavelet transform", "filter length", "region boundaries", "disjoint segments", "integer values", "steps scheme", "rate allocation", "diagnostic relevance", "extra"]], "positionrank": [["mri data", "lossless coding", "object", "zerotree coding", "volumetric data"], ["mri data", "lossless coding", "object", "zerotree coding", "volumetric data", "coding", "data", "discrete wavelet transform", "different regions", "inverse transform"]], "multipartiterank": [["object", "coding", "mri data", "mlzc", "ezw-3d"], ["object", "coding", "mri data", "mlzc", "ezw-3d", "region", "results", "system", "bitstream", "different regions"]]}, {"id": "2149", "text": "Security crisis management - the basics\nOf the more pervasive problems in any kind of security event is how the\n\tsecurity event is managed from the inception to the end. There's a lot\n\twritten about how to manage a specific incident or how to deal with a\n\tpoint problem such as a firewall log, but little tends to be written\n\tabout how to deal with the management of a security event as part of\n\tcorporate crisis management. This article discusses the basics of\n\tsecurity crisis management and of the logical steps required to ensure\n\tthat a security crisis does not get out of hand\n", "keywords": "security crisis management; security event; firewall log; corporate crisis\n\tmanagement\n", "topicrank": [["security crisis management", "security event", "basics", "part", "kind"], ["security crisis management", "security event", "basics", "part", "kind", "article", "inception", "end", "pervasive problems", "management"]], "textrank": [["security crisis", "specific incident", "pervasive problems", "crisis", "problem"], ["security crisis", "specific incident", "pervasive problems", "crisis", "problem", "security", "firewall"]], "positionrank": [["security crisis management", "security crisis", "corporate crisis management", "security event", "management"], ["security crisis management", "security crisis", "corporate crisis management", "security event", "management", "basics", "pervasive problems", "logical steps", "article", "kind"]], "multipartiterank": [["security crisis management", "security event", "basics", "article", "kind"], ["security crisis management", "security event", "basics", "article", "kind", "part", "pervasive problems", "logical steps", "inception", "end"]]}, {"id": "203", "text": "Plenoptic image editing\nThis paper presents a new class of interactive image editing operations\n\tdesigned to maintain consistency between multiple images of a physical\n\t3D scene. The distinguishing feature of these operations is that edits\n\tto any one image propagate automatically to all other images as if the\n\t(unknown) 3D scene had itself been modified. The modified scene can\n\tthen be viewed interactively from any other camera viewpoint and under\n\tdifferent scene illuminations. The approach is useful first as a\n\tpower-assist that enables a user to quickly modify many images by\n\tediting just a few, and second as a means for constructing and editing\n\timage-based scene representations by manipulating a set of photographs.\n\tThe approach works by extending operations like image painting,\n\tscissoring, and morphing so that they alter a scene's plenoptic\n\tfunction in a physically-consistent way, thereby affecting scene\n\tappearance from all viewpoints simultaneously. A key element in\n\trealizing these operations is a new volumetric decomposition technique\n\tfor reconstructing an scene's plenoptic function from an incomplete set\n\tof camera viewpoints\n", "keywords": "interactive image editing operations; multiple images; physical 3D scene;\n\tmodified scene; camera viewpoint; image-based scene representations;\n\timage painting; scissoring; morphing; plenoptic function; volumetric\n\tdecomposition technique; plenoptic image editing\n", "topicrank": [["3d scene", "operations", "image", "approach", "function"], ["3d scene", "operations", "image", "approach", "function", "multiple images", "set", "plenoptic image editing", "viewpoints", "plenoptic"]], "textrank": [["plenoptic image editing", "new volumetric decomposition", "image editing", "scene", "other camera"], ["plenoptic image editing", "new volumetric decomposition", "image editing", "scene", "other camera", "other images", "image", "key element", "consistent way", "camera"]], "positionrank": [["plenoptic image editing", "plenoptic function", "3d scene", "different scene illuminations", "image painting"], ["plenoptic image editing", "plenoptic function", "3d scene", "different scene illuminations", "image painting", "scene representations", "modified scene", "image", "scene", "new class"]], "multipartiterank": [["3d scene", "plenoptic image editing", "operations", "image", "multiple images"], ["3d scene", "plenoptic image editing", "operations", "image", "multiple images", "scene", "physical", "approach", "paper", "new class"]]}, {"id": "246", "text": "Adaptive and efficient mutual exclusion\nThe paper presents adaptive algorithms for mutual exclusion using only read and\n\twrite operations; the performance of the algorithms depends only on the\n\tpoint contention, i.e., the number of processes that are concurrently\n\tactive during algorithm execution (and not on n, the total number of\n\tprocesses). Our algorithm has O(k) remote step complexity and O(log k)\n\tsystem response time, where k is the point contention. The remote step\n\tcomplexity is the maximal number of steps performed by a process where\n\ta wait is counted as one step. The system response time is the time\n\tinterval between subsequent entries to the critical section, where one\n\ttime unit is the minimal interval in which every active process\n\tperforms at least one step. The space complexity of this algorithm is\n\tO(N log n), where N is the range of process names. We show how to make\n\tthe space complexity of our algorithm depend solely on n, while\n\tpreserving the other performance measures of the algorithm\n", "keywords": "adaptive mutual exclusion; adaptive algorithms; read operations; write\n\toperations; point contention; algorithm execution; remote step\n\tcomplexity; system response time; critical section; minimal interval;\n\tactive process; space complexity; performance measures\n", "topicrank": [["remote step complexity", "system response time", "algorithm execution", "number", "complexity"], ["remote step complexity", "system response time", "algorithm execution", "number", "complexity", "efficient mutual exclusion", "interval", "adaptive", "processes", "point contention"]], "textrank": [["response time", "step complexity", "point contention", "adaptive algorithms", "log"], ["response time", "step complexity", "point contention", "adaptive algorithms", "log", "process", "number", "performance", "mutual", "time"]], "positionrank": [["efficient mutual exclusion", "mutual exclusion", "adaptive algorithms", "algorithms", "paper"], ["efficient mutual exclusion", "mutual exclusion", "adaptive algorithms", "algorithms", "paper", "remote step complexity", "system response time", "read", "point contention", "remote step"]], "multipartiterank": [["adaptive", "algorithm execution", "remote step complexity", "number", "efficient mutual exclusion"], ["adaptive", "algorithm execution", "remote step complexity", "number", "efficient mutual exclusion", "system response time", "processes", "active", "complexity", "point contention"]]}, {"id": "1938", "text": "A method for solution of systems of linear algebraic equations with\n\tm-dimensional lambda -matrices\nA system of linear algebraic equations with m-dimensional lambda -matrices is\n\tconsidered. The proposed method of searching for the solution of this\n\tsystem lies in reducing it to a numerical system of a special kind\n", "keywords": "linear algebraic equations; numerical system; m-dimensional lambda -matrices\n", "topicrank": [["linear algebraic equations", "system", "solution", "method", "dimensional lambda"], ["linear algebraic equations", "system", "solution", "method", "dimensional lambda", "systems", "special kind"]], "textrank": [["dimensional lambda", "algebraic", "system"], ["dimensional lambda", "algebraic", "system"]], "positionrank": [["linear algebraic equations", "dimensional lambda", "numerical system", "method", "m"], ["linear algebraic equations", "dimensional lambda", "numerical system", "method", "m", "system", "solution", "systems", "special kind"]], "multipartiterank": [["linear algebraic equations", "system", "solution", "method", "dimensional lambda"], ["linear algebraic equations", "system", "solution", "method", "dimensional lambda", "systems", "special kind", "numerical system"]]}, {"id": "2032", "text": "Adaptive digital watermarking using fuzzy logic techniques\nDigital watermarking has been proposed for copyright protection in our digital\n\tsociety. We propose an adaptive digital watermarking scheme based on\n\tthe human visual system model and a fuzzy logic technique. The fuzzy\n\tlogic approach is employed to obtain the different strengths and\n\tlengths of a watermark by the local characteristics of the image in our\n\tproposed scheme. In our experiments, this scheme provides a more robust\n\tand imperceptible watermark\n", "keywords": "adaptive digital watermarking; fuzzy logic techniques; copyright protection;\n\tdigital society; human visual system model; local characteristics;\n\timperceptible watermark; robust watermark; image processing\n", "topicrank": [["adaptive digital", "fuzzy logic techniques", "scheme", "watermark", "local characteristics"], ["adaptive digital", "fuzzy logic techniques", "scheme", "watermark", "local characteristics", "lengths", "logic approach", "society", "different strengths", "image"]], "textrank": [["visual system", "logic", "different strengths", "copyright protection", "digital"], ["visual system", "logic", "different strengths", "copyright protection", "digital"]], "positionrank": [["fuzzy logic techniques", "fuzzy logic technique", "digital watermarking", "logic approach", "copyright protection"], ["fuzzy logic techniques", "fuzzy logic technique", "digital watermarking", "logic approach", "copyright protection", "scheme", "different strengths", "society", "imperceptible watermark", "local characteristics"]], "multipartiterank": [["adaptive digital", "fuzzy logic techniques", "scheme", "watermark", "society"], ["adaptive digital", "fuzzy logic techniques", "scheme", "watermark", "society", "copyright protection", "human visual system model", "local characteristics", "logic approach", "lengths"]]}, {"id": "385", "text": "Multiple model adaptive estimation with filter spawning\nMultiple model adaptive estimation (MMAE) with filter spawning is used to\n\tdetect and estimate partial actuator failures on the VISTA F-16. The\n\ttruth model is a full six-degree-of-freedom simulation provided by\n\tCalspan and General Dynamics. The design models are chosen as 13-state\n\tlinearized models, including first order actuator models. Actuator\n\tfailures are incorporated into the truth model and design model\n\tassuming a \"failure to free stream.\" Filter spawning is used to include\n\tadditional filters with partial actuator failure hypotheses into the\n\tMMAE bank. The spawned filters are based on varying degrees of partial\n\tfailures (in terms of effectiveness) associated with the\n\tcomplete-actuaton-failure hypothesis with the highest conditional\n\tprobability of correctness at the current time. Thus, a blended\n\testimate of the failure effectiveness is found using the filters'\n\testimates based upon a no-failure hypothesis, a complete actuator\n\tfailure hypothesis, and the spawned filters' partial-failure\n\thypotheses. This yields substantial precision in effectiveness\n\testimation, compared with what is possible without spawning additional\n\tfilters, making partial failure adaptation a viable methodology\n", "keywords": "multiple model adaptive estimation; filter spawning; partial actuator failures;\n\tVISTA F-16; truth model; six-degree-of-freedom simulation; Calspan;\n\tin-flight simulator; test aircraft; flight control systems; General\n\tDynamics; linearized models; MMAE; partial failures; conditional\n\tprobability; no-failure hypothesis\n", "topicrank": [["failure", "partial actuator failures", "spawned filters", "truth model", "filter spawning"], ["failure", "partial actuator failures", "spawned filters", "truth model", "filter spawning", "effectiveness", "failures", "actuator", "additional filters", "mmae"]], "textrank": [["actuator failure", "order actuator", "model adaptive", "failure", "actuator"], ["actuator failure", "order actuator", "model adaptive", "failure", "actuator", "model", "mmae bank", "free stream", "general dynamics", "freedom simulation"]], "positionrank": [["multiple model", "adaptive estimation", "filter spawning", "truth model", "design model"], ["multiple model", "adaptive estimation", "filter spawning", "truth model", "design model", "partial actuator failures", "partial failure adaptation", "failure hypothesis", "failure effectiveness", "estimation"]], "multipartiterank": [["partial actuator failures", "failure", "filter spawning", "truth model", "spawned filters"], ["partial actuator failures", "failure", "filter spawning", "truth model", "spawned filters", "multiple model adaptive estimation", "failures", "mmae", "actuator", "failure hypothesis"]]}, {"id": "378", "text": "Incremental motion control of linear synchronous motor\nIn this study a particular incremental motion control problem, which is\n\tspecified by the trapezoidal velocity profile using multisegment\n\tsliding mode control (MSSMC), is proposed to control a permanent magnet\n\tlinear synchronous motor (PMLSM) servo drive system. First, the\n\tstructure and operating principle of the PMLSM are described in detail.\n\tSecond, a field-oriented control PMLSM servo drive is introduced. Then,\n\teach segment of the multisegment switching surfaces is designed to\n\tmatch the corresponding part of the trapezoidal velocity profile, thus\n\tthe motor dynamics on the specified-segment switching surface have the\n\tdesired velocity or acceleration corresponding part of the trapezoidal\n\tvelocity profile. In addition, the proposed control system is\n\timplemented in a PC-based computer control system. Finally, the\n\teffectiveness of the proposed PMLSM servo drive system is demonstrated\n\tby some simulated and experimental results\n", "keywords": "incremental motion control; linear synchronous motor; trapezoidal velocity\n\tprofile; multisegment sliding mode control; permanent magnet motor;\n\tservo drive system; field-oriented control; multisegment switching\n\tsurfaces; motor dynamics\n", "topicrank": [["trapezoidal velocity profile", "servo drive system", "mode control", "pmlsm", "linear synchronous motor"], ["trapezoidal velocity profile", "servo drive system", "mode control", "pmlsm", "linear synchronous motor", "corresponding part", "multisegment", "segment", "incremental motion control", "acceleration"]], "textrank": [["incremental motion control", "control", "synchronous motor", "switching", "corresponding part"], ["incremental motion control", "control", "synchronous motor", "switching", "corresponding part", "operating principle", "permanent magnet", "velocity", "motor"]], "positionrank": [["incremental motion control", "linear synchronous motor", "computer control system", "control system", "servo drive system"], ["incremental motion control", "linear synchronous motor", "computer control system", "control system", "servo drive system", "trapezoidal velocity profile", "mode control", "motor dynamics", "velocity profile", "velocity"]], "multipartiterank": [["trapezoidal velocity profile", "linear synchronous motor", "incremental motion control", "servo drive system", "pmlsm"], ["trapezoidal velocity profile", "linear synchronous motor", "incremental motion control", "servo drive system", "pmlsm", "mode control", "multisegment", "corresponding part", "segment", "mssmc"]]}, {"id": "410", "text": "Lossy SPICE models produce realistic averaged simulations\nIn previous averaged models, the state-space averaging technique or switch\n\twaveforms analysis were usually applied over perfect elements,\n\tnon-inclusive of the ohmic losses. However, if these elements play an\n\tactive role in the DC transfer function, they affect the small-signal\n\tAC analysis by introducing various damping effects. A model is\n\tintroduced in a boost voltage-mode application\n", "keywords": "lossy SPICE models; realistic averaged simulations; state-space averaging\n\ttechnique; switch waveforms analysis; damping effects; boost\n\tvoltage-mode application; ohmic losses; DC transfer function\n", "topicrank": [["waveforms analysis", "lossy spice models", "perfect elements", "signal", "small"], ["waveforms analysis", "lossy spice models", "perfect elements", "signal", "small", "state", "previous", "space averaging technique", "various damping effects", "realistic averaged simulations"]], "textrank": [["ohmic losses", "perfect elements", "damping", "transfer", "analysis"], ["ohmic losses", "perfect elements", "damping", "transfer", "analysis", "averaging", "-", "averaged", "spice", "elements"]], "positionrank": [["lossy spice models", "realistic averaged simulations", "models", "space averaging technique", "waveforms analysis"], ["lossy spice models", "realistic averaged simulations", "models", "space averaging technique", "waveforms analysis", "state", "ac analysis", "perfect elements", "various damping effects", "dc transfer function"]], "multipartiterank": [["lossy spice models", "realistic averaged simulations", "waveforms analysis", "perfect elements", "previous"], ["lossy spice models", "realistic averaged simulations", "waveforms analysis", "perfect elements", "previous", "state", "space averaging technique", "signal", "models", "ac analysis"]]}, {"id": "265", "text": "Pattern recognition strategies for molecular surfaces. II. Surface\n\tcomplementarity\nFor pt.I see ibid., vol.23, p.1176-87 (2002). Fuzzy logic based algorithms for\n\tthe quantitative treatment of complementarity of molecular surfaces are\n\tpresented. Therein, the overlapping surface patches defined in part I\n\tof this series are used. The identification of complementary surface\n\tpatches can be considered as a first step for the solution of molecular\n\tdocking problems. Standard technologies can then be used for further\n\toptimization of the resulting complex structures. The algorithms are\n\tapplied to 33 biomolecular complexes. After the optimization with a\n\tdownhill simplex method, for all these complexes one structure was\n\tfound, which is in very good agreement with the experimental results\n", "keywords": "pattern recognition strategies; surface complementarity; fuzzy logic based\n\talgorithms; quantitative treatment; molecular surfaces; overlapping\n\tsurface; biomolecular complexes; optimization; downhill simplex method\n", "topicrank": [["molecular surfaces", "surface", "complementarity", "surface patches", "algorithms"], ["molecular surfaces", "surface", "complementarity", "surface patches", "algorithms", "biomolecular complexes", "optimization", "docking problems", "solution", "identification"]], "textrank": [["docking problems", "first step", "quantitative treatment", "fuzzy logic", "molecular surfaces"], ["docking problems", "first step", "quantitative treatment", "fuzzy logic", "molecular surfaces", "surface", "recognition", "standard", "molecular"]], "positionrank": [["pattern recognition strategies", "molecular surfaces", "surface patches", "complementary surface", "surface"], ["pattern recognition strategies", "molecular surfaces", "surface patches", "complementary surface", "surface", "complementarity", "ii", "quantitative treatment", "first step", "fuzzy logic"]], "multipartiterank": [["molecular surfaces", "complementarity", "surface", "algorithms", "surface patches"], ["molecular surfaces", "complementarity", "surface", "algorithms", "surface patches", "optimization", "biomolecular complexes", "quantitative treatment", "pattern recognition strategies", "docking problems"]]}, {"id": "2197", "text": "A context-aware decision engine for content adaptation\nBuilding a good content adaptation service for mobile devices poses many\n\tchallenges. To meet these challenges, this quality-of-service-aware\n\tdecision engine automatically negotiates for the appropriate adaptation\n\tdecision for synthesizing an optimal content version\n", "keywords": "content adaptation; mobile devices; quality-of-service-aware; decision engine;\n\toptimal content version; adaptation decision\n", "topicrank": [["aware decision engine", "content adaptation", "challenges", "mobile devices", "many"], ["aware decision engine", "content adaptation", "challenges", "mobile devices", "many", "aware", "service", "quality", "context", "optimal content version"]], "textrank": [["content adaptation", "content", "mobile devices", "adaptation", "decision"], ["content adaptation", "content", "mobile devices", "adaptation", "decision"]], "positionrank": [["aware decision engine", "content adaptation", "decision engine", "appropriate adaptation", "optimal content version"], ["aware decision engine", "content adaptation", "decision engine", "appropriate adaptation", "optimal content version", "decision", "mobile devices", "service", "context", "challenges"]], "multipartiterank": [["aware decision engine", "content adaptation", "challenges", "context", "mobile devices"], ["aware decision engine", "content adaptation", "challenges", "context", "mobile devices", "many", "good content adaptation service", "aware", "service", "quality"]]}, {"id": "220", "text": "How to avoid merger pitfalls\nPaul Diamond of consultancy KPMG explains why careful IT asset management is\n\tcrucial to the success of mergers\n", "keywords": "consultancy; KPMG; IT asset management; mergers\n", "topicrank": [["paul diamond", "success", "consultancy kpmg", "mergers", "merger pitfalls"], ["paul diamond", "success", "consultancy kpmg", "mergers", "merger pitfalls", "crucial"]], "textrank": [["it asset", "merger pitfalls"], ["it asset", "merger pitfalls"]], "positionrank": [["consultancy kpmg", "paul diamond", "merger pitfalls", "success", "mergers"], ["consultancy kpmg", "paul diamond", "merger pitfalls", "success", "mergers"]], "multipartiterank": [["paul diamond", "success", "consultancy kpmg", "mergers", "merger pitfalls"], ["paul diamond", "success", "consultancy kpmg", "mergers", "merger pitfalls", "crucial"]]}, {"id": "199", "text": "On optimality in auditory information processing\nWe study limits for the detection and estimation of weak sinusoidal signals in\n\tthe primary part of the mammalian auditory system using a stochastic\n\tFitzhugh-Nagumo model and an action-recovery model for synaptic\n\tdepression. Our overall model covers the chain from a hair cell to a\n\tpoint just after the synaptic connection with a cell in the cochlear\n\tnucleus. The information processing performance of the system is\n\tevaluated using so-called phi -divergences from statistics that\n\tquantify \"dissimilarity\" between probability measures and are\n\tintimately related to a number of fundamental limits in statistics and\n\tinformation theory (IT). We show that there exists a set of parameters\n\tthat can optimize several important phi -divergences simultaneously and\n\tthat this set corresponds to a constant quiescent firing rate (QFR) of\n\tthe spiral ganglion neuron. The optimal value of the QFR is frequency\n\tdependent but is essentially independent of the amplitude of the signal\n\t(for small amplitudes). Consequently, optimal processing according to\n\tseveral standard IT criteria can be accomplished for this model if and\n\tonly if the parameters are \"tuned\" to values that correspond to one and\n\tthe same QFR. This offers a new explanation for the QFR and can provide\n\tnew insight into the role played by several other parameters of the\n\tperipheral auditory system\n", "keywords": "weak sinusoidal signals; mammalian auditory system; stochastic Fitzhugh-Nagumo\n\tmodel; action-recovery model; peripheral auditory system; quiescent\n\tfiring rate; spiral ganglion neuron; brain\n", "topicrank": [["nagumo model", "qfr", "mammalian auditory system", "synaptic", "statistics"], ["nagumo model", "qfr", "mammalian auditory system", "synaptic", "statistics", "limits", "hair cell", "auditory information processing", "phi -divergences", "optimal value"]], "textrank": [["auditory information processing", "several standard it", "several important phi", "information processing", "optimal processing"], ["auditory information processing", "several standard it", "several important phi", "information processing", "optimal processing", "several other", "quiescent firing", "auditory", "synaptic connection", "hair cell"]], "positionrank": [["auditory information processing", "information processing performance", "mammalian auditory system", "peripheral auditory system", "optimal processing"], ["auditory information processing", "information processing performance", "mammalian auditory system", "peripheral auditory system", "optimal processing", "weak sinusoidal signals", "information theory", "fundamental limits", "nagumo model", "recovery model"]], "multipartiterank": [["nagumo model", "mammalian auditory system", "synaptic", "auditory information processing", "qfr"], ["nagumo model", "mammalian auditory system", "synaptic", "auditory information processing", "qfr", "limits", "fitzhugh", "hair cell", "statistics", "stochastic"]]}, {"id": "298", "text": "Defining electronic librarianship: a content analysis of job advertisements\nAdvances in technology create dramatic changes within libraries. The complex\n\tissues surrounding this new electronic, end-user environment have major\n\tramifications and require expert knowledge. Electronic services\n\tlibrarians and electronic resources librarians are two specialized\n\ttitles that have recently emerged within the field of librarianship to\n\tfill this niche. Job advertisements listed in American Libraries from\n\tJanuary 1989 to December 1998 were examined to identify\n\tresponsibilities, qualifications, organizational and salary information\n\trelating to the newly emerging role of electronic librarian\n", "keywords": "electronic librarianship; content analysis; job advertisements; electronic\n\tend-user environment; electronic resources librarians; electronic\n\tservices librarians; American Libraries; responsibilities;\n\tqualifications; organizational information; salary information\n", "topicrank": [["new electronic", "job advertisements", "libraries", "librarians", "electronic librarianship"], ["new electronic", "job advertisements", "libraries", "librarians", "electronic librarianship", "user environment", "major", "dramatic changes", "end", "technology"]], "textrank": [["electronic resources", "electronic", "user environment", "dramatic changes", "job advertisements"], ["electronic resources", "electronic", "user environment", "dramatic changes", "job advertisements", "content analysis", "expert", "libraries"]], "positionrank": [["electronic resources librarians", "electronic librarianship", "electronic services", "electronic librarian", "job advertisements"], ["electronic resources librarians", "electronic librarianship", "electronic services", "electronic librarian", "job advertisements", "content analysis", "american libraries", "dramatic changes", "librarianship", "expert knowledge"]], "multipartiterank": [["new electronic", "job advertisements", "libraries", "electronic librarianship", "librarians"], ["new electronic", "job advertisements", "libraries", "electronic librarianship", "librarians", "end", "dramatic changes", "user environment", "issues", "complex"]]}, {"id": "36", "text": "Model predictive control helps to regulate slow processes-robust barrel\n\ttemperature control\nSlow temperature control is a challenging control problem. The problem becomes\n\teven more challenging when multiple zones are involved, such as in\n\tbarrel temperature control for extruders. Often, strict closed-loop\n\tperformance requirements (such as fast startup with no overshoot and\n\tmaintaining tight temperature control during production) are given for\n\tsuch applications. When characteristics of the system are examined, it\n\tbecomes clear that a commonly used proportional plus integral plus\n\tderivative (PID) controller cannot meet such performance specifications\n\tfor this kind of system. The system either will overshoot or not\n\tmaintain the temperature within the specified range during the\n\tproduction run. In order to achieve the required performance, a control\n\tstrategy that utilizes techniques such as model predictive control,\n\tautotuning, and multiple parameter PID is formulated. This control\n\tstrategy proves to be very effective in achieving the desired\n\tspecifications, and is very robust\n", "keywords": "model predictive control; slow processes regulation; robust barrel temperature\n\tcontrol; extruders; autotuning; multiple parameter PID\n", "topicrank": [["temperature control", "model predictive control", "system", "performance requirements", "pid"], ["temperature control", "model predictive control", "system", "performance requirements", "pid", "production", "strategy", "robust barrel", "derivative", "loop"]], "textrank": [["barrel temperature control", "slow temperature control", "temperature control", "such performance", "predictive control"], ["barrel temperature control", "slow temperature control", "temperature control", "such performance", "predictive control", "multiple parameter", "temperature", "fast startup", "strict closed", "performance"]], "positionrank": [["model predictive control", "slow temperature control", "barrel temperature control", "tight temperature control", "temperature control"], ["model predictive control", "slow temperature control", "barrel temperature control", "tight temperature control", "temperature control", "predictive control", "control problem", "control", "such performance specifications", "slow processes"]], "multipartiterank": [["model predictive control", "temperature control", "robust barrel", "system", "pid"], ["model predictive control", "temperature control", "robust barrel", "system", "pid", "performance requirements", "slow processes", "production", "strategy", "loop"]]}, {"id": "2112", "text": "Allan variance and fractal Brownian motion\nNoise filtering is the subject of a voluminous literature in radio engineering.\n\tThe methods of filtering require knowledge of the frequency response,\n\twhich is usually unknown. D.W. Allan (see Proc. IEEE, vol.54, no.2,\n\tp.221-30, 1966; IEEE Trans. Instr. Measur., vol.IM-36, p.646-54, 1987)\n\tproposed a simple method of determining the interval between equally\n\taccurate observations which does without this information. In this\n\tmethod, the variances of the increments of noise and signal are equal,\n\tso that, in observations with a greater step, the variations caused by\n\tnoise are smaller than those caused by the signal. This method is the\n\tstandard accepted by the USA metrology community. The present paper is\n\tdevoted to a statistical analysis of the Allan method and acquisition\n\tof additional information\n", "keywords": "Allan variance; fractal Brownian motion; noise filtering; radio engineering;\n\tfrequency response; USA metrology community; statistical analysis;\n\twhite noise\n", "topicrank": [["simple method", "noise filtering", "signal", "ieee", "accurate observations"], ["simple method", "noise filtering", "signal", "ieee", "accurate observations", "information", "increments", "instr", "measur", "equal"]], "textrank": [["allan method", "filtering require knowledge", "ieee trans", "frequency response", "radio engineering"], ["allan method", "filtering require knowledge", "ieee trans", "frequency response", "radio engineering", "voluminous literature", "noise filtering", "allan", "metrology", "brownian"]], "positionrank": [["allan variance", "allan method", "fractal brownian motion", "d.w. allan", "noise filtering"], ["allan variance", "allan method", "fractal brownian motion", "d.w. allan", "noise filtering", "noise", "voluminous literature", "radio engineering", "simple method", "ieee trans"]], "multipartiterank": [["noise filtering", "simple method", "ieee", "fractal brownian motion", "accurate observations"], ["noise filtering", "simple method", "ieee", "fractal brownian motion", "accurate observations", "noise", "signal", "voluminous literature", "subject", "method"]]}, {"id": "2157", "text": "Shaping the future. BendWizard: a tool for off-line programming of robotic\n\ttending systems\nSetting up a robot to make metal cabinets or cases for desktop computers can be\n\ta complex operation. For instance, one expert might be required to\n\tcarry out a feasibility study, and then another to actually program the\n\trobot. Understandably, the need for so much expertise, and the time\n\tthat's required, generally limits the usefulness of automation to\n\thigh-volume production. Workshops producing parts in batches smaller\n\tthan 50 or so, or which rely heavily on semiskilled operators, are\n\ttherefore often discouraged from investing in automation, and so miss\n\tout on its many advantages. What is needed is a software tool that\n\toperators without special knowledge of robotics, or with no more than\n\trudimentary CAD skills, can use. One which allows easy offline\n\tprogramming and simulation of the work cell on a PC\n", "keywords": "robotic tending systems; BendWizard offline programming tool; metal cabinets;\n\tdesktop computer cases; feasibility study; high-volume production;\n\tworkshops; CAD skills; work cell simulation\n", "topicrank": [["line programming", "tool", "automation", "robot", "operators"], ["line programming", "tool", "automation", "robot", "operators", "volume production", "workshops", "parts", "cases", "high"]], "textrank": [["volume production", "much expertise", "feasibility study", "complex operation", "desktop computers"], ["volume production", "much expertise", "feasibility study", "complex operation", "desktop computers", "metal cabinets", "line programming", "cad", "programming", "tool"]], "positionrank": [["line programming", "software tool", "tool", "future", "programming"], ["line programming", "software tool", "tool", "future", "programming", "desktop computers", "bendwizard", "metal cabinets", "complex operation", "robot"]], "multipartiterank": [["line programming", "tool", "robot", "automation", "robotic"], ["line programming", "tool", "robot", "automation", "robotic", "cases", "metal cabinets", "bendwizard", "operators", "volume production"]]}, {"id": "258", "text": "Building digital collections at the OAC: current strategies with a view to\n\tfuture uses\nProviding a context for the exploration of user defined virtual collections,\n\tthe article describes the history and recent development of the Online\n\tArchive of California (OAC). Stating that usability and user needs are\n\tprimary factors in digital resource development, issues explored\n\tinclude collaborations to build digital collections, reliance upon\n\tprofessional standards for description and encoding, system\n\tarchitecture, interface design, the need for user tools, and the role\n\tof archivists as interpreters in the digital environment\n", "keywords": "digital collections; OAC; future uses; user defined virtual collections;\n\thistory; Online Archive of California; user needs; digital resource;\n\tprofessional standards; system architecture; interface design; user\n\ttools; digital environment; Encoded Archival Description; archival\n\tdescriptive standards; metadata standards; best practices; user studies\n", "topicrank": [["user", "digital collections", "oac", "encoding", "system"], ["user", "digital collections", "oac", "encoding", "system", "description", "archive", "architecture", "california", "professional standards"]], "textrank": [["digital resource development", "digital collections", "professional standards", "primary factors", "future uses"], ["digital resource development", "digital collections", "professional standards", "primary factors", "future uses", "current strategies", "digital", "user", "development", "collections"]], "positionrank": [["digital collections", "digital resource development", "digital environment", "virtual collections", "user needs"], ["digital collections", "digital resource development", "digital environment", "virtual collections", "user needs", "user tools", "current strategies", "recent development", "future uses", "user"]], "multipartiterank": [["user", "digital collections", "oac", "virtual collections", "exploration"], ["user", "digital collections", "oac", "virtual collections", "exploration", "archive", "recent development", "california", "history", "online"]]}, {"id": "1963", "text": "The variance of firm growth rates: the 'scaling' puzzle\nRecent evidence suggests that a power-law relationship exists between a firm's\n\tsize and the variance of its growth rate. The flatness of the relation\n\tis regarded as puzzling, in that it suggests that large firms are not\n\tmuch more stable than small firms. It has been suggested that the\n\tpowerlaw nature of the relationship reflects the presence of some form\n\tof correlation of growth rates across the firm's constituent\n\tbusinesses. Here, it is shown that a model of independent businesses\n\twhich allows for the fact that these businesses vary in size, as\n\tmodelled by a simple 'partitions of integers' model, provides a good\n\trepresentation of what is observed empirically\n", "keywords": "firm growth rates; scaling puzzle; power-law; flatness; correlation;\n\tconstituent businesses; partitions of integers model; size\n\tdistribution; corporate growth\n", "topicrank": [["firm growth rates", "businesses", "firm", "law relationship", "model"], ["firm growth rates", "businesses", "firm", "law relationship", "model", "size", "variance", "large firms", "partitions", "integers"]], "textrank": [["independent businesses", "powerlaw nature", "law relationship", "recent evidence", "growth"], ["independent businesses", "powerlaw nature", "law relationship", "recent evidence", "growth", "firms", "businesses", "relationship"]], "positionrank": [["firm growth rates", "growth rates", "growth rate", "firm", "law relationship"], ["firm growth rates", "growth rates", "growth rate", "firm", "law relationship", "variance", "recent evidence", "relationship", "independent businesses", "size"]], "multipartiterank": [["firm growth rates", "variance", "businesses", "firm", "law relationship"], ["firm growth rates", "variance", "businesses", "firm", "law relationship", "size", "model", "power", "recent evidence", "large firms"]]}, {"id": "300", "text": "The plot thins: thin-client computer systems and academic libraries\nThe few libraries that have tried thin client architectures have noted a number\n\tof compelling reasons to do so. For starters, thin client devices are\n\tfar less expensive than most PCs. More importantly, thin client\n\tcomputing devices are believed to be far less expensive to manage and\n\tsupport than traditional PCs\n", "keywords": "academic libraries; thin-client computer systems\n", "topicrank": [["thin", "expensive", "client computer systems", "starters", "academic libraries"], ["thin", "expensive", "client computer systems", "starters", "academic libraries", "compelling reasons", "number", "computing devices", "support", "plot thins"]], "textrank": [["client devices", "client computer", "client", "pcs", "libraries"], ["client devices", "client computer", "client", "pcs", "libraries", "devices", "plot"]], "positionrank": [["thin client devices", "thin client architectures", "thin client", "client computer systems", "academic libraries"], ["thin client devices", "thin client architectures", "thin client", "client computer systems", "academic libraries", "few libraries", "plot thins", "most pcs", "computing devices", "compelling reasons"]], "multipartiterank": [["thin", "client computer systems", "plot thins", "academic libraries", "expensive"], ["thin", "client computer systems", "plot thins", "academic libraries", "expensive", "number", "starters", "compelling reasons", "computing devices", "support"]]}, {"id": "345", "text": "In search of strategic operations research/management science\nWe define strategic OR/MS as \"OR/MS work that leads to a sustainable\n\tcompetitive advantage.\" We found evidence of strategic OR/MS in the\n\tliterature of strategic information systems (SIS) and OR/MS. We\n\texamined 30 early examples of SIS, many of which contained OR/MS work.\n\tMany of the most successful had high OR/MS content, while the least\n\tsuccessful contained none. The inclusion of OR/MS work may be a key to\n\tsustaining an advantage from information technology. We also examined\n\tthe Edelman Prize finalist articles published between 1990 and 1999. We\n\tfound that 13 of the 42 private sector applications meet our definition\n\tof strategic OR/MS\n", "keywords": "operations research; management science; strategic OR/MS; strategic information\n\tsystems; SIS\n", "topicrank": [["ms work", "successful", "sis", "competitive advantage", "many"], ["ms work", "successful", "sis", "competitive advantage", "many", "none", "least", "strategic information systems", "inclusion", "strategic operations research"]], "textrank": [["strategic information", "strategic or", "strategic operations", "prize finalist", "management science"], ["strategic information", "strategic or", "strategic operations", "prize finalist", "management science", "information", "sector", "ms", "or", "competitive"]], "positionrank": [["strategic or", "strategic operations research", "strategic information systems", "ms work", "high or"], ["strategic or", "strategic operations research", "strategic information systems", "ms work", "high or", "or", "ms content", "ms", "management science", "search"]], "multipartiterank": [["ms work", "sis", "successful", "competitive advantage", "many"], ["ms work", "sis", "successful", "competitive advantage", "many", "sustainable", "strategic information systems", "none", "strategic operations research", "least"]]}, {"id": "1947", "text": "Modelling user acceptance of building management systems\nThis study examines user acceptance of building management systems (BMS) using\n\ta questionnaire survey. These systems are crucial for optimising\n\tbuilding performance and yet it has been widely reported that users are\n\tnot making full use of their systems' facilities. Established models of\n\ttechnology acceptance have been employed in this research, and the\n\tpositive influence of user perceptions of ease of use and compatibility\n\thas been demonstrated. Previous research has indicated differing levels\n\tof importance of perceived ease of use relative to other factors. Here,\n\tperceived ease of use is shown generally to be more important, though\n\tthe balance between this and compatibility is moderated by the user\n\tperceptions of voluntariness\n", "keywords": "user acceptance modelling; building management systems; technology acceptance\n\tmodel; innovation characteristics; information systems; questionnaire\n\tsurvey; user perceptions; ease of use; compatibility; voluntariness\n", "topicrank": [["management systems", "full use", "ease", "user perceptions", "acceptance"], ["management systems", "full use", "ease", "user perceptions", "acceptance", "compatibility", "research", "user acceptance", "facilities", "positive influence"]], "textrank": [["building management systems", "user acceptance", "building performance", "questionnaire survey", "use"], ["building management systems", "user acceptance", "building performance", "questionnaire survey", "use", "user", "acceptance", "research", "systems"]], "positionrank": [["management systems", "user acceptance", "systems", "user perceptions", "technology acceptance"], ["management systems", "user acceptance", "systems", "user perceptions", "technology acceptance", "acceptance", "user", "full use", "use", "questionnaire survey"]], "multipartiterank": [["management systems", "full use", "acceptance", "ease", "systems"], ["management systems", "full use", "acceptance", "ease", "systems", "user acceptance", "study", "bms", "user perceptions", "research"]]}, {"id": "239", "text": "Content standards for electronic books: the OEBF publication structure and the\n\trole of public interest participation\nIn the emerging world of electronic publishing how we create, distribute, and\n\tread books will be in a large part determined by an underlying\n\tframework of content standards that establishes the range of\n\ttechnological opportunities and constraints for publishing and reading\n\tsystems. But efforts to develop content standards based on sound\n\tengineering models must skillfully negotiate competing and sometimes\n\tapparently irreconcilable objectives if they are to produce results\n\trelevant to the rapidly changing course of technology. The Open eBook\n\tForum's Publication Structure, an XML-based specification for\n\telectronic books, is an example of the sort of timely and innovative\n\tproblem solving required for successful real-world standards\n\tdevelopment. As a result of this effort, the electronic book industry\n\twill not only happen sooner and on a larger scale than it would have\n\totherwise, but the electronic books it produces will be more\n\tfunctional, more interoperable, and more accessible to all readers.\n\tPublic interest participants have a critical role in this process\n", "keywords": "electronic publishing; electronic books; content standards; OEBF Publication\n\tStructure; public interest participation; Open eBook Forum Publication\n\tStructure; XML-based specification\n", "topicrank": [["electronic books", "content standards", "world", "oebf publication structure", "electronic publishing"], ["electronic books", "content standards", "world", "oebf publication structure", "electronic publishing", "public interest participation", "role", "timely", "innovative", "forum"]], "textrank": [["electronic book", "successful real", "problem solving", "open ebook", "irreconcilable objectives"], ["electronic book", "successful real", "problem solving", "open ebook", "irreconcilable objectives", "engineering models", "technological opportunities", "large part", "interest", "electronic"]], "positionrank": [["content standards", "world standards", "electronic books", "oebf publication structure", "electronic publishing"], ["content standards", "world standards", "electronic books", "oebf publication structure", "electronic publishing", "publication structure", "electronic book industry", "public interest participation", "public interest participants", "books"]], "multipartiterank": [["electronic books", "content standards", "world", "electronic publishing", "oebf publication structure"], ["electronic books", "content standards", "world", "electronic publishing", "oebf publication structure", "public interest participation", "role", "framework", "constraints", "technological opportunities"]]}, {"id": "2136", "text": "A method of determining a sequence of the best solutions to the problems of\n\toptimization on finite sets and the problem of network reconstruction\nA method of determining a sequence of the best solutions to the problems of\n\toptimization on finite sets was proposed. Its complexity was estimated\n\tby a polynomial of the dimension of problem input, given number of\n\tsequence terms, and complexity of completing the design of the original\n\textremal problem. The technique developed was applied to the typical\n\tproblem of network reconstruction with the aim of increasing its\n\tthroughput under restricted reconstruction costs\n", "keywords": "best solutions; optimization; finite sets; network reconstruction; complexity\n", "topicrank": [["problem", "network reconstruction", "sequence", "finite sets", "optimization"], ["problem", "network reconstruction", "sequence", "finite sets", "optimization", "problems", "best solutions", "complexity", "method", "original"]], "textrank": [["sequence terms", "finite sets", "best solutions", "reconstruction", "problem"], ["sequence terms", "finite sets", "best solutions", "reconstruction", "problem", "sequence"]], "positionrank": [["best solutions", "finite sets", "sequence terms", "network reconstruction", "problem input"], ["best solutions", "finite sets", "sequence terms", "network reconstruction", "problem input", "extremal problem", "method", "sequence", "problem", "reconstruction costs"]], "multipartiterank": [["problem", "network reconstruction", "sequence", "finite sets", "optimization"], ["problem", "network reconstruction", "sequence", "finite sets", "optimization", "best solutions", "problems", "method", "complexity", "typical"]]}, {"id": "281", "text": "Factors contributing to preservice teachers' discomfort in a Web-based course\n\tstructured as an inquiry\nA report is given of a qualitative emergent design study of a Science,\n\tTechnology, Society Interaction (STS) Web-enhanced course. Students'\n\tdiscomfort during the pilot test provided insight into the intellectual\n\tscaffolding that preservice secondary science teachers needed to\n\toptimize their performance when required to develop understanding\n\tthrough open-ended inquiry in a Web environment. Eight factors\n\tidentified contributed to student discomfort: computer skills, paradigm\n\tshifts, trust, time management, thinking about their own thinking,\n\tsystematic inquiry, self-assessment, and scientific discourse. These\n\tfactors suggested developing understanding through inquiry by\n\tconducting a self-designed, open-ended, systematic inquiry required\n\tautonomous learning involving metacognitive skills and time management\n\tskills. To the extent in which students either came into the course\n\twith this scaffolding, or developed it during the course, they were\n\tsuccessful in learning about STS and its relationship to science\n\tteaching. Changes in the Web site made to accommodate learners' needs\n\tas they surfaced are described\n", "keywords": "preservice teacher discomfort; Web-based course; qualitative emergent design\n\tstudy; science technology society interaction course; Web-enhanced\n\tcourse; student discomfort; intellectual scaffolding; preservice\n\tsecondary science teachers; open-ended inquiry; Web environment;\n\tcomputer skills; paradigm shifts; trust; time management; thinking;\n\tsystematic inquiry; self-assessment; scientific discourse; autonomous\n\tlearning; metacognitive skills; time management skills; STS; science\n\tteaching\n", "topicrank": [["web", "inquiry", "course", "computer skills", "discomfort"], ["web", "inquiry", "course", "computer skills", "discomfort", "factors", "time management", "science", "sts", "ended inquiry"]], "textrank": [["preservice secondary science teachers", "emergent design", "own thinking", "time management", "pilot test"], ["preservice secondary science teachers", "emergent design", "own thinking", "time management", "pilot test", "society interaction", "preservice teachers", "skills", "inquiry", "web"]], "positionrank": [["secondary science teachers", "factors", "preservice teachers", "ended inquiry", "systematic inquiry"], ["secondary science teachers", "factors", "preservice teachers", "ended inquiry", "systematic inquiry", "web environment", "web site", "web", "inquiry", "discomfort"]], "multipartiterank": [["web", "inquiry", "discomfort", "course", "computer skills"], ["web", "inquiry", "discomfort", "course", "computer skills", "factors", "sts", "preservice teachers", "science", "understanding"]]}, {"id": "2173", "text": "E-mail and the legal profession\nThe widespread use of E-mail can be found in all areas of commerce, and the\n\tlegal profession is one that has embraced this new medium of\n\tcommunication. E-mail is not without its drawbacks, however. Due to the\n\tnature of the technologies behind the medium, it is a less secure form\n\tof communication than many of those traditionally used by the legal\n\tprofession, including DX, facsimile, and standard and registered post.\n\tThere are a number of ways in which E-mails originating from the\n\tpractice may be protected, including software encryption, hardware\n\tencryption and various methods of controlling and administering access\n\tto the E-mails\n", "keywords": "E-mail; legal profession; secure communication; software encryption; hardware\n\tencryption; access control\n", "topicrank": [["legal profession", "software encryption", "communication", "new medium", "mails"], ["legal profession", "software encryption", "communication", "new medium", "mails", "hardware", "standard", "registered post", "profession", "many"]], "textrank": [["registered post", "secure form", "new medium", "widespread use", "legal profession"], ["registered post", "secure form", "new medium", "widespread use", "legal profession", "-", "profession", "legal", "medium"]], "positionrank": [["e - mail", "legal profession", "e", "widespread use", "profession"], ["e - mail", "legal profession", "e", "widespread use", "profession", "new medium", "medium", "communication", "software encryption", "registered post"]], "multipartiterank": [["legal profession", "communication", "new medium", "software encryption", "hardware"], ["legal profession", "communication", "new medium", "software encryption", "hardware", "one", "mails", "commerce", "areas", "standard"]]}, {"id": "2093", "text": "Fresh tracks [food processing]\nBar code labels and wireless terminals linked to a centralized database\n\taccurately track meat products from receiving to customers for Farmland\n\tFoods\n", "keywords": "food processing; bar code labels; wireless terminals; Farmland Foods; automatic\n\tdata capture; Intermec Technologies\n", "topicrank": [["farmland", "bar code labels", "customers", "wireless terminals", "food processing"], ["farmland", "bar code labels", "customers", "wireless terminals", "food processing", "foods", "meat products", "centralized database", "fresh tracks"]], "textrank": [["food processing", "fresh tracks", "code"], ["food processing", "fresh tracks", "code"]], "positionrank": [["bar code labels", "fresh tracks", "food processing", "wireless terminals", "centralized database"], ["bar code labels", "fresh tracks", "food processing", "wireless terminals", "centralized database", "meat products", "customers", "farmland", "foods"]], "multipartiterank": [["farmland", "bar code labels", "customers", "wireless terminals", "food processing"], ["farmland", "bar code labels", "customers", "wireless terminals", "food processing", "foods", "meat products", "centralized database", "fresh tracks"]]}, {"id": "324", "text": "Using NetCloak to develop server-side Web-based experiments without writing CGI\n\tprograms\nServer-side experiments use the Web server, rather than the participant's\n\tbrowser, to handle tasks such as random assignment, eliminating\n\tinconsistencies with Java and other client-side applications.\n\tHeretofore, experimenters wishing to create server-side experiments\n\thave had to write programs to create common gateway interface (CGI)\n\tscripts in programming languages such as Perl and C++. NetCloak uses\n\tsimple, HTML-like commands to create CGIs. We used NetCloak to\n\timplement an experiment on probability estimation. Measurements of time\n\ton task and participants' IP addresses assisted quality control.\n\tWithout prior training, in less than 1 month, we were able to use\n\tNetCloak to design and create a Web-based experiment and to help\n\tgraduate students create three Web-based experiments of their own\n", "keywords": "NetCloak; server-side Web-based experiments; CGI programs; Web server; random\n\tassignment; Java; client-side applications; common gateway interface\n\tscripts; Perl; C++ language; HTML; probability estimation; IP\n\taddresses; quality control; graduate students; Internet; behavioral\n\tdata; psychology\n", "topicrank": [["server", "experiments", "netcloak", "side web", "cgi"], ["server", "experiments", "netcloak", "side web", "cgi", "programs", "experiment", "probability estimation", "measurements", "html"]], "textrank": [["side web", "languages such", "quality control", "probability estimation", "like commands"], ["side web", "languages such", "quality control", "probability estimation", "like commands", "other client", "random assignment", "side", "gateway", "such"]], "positionrank": [["side experiments", "web server", "side web", "side applications", "netcloak"], ["side experiments", "web server", "side web", "side applications", "netcloak", "server", "experiments", "web", "programs", "common gateway interface"]], "multipartiterank": [["server", "experiments", "netcloak", "side web", "cgi"], ["server", "experiments", "netcloak", "side web", "cgi", "programs", "side experiments", "experiment", "web", "probability estimation"]]}, {"id": "361", "text": "A pretopological approach for structural analysis\nThe aim of this paper is to present a methodological approach for problems\n\tencountered in structural analysis. This approach is based upon the\n\tpretopological concepts of pseudoclosure and minimal closed subsets.\n\tThe advantage of this approach is that it provides a framework which is\n\tgeneral enough to model and formulate different types of connections\n\tthat exist between the elements of a population. In addition, it has\n\tenabled us to develop a new structural analysis algorithm. An\n\texplanation of the definitions and properties of the pretopological\n\tconcepts applied in this work is first shown and illustrated in sample\n\tsettings. The structural analysis algorithm is then described and the\n\tresults obtained in an economic study of the impact of geographic\n\tproximity on scientific collaborations are presented\n", "keywords": "pretopological approach; structural analysis; minimal closed subsets;\n\tpseudoclosure; connections; economic study; geographic proximity;\n\tscientific collaborations\n", "topicrank": [["structural analysis", "methodological approach", "pretopological concepts", "pretopological approach", "geographic"], ["structural analysis", "methodological approach", "pretopological concepts", "pretopological approach", "geographic", "properties", "definitions", "proximity", "pseudoclosure", "impact"]], "textrank": [["structural analysis", "pretopological approach", "minimal closed", "scientific collaborations", "economic study"], ["structural analysis", "pretopological approach", "minimal closed", "scientific collaborations", "economic study", "different types", "pretopological", "approach"]], "positionrank": [["structural analysis algorithm", "pretopological approach", "structural analysis", "methodological approach", "pretopological concepts"], ["structural analysis algorithm", "pretopological approach", "structural analysis", "methodological approach", "pretopological concepts", "approach", "minimal closed subsets", "concepts", "aim", "paper"]], "multipartiterank": [["structural analysis", "methodological approach", "pretopological approach", "pretopological concepts", "approach"], ["structural analysis", "methodological approach", "pretopological approach", "pretopological concepts", "approach", "problems", "aim", "paper", "pseudoclosure", "minimal closed subsets"]]}, {"id": "319", "text": "Designing a screening experiment for highly reliable products\nWithin a reasonable life-testing time, how to improve the reliability of highly\n\treliable products is one of the great challenges. By using a resolution\n\tIII experiment together with degradation test, Tseng et al. (1995)\n\tpresented a case study of improving the reliability of fluorescent\n\tlamps. However, in conducting such an experiment, they did not address\n\tthe problem of how to choose the optimal settings of variables, such as\n\tsample size, inspection frequency, and termination time for each run,\n\twhich are influential to the correct identification of significant\n\tfactors and the experimental cost. Assuming that the product's\n\tdegradation paths satisfy Wiener processes, this paper proposes a\n\tsystematic approach to the aforementioned problem. First, an\n\tidentification rule is proposed. Next, under the constraints of a\n\tminimum probability of correct decision and a maximum probability of\n\tincorrect decision of the proposed identification rule, the optimum\n\ttest plan can be obtained by minimizing the total experimental cost. An\n\texample is provided to illustrate the proposed method\n", "keywords": "screening experiment; highly reliable products; resolution III design;\n\tdegradation tests; Wiener process; inspection frequency; termination\n\ttime; optimal test plan; fluorescent lamps; minimum probability of\n\tcorrect decision; maximum probability of incorrect decision;\n\tidentification rule\n", "topicrank": [["correct identification", "degradation test", "screening experiment", "testing time", "minimum probability"], ["correct identification", "degradation test", "screening experiment", "testing time", "minimum probability", "experimental cost", "reliability", "identification rule", "problem", "reliable products"]], "textrank": [["degradation test", "correct decision", "correct identification", "case study", "great challenges"], ["degradation test", "correct decision", "correct identification", "case study", "great challenges", "reasonable life", "reliable products", "screening experiment", "probability", "experimental"]], "positionrank": [["reliable products", "screening experiment", "reasonable life", "experiment", "testing time"], ["reliable products", "screening experiment", "reasonable life", "experiment", "testing time", "termination time", "great challenges", "degradation test", "reliability", "correct identification"]], "multipartiterank": [["screening experiment", "reliable products", "testing time", "degradation test", "correct identification"], ["screening experiment", "reliable products", "testing time", "degradation test", "correct identification", "reliability", "experiment", "reasonable life", "experimental cost", "problem"]]}, {"id": "2053", "text": "Teaching management science with spreadsheets: From decision models to decision\n\tsupport\nThe 1990s were a decade of enormous change for management science (MS)\n\teducators. While the outlook at the beginning of the decade was\n\tsomewhat bleak, the renaissance in MS education brought about by the\n\tuse of spreadsheets as the primary delivery vehicle for quantitative\n\tmodeling techniques has resulted in a much brighter future. This paper\n\ttakes inventory of the current state of MS education and suggests some\n\tpromising new directions in the area of decision support systems for MS\n\teducators to consider for the future\n", "keywords": "management science; MS education; spreadsheets; quantitative modeling; decision\n\tsupport systems\n", "topicrank": [["decade", "ms education", "support", "spreadsheets", "teaching management science"], ["decade", "ms education", "support", "spreadsheets", "teaching management science", "decision models", "educators", "brighter future", "primary delivery vehicle", "enormous change"]], "textrank": [["decision support", "modeling techniques", "ms education", "enormous change", "delivery"], ["decision support", "modeling techniques", "ms education", "enormous change", "delivery", "management", "support", "decision", "brighter", "ms"]], "positionrank": [["teaching management science", "decision support systems", "management science", "decision models", "ms education"], ["teaching management science", "decision support systems", "management science", "decision models", "ms education", "decision", "ms", "spreadsheets", "enormous change", "support"]], "multipartiterank": [["teaching management science", "spreadsheets", "decision models", "support", "decade"], ["teaching management science", "spreadsheets", "decision models", "support", "decade", "ms education", "educators", "brighter future", "enormous change", "1990s"]]}, {"id": "2016", "text": "Fully automatic algorithm for region of interest location in camera calibration\nWe present an automatic method for region of interest (ROI) location in camera\n\tcalibration used in computer vision inspection. An intelligent ROI\n\tlocation algorithm based on the Radon transform is developed to\n\tautomate the calibration process. The algorithm remains robust even if\n\tthe anchor target has a notable rotation angle in the target plane.\n\tThis method functions well although the anchor target is not carefully\n\tpositioned. Several improvement methods are studied to avoid the\n\talgorithm's huge time/space consumption problem. The algorithm runs\n\tabout 100 times faster if these improvement methods are applied. Using\n\tthis method fully automatic camera calibration is achieved without\n\thuman interactive ROI specification. Experiments show that this\n\talgorithm can help to calibrate the intrinsic parameters of the zoom\n\tlens and the camera parameters quickly and automatically\n", "keywords": "Fully automatic algorithm; interest location; camera calibration; region of\n\tinterest location; computer vision inspection; ROI location algorithm;\n\tRadon transform; calibration process; rotation angle; time/space\n\tconsumption problem; fully automatic camera calibration; human\n\tinteractive specification; intrinsic parameters; zoom lens; camera\n\tparameters\n", "topicrank": [["automatic algorithm", "camera calibration", "automatic method", "roi", "location"], ["automatic algorithm", "camera calibration", "automatic method", "roi", "location", "interest location", "region", "anchor target", "camera", "several improvement methods"]], "textrank": [["automatic camera calibration", "interactive roi", "camera parameters", "camera calibration", "automatic method"], ["automatic camera calibration", "interactive roi", "camera parameters", "camera calibration", "automatic method", "roi", "camera", "automatic", "consumption", "improvement"]], "positionrank": [["automatic camera calibration", "automatic algorithm", "location algorithm", "camera calibration", "automatic method"], ["automatic camera calibration", "automatic algorithm", "location algorithm", "camera calibration", "automatic method", "interest location", "algorithm", "camera parameters", "calibration process", "intelligent roi"]], "multipartiterank": [["automatic algorithm", "camera calibration", "region", "interest location", "automatic method"], ["automatic algorithm", "camera calibration", "region", "interest location", "automatic method", "roi", "location", "camera", "algorithm", "interest"]]}, {"id": "1987", "text": "Virus hunting\nWe all appreciate the need for, and hopefully we have all deployed, anti-virus\n\tsoftware. The good news is that AV software has come a long way fast.\n\tFour or so years ago it was true to write that AV software could not\n\tdetect Trojan Horses and similar intrusion attempts. Now it can and\n\tdoes. McAfee's VirusScan, for example, goes one further; it detects\n\tviruses, worms and Trojan Horses and deploys itself as a firewall to\n\tfilter data packets, control access to Internet resources, activate\n\trule sets for specific applications, in general to protect against\n\thackers. But like so much software, we use it with little thought as to\n\thow it came to do its job. Behind the scenes there is an army of top\n\tnotch programmers trying to stay ahead of the baddies who, at the last\n\tcount, had produced some 60,000 viruses\n", "keywords": "anti-virus software; programmers; worms; Trojan Horses\n", "topicrank": [["software", "trojan horses", "viruses", "top", "worms"], ["software", "trojan horses", "viruses", "top", "worms", "internet resources", "specific applications", "access", "rule sets", "filter data packets"]], "textrank": [["- virus", "rule sets", "internet resources", "trojan horses", "long way"], ["- virus", "rule sets", "internet resources", "trojan horses", "long way", "good news", "data", "intrusion", "software", "virus"]], "positionrank": [["virus hunting", "av software", "much software", "good news", "software"], ["virus hunting", "av software", "much software", "good news", "software", "anti -", "need", "trojan horses", "long way", "similar intrusion attempts"]], "multipartiterank": [["software", "trojan horses", "good news", "viruses", "av software"], ["software", "trojan horses", "good news", "viruses", "av software", "worms", "top", "internet resources", "access", "specific applications"]]}, {"id": "241", "text": "Perspectives on scholarly online books: the Columbia University Online Books\n\tEvaluation Project\nThe Online Books Evaluation Project at Columbia University studied the\n\tpotential for scholarly online books from 1995 to 1999. Issues included\n\tscholars' interest in using online books, the role they might play in\n\tscholarly life, features that scholars and librarians sought in online\n\tbooks, the costs of producing and owning print and online books, and\n\tpotential marketplace arrangements. Scholars see potential for online\n\tbooks to make their research, learning, and teaching more efficient and\n\teffective. Librarians see potential to serve their scholars better.\n\tLibrarians may face lower costs if they can serve their scholars with\n\tonline books instead of print books. Publishers may be able to offer\n\tscholars greater opportunities to use their books while enhancing their\n\town profitability\n", "keywords": "Columbia University Online Books Evaluation Project; scholarly online books;\n\tprint books; costs; marketplace arrangements; research; learning\n", "topicrank": [["scholarly online books", "scholars", "potential", "books", "librarians"], ["scholarly online books", "scholars", "potential", "books", "librarians", "costs", "columbia university online books", "evaluation project", "effective", "research"]], "textrank": [["online books evaluation", "university online books", "scholarly online books", "online books", "lower costs"], ["online books evaluation", "university online books", "scholarly online books", "online books", "lower costs", "books", "online", "greater", "marketplace", "evaluation"]], "positionrank": [["scholarly online books", "online books", "print books", "books", "columbia university"], ["scholarly online books", "online books", "print books", "books", "columbia university", "evaluation project", "potential marketplace arrangements", "scholarly life", "scholars", "perspectives"]], "multipartiterank": [["scholarly online books", "scholars", "potential", "columbia university online books", "books"], ["scholarly online books", "scholars", "potential", "columbia university online books", "books", "evaluation project", "librarians", "online books", "online", "perspectives"]]}, {"id": "204", "text": "Self-calibration from image derivatives\nThis study investigates the problem of estimating camera calibration parameters\n\tfrom image motion fields induced by a rigidly moving camera with\n\tunknown parameters, where the image formation is modeled with a linear\n\tpinhole-camera model. The equations obtained show the flow to be\n\tseparated into a component due to the translation and the calibration\n\tparameters and a component due to the rotation and the calibration\n\tparameters. A set of parameters encoding the latter component is\n\tlinearly related to the flow, and from these parameters the calibration\n\tcan be determined. However, as for discrete motion, in general it is\n\tnot possible to decouple image measurements obtained from only two\n\tframes into translational and rotational components. Geometrically, the\n\tambiguity takes the form of a part of the rotational component being\n\tparallel to the translational component, and thus the scene can be\n\treconstructed only up to a projective transformation. In general, for\n\tfull calibration at least four successive image frames are necessary,\n\twith the 3D rotation changing between the measurements. The geometric\n\tanalysis gives rise to a direct self-calibration method that avoids\n\tcomputation of optical flow or point correspondences and uses only\n\tnormal flow measurements. New constraints on the smoothness of the\n\tsurfaces in view are formulated to relate structure and motion directly\n\tto image derivatives, and on the basis of these constraints the\n\ttransformation of the viewing geometry between consecutive images is\n\testimated. The calibration parameters are then estimated from the\n\trotational components of several flow fields. As the proposed technique\n\tneither requires a special set up nor needs exact correspondence it is\n\tpotentially useful for the calibration of active vision systems which\n\thave to acquire knowledge about their intrinsic parameters while they\n\tperform other tasks, or as a tool for analyzing image sequences in\n\tlarge video databases\n", "keywords": "camera calibration parameters; image motion fields; rigidly moving camera;\n\timage formation; linear pinhole-camera model; calibration parameters;\n\timage measurements; translational components; rotational components;\n\tdirect self-calibration method; optical flow; point correspondences;\n\tnormal flow measurements; active vision systems; image sequences; large\n\tvideo databases; depth distortion\n", "topicrank": [["calibration", "unknown parameters", "flow", "component", "image derivatives"], ["calibration", "unknown parameters", "flow", "component", "image derivatives", "image measurements", "image motion fields", "frames", "new constraints", "translational"]], "textrank": [["camera calibration parameters", "image motion", "calibration parameters", "image", "rotational component"], ["camera calibration parameters", "image motion", "calibration parameters", "image", "rotational component", "flow", "calibration", "exact correspondence", "special set", "consecutive images"]], "positionrank": [["camera calibration parameters", "calibration parameters", "calibration method", "image motion fields", "full calibration"], ["camera calibration parameters", "calibration parameters", "calibration method", "image motion fields", "full calibration", "image derivatives", "calibration", "successive image frames", "image measurements", "direct self"]], "multipartiterank": [["calibration", "unknown parameters", "image derivatives", "parameters", "component"], ["calibration", "unknown parameters", "image derivatives", "parameters", "component", "flow", "image motion fields", "self", "camera", "image measurements"]]}, {"id": "2051", "text": "Who wants to see a $million error?\nInspired by the popular television show \"Who Wants to Be a Millionaire?\", this\n\tcase discusses the monetary decisions contestants face on a game\n\tconsisting of 15 increasingly difficult multiple choice questions.\n\tSince the game continues as long as a contestant answers correctly,\n\tthis case, at its core, is one of sequential decision analysis,\n\tamenable to analysis via stochastic dynamic programming. The case is\n\talso suitable for a course dealing with single decision analysis,\n\tallowing for discussion of utility theory and Bayesian probability\n\trevision. In developing a story line for the case, the author has\n\tsprinkled in much background material on probability and statistics.\n\tThis material is placed in a historical context, illuminating some of\n\tthe influential scholars involved in the development of these subjects\n\tas well as the birth of operations research and the management sciences\n", "keywords": "operations research; game theory; decision analysis; stochastic dynamic\n\tprogramming; educational course; statistics; probabilistic models\n", "topicrank": [["case", "sequential decision analysis", "bayesian probability", "much background material", "game"], ["case", "sequential decision analysis", "bayesian probability", "much background material", "game", "utility theory", "stochastic dynamic programming", "amenable", "revision", "discussion"]], "textrank": [["multiple choice", "story line", "bayesian probability", "utility theory", "contestant answers"], ["multiple choice", "story line", "bayesian probability", "utility theory", "contestant answers", "decision", "background", "dynamic", "decisions", "television"]], "positionrank": [["popular television show", "sequential decision analysis", "single decision analysis", "case", "monetary decisions contestants"], ["popular television show", "sequential decision analysis", "single decision analysis", "case", "monetary decisions contestants", "error", "game", "millionaire", "stochastic dynamic programming", "analysis"]], "multipartiterank": [["case", "sequential decision analysis", "bayesian probability", "much background material", "amenable"], ["case", "sequential decision analysis", "bayesian probability", "much background material", "amenable", "utility theory", "game", "stochastic dynamic programming", "revision", "discussion"]]}, {"id": "2014", "text": "Adaptive filtering for noise reduction in hue saturation intensity color space\nEven though the hue saturation intensity (HSI) color model has been widely used\n\tin color image processing and analysis, the conversion formulas from\n\tthe RGB color model to HSI are nonlinear and complicated in comparison\n\twith the conversion formulas of other color models. When an RGB image\n\tis degraded by random Gaussian noise, this nonlinearity leads to a\n\tnonuniform noise distribution in HSI, making accurate image analysis\n\tmore difficult. We have analyzed the noise characteristics of the HSI\n\tcolor model and developed an adaptive spatial filtering method to\n\treduce the magnitude of noise and the nonuniformity of noise variance\n\tin the HSI color space. With this adaptive filtering method, the filter\n\tkernel for each pixel is dynamically adjusted, depending on the values\n\tof intensity and saturation. In our experiments we have filtered the\n\tsaturation and hue components and generated edge maps from color\n\tgradients. We have found that by using the adaptive filtering method,\n\tthe minimum error rate in edge detection improves by approximately 15%\n", "keywords": "adaptive filtering; noise reduction; hue saturation intensity color space;\n\tcolor image processing; color image analysis; RGB color model; random\n\tGaussian noise; nonuniform noise distribution; accurate image analysis;\n\tadaptive spatial filtering method; nonuniformity; noise variance; HSI\n\tcolor space; filter kernel; pixel; saturation; intensity; generated\n\tedge maps; color gradients; edge detection; minimum error rate\n", "topicrank": [["hsi", "color model", "noise reduction", "adaptive filtering", "hue saturation intensity color space"], ["hsi", "color model", "noise reduction", "adaptive filtering", "hue saturation intensity color space", "saturation", "analysis", "edge maps", "conversion", "nonlinear"]], "textrank": [["hue saturation intensity color", "color image", "rgb color", "gaussian noise", "color"], ["hue saturation intensity color", "color image", "rgb color", "gaussian noise", "color", "adaptive spatial filtering", "rgb image", "noise", "hue saturation intensity", "adaptive filtering"]], "positionrank": [["adaptive filtering method", "hsi color space", "adaptive filtering", "rgb color model", "hue saturation intensity"], ["adaptive filtering method", "hsi color space", "adaptive filtering", "rgb color model", "hue saturation intensity", "color model", "color image processing", "other color models", "color", "noise reduction"]], "multipartiterank": [["noise reduction", "adaptive filtering", "hsi", "color model", "hue saturation intensity color space"], ["noise reduction", "adaptive filtering", "hsi", "color model", "hue saturation intensity color space", "analysis", "conversion", "hue saturation intensity", "nonlinear", "color image processing"]]}, {"id": "243", "text": "BioOne: a new model for scholarly publishing\nThis article describes a unique electronic journal publishing project involving\n\tthe University of Kansas, the Big 12 Plus Libraries Consortium, the\n\tAmerican Institute of Biological Sciences, Allen Press, and SPARC, the\n\tScholarly Publishing and Academic Resources Coalition. This partnership\n\thas created BioOne, a database of 40 full-text society journals in the\n\tbiological and environmental sciences, which was launched in April,\n\t2001. The genesis and development of the project is described and\n\tfinancial, technical, and intellectual property models for the project\n\tare discussed. Collaborative strategies for the project are described\n", "keywords": "BioOne full-text society journal database; electronic journal publishing\n\tproject; scholarly publishing model; University of Kansas; Big 12 Plus\n\tLibraries Consortium; American Institute of Biological Sciences; Allen\n\tPress; SPARC; Scholarly Publishing and Academic Resources Coalition;\n\tbiological sciences; environmental sciences; intellectual property\n\tmodels; technical models; financial models; collaborative strategies\n", "topicrank": [["biological sciences", "project", "scholarly publishing", "bioone", "academic resources coalition"], ["biological sciences", "project", "scholarly publishing", "bioone", "academic resources coalition", "allen press", "text society journals", "plus libraries consortium", "full", "big"]], "textrank": [["electronic journal publishing", "allen press", "american institute", "new model", "publishing"], ["electronic journal publishing", "allen press", "american institute", "new model", "publishing", "property", "society", "resources", "sciences", "libraries"]], "positionrank": [["scholarly publishing", "bioone", "academic resources coalition", "new model", "text society journals"], ["scholarly publishing", "bioone", "academic resources coalition", "new model", "text society journals", "biological sciences", "plus libraries consortium", "project", "environmental sciences", "allen press"]], "multipartiterank": [["biological sciences", "scholarly publishing", "project", "bioone", "allen press"], ["biological sciences", "scholarly publishing", "project", "bioone", "allen press", "american institute", "plus libraries consortium", "big", "academic resources coalition", "kansas"]]}, {"id": "206", "text": "Information architecture: looking ahead\nIt may be a bit strange to consider where the field of information architecture\n\t(IA) is headed. After all, many would argue that it's too new to be\n\tconsidered as a field at all, or that it is mislabeled, and by no means\n\tis there a widely accepted definition of what information architecture\n\tactually is. Practicing information architects probably number in the\n\tthousands, and this vibrant group is already building various forms of\n\tcommunal infrastructure, ranging from an IA journal and a\n\tself-organizing \"library\" of resources to a passel of local\n\tprofessional groups and degree-granting academic programs. So the\n\tprofession has achieved a beachhead that will enable it to stabilize\n\tand perhaps even grow during these difficult times\n", "keywords": "information architecture; information architects; communal infrastructure;\n\tlocal professional groups; degree-granting academic programs\n", "topicrank": [["information architecture", "professional groups", "local", "passel", "field"], ["information architecture", "professional groups", "local", "passel", "field", "degree", "resources", "library", "number", "academic programs"]], "textrank": [["ia journal", "communal infrastructure", "various forms", "vibrant group", "bit strange"], ["ia journal", "communal infrastructure", "various forms", "vibrant group", "bit strange", "information", "ia"]], "positionrank": [["information architecture", "information architects", "ia journal", "field", "bit"], ["information architecture", "information architects", "ia journal", "field", "bit", "ia", "vibrant group", "communal infrastructure", "number", "various forms"]], "multipartiterank": [["information architecture", "field", "professional groups", "local", "passel"], ["information architecture", "field", "professional groups", "local", "passel", "degree", "resources", "number", "library", "definition"]]}, {"id": "1978", "text": "Multilayered image representation: application to image compression\nThe main contribution of this work is a new paradigm for image representation\n\tand image compression. We describe a new multilayered representation\n\ttechnique for images. An image is parsed into a superposition of\n\tcoherent layers: piecewise smooth regions layer, textures layer, etc.\n\tThe multilayered decomposition algorithm consists in a cascade of\n\tcompressions applied successively to the image itself and to the\n\tresiduals that resulted from the previous compressions. During each\n\titeration of the algorithm, we code the residual part in a lossy way:\n\twe only retain the most significant structures of the residual part,\n\twhich results in a sparse representation. Each layer is encoded\n\tindependently with a different transform, or basis, at a different\n\tbitrate, and the combination of the compressed layers can always be\n\treconstructed in a meaningful way. The strength of the multilayer\n\tapproach comes from the fact that different sets of basis functions\n\tcomplement each others: some of the basis functions will give\n\treasonable account of the large trend of the data, while others will\n\tcatch the local transients, or the oscillatory patterns. This\n\tmultilayered representation has a lot of beautiful applications in\n\timage understanding, and image and video coding. We have implemented\n\tthe algorithm and we have studied its capabilities\n", "keywords": "image compression; multilayered representation; image representation; piecewise\n\tsmooth regions layer; textures layer; multilayered decomposition\n\talgorithm; residual part; sparse representation; basis functions;\n\twavelet transforms; cosine transforms; transform coding\n", "topicrank": [["image compression", "image representation", "different transform", "basis", "decomposition algorithm"], ["image compression", "image representation", "different transform", "basis", "decomposition algorithm", "new paradigm", "coherent layers", "others", "lossy way", "textures layer"]], "textrank": [["image representation", "smooth regions layer", "residual part", "previous compressions", "decomposition algorithm"], ["image representation", "smooth regions layer", "residual part", "previous compressions", "decomposition algorithm", "textures layer", "coherent layers", "new paradigm", "main contribution", "image"]], "positionrank": [["image representation", "image compression", "image understanding", "image", "sparse representation"], ["image representation", "image compression", "image understanding", "image", "sparse representation", "representation", "new paradigm", "main contribution", "beautiful applications", "decomposition algorithm"]], "multipartiterank": [["image representation", "image compression", "new paradigm", "different transform", "image"], ["image representation", "image compression", "new paradigm", "different transform", "image", "basis", "decomposition algorithm", "application", "textures layer", "coherent layers"]]}, {"id": "1985", "text": "Prospective on computer applications in power\nThe so-called \"deregulation\" and restructuring of the electric power industry\n\thave made it very difficult to keep up with industry changes and have\n\tmade it much more difficult to envision the future. In this article,\n\tcurrent key issues and major developments of the past few years are\n\treviewed to provide perspective, and prospects for future computer\n\tapplications in power are suggested. Technology changes are occurring\n\tat an exponential rate. The interconnected bulk electric systems are\n\tbecoming integrated with vast networked information systems. This\n\tarticle discusses the skills that will be needed by future power\n\tengineers to keep pace with these developments and trends\n", "keywords": "electric power industry deregulation; computer applications; electricity\n\tindustry restructuring; technology changes; interconnected bulk\n\telectric systems; networked information systems\n", "topicrank": [["power", "computer applications", "future", "major developments", "article"], ["power", "computer applications", "future", "major developments", "article", "industry changes", "difficult", "prospects", "current key issues", "engineers"]], "textrank": [["electric power industry", "bulk electric", "future power", "networked information", "future computer"], ["electric power industry", "bulk electric", "future power", "networked information", "future computer", "industry changes", "few", "key", "power", "changes"]], "positionrank": [["electric power industry", "future power", "computer applications", "future computer", "power"], ["electric power industry", "future power", "computer applications", "future computer", "power", "applications", "industry changes", "technology changes", "future", "current key issues"]], "multipartiterank": [["power", "computer applications", "future", "difficult", "article"], ["power", "computer applications", "future", "difficult", "article", "industry changes", "major developments", "prospective", "current key issues", "applications"]]}, {"id": "2109", "text": "Internet-based psychological experimenting: five dos and five don'ts\nInternet-based psychological experimenting is presented as a method that needs\n\tcareful consideration of a number of issues-from potential data\n\tcorruption to revealing confidential information about participants.\n\tTen issues are grouped into five areas of actions to be taken when\n\tdeveloping an Internet experiment (dos) and five errors to be avoided\n\t(don'ts). Dos include: (a) utilizing dropout as a dependent variable,\n\t(b) the use of dropout to detect motivational confounding, (c)\n\tplacement of questions for personal information, (d) using a collection\n\tof techniques, and (e) using Internet-based tools. Don'ts are about:\n\t(a) unprotected directories, (b) public access to confidential data,\n\t(c) revealing the experiment's structure, (d) ignoring the Internet's\n\ttechnical variance, and (e) improper use of form elements\n", "keywords": "Internet-based psychological experimenting; data corruption; data\n\tconfidentiality; dropout; motivational confounding; personal\n\tinformation; unprotected directories; Web experiment; online research\n\ttechniques; psychology\n", "topicrank": [["internet", "dos", "confidential information", "issues", "dropout"], ["internet", "dos", "confidential information", "issues", "dropout", "internet experiment", "use", "psychological experimenting", "potential data", "questions"]], "textrank": [["confidential data", "confidential information", "motivational confounding", "dependent variable", "internet experiment"], ["confidential data", "confidential information", "motivational confounding", "dependent variable", "internet experiment", "careful consideration", "psychological experimenting", "information", "data", "experiment"]], "positionrank": [["internet experiment", "internet", "psychological experimenting", "dos", "don'ts"], ["internet experiment", "internet", "psychological experimenting", "dos", "don'ts", "confidential data", "confidential information", "potential data", "careful consideration", "experiment"]], "multipartiterank": [["internet", "dos", "issues", "confidential information", "dropout"], ["internet", "dos", "issues", "confidential information", "dropout", "internet experiment", "use", "psychological experimenting", "potential data", "corruption"]]}, {"id": "2134", "text": "Linear models of circuits based on the multivalued components\nLinearization and planarization of the circuit models is pivotal to the\n\tsubmicron technologies. On the other hand, the characteristics of the\n\tVLSI circuits can be sometimes improved by using the multivalued\n\tcomponents. It was shown that any l-level circuit based on the\n\tmultivalued components is representable as an algebraic model based on\n\tl linear arithmetic polynomials mapped correspondingly into l decision\n\tdiagrams that are linear and planar by nature. Complexity of\n\trepresenting a circuit as the linear decision diagram was estimated as\n\tO(G) with G for the number of multivalued components in the circuit.\n\tThe results of testing the LinearDesignMV algorithm on circuits of more\n\tthan 8000 LGSynth 93 multivalued components were presented\n", "keywords": "linear circuit model; linearization; planarization; submicron technologies;\n\tVLSI circuits; linear arithmetic polynomials; linear planar decision\n\tdiagrams; circuit representation complexity; LinearDesignMV algorithm;\n\tLGSynth 93 multivalued components\n", "topicrank": [["components", "circuit models", "linear models", "circuits", "nature"], ["components", "circuit models", "linear models", "circuits", "nature", "planar", "linearization", "complexity", "planarization", "pivotal"]], "textrank": [["linear decision", "linear arithmetic", "vlsi circuits", "other hand", "submicron technologies"], ["linear decision", "linear arithmetic", "vlsi circuits", "other hand", "submicron technologies", "linear", "decision", "circuit", "algebraic", "circuits"]], "positionrank": [["linear models", "linear decision diagram", "l linear", "circuit models", "l decision"], ["linear models", "linear decision diagram", "l linear", "circuit models", "l decision", "level circuit", "components", "vlsi circuits", "circuit", "circuits"]], "multipartiterank": [["linear models", "components", "circuits", "circuit models", "planarization"], ["linear models", "components", "circuits", "circuit models", "planarization", "linearization", "pivotal", "circuit", "submicron technologies", "lineardesignmv algorithm"]]}, {"id": "283", "text": "Alien Rescue: a problem-based hypermedia learning environment for middle school\n\tscience\nThe article describes an innovative hypermedia product for sixth graders in\n\tspace science: Alien Rescue. Using a problem-based learning approach\n\tthat is highly interactive, Alien Rescue engages students in scientific\n\tinvestigations aimed at finding solutions to complex and meaningful\n\tproblems. Problem-based learning (PBL) is an instructional strategy\n\tproven to be effective in medical and business fields, and it is\n\tincreasingly popular in education. However, using PBL in K-12\n\tclassrooms is challenging and requires access to rich knowledge bases\n\tand cognitive tools. Alien Rescue is designed to provide such cognitive\n\tsupport for successful use of PBL in sixth-grade classrooms. The design\n\tand development of Alien Rescue is guided by current educational\n\tresearch. Research is an integral part of this project. Results of\n\tformative evaluation and research studies are being integrated into the\n\tdevelopment and improvement of the program. Alien Rescue is designed in\n\taccordance with the National Science Standards and the Texas Essential\n\tKnowledge and Skills (TEKS) for science. So far Alien Rescue has been\n\tfield-tested by approximately 1400 sixth graders. More use in middle\n\tschools is in progress and more research on its use is planned\n", "keywords": "Alien Rescue; problem-based hypermedia learning environment; middle school\n\tscience; space science; sixth graders; scientific investigations; PBL;\n\tinstructional strategy; medical fields; business fields; K-12\n\tclassrooms; rich knowledge bases; cognitive tools; cognitive support;\n\teducational research; formative evaluation; middle schools\n", "topicrank": [["alien rescue", "science", "pbl", "hypermedia learning environment", "research"], ["alien rescue", "science", "pbl", "hypermedia learning environment", "research", "sixth graders", "problem", "rich knowledge bases", "development", "classrooms"]], "textrank": [["hypermedia learning", "more research", "more use", "current educational", "grade classrooms"], ["hypermedia learning", "more research", "more use", "current educational", "grade classrooms", "business fields", "instructional strategy", "sixth graders", "middle school", "alien rescue"]], "positionrank": [["alien rescue", "hypermedia learning environment", "national science standards", "space science", "innovative hypermedia product"], ["alien rescue", "hypermedia learning environment", "national science standards", "space science", "innovative hypermedia product", "learning approach", "sixth graders", "science", "problem", "learning"]], "multipartiterank": [["alien rescue", "science", "hypermedia learning environment", "problem", "pbl"], ["alien rescue", "science", "hypermedia learning environment", "problem", "pbl", "sixth graders", "research", "middle school", "rich knowledge bases", "classrooms"]]}, {"id": "2171", "text": "Evicting orang utans from the office [electronic storage of legal files]\nHaving espoused the principle of the paperless office some time ago, we decided\n\tto apply it to our stored files. First we consulted the Law Society\n\trules governing storage of files on electronic media. The next step was\n\tfor us to draw up a protocol for scanning the files. The benefits of\n\tthe exercise have been significant. The area previously used for\n\tstorage has been freed for other use. Files are now available online,\n\tinstantaneously. When we have needed to send out files to the client or\n\tfollowing a change of solicitor, we have been able to do so almost\n\timmediately, by E-mail, retaining a copy for our future reference. The\n\tfiles are protected from loss or deterioration, back-up copies having\n\tbeen taken which are stored off site. The complete stored file archive\n\tcan be put in your pocket (in CD-ROM format) or on a laptop,\n\tfacilitating remote working\n", "keywords": "paperless office; legal files; electronic storage; Law Society rules; file\n\tscanning; CD-ROM; file archive\n", "topicrank": [["legal files", "electronic storage", "office", "rules", "electronic media"], ["legal files", "electronic storage", "office", "rules", "electronic media", "law society", "loss", "significant", "deterioration", "exercise"]], "textrank": [["stored file", "stored files", "other use", "next step", "law society"], ["stored file", "stored files", "other use", "next step", "law society", "paperless office", "orang utans", "stored", "-", "electronic"]], "positionrank": [["legal files", "electronic storage", "stored files", "orang utans", "files"], ["legal files", "electronic storage", "stored files", "orang utans", "files", "electronic media", "storage", "paperless office", "office", "law society"]], "multipartiterank": [["legal files", "electronic storage", "office", "files", "orang utans"], ["legal files", "electronic storage", "office", "files", "orang utans", "principle", "storage", "paperless office", "time", "rules"]]}, {"id": "1945", "text": "The development of a mobile manipulator imaging system for bridge crack\n\tinspection\nA mobile manipulator imaging system is developed for the automation of bridge\n\tcrack inspection. During bridge safety inspections, an eyesight\n\tinspection is made for preliminary evaluation and screening before a\n\tmore precise inspection. The inspection for cracks is an important part\n\tof the preliminary evaluation. Currently, the inspectors must stand on\n\tthe platform of a bridge inspection vehicle or a temporarily erected\n\tscaffolding to examine the underside of a bridge. However, such a\n\tprocedure is risky. To help automate the bridge crack inspection\n\tprocess, we installed two CCD cameras and a four-axis manipulator\n\tsystem on a mobile vehicle. The parallel cameras are used to detect\n\tcracks. The manipulator system is equipped with binocular charge\n\tcoupled devices (CCD) for examining structures that may not be\n\taccessible to the eye. The system also reduces the danger of accidents\n\tto the human inspectors. The manipulator system consists of four arms.\n\tBalance weights are placed at the ends of arms 2 and 4, respectively,\n\tto maintain the center of gravity during operation. Mechanically, arms\n\t2 and 4 can revolve smoothly. Experiments indicated that the system\n\tcould be useful for bridge crack inspections\n", "keywords": "mobile manipulator; imaging system; bridge crack inspection; automation;\n\teyesight inspection; CCD cameras; four-axis manipulator; parallel\n\tcameras; binocular CCD; charge coupled devices\n", "topicrank": [["mobile manipulator imaging system", "bridge crack", "inspection", "arms", "ccd cameras"], ["mobile manipulator imaging system", "bridge crack", "inspection", "arms", "ccd cameras", "cracks", "preliminary evaluation", "inspectors", "devices", "danger"]], "textrank": [["bridge crack inspection", "bridge inspection", "crack inspection", "manipulator imaging", "bridge crack"], ["bridge crack inspection", "bridge inspection", "crack inspection", "manipulator imaging", "bridge crack", "balance weights", "human inspectors", "binocular charge", "important part", "preliminary evaluation"]], "positionrank": [["bridge crack inspection", "bridge inspection vehicle", "bridge crack inspections", "manipulator system", "bridge crack"], ["bridge crack inspection", "bridge inspection vehicle", "bridge crack inspections", "manipulator system", "bridge crack", "crack inspection", "bridge safety inspections", "precise inspection", "system", "bridge"]], "multipartiterank": [["mobile manipulator imaging system", "bridge crack", "inspection", "preliminary evaluation", "cracks"], ["mobile manipulator imaging system", "bridge crack", "inspection", "preliminary evaluation", "cracks", "bridge", "system", "arms", "automation", "inspectors"]]}, {"id": "2091", "text": "Prospects for quantitative computed tomography imaging in the presence of\n\tforeign metal bodies using statistical image reconstruction\nX-ray computed tomography (CT) images of patients bearing metal intracavitary\n\tapplicators or other metal foreign objects exhibit severe artifacts\n\tincluding streaks and aliasing. We have systematically evaluated via\n\tcomputer simulations the impact of scattered radiation, the\n\tpolyenergetic spectrum, and measurement noise on the performance of\n\tthree reconstruction algorithms: conventional filtered backprojection\n\t(FBP), deterministic iterative deblurring, and a new iterative\n\talgorithm, alternating minimization (AM), based on a CT detector model\n\tthat includes noise, scatter, and polyenergetic spectra. Contrary to\n\tthe dominant view of the literature, FBP streaking artifacts are due\n\tmostly to mismatches between FBP's simplified model of CT detector\n\tresponse and the physical process of signal acquisition. Artifacts on\n\tAM images are significantly mitigated as this algorithm substantially\n\treduces detector-model mismatches. However, metal artifacts are reduced\n\tto acceptable levels only when prior knowledge of the metal object in\n\tthe patient, including its pose, shape, and attenuation map, are used\n\tto constrain AM's iterations. AM image reconstruction, in combination\n\twith object-constrained CT to estimate the pose of metal objects in the\n\tpatient, is a promising approach for effectively mitigating metal\n\tartifacts and making quantitative estimation of tissue attenuation\n\tcoefficients a clinical possibility\n", "keywords": "quantitative computed tomography imaging; foreign metal bodies; statistical\n\timage reconstruction; metal artifact reduction; brachytherapy; medical\n\tdiagnostic imaging; signal acquisition physical process;\n\tobject-constrained CT; iterative algorithm; alternating minimization;\n\tCT detector model; noise; scatter; polyenergetic spectra; clinical\n\tpossibility; deterministic iterative deblurring; filtered\n\tbackprojection\n", "topicrank": [["severe artifacts", "fbp", "ct detector model", "metal intracavitary", "mismatches"], ["severe artifacts", "fbp", "ct detector model", "metal intracavitary", "mismatches", "measurement noise", "polyenergetic spectrum", "attenuation map", "algorithm", "pose"]], "textrank": [["metal artifacts", "detector - model", "am image reconstruction", "metal", "quantitative computed tomography"], ["metal artifacts", "detector - model", "am image reconstruction", "metal", "quantitative computed tomography", "detector model", "image reconstruction", "computed tomography", "acceptable levels", "signal acquisition"]], "positionrank": [["foreign metal bodies", "metal artifacts", "metal objects", "metal intracavitary", "other metal"], ["foreign metal bodies", "metal artifacts", "metal objects", "metal intracavitary", "other metal", "metal object", "mitigating metal", "am image reconstruction", "statistical image reconstruction", "quantitative estimation"]], "multipartiterank": [["severe artifacts", "fbp", "metal intracavitary", "ct detector model", "measurement noise"], ["severe artifacts", "fbp", "metal intracavitary", "ct detector model", "measurement noise", "artifacts", "polyenergetic spectrum", "patients", "mismatches", "algorithm"]]}, {"id": "326", "text": "Web-based experiments controlled by JavaScript: an example from probability\n\tlearning\nJavaScript programs can be used to control Web experiments. This technique is\n\tillustrated by an experiment that tested the effects of advice on\n\tperformance in the classic probability-learning paradigm. Previous\n\tresearch reported that people tested via the Web or in the lab tended\n\tto match the probabilities of their responses to the probabilities that\n\tthose responses would be reinforced. The optimal strategy, however, is\n\tto consistently choose the more frequent event; probability matching\n\tproduces suboptimal performance. We investigated manipulations we\n\treasoned should improve performance. A horse race scenario in which\n\tparticipants predicted the winner in each of a series of races between\n\ttwo horses was compared with an abstract scenario used previously. Ten\n\tgroups of learners received different amounts of advice, including all\n\tcombinations of (1) explicit instructions concerning the optimal\n\tstrategy, (2) explicit instructions concerning a monetary sum to\n\tmaximize, and (3) accurate information concerning the probabilities of\n\tevents. The results showed minimal effects of horse race versus\n\tabstract scenario. Both advice concerning the optimal strategy and\n\tprobability information contributed significantly to performance in the\n\ttask. This paper includes a brief tutorial on JavaScript, explaining\n\twith simple examples how to assemble a browser-based experiment\n", "keywords": "Web-based experiments; JavaScript; probability learning; advice; explicit\n\tinstructions; probability; browser-based experiment; Internet-based\n\tresearch\n", "topicrank": [["probability", "performance", "advice", "optimal strategy", "javascript"], ["probability", "performance", "advice", "optimal strategy", "javascript", "probabilities", "effects", "horse race scenario", "abstract scenario", "explicit instructions"]], "textrank": [["probability information", "race scenario", "different amounts", "suboptimal performance", "frequent event"], ["probability information", "race scenario", "different amounts", "suboptimal performance", "frequent event", "optimal strategy", "web experiments", "javascript programs", "race", "information"]], "positionrank": [["web experiments", "web", "javascript programs", "javascript", "classic probability"], ["web experiments", "web", "javascript programs", "javascript", "classic probability", "probability information", "probability", "experiments", "suboptimal performance", "horse race scenario"]], "multipartiterank": [["probability", "performance", "javascript", "advice", "optimal strategy"], ["probability", "performance", "javascript", "advice", "optimal strategy", "probabilities", "effects", "experiments", "horse race scenario", "web"]]}, {"id": "363", "text": "Synthetic simultaneity - natural and artificial\nIn control loops, each element introduces time delays. If those time delays are\n\tlarger than the critical times for control of the system, a problem\n\texists. I show a simple approach to mitigating this problem by basing\n\tthe controller's decisions not on the observations themselves but on\n\tour projections as to what the observations will be at the time our\n\tcontrols reach the controlled system. Finally, I argue that synthetic\n\tsimultaneity explains Libet's (1993) results better than Libet's\n\texplanation\n", "keywords": "control loops; time delays; critical times; controller decisions; observations;\n\tsynthetic simultaneity\n", "topicrank": [["time delays", "control loops", "synthetic simultaneity", "system", "problem"], ["time delays", "control loops", "synthetic simultaneity", "system", "problem", "observations", "libet", "critical times", "natural", "element"]], "textrank": [["time delays", "control loops", "synthetic simultaneity", "simultaneity", "synthetic"], ["time delays", "control loops", "synthetic simultaneity", "simultaneity", "synthetic", "time", "control", "critical"]], "positionrank": [["synthetic simultaneity", "time delays", "control loops", "simultaneity", "control"], ["synthetic simultaneity", "time delays", "control loops", "simultaneity", "control", "time", "controlled system", "critical times", "system", "element"]], "multipartiterank": [["time delays", "synthetic simultaneity", "control loops", "natural", "artificial"], ["time delays", "synthetic simultaneity", "control loops", "natural", "artificial", "problem", "system", "element", "critical times", "observations"]]}, {"id": "2029", "text": "Block truncation image bit plane coding\nBlock truncation coding (BTC) is a successful image compression technique due\n\tto its simple and fast computational burden. The bit rate is fixed to\n\t2.0 bits/pixel, whose performance is moderate in terms of compression\n\tratio compared to other compression schemes such as discrete cosine\n\ttransform (DCT), vector quantization (VQ), wavelet transform coding\n\t(WTC), etc. Two kinds of overheads are required for BTC coding: bit\n\tplane and quantization values, respectively. A new technique is\n\tpresented to reduce the bit plane overhead. Conventional bit plane\n\toverhead is 1.0 bits/pixel; we decrease it to 0.734 bits/pixel while\n\tmaintaining the same decoded quality as absolute moment BTC (AMBTC)\n\tdoes for the \"Lena\" image. Compared to other published bit plane coding\n\tstrategies, the proposed method outperforms all of the existing methods\n", "keywords": "image bit plane coding; block truncation coding; image compression technique;\n\tbit rate; performance; compression ratio; bit plane overhead; decoded\n\tquality; absolute moment BTC; AMBTC; quantization values; Lena image\n", "topicrank": [["plane", "btc", "pixel", "bits", "bit rate"], ["plane", "btc", "pixel", "bits", "bit rate", "transform", "vector quantization", "terms", "moderate", "compression"]], "textrank": [["truncation image bit plane coding", "image compression technique", "bit plane coding", "truncation coding", "compression schemes"], ["truncation image bit plane coding", "image compression technique", "bit plane coding", "truncation coding", "compression schemes", "transform coding", "btc coding", "bit plane", "fast computational", "moment btc"]], "positionrank": [["bit plane coding", "block truncation coding", "conventional bit plane", "bit plane", "btc coding"], ["bit plane coding", "block truncation coding", "conventional bit plane", "bit plane", "btc coding", "wavelet transform coding", "bit rate", "bit", "plane", "other compression schemes"]], "multipartiterank": [["btc", "plane", "bits", "pixel", "bit rate"], ["btc", "plane", "bits", "pixel", "bit rate", "transform", "vector quantization", "block truncation coding", "fast computational burden", "dct"]]}, {"id": "1961", "text": "The influence of tollbooths on highway traffic\nWe study the effects of tollbooths on the traffic flow. The highway traffic is\n\tsimulated by the Nagel-Schreckenberg model. Various types of toll\n\tcollection are examined, which can be characterized either by a waiting\n\ttime or a reduced speed. A first-order phase transition is observed.\n\tThe phase separation results a saturated flow, which is observed as a\n\tplateau region in the fundamental diagram. The effects of lane\n\texpansion near the tollbooth are examined. The full capacity of a\n\thighway can be restored. The emergence of vehicle queuing is studied.\n\tBesides the numerical results, we also obtain analytical expressions\n\tfor various quantities. The numerical simulations can be well described\n\tby the analytical formulas. We also discuss the influence on the travel\n\ttime and its variance. The tollbooth increases the travel time but\n\tdecreases its variance. The differences between long- and\n\tshort-distance travelers are also discussed\n", "keywords": "highway traffic; tollbooths; Nagel-Schreckenberg model; toll collection;\n\twaiting time; reduced speed; first-order phase transition; saturated\n\tflow; lane expansion; vehicle queuing; numerical simulations\n", "topicrank": [["time", "highway traffic", "various types", "effects", "tollbooth"], ["time", "highway traffic", "various types", "effects", "tollbooth", "variance", "tollbooths", "traffic flow", "influence", "analytical expressions"]], "textrank": [["fundamental diagram", "plateau region", "reduced speed", "schreckenberg model", "phase"], ["fundamental diagram", "plateau region", "reduced speed", "schreckenberg model", "phase", "analytical", "numerical", "various", "traffic", "full"]], "positionrank": [["highway traffic", "traffic flow", "highway", "tollbooths", "influence"], ["highway traffic", "traffic flow", "highway", "tollbooths", "influence", "travel time", "effects", "order phase transition", "schreckenberg model", "various types"]], "multipartiterank": [["highway traffic", "time", "various types", "tollbooths", "effects"], ["highway traffic", "time", "various types", "tollbooths", "effects", "traffic flow", "tollbooth", "influence", "variance", "schreckenberg model"]]}, {"id": "2110", "text": "Psychology and the Internet\nThis article presents an overview of the way that the Internet is being used to\n\tassist psychological research and mediate psychological practice. It\n\tshows how psychologists are using the Internet to examine the\n\tinteractions between people and computers, and highlights some of the\n\tways that this research is important to the design and development of\n\tuseable and acceptable computer systems. In particular, this\n\tintroduction reviews the research presented at the International\n\tConference on Psychology and the Internet held in the United Kingdom.\n\tThe final part introduces the eight articles in this special edition.\n\tThe articles are representative of the breadth of research being\n\tconducted on psychology and the Internet: there are two on\n\tmethodological issues, three on group processes, one on organizational\n\timplications, and two on social implications of Internet use\n", "keywords": "Internet; psychological research; human-computer interactions; usability;\n\tsocial implications; psychology; organizational implications; group\n\tprocesses; methodological issues; online research\n", "topicrank": [["internet", "psychological research", "psychology", "articles", "implications"], ["internet", "psychological research", "psychology", "articles", "implications", "acceptable computer systems", "conference", "development", "design", "useable"]], "textrank": [["group processes", "methodological issues", "special edition", "final part", "united kingdom"], ["group processes", "methodological issues", "special edition", "final part", "united kingdom", "computer", "psychological", "internet"]], "positionrank": [["internet use", "internet", "psychology", "psychological research", "research"], ["internet use", "internet", "psychology", "psychological research", "research", "united kingdom", "psychological practice", "acceptable computer systems", "social implications", "article"]], "multipartiterank": [["internet", "psychological research", "research", "psychology", "articles"], ["internet", "psychological research", "research", "psychology", "articles", "psychological practice", "implications", "people", "conference", "acceptable computer systems"]]}, {"id": "2048", "text": "An object-oriented version of SIMLIB (a simple simulation package)\nThis paper introduces an object-oriented version of SIMLIB (an\n\teasy-to-understand discrete-event simulation package). The\n\tobject-oriented version is preferable to the original procedural\n\tlanguage versions of SIMLIB in that it is easier to understand and\n\tteach simulation from an object point of view. A single-server queue\n\tsimulation is demonstrated using the object-oriented SIMLIB\n", "keywords": "object-oriented version; SIMLIB; discrete-event simulation; teach simulation\n", "topicrank": [["object", "simple simulation package", "simlib", "version", "language versions"], ["object", "simple simulation package", "simlib", "version", "language versions", "original procedural", "server queue", "preferable", "single", "view"]], "textrank": [["language versions", "original procedural", "simulation", "object"], ["language versions", "original procedural", "simulation", "object"]], "positionrank": [["simple simulation package", "event simulation package", "object point", "object", "simulation"], ["simple simulation package", "event simulation package", "object point", "object", "simulation", "simlib", "version", "language versions", "server queue", "paper"]], "multipartiterank": [["object", "simlib", "simple simulation package", "version", "simulation"], ["object", "simlib", "simple simulation package", "version", "simulation", "paper", "language versions", "preferable", "original procedural", "discrete"]]}, {"id": "302", "text": "Using Internet search engines to estimate word frequency\nThe present research investigated Internet search engines as a rapid,\n\tcost-effective alternative for estimating word frequencies. Frequency\n\testimates for 382 words were obtained and compared across four methods:\n\t(1) Internet search engines, (2) the Kucera and Francis (1967) analysis\n\tof a traditional linguistic corpus, (3) the CELEX English linguistic\n\tdatabase (Baayen et al., 1995), and (4) participant ratings of\n\tfamiliarity. The results showed that Internet search engines produced\n\tfrequency estimates that were highly consistent with those reported by\n\tKucera and Francis and those calculated from CELEX, highly consistent\n\tacross search engines, and very reliable over a 6 month period of time.\n\tAdditional results suggested that Internet search engines are an\n\texcellent option when traditional word frequency analyses do not\n\tcontain the necessary data (e.g., estimates for forenames and slang).\n\tIn contrast, participants' familiarity judgments did not correspond\n\twell with the more objective estimates of word frequency. Researchers\n\tare advised to use search engines with large databases (e.g.,\n\tAltaVista) to ensure the greatest representativeness of the frequency\n\testimates\n", "keywords": "Internet search engines; word frequency estimation; linguistic corpus; CELEX\n\tEnglish linguistic database; participant familiarity ratings; large\n\tdatabases\n", "topicrank": [["internet search engines", "word frequency", "estimates", "results", "familiarity"], ["internet search engines", "word frequency", "estimates", "results", "familiarity", "francis", "kucera", "celex english linguistic", "consistent", "forenames"]], "textrank": [["traditional word frequency", "word frequency", "english linguistic", "frequency estimates", "traditional linguistic"], ["traditional word frequency", "word frequency", "english linguistic", "frequency estimates", "traditional linguistic", "et al", "participant ratings", "effective alternative", "present research", "frequency"]], "positionrank": [["internet search engines", "search engines", "word frequency", "frequency estimates", "word frequencies"], ["internet search engines", "search engines", "word frequency", "frequency estimates", "word frequencies", "frequency", "present research", "objective estimates", "traditional linguistic corpus", "additional results"]], "multipartiterank": [["internet search engines", "word frequency", "estimates", "results", "familiarity"], ["internet search engines", "word frequency", "estimates", "results", "familiarity", "frequency", "francis", "celex english linguistic", "kucera", "consistent"]]}, {"id": "347", "text": "From revenue management concepts to software systems\nIn 1999, after developing and installing over 170 revenue management (RM)\n\tsystems for more than 70 airlines, PROS Revenue Management, Inc. had\n\tthe opportunity to develop RM systems for three companies in nonairline\n\tindustries. PROS research and design department designed the\n\topportunity analysis study (OAS), a mix of OR/MS, consulting, and\n\tsoftware development practices to determine the applicability of RM in\n\tnew business situations. PROS executed OASs with the three companies.\n\tIn all three cases, the OAS supported the value of RM and led to\n\tcontracts for implementation of RM systems\n", "keywords": "revenue management concepts; software systems; RM systems; PROS Revenue\n\tManagement; Inc; opportunity analysis study; OAS; OR/MS; consulting\n\tpractices; software development practices\n", "topicrank": [["software systems", "pros research", "companies", "oas", "opportunity"], ["software systems", "pros research", "companies", "oas", "opportunity", "revenue management concepts", "industries", "nonairline", "design department", "new business situations"]], "textrank": [["pros revenue management", "software development", "software systems", "revenue management", "opportunity analysis"], ["pros revenue management", "software development", "software systems", "revenue management", "opportunity analysis", "design department", "business", "pros", "systems", "opportunity"]], "positionrank": [["pros revenue management", "revenue management concepts", "revenue management", "rm systems", "software systems"], ["pros revenue management", "revenue management concepts", "revenue management", "rm systems", "software systems", "systems", "rm", "software development practices", "pros research", "opportunity analysis study"]], "multipartiterank": [["software systems", "revenue management concepts", "pros research", "opportunity", "companies"], ["software systems", "revenue management concepts", "pros research", "opportunity", "companies", "oas", "rm systems", "industries", "nonairline", "design department"]]}, {"id": "412", "text": "Using virtual reality to teach disability awareness\nA desktop virtual reality (VR) program was designed and evaluated to teach\n\tchildren about the accessibility and attitudinal barriers encountered\n\tby their peers with mobility impairments. Within this software,\n\tchildren sitting in a virtual wheelchair experience obstacles such as\n\tstairs, narrow doors, objects too high to reach, and attitudinal\n\tbarriers such as inappropriate comments. Using a collaborative research\n\tmethodology, 15 youth with mobility impairments assisted in developing\n\tand beta-testing the software. The effectiveness of the program was\n\tthen evaluated with 60 children in Grades 4-6 using a controlled\n\tpretest/posttest design. The results indicated that the program was\n\teffective for increasing children's knowledge of accessibility\n\tbarriers. Attitudes, grade level, familiarity with individuals with a\n\tdisability, and gender were also investigated\n", "keywords": "virtual reality; disability awareness teaching; children; accessibility;\n\tvirtual wheelchair; collaborative research methodology; mobility\n\timpairments; software beta-testing; collaborative software development;\n\tcomputer aided instruction; software effectiveness; gender\n", "topicrank": [["children", "program", "accessibility", "mobility impairments", "software"], ["children", "program", "accessibility", "mobility impairments", "software", "attitudinal barriers", "disability awareness", "barriers", "grade level", "attitudes"]], "textrank": [["virtual wheelchair experience obstacles such", "barriers such", "inappropriate comments", "narrow doors", "mobility impairments"], ["virtual wheelchair experience obstacles such", "barriers such", "inappropriate comments", "narrow doors", "mobility impairments", "disability awareness", "virtual", "barriers", "disability"]], "positionrank": [["desktop virtual reality", "virtual reality", "disability awareness", "attitudinal barriers", "disability"], ["desktop virtual reality", "virtual reality", "disability awareness", "attitudinal barriers", "disability", "program", "children", "mobility impairments", "barriers", "narrow doors"]], "multipartiterank": [["children", "program", "accessibility", "disability awareness", "virtual reality"], ["children", "program", "accessibility", "disability awareness", "virtual reality", "mobility impairments", "attitudinal barriers", "software", "barriers", "knowledge"]]}, {"id": "2088", "text": "Layer-based machining: recent development and support structure design\nThere is growing interest in additive and subtractive shaping theories that are\n\tsynthesized to integrate the layered manufacturing process and material\n\tremoval process. Layer-based machining has emerged as a promising\n\tmethod for integrated additive and subtractive shaping theory. In the\n\tpaper, major layer-based machining systems are reviewed and compared\n\taccording to characteristics of stock layers, numerical control\n\tmachining configurations, stacking operations, input format and raw\n\tmaterials. Support structure, a major issue in machining-based systems\n\twhich has seldom been addressed in previous research, is investigated\n\tin the paper with considerations of four situations: floating overhang,\n\tcantilever, vaulted overhang and ceiling. Except for the floating\n\toverhang where a support structure should not be overlooked, the\n\tnecessity for support structures for the other three situations is\n\tdetermined by stress and deflection analysis. This is demonstrated by\n\tthe machining of a large castle model\n", "keywords": "layer-based machining; support structure design; additive shaping theories;\n\tsubtractive shaping theories; layered manufacturing process; material\n\tremoval process; stock layers; numerical control machining\n\tconfigurations; stacking operations; input format; raw materials;\n\tfloating overhang; cantilever; vaulted overhang; ceiling; stress;\n\tdeflection analysis\n", "topicrank": [["machining", "support structure design", "overhang", "layer", "additive"], ["machining", "support structure design", "overhang", "layer", "additive", "paper", "subtractive shaping theories", "situations", "input format", "raw"]], "textrank": [["manufacturing process", "support structure", "input format", "numerical control", "stock layers"], ["manufacturing process", "support structure", "input format", "numerical control", "stock layers", "machining systems", "recent development", "shaping", "castle", "major"]], "positionrank": [["major layer", "support structure design", "support structure", "machining systems", "layer"], ["major layer", "support structure design", "support structure", "machining systems", "layer", "subtractive shaping theory", "layered manufacturing process", "machining", "subtractive shaping theories", "support structures"]], "multipartiterank": [["machining", "layer", "support structure design", "additive", "subtractive shaping theories"], ["machining", "layer", "support structure design", "additive", "subtractive shaping theories", "overhang", "recent development", "paper", "removal process", "support structure"]]}, {"id": "2030", "text": "Elimination of zero-order diffraction in digital holography\nA simple method to suppress the zero-order diffraction in the reconstructed\n\timage of digital holography is presented. In this method, the Laplacian\n\tof a detected hologram is used instead of the hologram itself for\n\tnumerical reconstruction by computing the discrete Fresnel integral.\n\tThis method can significantly improve the image quality and give better\n\tresolution and higher accuracy of the reconstructed image. The main\n\tadvantages of this method are its simplicity in experimental\n\trequirements and convenience in data processing\n", "keywords": "zero-order diffraction suppression; reconstructed image; Laplacian; detected\n\thologram; numerical image reconstruction; discrete Fresnel integral;\n\timage quality; image resolution; accuracy; data processing; image.\n\tprocessing; digital holography\n", "topicrank": [["simple method", "image", "digital holography", "order diffraction", "hologram"], ["simple method", "image", "digital holography", "order diffraction", "hologram", "experimental", "requirements", "resolution", "simplicity", "advantages"]], "textrank": [["simple method", "digital holography", "order diffraction", "fresnel", "numerical"], ["simple method", "digital holography", "order diffraction", "fresnel", "numerical", "method", "image"]], "positionrank": [["order diffraction", "digital holography", "simple method", "method", "image quality"], ["order diffraction", "digital holography", "simple method", "method", "image quality", "elimination", "image", "discrete fresnel integral", "higher accuracy", "numerical reconstruction"]], "multipartiterank": [["simple method", "image", "digital holography", "order diffraction", "method"], ["simple method", "image", "digital holography", "order diffraction", "method", "reconstructed", "hologram", "experimental", "resolution", "main"]]}, {"id": "387", "text": "Design and implementation of a brain-computer interface with high transfer\n\trates\nThis paper presents a brain-computer interface (BCI) that can help users to\n\tinput phone numbers. The system is based on the steady-state visual\n\tevoked potential (SSVEP). Twelve buttons illuminated at different rates\n\twere displayed on a computer monitor. The buttons constituted a virtual\n\ttelephone keypad, representing the ten digits 0-9, BACKSPACE, and\n\tENTER. Users could input phone number by gazing at these buttons. The\n\tfrequency-coded SSVEP was used to judge which button the user desired.\n\tEight of the thirteen subjects succeeded in ringing the mobile phone\n\tusing the system. The average transfer rate over all subjects was 27.15\n\tbits/min. The attractive features of the system are noninvasive signal\n\trecording, little training required for use, and high information\n\ttransfer rate. Approaches to improve the performance of the system are\n\tdiscussed\n", "keywords": "brain-computer interface with high transfer rates; phone numbers input;\n\tsteady-state visual evoked potential; illuminated buttons; system\n\tperformance improvement; virtual telephone keypad; frequency-coded\n\tSSVEP; mobile phone ringing; computer monitor\n", "topicrank": [["system", "computer interface", "buttons", "high transfer", "average transfer rate"], ["system", "computer interface", "buttons", "high transfer", "average transfer rate", "brain", "rates", "users", "ssvep", "phone number"]], "textrank": [["high transfer", "phone", "little training", "noninvasive signal", "attractive features"], ["high transfer", "phone", "little training", "noninvasive signal", "attractive features", "telephone keypad", "different rates", "state visual", "transfer", "computer"]], "positionrank": [["computer interface", "high transfer", "computer monitor", "average transfer rate", "transfer rate"], ["computer interface", "high transfer", "computer monitor", "average transfer rate", "transfer rate", "design", "brain", "different rates", "high information", "implementation"]], "multipartiterank": [["computer interface", "system", "brain", "high transfer", "buttons"], ["computer interface", "system", "brain", "high transfer", "buttons", "rates", "users", "ssvep", "average transfer rate", "phone number"]]}, {"id": "2168", "text": "Cyberobscenity and the ambit of English criminal law\nThe author looks at a recent case and questions the Court of Appeal's approach.\n\tIn the author's submission, the Court of Appeal's decision in Perrin\n\twas wrong. P published no material in England and Wales, and should not\n\thave been convicted of any offence under English law, even if it were\n\tproved that he sought to attract English subscribers to his site. That\n\tmay be an unpalatable conclusion but, if the content of foreign-hosted\n\tInternet sites is to be controlled, the only sensible way forward is\n\tthrough international agreement and cooperation. The Council of\n\tEurope's Cybercrime Convention provides some indication of the limited\n\tareas over which widespread international agreement might be achieved\n", "keywords": "cyberobscenity; criminal law; Court of Appeal; Internet sites; Cybercrime\n\tConvention; Council of Europe; international agreement; England\n", "topicrank": [["appeal", "english criminal law", "court", "author", "international agreement"], ["appeal", "english criminal law", "court", "author", "international agreement", "decision", "questions", "perrin", "submission", "england"]], "textrank": [["english criminal law", "english law", "only sensible", "cybercrime convention", "internet sites"], ["english criminal law", "english law", "only sensible", "cybercrime convention", "internet sites", "unpalatable conclusion", "recent case", "international", "english"]], "positionrank": [["english criminal law", "english law", "english subscribers", "recent case", "cyberobscenity"], ["english criminal law", "english law", "english subscribers", "recent case", "cyberobscenity", "author", "ambit", "appeal", "court", "approach"]], "multipartiterank": [["english criminal law", "appeal", "court", "author", "international agreement"], ["english criminal law", "appeal", "court", "author", "international agreement", "questions", "ambit", "decision", "recent case", "submission"]]}, {"id": "34", "text": "Design of PID-type controllers using multiobjective genetic algorithms\nThe design of a PID controller is a multiobjective problem. A plant and a set\n\tof specifications to be satisfied are given. The designer has to adjust\n\tthe parameters of the PID controller such that the feedback\n\tinterconnection of the plant and the controller satisfies the\n\tspecifications. These specifications are usually competitive and any\n\tacceptable solution requires a tradeoff among them. An approach for\n\tadjusting the parameters of a PID controller based on multiobjective\n\toptimization and genetic algorithms is presented in this paper. The\n\tMRCD (multiobjective robust control design) genetic algorithm has been\n\temployed. The approach can be easily generalized to design\n\tmultivariable coupled and decentralized PID loops and has been\n\tsuccessfully validated for a large number of experimental cases\n", "keywords": "PID-type controllers; multiobjective genetic algorithms; feedback\n\tinterconnection; multiobjective robust control design; multivariable\n\tcoupled PID loops; decentralized PID loops; tuning methods\n", "topicrank": [["pid controller", "multiobjective genetic algorithms", "specifications", "multiobjective problem", "plant"], ["pid controller", "multiobjective genetic algorithms", "specifications", "multiobjective problem", "plant", "parameters", "pid", "design", "approach", "optimization"]], "textrank": [["multiobjective robust control", "multiobjective genetic", "pid controller", "acceptable solution", "type controllers"], ["multiobjective robust control", "multiobjective genetic", "pid controller", "acceptable solution", "type controllers", "genetic", "multiobjective", "controller", "pid", "multivariable"]], "positionrank": [["multiobjective genetic algorithms", "pid controller", "genetic algorithms", "design", "multiobjective problem"], ["multiobjective genetic algorithms", "pid controller", "genetic algorithms", "design", "multiobjective problem", "pid loops", "pid", "genetic algorithm", "controller", "type controllers"]], "multipartiterank": [["pid controller", "multiobjective genetic algorithms", "specifications", "design", "multiobjective problem"], ["pid controller", "multiobjective genetic algorithms", "specifications", "design", "multiobjective problem", "plant", "pid", "type controllers", "parameters", "approach"]]}, {"id": "267", "text": "An efficient parallel algorithm for the calculation of canonical MP2 energies\nWe present the parallel version of a previous serial algorithm for the\n\tefficient calculation of canonical MP2 energies. It is based on the\n\tSaebo-Almlof direct-integral transformation, coupled with an efficient\n\tprescreening of the AO integrals. The parallel algorithm avoids\n\tsynchronization delays by spawning a second set of slaves during the\n\tbin-sort prior to the second half-transformation. Results are presented\n\tfor systems with up to 2000 basis functions. MP2 energies for molecules\n\twith 400-500 basis functions can be routinely calculated to\n\tmicrohartree accuracy on a small number of processors (6-8) in a matter\n\tof minutes with modern PC-based parallel computers\n", "keywords": "parallel algorithm; canonical MP2 energies; Saebo-Almlof direct-integral\n\ttransformation; AO integrals; synchronization delays; second\n\thalf-transformation; basis functions; MP2 energies; microhartree\n\taccuracy; PC-based parallel computers\n", "topicrank": [["efficient parallel algorithm", "canonical mp2 energies", "integral transformation", "second set", "basis functions"], ["efficient parallel algorithm", "canonical mp2 energies", "integral transformation", "second set", "basis functions", "calculation", "almlof direct", "results", "small number", "minutes"]], "textrank": [["efficient parallel algorithm", "parallel algorithm", "serial algorithm", "parallel", "ao integrals"], ["efficient parallel algorithm", "parallel algorithm", "serial algorithm", "parallel", "ao integrals", "integral transformation", "almlof direct", "second", "mp2", "efficient"]], "positionrank": [["efficient parallel algorithm", "canonical mp2 energies", "parallel algorithm", "efficient calculation", "previous serial algorithm"], ["efficient parallel algorithm", "canonical mp2 energies", "parallel algorithm", "efficient calculation", "previous serial algorithm", "mp2 energies", "parallel version", "parallel computers", "calculation", "basis functions"]], "multipartiterank": [["efficient parallel algorithm", "canonical mp2 energies", "calculation", "integral transformation", "second set"], ["efficient parallel algorithm", "canonical mp2 energies", "calculation", "integral transformation", "second set", "almlof direct", "basis functions", "previous serial algorithm", "efficient calculation", "saebo"]]}, {"id": "2195", "text": "Modeling privacy control in context-aware systems\nSignificant complexity issues challenge designers of context-aware systems with\n\tprivacy control. Information spaces provide a way to organize\n\tinformation, resources, and services around important privacy-relevant\n\tcontextual factors. In this article, we describe a theoretical model\n\tfor privacy control in context-aware systems based on a core\n\tabstraction of information spaces. We have previously focused on\n\tderiving socially based privacy objectives in pervasive computing\n\tenvironments. Building on Ravi Sandhu's four-layer OM-AM (objectives,\n\tmodels, architectures, and mechanisms) idea, we aim to use information\n\tspaces to construct a model for privacy control that supports our\n\tsocially based privacy objectives. We also discuss how we can introduce\n\tdecentralization, a desirable property for many pervasive computing\n\tsystems, into our information space model, using unified privacy\n\ttagging\n", "keywords": "privacy; pervasive computing; context-aware systems; privacy control; smart\n\toffice\n", "topicrank": [["privacy control", "information spaces", "aware systems", "context", "privacy objectives"], ["privacy control", "information spaces", "aware systems", "context", "privacy objectives", "pervasive computing", "theoretical model", "relevant", "architectures", "models"]], "textrank": [["information space model", "complexity issues challenge", "privacy", "ravi sandhu", "contextual factors"], ["information space model", "complexity issues challenge", "privacy", "ravi sandhu", "contextual factors", "aware systems", "pervasive", "model", "information", "systems"]], "positionrank": [["privacy control", "aware systems", "privacy objectives", "important privacy", "unified privacy"], ["privacy control", "aware systems", "privacy objectives", "important privacy", "unified privacy", "information space model", "information spaces", "systems", "context", "information"]], "multipartiterank": [["privacy control", "information spaces", "aware systems", "context", "privacy objectives"], ["privacy control", "information spaces", "aware systems", "context", "privacy objectives", "theoretical model", "pervasive computing", "information", "abstraction", "significant complexity issues challenge designers"]]}, {"id": "306", "text": "Measuring keyboard response delays by comparing keyboard and joystick inputs\nThe response characteristics of PC keyboards have to be identified when they\n\tare used as response devices in psychological experiments. In the past,\n\tthe proposed method has been to check the characteristics independently\n\tby means of external measurement equipment. However, with the\n\tavailability of different PC models and the rapid pace of model change,\n\tthere is an urgent need for the development of convenient and accurate\n\tmethods of checking. The method proposed consists of raising the\n\tprecision of the PC's clock to the microsecond level and using a\n\tjoystick connected to the MIDI terminal of a sound board to give the PC\n\tan independent timing function. Statistical processing of the data\n\tprovided by this method makes it possible to estimate accurately the\n\tkeyboard scanning interval time and the average keyboard delay time.\n\tThe results showed that measured keyboard delay times varied from 11 to\n\t73 msec, depending on the keyboard model, with most values being less\n\tthan 30 msec\n", "keywords": "keyboard response delay measurement; joystick inputs; keyboard inputs; PC\n\tkeyboards; psychological experiments; model change; checking; PC clock\n\tprecision; MIDI terminal; sound board; independent timing function;\n\tstatistical data processing; keyboard scanning interval time; average\n\tkeyboard delay time\n", "topicrank": [["method", "joystick inputs", "keyboard response delays", "response characteristics", "average keyboard delay time"], ["method", "joystick inputs", "keyboard response delays", "response characteristics", "average keyboard delay time", "accurate", "convenient", "methods", "development", "checking"]], "textrank": [["keyboard response", "keyboard delay", "keyboard model", "keyboard", "response"], ["keyboard response", "keyboard delay", "keyboard model", "keyboard", "response", "microsecond level", "urgent need", "rapid pace", "psychological experiments", "joystick inputs"]], "positionrank": [["keyboard response delays", "keyboard delay times", "keyboard model", "keyboard", "response characteristics"], ["keyboard response delays", "keyboard delay times", "keyboard model", "keyboard", "response characteristics", "response devices", "joystick inputs", "different pc models", "pc keyboards", "pc"]], "multipartiterank": [["keyboard response delays", "joystick inputs", "method", "response characteristics", "pc keyboards"], ["keyboard response delays", "joystick inputs", "method", "response characteristics", "pc keyboards", "accurate", "convenient", "average keyboard delay time", "methods", "development"]]}, {"id": "343", "text": "Using the Small Business Innovation Research Program to turn your ideas into\n\tproducts\nThe US Government's Small Business Innovation Research Program helps small\n\tbusinesses transform new ideas into commercial products. The program\n\tprovides an ideal means for businesses and universities to obtaining\n\tfunding for cooperative projects. Rules and information for the program\n\tare readily available, and I will give a few helpful hints to provide\n\tguidance\n", "keywords": "Small Business Innovation Research Program; commercial product development;\n\tbusinesses; universities; funding; cooperative projects; US Government;\n\tUSA\n", "topicrank": [["businesses", "ideas", "products", "program", "small business innovation research program"], ["businesses", "ideas", "products", "program", "small business innovation research program", "cooperative projects", "rules", "small", "funding", "ideal means"]], "textrank": [["business innovation research", "us government", "helpful", "products", "ideas"], ["business innovation research", "us government", "helpful", "products", "ideas"]], "positionrank": [["program", "new ideas", "commercial products", "us government", "ideas"], ["program", "new ideas", "commercial products", "us government", "ideas", "products", "businesses", "ideal means", "cooperative projects", "few helpful hints"]], "multipartiterank": [["products", "ideas", "small business innovation research program", "businesses", "program"], ["products", "ideas", "small business innovation research program", "businesses", "program", "us government", "small", "cooperative projects", "rules", "new ideas"]]}, {"id": "2009", "text": "A survey of interactive mesh-cutting techniques and a new method for\n\timplementing generalized interactive mesh cutting using virtual tools\nIn our experience, mesh-cutting methods can be distinguished by how their\n\tsolutions address the following major issues: definition of the cut\n\tpath, primitive removal and re-meshing, number of new primitives\n\tcreated, when re-meshing is performed, and representation of the\n\tcutting tool. Many researchers have developed schemes for interactive\n\tmesh cutting with the goals of reducing the number of new primitives\n\tcreated, creating new primitives with good aspect ratios, avoiding a\n\tdisconnected mesh structure between primitives in the cut path, and\n\trepresenting the path traversed by the tool as accurately as possible.\n\tThe goal of this paper is to explain how, by using a very simple\n\tframework, one can build a generalized cutting scheme. This method\n\tallows for any arbitrary cut to be made within a virtual object, and\n\tcan simulate cutting surface, layered surface or tetrahedral objects\n\tusing a virtual scalpel, scissors, or loop cautery tool. This method\n\thas been implemented in a real-time, haptic-rate surgical simulation\n\tsystem allowing arbitrary cuts to be made on high-resolution\n\tpatient-specific models\n", "keywords": "generalized interactive mesh cutting; virtual tools; cut path definition;\n\tre-meshing; cutting tool; disconnected mesh structure; virtual object;\n\ttetrahedral objects; layered surface; real-time system; haptic-rate\n\tsurgical simulation system; high-resolution patient-specific models;\n\trendering; haptic interfaces\n", "topicrank": [["interactive mesh", "new primitives", "tool", "path", "virtual tools"], ["interactive mesh", "new primitives", "tool", "path", "virtual tools", "new method", "number", "cut", "surface", "rate surgical simulation"]], "textrank": [["mesh - cutting", "- specific models", "mesh cutting", "arbitrary cut", "mesh"], ["mesh - cutting", "- specific models", "mesh cutting", "arbitrary cut", "mesh", "tetrahedral objects", "many researchers", "primitive removal", "major issues", "virtual"]], "positionrank": [["interactive mesh cutting", "interactive mesh", "mesh cutting", "disconnected mesh structure", "new primitives"], ["interactive mesh cutting", "interactive mesh", "mesh cutting", "disconnected mesh structure", "new primitives", "new method", "mesh", "interactive", "cut path", "cutting scheme"]], "multipartiterank": [["interactive mesh", "new primitives", "new method", "path", "virtual tools"], ["interactive mesh", "new primitives", "new method", "path", "virtual tools", "tool", "survey", "techniques", "number", "cut"]]}, {"id": "2114", "text": "Automation of the recovery of efficiency of complex structure systems\nBasic features are set forth of the method for automation of the serviceability\n\trecovery of systems of complex structures in real time without the\n\tinterruption of operation. Specific features of the method are revealed\n\tin an important example of the system of control of hardware components\n\tof ships\n", "keywords": "efficiency recovery; serviceability recovery; complex structure systems; ships;\n\thardware components\n", "topicrank": [["complex structure systems", "recovery", "basic features", "method", "automation"], ["complex structure systems", "recovery", "basic features", "method", "automation", "complex structures", "operation", "serviceability", "control", "real time"]], "textrank": [["complex structure", "important example", "real time", "features", "complex"], ["complex structure", "important example", "real time", "features", "complex"]], "positionrank": [["complex structure systems", "complex structures", "automation", "basic features", "recovery"], ["complex structure systems", "complex structures", "automation", "basic features", "recovery", "specific features", "systems", "real time", "method", "efficiency"]], "multipartiterank": [["complex structure systems", "recovery", "basic features", "method", "automation"], ["complex structure systems", "recovery", "basic features", "method", "automation", "efficiency", "complex structures", "serviceability", "systems", "operation"]]}, {"id": "2151", "text": "Industrial/sup IT/ for performance buildings\nABB has taken a close look at how buildings are used and has come up with a\n\tradical solution for the technical infrastructure that places the\n\tend-user's processes at the center and integrates all the building's\n\tsystems around their needs. The new solution is based on the\n\trealization that tasks like setting up an office meeting, registering a\n\thotel guest or moving a patient in a hospital, can all benefit from the\n\tsame Industrial IT concepts employed by ABB to optimize manufacturing,\n\tfor example in the automotive industry\n", "keywords": "Industrial/sup IT/; ABB; building management system; technical infrastructure;\n\tbuilding systems integration; industrial IT concepts\n", "topicrank": [["radical solution", "abb", "performance buildings", "user", "processes"], ["radical solution", "abb", "performance buildings", "user", "processes", "end", "systems", "needs", "center", "building"]], "textrank": [["industrial it", "technical infrastructure", "close look", "performance buildings", "sup it/"], ["industrial it", "technical infrastructure", "close look", "performance buildings", "sup it/", "solution", "industrial", "buildings"]], "positionrank": [["performance buildings", "industrial", "sup it/", "abb", "close look"], ["performance buildings", "industrial", "sup it/", "abb", "close look", "buildings", "manufacturing", "new solution", "automotive industry", "radical solution"]], "multipartiterank": [["abb", "radical solution", "performance buildings", "user", "processes"], ["abb", "radical solution", "performance buildings", "user", "processes", "end", "technical infrastructure", "center", "systems", "close look"]]}, {"id": "1998", "text": "A friction compensator for pneumatic control valves\nA procedure that compensates for static friction (stiction) in pneumatic\n\tcontrol valves is presented. The compensation is obtained by adding\n\tpulses to the control signal. The characteristics of the pulses are\n\tdetermined from the control action. The compensator is implemented in\n\tindustrial controllers and control systems, and the industrial\n\texperiences show that the procedure reduces the control error during\n\tstick-slip motion significantly compared to standard control without\n\tstiction compensation\n", "keywords": "friction compensator; pneumatic control valves; static friction compensation;\n\tstiction compensation; industrial controllers; control error reduction;\n\tstick-slip motion; standard control\n", "topicrank": [["pneumatic control valves", "industrial controllers", "procedure", "pulses", "friction compensator"], ["pneumatic control valves", "industrial controllers", "procedure", "pulses", "friction compensator", "compensation", "stiction", "pneumatic", "static friction", "experiences"]], "textrank": [["control", "stiction compensation", "industrial controllers", "friction", "slip"], ["control", "stiction compensation", "industrial controllers", "friction", "slip", "industrial", "compensation", "stiction"]], "positionrank": [["pneumatic control valves", "control valves", "control systems", "standard control", "control error"], ["pneumatic control valves", "control valves", "control systems", "standard control", "control error", "control action", "control signal", "friction compensator", "static friction", "stiction compensation"]], "multipartiterank": [["pneumatic control valves", "friction compensator", "procedure", "pulses", "static friction"], ["pneumatic control valves", "friction compensator", "procedure", "pulses", "static friction", "industrial controllers", "stiction", "pneumatic", "compensation", "control valves"]]}, {"id": "1965", "text": "Stock market dynamics\nWe elucidate on several empirical statistical observations of stock market\n\treturns. Moreover, we find that these properties are recurrent and are\n\talso present in invariant measures of low-dimensional dynamical\n\tsystems. Thus, we propose that the returns are modeled by the first\n\tPoincare return time of a low-dimensional chaotic trajectory. This\n\tmodeling, which captures the recurrent properties of the return\n\tfluctuations, is able to predict well the evolution of the observed\n\tstatistical quantities. In addition, it explains the reason for which\n\tstocks present simultaneously dynamical properties and high\n\tuncertainties. In our analysis, we use data from the S&P 500 index and\n\tthe Brazilian stock Telebras\n", "keywords": "stock market returns; empirical statistical observations; invariant measures;\n\tlow-dimensional dynamical systems; first Poincare return time;\n\tlow-dimensional chaotic trajectory; statistical quantities; Brazilian\n\tstock; econophysics\n", "topicrank": [["low", "poincare return time", "properties", "recurrent", "returns"], ["low", "poincare return time", "properties", "recurrent", "returns", "stock market dynamics", "high", "invariant measures", "dimensional dynamical", "statistical quantities"]], "textrank": [["empirical statistical", "stock market", "poincare return time", "dynamical properties", "dimensional chaotic"], ["empirical statistical", "stock market", "poincare return time", "dynamical properties", "dimensional chaotic", "dimensional dynamical", "invariant measures", "stock", "statistical", "return"]], "positionrank": [["stock market dynamics", "stock market", "brazilian stock telebras", "statistical quantities", "poincare return time"], ["stock market dynamics", "stock market", "brazilian stock telebras", "statistical quantities", "poincare return time", "returns", "dynamical properties", "dimensional chaotic trajectory", "recurrent properties", "properties"]], "multipartiterank": [["stock market dynamics", "low", "properties", "recurrent", "poincare return time"], ["stock market dynamics", "low", "properties", "recurrent", "poincare return time", "returns", "invariant measures", "several empirical statistical observations", "dimensional dynamical", "present"]]}, {"id": "1958", "text": "Option pricing from path integral for non-Gaussian fluctuations. Natural\n\tmartingale and application to truncated Levy distributions\nWithin a path integral formalism for non-Gaussian price fluctuations, we set up\n\ta simple stochastic calculus and derive a natural martingale for option\n\tpricing from the wealth balance of options, stocks, and bonds. The\n\tresulting formula is evaluated for truncated Levy distributions\n", "keywords": "option pricing; path integrals; stochastic calculus; stocks; bonds; nonGaussian\n\tfluctuations; natural martingale; truncated Levy distributions\n", "topicrank": [["martingale", "option pricing", "levy distributions", "path integral", "options"], ["martingale", "option pricing", "levy distributions", "path integral", "options", "wealth balance", "pricing", "stocks", "application", "bonds"]], "textrank": [["- gaussian", "option pricing", "stochastic", "integral", "pricing"], ["- gaussian", "option pricing", "stochastic", "integral", "pricing", "option", "natural"]], "positionrank": [["option pricing", "natural martingale", "integral formalism", "option", "simple stochastic calculus"], ["option pricing", "natural martingale", "integral formalism", "option", "simple stochastic calculus", "pricing", "path", "levy distributions", "martingale", "wealth balance"]], "multipartiterank": [["option pricing", "path integral", "martingale", "levy distributions", "natural"], ["option pricing", "path integral", "martingale", "levy distributions", "natural", "application", "options", "wealth balance", "stocks", "pricing"]]}, {"id": "263", "text": "K-12 instruction and digital access to archival materials\nProviding K-12 schools with digital access to archival materials can strengthen\n\tboth student learning and archival practice, although it cannot replace\n\tdirect physical access to records. The article compares a variety of\n\telectronic and nonelectronic projects to promote teaching with primary\n\tsource materials. The article also examines some of the different\n\thistoriographical and pedagogical approaches used in archival Web sites\n\tgeared for K-12 instruction, focusing on differences between the\n\teducational sites sponsored by the Library of Congress and the National\n\tArchives and Records Administration\n", "keywords": "K-12 instruction; digital access; archival materials; student learning;\n\tarchival practice; electronic projects; nonelectronic projects; primary\n\tsource materials; direct physical access; historiographical approaches;\n\tpedagogical approaches; archival Web; educational sites; Library of\n\tCongress; National Archives and Records Administration\n", "topicrank": [["archival materials", "article", "records", "digital access", "instruction"], ["archival materials", "article", "records", "digital access", "instruction", "primary", "nonelectronic projects", "teaching", "source materials", "historiographical"]], "textrank": [["archival web sites", "archival materials", "physical access", "student learning", "archival"], ["archival web sites", "archival materials", "physical access", "student learning", "archival", "access", "sites", "materials", "nonelectronic", "records"]], "positionrank": [["archival materials", "archival web sites", "digital access", "archival practice", "direct physical access"], ["archival materials", "archival web sites", "digital access", "archival practice", "direct physical access", "source materials", "instruction", "educational sites", "student learning", "nonelectronic projects"]], "multipartiterank": [["archival materials", "digital access", "article", "records", "instruction"], ["archival materials", "digital access", "article", "records", "instruction", "primary", "nonelectronic projects", "teaching", "electronic", "source materials"]]}, {"id": "2191", "text": "The role of speech input in wearable computing\nSpeech recognition seems like an attractive input mechanism for wearable\n\tcomputers, and as we saw in this magazine's first issue, several\n\tcompanies are promoting products that use limited speech interfaces for\n\tspecific tasks. However, we must overcome several challenges to using\n\tspeech recognition in more general contexts, and interface designers\n\tmust be wary of applying the technology to situations where speech is\n\tinappropriate\n", "keywords": "wearable computing; speech input; speech recognition; wearable computer; speech\n\trecognizers; mobile speech recognition; background noise; speech\n\tinterfaces\n", "topicrank": [["speech input", "wearable computing", "several", "first issue", "companies"], ["speech input", "wearable computing", "several", "first issue", "companies", "situations", "attractive input mechanism", "products", "magazine", "technology"]], "textrank": [["speech input", "speech", "first issue", "wearable computing", "input"], ["speech input", "speech", "first issue", "wearable computing", "input", "general", "specific", "several", "wearable"]], "positionrank": [["speech input", "speech recognition", "limited speech interfaces", "attractive input mechanism", "speech"], ["speech input", "speech recognition", "limited speech interfaces", "attractive input mechanism", "speech", "wearable computing", "more general contexts", "several challenges", "role", "interface designers"]], "multipartiterank": [["speech input", "wearable computing", "role", "several", "speech recognition"], ["speech input", "wearable computing", "role", "several", "speech recognition", "attractive input mechanism", "first issue", "companies", "computers", "wearable"]]}, {"id": "226", "text": "Online masquerade: whose e-mail is it?\nE-mails carrying viruses like the recent Klez worm use deceptively simple\n\ttechniques and known vulnerabilities to spread from one computer to\n\tanother with ease\n", "keywords": "e-mail; Klez worm; viruses; vulnerabilities\n", "topicrank": [["simple", "techniques", "recent klez worm", "viruses", "vulnerabilities"], ["simple", "techniques", "recent klez worm", "viruses", "vulnerabilities", "mails", "computer", "ease", "online masquerade"]], "textrank": [["online masquerade", "klez", "-"], ["online masquerade", "klez", "-"]], "positionrank": [["e - mail", "online masquerade", "recent klez worm", "e", "mails"], ["e - mail", "online masquerade", "recent klez worm", "e", "mails", "viruses", "techniques", "vulnerabilities", "computer", "ease"]], "multipartiterank": [["simple", "techniques", "recent klez worm", "viruses", "vulnerabilities"], ["simple", "techniques", "recent klez worm", "viruses", "vulnerabilities", "mails", "computer", "ease", "online masquerade"]]}, {"id": "30", "text": "Improvements and critique on Sugeno's and Yasukawa's qualitative modeling\nInvestigates Sugeno's and Yasukawa's (1993) qualitative fuzzy modeling\n\tapproach. We propose some easily implementable solutions for the\n\tunclear details of the original paper, such as trapezoid approximation\n\tof membership functions, rule creation from sample data points, and\n\tselection of important variables. We further suggest an improved\n\tparameter identification algorithm to be applied instead of the\n\toriginal one. These details are crucial concerning the method's\n\tperformance as it is shown in a comparative analysis and helps to\n\timprove the accuracy of the built-up model. Finally, we propose a\n\tpossible further rule base reduction which can be applied successfully\n\tin certain cases. This improvement reduces the time requirement of the\n\tmethod by up to 16% in our experiments\n", "keywords": "qualitative modeling; fuzzy modeling; trapezoid approximation; membership\n\tfunctions; rule creation; parameter identification algorithm; rule base\n\treduction; Sugeno-Yasukawa method\n", "topicrank": [["qualitative modeling", "sugeno", "unclear details", "yasukawa", "original paper"], ["qualitative modeling", "sugeno", "unclear details", "yasukawa", "original paper", "method", "sample data points", "creation", "crucial", "membership functions"]], "textrank": [["further rule base", "qualitative fuzzy modeling", "original paper", "unclear details", "implementable solutions"], ["further rule base", "qualitative fuzzy modeling", "original paper", "unclear details", "implementable solutions", "investigates sugeno", "qualitative modeling", "identification", "data", "further"]], "positionrank": [["qualitative fuzzy modeling", "qualitative modeling", "investigates sugeno", "yasukawa", "sugeno"], ["qualitative fuzzy modeling", "qualitative modeling", "investigates sugeno", "yasukawa", "sugeno", "improvements", "critique", "implementable solutions", "original paper", "unclear details"]], "multipartiterank": [["sugeno", "qualitative modeling", "yasukawa", "unclear details", "original paper"], ["sugeno", "qualitative modeling", "yasukawa", "unclear details", "original paper", "critique", "method", "investigates sugeno", "improvements", "sample data points"]]}, {"id": "2129", "text": "A universal decomposition of the integration range for exponential functions\nThe problem of determining the independent constants for decomposition of the\n\tintegration range of exponential functions was solved on the basis of a\n\tsimilar approach to polynomials. The constants obtained enable one to\n\tdecompose the integration range in two so that the integrals over them\n\tare equal independently of the function parameters. For the\n\tnontrigonometrical polynomials of even functions, an alternative\n\tapproach was presented\n", "keywords": "integration range universal decomposition; exponential functions; polynomials;\n\tintegration range decomposition; nontrigonometrical polynomials; even\n\tfunctions\n", "topicrank": [["exponential functions", "integration range", "polynomials", "independent constants", "similar approach"], ["exponential functions", "integration range", "polynomials", "independent constants", "similar approach", "universal decomposition", "alternative", "problem", "basis", "function parameters"]], "textrank": [["integration range", "universal decomposition", "functions", "decomposition", "independent"], ["integration range", "universal decomposition", "functions", "decomposition", "independent"]], "positionrank": [["integration range", "exponential functions", "universal decomposition", "even functions", "independent constants"], ["integration range", "exponential functions", "universal decomposition", "even functions", "independent constants", "decomposition", "constants", "nontrigonometrical polynomials", "similar approach", "problem"]], "multipartiterank": [["integration range", "exponential functions", "universal decomposition", "independent constants", "polynomials"], ["integration range", "exponential functions", "universal decomposition", "independent constants", "polynomials", "similar approach", "problem", "decomposition", "basis", "constants"]]}, {"id": "383", "text": "Outlier resistant adaptive matched filtering\nRobust adaptive matched filtering (AMF) whereby outlier data vectors are\n\tcensored from the covariance matrix estimate is considered in a maximum\n\tlikelihood estimation (MLE) setting. It is known that outlier data\n\tvectors whose steering vector is highly correlated with the desired\n\tsteering vector, can significantly degrade the performance of AMF\n\talgorithms such as sample matrix inversion (SMI) or fast maximum\n\tlikelihood (FML). Four new algorithms that censor outliers are\n\tpresented which are derived via approximation to the MLE solution. Two\n\talgorithms each are related to using the SMI or the FML to estimate the\n\tunknown underlying covariance matrix. Results are presented using\n\tcomputer simulations which demonstrate the relative effectiveness of\n\tthe four algorithms versus each other and also versus the SMI and FML\n\talgorithms in the presence of outliers and no outliers. It is shown\n\tthat one of the censoring algorithms, called the reiterative censored\n\tfast maximum likelihood (CFML) technique is significantly superior to\n\tthe other three censoring methods in stressful outlier scenarios\n", "keywords": "outlier resistant adaptive matched filtering; covariance matrix estimate;\n\tmaximum likelihood estimation setting; steering vector; sample matrix\n\tinversion; fast maximum likelihood; censoring algorithms; reiterative\n\tcensored fast maximum likelihood\n", "topicrank": [["new algorithms", "maximum", "fml", "smi", "censor outliers"], ["new algorithms", "maximum", "fml", "smi", "censor outliers", "likelihood estimation", "mle", "covariance matrix estimate", "amf", "outlier data vectors"]], "textrank": [["outlier data", "adaptive matched", "maximum likelihood", "matrix", "mle solution"], ["outlier data", "adaptive matched", "maximum likelihood", "matrix", "mle solution", "censor outliers", "steering vector", "outlier", "algorithms", "likelihood"]], "positionrank": [["outlier data vectors", "outlier data", "filtering", "fast maximum likelihood", "covariance matrix estimate"], ["outlier data vectors", "outlier data", "filtering", "fast maximum likelihood", "covariance matrix estimate", "stressful outlier scenarios", "sample matrix inversion", "covariance matrix", "amf", "new algorithms"]], "multipartiterank": [["new algorithms", "maximum", "likelihood estimation", "mle", "fml"], ["new algorithms", "maximum", "likelihood estimation", "mle", "fml", "outlier data vectors", "smi", "amf", "censor outliers", "algorithms"]]}, {"id": "1981", "text": "Optimal linear control in stabilizer design\nThe most common method of improving stability of the power system is the\n\tsynthesis of the turbine and generator control systems, because of the\n\thigh effectiveness and relatively low cost of these elements. The\n\tsynthesis and construction of the effective synchronous generator and\n\tturbine controller is a very difficult task. This paper describes the\n\tseven step mu -synthesis approach to PSS design enabling the\n\tsynchronous generator to remain stable over a wide range of system\n\toperating conditions\n", "keywords": "mu -synthesis approach; PSS design; optimal linear control; synchronous\n\tgenerator control system synthesis; turbine control system synthesis\n", "topicrank": [["synthesis", "power system", "turbine", "effective synchronous generator", "stabilizer design"], ["synthesis", "power system", "turbine", "effective synchronous generator", "stabilizer design", "construction", "wide range", "low cost", "generator control systems", "step mu -synthesis approach"]], "textrank": [["linear control", "generator control", "mu -synthesis", "synchronous generator", "power system"], ["linear control", "generator control", "mu -synthesis", "synchronous generator", "power system", "common method", "design", "system"]], "positionrank": [["optimal linear control", "generator control systems", "stabilizer design", "effective synchronous generator", "common method"], ["optimal linear control", "generator control systems", "stabilizer design", "effective synchronous generator", "common method", "synchronous generator", "pss design", "power system", "turbine controller", "high effectiveness"]], "multipartiterank": [["synthesis", "turbine", "stabilizer design", "power system", "effective synchronous generator"], ["synthesis", "turbine", "stabilizer design", "power system", "effective synchronous generator", "generator control systems", "stability", "common method", "construction", "optimal linear control"]]}, {"id": "2148", "text": "Information security policy - what do international information security\n\tstandards say?\nOne of the most important information security controls, is the information\n\tsecurity policy. This vital direction-giving document is, however, not\n\talways easy to develop and the authors thereof battle with questions\n\tsuch as what constitutes a policy. This results in the policy authors\n\tturning to existing sources for guidance. One of these sources is the\n\tvarious international information security standards. These standards\n\tare a good starting point for determining what the information security\n\tpolicy should consist of, but should not be relied upon exclusively for\n\tguidance. Firstly, they are not comprehensive in their coverage and\n\tfurthermore, tending to rather address the processes needed for\n\tsuccessfully implementing the information security policy. It is far\n\tmore important the information security policy must fit in with the\n\torganisation's culture and must therefore be developed with this in\n\tmind\n", "keywords": "information security policy; international information security standards\n", "topicrank": [["information security policy", "sources", "standards", "guidance", "authors"], ["information security policy", "sources", "standards", "guidance", "authors", "policy", "vital direction", "document", "organisation", "good starting point"]], "textrank": [["international information security", "information security policy", "information security", "security policy", "good starting"], ["international information security", "information security policy", "information security", "security policy", "good starting", "vital direction", "information", "policy"]], "positionrank": [["information security policy", "international information security", "information security", "security policy", "information"], ["information security policy", "international information security", "information security", "security policy", "information", "policy authors", "policy", "standards", "good starting point", "vital direction"]], "multipartiterank": [["information security policy", "important", "standards", "organisation", "culture"], ["information security policy", "important", "standards", "organisation", "culture", "guidance", "policy", "sources", "authors", "processes"]]}, {"id": "247", "text": "The congenial talking philosophers problem in computer networks\nGroup mutual exclusion occurs naturally in situations where a resource can be\n\tshared by processes of the same group, but not by processes of\n\tdifferent groups. For example, suppose data is stored in a CD-jukebox.\n\tThen, when a disc is loaded for access, users that need data on the\n\tdisc can concurrently access the disc, while users that need data on a\n\tdifferent disc have to wait until the current disc is unloaded. The\n\tdesign issues for group mutual exclusion have been modeled as the\n\tCongenial Talking Philosophers problem, and solutions for shared memory\n\tmodels have been proposed (Y.-J. Young, 2000; P. Keane and M. Moir,\n\t1999). As in ordinary mutual exclusion and many other problems in\n\tdistributed systems, however, techniques developed for shared memory do\n\tnot necessarily apply to message passing (and vice versa). We\n\tinvestigate solutions for Congenial Talking Philosophers in computer\n\tnetworks where processes communicate by asynchronous message passing.\n\tWe first present a solution that is a straightforward adaptation from\n\tG. Ricart and A.K. Agrawala's (1981) algorithm for ordinary mutual\n\texclusion. Then we show that the simple modification suffers a severe\n\tperformance degradation that could cause the system to behave as though\n\tonly one process of a group can be in the critical section at a time.\n\tWe then present a more efficient and highly concurrent distributed\n\talgorithm for the problem, the first such solution in computer networks\n", "keywords": "congenial talking philosophers problem; computer networks; group mutual\n\texclusion; resource sharing; shared-memory models; distributed systems;\n\tprocess communication; asynchronous message passing; critical section;\n\tconcurrent distributed algorithm\n", "topicrank": [["disc", "group mutual exclusion", "congenial", "computer networks", "data"], ["disc", "group mutual exclusion", "congenial", "computer networks", "data", "processes", "solutions", "users", "shared memory", "algorithm"]], "textrank": [["group mutual", "different disc", "talking philosophers", "m. moir", "p. keane"], ["group mutual", "different disc", "talking philosophers", "m. moir", "p. keane", "y.-j. young", "shared memory", "design issues", "computer networks", "mutual"]], "positionrank": [["congenial talking philosophers", "ordinary mutual exclusion", "philosophers problem", "mutual exclusion", "computer networks"], ["congenial talking philosophers", "ordinary mutual exclusion", "philosophers problem", "mutual exclusion", "computer networks", "same group", "different disc", "group", "problem", "exclusion"]], "multipartiterank": [["congenial", "group mutual exclusion", "disc", "computer networks", "philosophers problem"], ["congenial", "group mutual exclusion", "disc", "computer networks", "philosophers problem", "data", "processes", "users", "solutions", "shared memory"]]}, {"id": "202", "text": "Estimation of error in curvature computation on multi-scale free-form surfaces\nA novel technique for multi-scale curvature computation on a free-form 3-D\n\tsurface is presented. This is achieved by convolving local\n\tparametrisations of the surface with 2-D Gaussian filters iteratively.\n\tIn our technique, semigeodesic coordinates are constructed at each\n\tvertex of the mesh. Smoothing results are shown for 3-D surfaces with\n\tdifferent shapes indicating that surface noise is eliminated and\n\tsurface details are removed gradually. A number of evolution properties\n\tof 3-D surfaces are described. Next, the surface Gaussian and mean\n\tcurvature values are estimated accurately at multiple scales which are\n\tthen mapped to colours and displayed directly on the surface. The\n\tperformance of the technique when selecting different directions as an\n\tarbitrary direction for the geodesic at each vertex are also presented.\n\tThe results indicate that the error observed for the estimation of\n\tGaussian and mean curvatures is quite low after only one iteration.\n\tFurthermore, as the surface is smoothed iteratively, the error is\n\tfurther reduced. The results also show that the estimation error of\n\tGaussian curvature is less than that of mean curvature. Our experiments\n\tdemonstrate that estimation of smoothed surface curvatures are very\n\taccurate and not affected by the arbitrary direction of the first\n\tgeodesic line when constructing semigeodesic coordinates. Our technique\n\tis independent of the underlying triangulation and is also more\n\tefficient than volumetric diffusion techniques since 2-D rather than\n\t3-D convolutions are employed. Finally, the method presented here is a\n\tgeneralisation of the Curvature Scale Space method for 2-D contours.\n\tThe CSS method has outperformed comparable techniques within the MPEG-7\n\tevaluation framework. As a result, it has been selected for inclusion\n\tin the MPEG-7 package of standards\n", "keywords": "multi-scale curvature computation; free-form 3D surface; local\n\tparametrisations; 2D Gaussian filters; surface noise; evolution\n\tproperties; surface Gaussian values; mean curvature values;\n\tsemigeodesic coordinates; underlying triangulation; volumetric\n\tdiffusion techniques; convolutions; Curvature Scale Space method;\n\tMPEG-7 evaluation framework\n", "topicrank": [["surface", "novel technique", "error", "gaussian filters", "estimation"], ["surface", "novel technique", "error", "gaussian filters", "estimation", "curvature computation", "results", "geodesic", "mpeg-7", "arbitrary direction"]], "textrank": [["curvature scale space method", "- scale curvature", "gaussian curvature", "surface gaussian", "- form surfaces"], ["curvature scale space method", "- scale curvature", "gaussian curvature", "surface gaussian", "- form surfaces", "- scale", "diffusion techniques", "curvature", "- form", "estimation error"]], "positionrank": [["estimation error", "curvature computation", "gaussian curvature", "surface gaussian", "estimation"], ["estimation error", "curvature computation", "gaussian curvature", "surface gaussian", "estimation", "curvature values", "form surfaces", "surface curvatures", "novel technique", "surface noise"]], "multipartiterank": [["surface", "novel technique", "error", "curvature computation", "gaussian filters"], ["surface", "novel technique", "error", "curvature computation", "gaussian filters", "form surfaces", "estimation", "technique", "results", "different shapes"]]}, {"id": "1939", "text": "Compatibility of systems of linear constraints over the set of natural numbers\nCriteria of compatibility of a system of linear Diophantine equations, strict\n\tinequations, and nonstrict inequations are considered. Upper bounds for\n\tcomponents of a minimal set of solutions and algorithms of construction\n\tof minimal generating sets of solutions for all types of systems are\n\tgiven. These criteria and the corresponding algorithms for constructing\n\ta minimal supporting set of solutions can be used in solving all the\n\tconsidered types of systems and systems of mixed types\n", "keywords": "linear constraints; set of natural numbers; linear Diophantine equations;\n\tstrict inequations; nonstrict inequations; upper bounds; minimal\n\tgenerating sets\n", "topicrank": [["systems", "minimal set", "solutions", "types", "algorithms"], ["systems", "minimal set", "solutions", "types", "algorithms", "set", "criteria", "compatibility", "inequations", "linear diophantine equations"]], "textrank": [["linear diophantine", "nonstrict inequations", "natural numbers", "linear", "inequations"], ["linear diophantine", "nonstrict inequations", "natural numbers", "linear", "inequations", "set"]], "positionrank": [["linear diophantine equations", "minimal set", "linear constraints", "compatibility", "natural numbers"], ["linear diophantine equations", "minimal set", "linear constraints", "compatibility", "natural numbers", "systems", "nonstrict inequations", "set", "criteria", "mixed types"]], "multipartiterank": [["solutions", "systems", "minimal set", "types", "algorithms"], ["solutions", "systems", "minimal set", "types", "algorithms", "inequations", "set", "criteria", "compatibility", "minimal"]]}, {"id": "2055", "text": "Causes of the decline of the business school management science course\nThe business school management science course is suffering serious decline. The\n\ttraditional model- and algorithm-based course fails to meet the needs\n\tof MBA programs and students. Poor student mathematical preparation is\n\ta reality, and is not an acceptable justification for poor teaching\n\toutcomes. Management science Ph.D.s are often poorly prepared to teach\n\tin a general management program, having more experience and interest in\n\talgorithms than management. The management science profession as a\n\twhole has focused its attention on algorithms and a narrow subset of\n\tmanagement problems for which they are most applicable. In contrast,\n\tMBA's rarely encounter problems that are suitable for straightforward\n\tapplication of management science tools, living instead in a world\n\twhere problems are ill-defined, data is scarce, time is short, politics\n\tis dominant, and rational \"decision makers\" are non-existent. The root\n\tcause of the profession's failure to address these issues seems to be\n\t(in Russell Ackoff's words) a habit of professional introversion that\n\tcaused the profession to be uninterested in what MBA's really do on the\n\tjob and how management science can help them\n", "keywords": "business school management science course; MBA programs; MBA students;\n\tmanagement science; profession\n", "topicrank": [["business school management science course", "mba programs", "algorithms", "problems", "profession"], ["business school management science course", "mba programs", "algorithms", "problems", "profession", "decline", "time", "short", "scarce", "straightforward"]], "textrank": [["management science ph .", "school management science", "management science", "poor student mathematical", "management ."], ["management science ph .", "school management science", "management science", "poor student mathematical", "management .", "serious decline .", "management", "decision makers", "narrow subset", "more experience"]], "positionrank": [["management science profession", "management science tools", "management science", "management problems", "general management program"], ["management science profession", "management science tools", "management science", "management problems", "general management program", "management", "serious decline", "causes", "course", "decline"]], "multipartiterank": [["business school management science course", "decline", "mba programs", "algorithms", "students"], ["business school management science course", "decline", "mba programs", "algorithms", "students", "problems", "profession", "traditional model-", "algorithm", "poor student mathematical preparation"]]}, {"id": "2010", "text": "Scale-invariant segmentation of dynamic contrast-enhanced perfusion MR images\n\twith inherent scale selection\nSelection of the best set of scales is problematic when developing\n\tsignal-driven approaches for pixel-based image segmentation. Often,\n\tdifferent possibly conflicting criteria need to be fulfilled in order\n\tto obtain the best trade-off between uncertainty (variance) and\n\tlocation accuracy. The optimal set of scales depends on several\n\tfactors: the noise level present in the image material, the prior\n\tdistribution of the different types of segments, the class-conditional\n\tdistributions associated with each type of segment as well as the\n\tactual size of the (connected) segments. We analyse, theoretically and\n\tthrough experiments, the possibility of using the overall and\n\tclass-conditional error rates as criteria for selecting the optimal\n\tsampling of the linear and morphological scale spaces. It is shown that\n\tthe overall error rate is optimized by taking the prior class\n\tdistribution in the image material into account. However, a uniform\n\t(ignorant) prior distribution ensures constant class-conditional error\n\trates. Consequently, we advocate for a uniform prior class distribution\n\twhen an uncommitted, scale-invariant segmentation approach is desired.\n\tExperiments with a neural net classifier developed for segmentation of\n\tdynamic magnetic resonance (MR) images, acquired with a paramagnetic\n\ttracer, support the theoretical results. Furthermore, the experiments\n\tshow that the addition of spatial features to the classifier, extracted\n\tfrom the linear or morphological scale spaces, improves the\n\tsegmentation result compared to a signal-driven approach based solely\n\ton the dynamic MR signal. The segmentation results obtained from the\n\ttwo types of features are compared using two novel quality measures\n\tthat characterize spatial properties of labelled images\n", "keywords": "scale-invariant segmentation; dynamic contrast-enhanced perfusion MR images;\n\tinherent scale selection; pixel-based image segmentation; noise level;\n\tclass-conditional error rates; optimal sampling; experiments; neural\n\tnet classifier; dynamic magnetic resonance images; paramagnetic tracer;\n\tquality measures; labelled images; class-conditional distributions\n", "topicrank": [["invariant segmentation", "scale", "prior", "conditional", "class"], ["invariant segmentation", "scale", "prior", "conditional", "class", "experiments", "signal", "perfusion mr images", "scales", "optimal set"]], "textrank": [["prior class distribution", "segmentation results", "image segmentation", "dynamic mr", "noise level present"], ["prior class distribution", "segmentation results", "image segmentation", "dynamic mr", "noise level present", "prior class", "dynamic magnetic", "segmentation", "best set", "prior distribution"]], "positionrank": [["inherent scale selection", "morphological scale spaces", "invariant segmentation approach", "invariant segmentation", "scale"], ["inherent scale selection", "morphological scale spaces", "invariant segmentation approach", "invariant segmentation", "scale", "dynamic mr signal", "perfusion mr images", "image segmentation", "segmentation results", "segmentation result"]], "multipartiterank": [["scale", "invariant segmentation", "prior", "class", "conditional"], ["scale", "invariant segmentation", "prior", "class", "conditional", "perfusion mr images", "scales", "dynamic contrast", "best set", "different"]]}, {"id": "2068", "text": "Modeling the labor market as an evolving institution: model ARTEMIS\nA stylized French labor market is modeled as an endogenously evolving\n\tinstitution. Boundedly rational firms and individuals strive to\n\tdecrease the cost or increase utility. The labor market is coordinated\n\tby a search process and decentralized setting of hiring standards, but\n\tintermediaries can speed up matching. The model reproduces the dynamics\n\tof the gross flows and spectacular changes in mobility patterns of some\n\tdemographic groups when the oil crisis in the 1970's occurred, notably\n\tthe sudden decline of the integration in good jobs. The internal labor\n\tmarkets of large firms are shown to increase unemployment if the\n\tsecondary (temporary or bad) jobs do not exist\n", "keywords": "ARTEMIS model; French labor market; endogenously evolving institution;\n\tsimulation model; jobs; endogenous intermediary; spectacular changes;\n\tmobility patterns; demographic groups\n", "topicrank": [["labor market", "rational firms", "good jobs", "model artemis", "institution"], ["labor market", "rational firms", "good jobs", "model artemis", "institution", "spectacular changes", "markets", "temporary", "gross flows", "mobility patterns"]], "textrank": [["spectacular changes", "gross flows", "decentralized setting", "search process", "model artemis"], ["spectacular changes", "gross flows", "decentralized setting", "search process", "model artemis", "labor", "firms", "mobility", "model"]], "positionrank": [["french labor market", "labor market", "internal labor", "model artemis", "institution"], ["french labor market", "labor market", "internal labor", "model artemis", "institution", "large firms", "rational firms", "model", "good jobs", "search process"]], "multipartiterank": [["labor market", "institution", "model artemis", "rational firms", "good jobs"], ["labor market", "institution", "model artemis", "rational firms", "good jobs", "utility", "individuals", "decentralized setting", "search process", "cost"]]}, {"id": "2095", "text": "Global stability of the attracting set of an enzyme-catalysed reaction system\nThe essential feature of enzymatic reactions is a nonlinear dependency of\n\treaction rate on metabolite concentration taking the form of saturation\n\tkinetics. Recently, it has been shown that this feature is associated\n\twith the phenomenon of \"loss of system coordination\" (Liu, 1999). In\n\tthis paper, we study a system of ordinary differential equations\n\trepresenting a branched biochemical system of enzyme-mediated\n\treactions. We show that this system can become very sensitive to\n\tchanges in certain maximum enzyme activities. In particular, we show\n\tthat the system exhibits three distinct responses: a unique,\n\tglobally-stable steady-state, large amplitude oscillations, and\n\tasymptotically unbounded solutions, with the transition between these\n\tstates being almost instantaneous. It is shown that the appearance of\n\tlarge amplitude, stable limit cycles occurs due to a \"false\"\n\tbifurcation or canard explosion. The subsequent disappearance of limit\n\tcycles corresponds to the collapse of the domain of attraction of the\n\tattracting set for the system and occurs due to a global bifurcation in\n\tthe flow, namely, a saddle connection. Subsequently, almost all\n\tnonnegative data become unbounded under the action of the dynamical\n\tsystem and correspond exactly to loss of system coordination. We\n\tdiscuss the relevance of these results to the possible consequences of\n\tmodulating such systems\n", "keywords": "enzymatic reactions; nonlinear dependency; metabolite concentration; saturation\n\tkinetics; biochemical system; ordinary differential equations;\n\tenzyme-mediated reactions; saddle connection; stable limit cycles;\n\tbifurcation\n", "topicrank": [["reaction system", "stable limit cycles", "large amplitude oscillations", "unbounded solutions", "bifurcation"], ["reaction system", "stable limit cycles", "large amplitude oscillations", "unbounded solutions", "bifurcation", "loss", "enzymatic reactions", "enzyme", "essential feature", "limit"]], "textrank": [["reaction system", "stable limit", "maximum enzyme", "canard explosion", "unbounded solutions"], ["reaction system", "stable limit", "maximum enzyme", "canard explosion", "unbounded solutions", "distinct responses", "metabolite concentration", "nonlinear dependency", "enzymatic reactions", "essential feature"]], "positionrank": [["reaction system", "global stability", "global bifurcation", "biochemical system", "system coordination"], ["reaction system", "global stability", "global bifurcation", "biochemical system", "system coordination", "system", "enzyme", "reaction rate", "enzymatic reactions", "essential feature"]], "multipartiterank": [["reaction system", "essential feature", "system", "enzyme", "enzymatic reactions"], ["reaction system", "essential feature", "system", "enzyme", "enzymatic reactions", "large amplitude oscillations", "stable limit cycles", "nonlinear dependency", "loss", "unbounded solutions"]]}, {"id": "322", "text": "Toward an Experimental Timing Standards Lab: benchmarking precision in the real\n\tworld\nMuch discussion has taken place over the relative merits of various platforms\n\tand operating systems for real-time data collection. Most would agree\n\tthat, provided great care is taken, many are capable of millisecond\n\ttiming precision. However, to date, much of this work has focused on\n\tthe theoretical aspects of raw performance. It is our belief that\n\tresearchers would be better informed if they could place confidence\n\tlimits on their own specific paradigms in situ and without\n\tmodification. To this end, we have developed a millisecond precision\n\ttest rig that can control and time experiments on a second presentation\n\tmachine. We report on the specialist hardware and software used. We\n\telucidate the importance of the approach in relation to real-world\n\texperimentation\n", "keywords": "benchmarking precision; Experimental Timing Standards Lab; performance\n\tevaluation; operating systems; Event Generation software; real-time\n\tdata collection; millisecond timing precision\n", "topicrank": [["real", "millisecond", "much discussion", "world", "precision"], ["real", "millisecond", "much discussion", "world", "precision", "capable", "relation", "operating systems", "many", "various platforms"]], "textrank": [["timing precision", "timing standards", "time data", "great care", "operating systems"], ["timing precision", "timing standards", "time data", "great care", "operating systems", "various platforms", "relative merits", "much discussion", "specific", "time"]], "positionrank": [["timing precision", "millisecond precision", "precision", "time data collection", "much discussion"], ["timing precision", "millisecond precision", "precision", "time data collection", "much discussion", "relative merits", "operating systems", "time experiments", "various platforms", "world"]], "multipartiterank": [["real", "world", "much discussion", "precision", "millisecond"], ["real", "world", "much discussion", "precision", "millisecond", "relative merits", "place", "various platforms", "capable", "operating systems"]]}, {"id": "367", "text": "A study on meaning processing of dialogue with an example of development of\n\ttravel consultation system\nThis paper describes an approach to processing meaning instead of processing\n\tinformation in computing. Human intellectual activity is supported by\n\tlinguistic activities in the brain. Therefore, processing the meaning\n\tof language instead of processing information should allow us to\n\trealize human intelligence on a computer. As an example of the proposed\n\tframework for processing meaning, we build a travel consultation\n\tdialogue system which can understand utterance by a user and retrieve\n\tinformation through dialogue. Through a simulation example of the\n\tsystem, we show that both information processing and language\n\tprocessing are integrated\n", "keywords": "meaning processing; human intellectual activity; linguistic activities; travel\n\tconsultation dialogue system; user utterance understanding; information\n\tretrieval; information processing; language processing\n", "topicrank": [["processing", "information", "dialogue", "example", "travel consultation system"], ["processing", "information", "dialogue", "example", "travel consultation system", "language", "computing", "human intellectual activity", "approach", "development"]], "textrank": [["human intellectual", "consultation system", "linguistic activities", "processing", "system"], ["human intellectual", "consultation system", "linguistic activities", "processing", "system", "consultation", "human", "example"]], "positionrank": [["travel consultation system", "information processing", "processing meaning", "dialogue system", "travel consultation"], ["travel consultation system", "information processing", "processing meaning", "dialogue system", "travel consultation", "processing", "simulation example", "dialogue", "example", "system"]], "multipartiterank": [["processing", "information", "dialogue", "example", "travel consultation system"], ["processing", "information", "dialogue", "example", "travel consultation system", "language", "processing meaning", "development", "computing", "paper"]]}, {"id": "2188", "text": "A nonlinear modulation strategy for hybrid AC/DC power systems\nA nonlinear control strategy to improve transient stability of a multi-machine\n\tAC power system with several DC links terminated in the presence of\n\tlarge disturbances is presented. The approach proposed in this paper is\n\tbased on differential geometric theory, and the HVDC systems are taken\n\tas a variable admittance connected at the inverter or rectifier AC bus.\n\tAfter deriving the analytical description of the relationship between\n\tthe variable admittance and active power flows of each generator, the\n\ttraditional generator dynamic equations can thus be expressed with the\n\tvariable admittance of HVDC systems as an additional state variable and\n\tchanged to an affine form, which is suitable for global linearization\n\tmethod being used to determine its control variable. An important\n\tfeature of the proposed method is that, the modulated DC power is an\n\tadaptive and non-linear function of AC system states, and it can be\n\trealized by local feedback and less transmitted data from, adjacent\n\tgenerators. The design procedure is tested on a dual-infeed hybrid\n\tAC/DC system\n", "keywords": "nonlinear control strategy; transient stability; multi-machine AC power system;\n\tDC links; nonlinear modulation strategy; hybrid AC/DC power systems;\n\tdifferential geometric theory; HVDC systems; variable admittance;\n\tinverter; rectifier AC bus; active power flows; generator dynamic\n\tequations; affine form; global linearization method; local feedback;\n\tadjacent generators; dual-infeed hybrid AC/DC system\n", "topicrank": [["variable admittance", "method", "hvdc systems", "dc power systems", "hybrid ac"], ["variable admittance", "method", "hvdc systems", "dc power systems", "hybrid ac", "ac power system", "nonlinear modulation strategy", "global linearization", "active power flows", "adjacent"]], "textrank": [["ac power system", "dc power systems", "dc power", "dc system", "ac system"], ["ac power system", "dc power systems", "dc power", "dc system", "ac system", "- linear", "control variable", "generator dynamic", "state variable", "power"]], "positionrank": [["dc power systems", "ac power system", "nonlinear modulation strategy", "nonlinear control strategy", "modulated dc power"], ["dc power systems", "ac power system", "nonlinear modulation strategy", "nonlinear control strategy", "modulated dc power", "ac system states", "hybrid ac", "dc system", "several dc links", "rectifier ac bus"]], "multipartiterank": [["variable admittance", "nonlinear modulation strategy", "hybrid ac", "dc power systems", "hvdc systems"], ["variable admittance", "nonlinear modulation strategy", "hybrid ac", "dc power systems", "hvdc systems", "ac power system", "method", "several dc links", "active power flows", "transient stability"]]}, {"id": "1941", "text": "Descriptological foundations of programming\nDescriptological foundations of programming are constructed. An explication of\n\tthe concept of a descriptive process is given. The operations of\n\tintroduction and elimination of abstraction at the level of processes\n\tare refined. An intensional concept of a bipolar function is\n\tintroduced. An explication of the concept of introduction and\n\textraction of abstraction at the bipole level is given. On this basis,\n\ta complete set of descriptological operations is constructed\n", "keywords": "descriptological foundations; programming; descriptive process; intensional\n\tconcept; bipolar function; bipole level\n", "topicrank": [["concept", "abstraction", "introduction", "level", "explication"], ["concept", "abstraction", "introduction", "level", "explication", "operations", "programming", "descriptological foundations", "elimination", "processes"]], "textrank": [["intensional concept", "descriptive process", "descriptological", "bipolar", "level"], ["intensional concept", "descriptive process", "descriptological", "bipolar", "level", "concept"]], "positionrank": [["descriptological foundations", "descriptological operations", "programming", "intensional concept", "concept"], ["descriptological foundations", "descriptological operations", "programming", "intensional concept", "concept", "explication", "bipole level", "complete set", "operations", "introduction"]], "multipartiterank": [["concept", "introduction", "abstraction", "level", "explication"], ["concept", "introduction", "abstraction", "level", "explication", "programming", "operations", "descriptological foundations", "elimination", "processes"]]}, {"id": "2130", "text": "Synchronizing experiments with linear interval systems\nConcerns generalized control problems without exact information. <P>A\n\tmethod of constructing a minimal synchronizing sequence for a linear\n\tinterval system over the field of real numbers is developed. This\n\tproblem is reduced to a system of linear inequalities\n", "keywords": "synchronizing experiments; linear interval systems; minimal synchronizing\n\tsequence construction; real numbers; linear inequalities; generalized\n\tcontrol problems; controllability\n", "topicrank": [["linear interval systems", "interval system", "control problems", "concerns", "field"], ["linear interval systems", "interval system", "control problems", "concerns", "field", "real numbers", "exact information", "minimal synchronizing sequence", "experiments", "method"]], "textrank": [["linear interval", "control problems", "interval", "synchronizing", "linear"], ["linear interval", "control problems", "interval", "synchronizing", "linear", "exact"]], "positionrank": [["linear interval systems", "interval system", "linear inequalities", "control problems", "minimal synchronizing sequence"], ["linear interval systems", "interval system", "linear inequalities", "control problems", "minimal synchronizing sequence", "exact information", "experiments", "concerns", "real numbers", "system"]], "multipartiterank": [["linear interval systems", "concerns", "control problems", "interval system", "experiments"], ["linear interval systems", "concerns", "control problems", "interval system", "experiments", "exact information", "minimal synchronizing sequence", "field", "linear", "real numbers"]]}, {"id": "29", "text": "Fuzzy polynomial neural networks: hybrid architectures of fuzzy modeling\nWe introduce a concept of fuzzy polynomial neural networks (FPNNs), a hybrid\n\tmodeling architecture combining polynomial neural networks (PNNs) and\n\tfuzzy neural networks (FNNs). The development of the FPNNs dwells on\n\tthe technologies of computational intelligence (CI), namely fuzzy sets,\n\tneural networks, and genetic algorithms. The structure of the FPNN\n\tresults from a synergistic usage of FNN and PNN. FNNs contribute to the\n\tformation of the premise part of the rule-based structure of the FPNN.\n\tThe consequence part of the FPNN is designed using PNNs. The structure\n\tof the PNN is not fixed in advance as it usually takes place in the\n\tcase of conventional neural networks, but becomes organized dynamically\n\tto meet the required approximation error. We exploit a group method of\n\tdata handling (GMDH) to produce this dynamic topology of the network.\n\tThe performance of the FPNN is quantified through experimentation that\n\texploits standard data already used in fuzzy modeling. The obtained\n\texperimental results reveal that the proposed networks exhibit high\n\taccuracy and generalization capabilities in comparison to other similar\n\tfuzzy models\n", "keywords": "fuzzy polynomial neural networks; hybrid architectures; fuzzy modeling; highly\n\tnonlinear rule-based models; computational intelligence; fuzzy sets;\n\tgenetic algorithms; group method of data handling; GMDH; dynamic\n\ttopology; fuzzy inference method; learning; standard backpropagation;\n\tmembership functions; learning rates; momentum coefficients; genetic\n\toptimization\n", "topicrank": [["fuzzy polynomial neural networks", "fpnn", "fuzzy modeling", "structure", "pnn"], ["fuzzy polynomial neural networks", "fpnn", "fuzzy modeling", "structure", "pnn", "fnns", "premise part", "results", "pnns", "data handling"]], "textrank": [["fuzzy neural", "fuzzy", "group method", "synergistic usage", "genetic algorithms"], ["fuzzy neural", "fuzzy", "group method", "synergistic usage", "genetic algorithms", "computational intelligence", "fpnns dwells", "hybrid architectures", "neural", "data"]], "positionrank": [["fuzzy neural networks", "polynomial neural networks", "conventional neural networks", "neural networks", "fuzzy modeling"], ["fuzzy neural networks", "polynomial neural networks", "conventional neural networks", "neural networks", "fuzzy modeling", "fuzzy sets", "fuzzy models", "networks", "hybrid architectures", "hybrid"]], "multipartiterank": [["fuzzy polynomial neural networks", "hybrid architectures", "fuzzy modeling", "fpnns", "fpnn"], ["fuzzy polynomial neural networks", "hybrid architectures", "fuzzy modeling", "fpnns", "fpnn", "concept", "structure", "fnns", "pnns", "pnn"]]}, {"id": "287", "text": "Loudspeaker voice-coil inductance losses: circuit models, parameter estimation,\n\tand effect on frequency response\nWhen the series resistance is separated and treated as a separate element, it\n\tis shown that losses in an inductor require the ratio of the flux to\n\tMMF in the core to be frequency dependent. For small-signal operation,\n\tthis dependence leads to a circuit model composed of a lossless\n\tinductor and a resistor in parallel, both of which are frequency\n\tdependent. Mathematical expressions for these elements are derived\n\tunder the assumption that the ratio of core flux to MMF varies as omega\n\t/sup n-1/, where n is a constant. A linear regression technique is\n\tdescribed for extracting the model parameters from measured data.\n\tExperimental data are presented to justify the model for the lossy\n\tinductance of a loudspeaker voice-coil. A SPICE example is presented to\n\tillustrate the effects of voice-coil inductor losses on the frequency\n\tresponse of a typical driver\n", "keywords": "loudspeaker voice-coil inductance losses; circuit models; parameter estimation;\n\tfrequency response; series resistance; small-signal operation; linear\n\tregression; lossy inductance; SPICE; loudspeaker driver; lossless\n\tinductor; core flux to MMF ratio\n", "topicrank": [["frequency response", "coil inductance losses", "loudspeaker voice", "circuit model", "dependent"], ["frequency response", "coil inductance losses", "loudspeaker voice", "circuit model", "dependent", "core", "mmf", "inductor", "ratio", "data"]], "textrank": [["coil inductance losses", "circuit model", "separate element", "series resistance", "frequency response"], ["coil inductance losses", "circuit model", "separate element", "series resistance", "frequency response", "parameter estimation", "loudspeaker voice", "regression", "model", "circuit"]], "positionrank": [["coil inductance losses", "loudspeaker voice", "coil inductor losses", "voice", "circuit model"], ["coil inductance losses", "loudspeaker voice", "coil inductor losses", "voice", "circuit model", "frequency response", "circuit models", "coil", "losses", "parameter estimation"]], "multipartiterank": [["loudspeaker voice", "coil inductance losses", "frequency response", "circuit model", "inductor"], ["loudspeaker voice", "coil inductance losses", "frequency response", "circuit model", "inductor", "dependent", "core", "mmf", "ratio", "circuit models"]]}, {"id": "2175", "text": "7 key tests in choosing your Web site firm\nMost legal firms now have a Web site and are starting to evaluate the return on\n\ttheir investment. The paper looks at factors involved when choosing a\n\tfirm to help set up or improve a Web site. (1) Look for a company that\n\tcombines technical skills and business experience. (2) Look for a\n\tcompany that offers excellent customer service. (3) Check that the Web\n\tsite firm is committed to developing and proactively updating the Web\n\tsite. (4) Make sure the firm has a proven track record and a good\n\tportfolio. (5) Look for a company with both a breadth as well as depth\n\tof skills. (6) Make sure the firm can deliver work on target, in budget\n\tand to specification. (7) Ensure that you will enjoy working and feel\n\tcomfortable with the Web site firm staff\n", "keywords": "Web site; customer service; proactive updating; legal firms; return on\n\tinvestment; technical skills; business experience\n", "topicrank": [["web site firm", "firm", "company", "sure", "technical skills"], ["web site firm", "firm", "company", "sure", "technical skills", "web", "work", "target", "good", "track record"]], "textrank": [["site firm", "business experience", "technical skills", "key tests", "customer"], ["site firm", "business experience", "technical skills", "key tests", "customer", "legal", "firm", "site", "skills", "track"]], "positionrank": [["web site firm", "web site", "site firm", "web", "site"], ["web site firm", "web site", "site firm", "web", "site", "most legal firms", "firm", "key tests", "company", "excellent customer service"]], "multipartiterank": [["web site firm", "firm", "company", "technical skills", "sure"], ["web site firm", "firm", "company", "technical skills", "sure", "web", "key tests", "paper", "investment", "web site"]]}, {"id": "2097", "text": "An algorithm to generate all spanning trees with flow\nSpanning tree enumeration in undirected graphs is an important issue and task\n\tin many problems encountered in computer network and circuit analysis.\n\tThis paper discusses the spanning tree with flow for the case that\n\tthere are flow requirements between each node pair. An algorithm based\n\ton minimal paths (MPs) is proposed to generate all spanning trees\n\twithout flow. The proposed algorithm is a structured approach, which\n\tsplits the system into structural MPs first, and also all steps in it\n\tare easy to follow\n", "keywords": "undirected graphs; spanning trees; minimal paths; computer network analysis;\n\tcircuit analysis\n", "topicrank": [["flow", "algorithm", "tree enumeration", "mps", "trees"], ["flow", "algorithm", "tree enumeration", "mps", "trees", "important issue", "computer network", "task", "circuit analysis", "undirected graphs"]], "textrank": [["many problems", "important issue", "undirected graphs", "tree enumeration", "tree"], ["many problems", "important issue", "undirected graphs", "tree enumeration", "tree", "flow", "algorithm"]], "positionrank": [["proposed algorithm", "flow requirements", "algorithm", "flow", "tree enumeration"], ["proposed algorithm", "flow requirements", "algorithm", "flow", "tree enumeration", "undirected graphs", "important issue", "many problems", "node pair", "trees"]], "multipartiterank": [["flow", "algorithm", "tree enumeration", "trees", "mps"], ["flow", "algorithm", "tree enumeration", "trees", "mps", "undirected graphs", "important issue", "minimal paths", "task", "computer network"]]}, {"id": "320", "text": "Warranty reserves for nonstationary sales processes\nEstimation of warranty costs, in the event of product failure within the\n\twarranty period, is of importance to the manufacturer. Costs associated\n\twith replacement or repair of the product are usually drawn from a\n\twarranty reserve fund created by the manufacturer. Considering a\n\tstochastic sales process, first and second moments (and thereby the\n\tvariance) are derived for the manufacturer's total discounted warranty\n\tcost of a single sale for single-component items under four different\n\twarranty policies from a manufacturer's point of view. These servicing\n\tstrategies represent a renewable free-replacement, nonrenewable\n\tfree-replacement, renewable pro-rata, and a nonrenewable minimal-repair\n\twarranty plans. The results are extended to determine the mean and\n\tvariance of total discounted warranty costs for the total sales over\n\tthe life cycle of the product. Furthermore, using a normal\n\tapproximation, warranty reserves necessary for a certain protection\n\tlevel, so that reserves are not completely depleted, are found. Results\n\tand their managerial implications are studied through an extensive\n\texample\n", "keywords": "nonstationary sales processes; warranty reserves; warranty costs estimation;\n\tproduct failure; product replacement; product repair; stochastic sales\n\tprocess; first moments; second moments; variance; total discounted\n\twarranty cost; single-component items; servicing strategies; renewable\n\tfree-replacement; nonrenewable free-replacement; renewable pro-rata;\n\tnonrenewable minimal-repair warranty plans; total discounted warranty\n\tcosts; product life cycle; normal approximation; managerial\n\timplications\n", "topicrank": [["warranty period", "manufacturer", "total", "replacement", "warranty costs"], ["warranty period", "manufacturer", "total", "replacement", "warranty costs", "product failure", "warranty reserves", "renewable free", "nonrenewable", "single sale"]], "textrank": [["warranty reserve", "warranty reserves", "single - component items", "renewable pro -", "nonrenewable minimal -"], ["warranty reserve", "warranty reserves", "single - component items", "renewable pro -", "nonrenewable minimal -", "warranty", "sales", "single sale", "second moments", "product failure"]], "positionrank": [["warranty reserves", "warranty costs", "warranty reserve fund", "warranty period", "warranty policies"], ["warranty reserves", "warranty costs", "warranty reserve fund", "warranty period", "warranty policies", "warranty plans", "warranty", "nonstationary sales processes", "total sales", "stochastic sales process"]], "multipartiterank": [["warranty period", "warranty reserves", "manufacturer", "warranty costs", "product failure"], ["warranty period", "warranty reserves", "manufacturer", "warranty costs", "product failure", "replacement", "total", "nonstationary sales processes", "renewable free", "repair"]]}, {"id": "365", "text": "Self-organizing feature maps predicting sea levels\nIn this paper, a new method for predicting sea levels employing self-organizing\n\tfeature maps is introduced. For that purpose the maps are transformed\n\tfrom an unsupervised learning procedure to a supervised one. Two\n\tconcepts, originally developed to solve the problems of convergence of\n\tother network types, are proposed to be applied to Kohonen networks: a\n\tfunctional relationship between the number of neurons and the number of\n\tlearning examples and a criterion to break off learning. The latter one\n\tcan be shown to be conform with the process of self-organization by\n\tusing U-matrices for visualization of the learning procedure. The\n\tpredictions made using these neural models are compared for accuracy\n\twith observations and with the prognoses prepared using six models: two\n\thydrodynamic models, a statistical model, a nearest neighbor model, the\n\tpersistence model, and the verbal forecasts that are broadcast and kept\n\ton record by the Sea Level Forecast Service of the Federal Maritime and\n\tHydrography Agency (BSH) in Hamburg. Before training the maps, the\n\tmeteorological and oceanographic situation has to be condensed as well\n\tas possible, and the weight and learning vectors have to be made as\n\tsmall as possible. The self-organizing feature maps predict sea levels\n\tbetter than all six models of comparison\n", "keywords": "self-organizing feature maps; sea level prediction; supervised learning;\n\tKohonen networks; neurons; U-matrices; visualization; hydrodynamic\n\tmodels; statistical model; nearest neighbor model; persistence model;\n\tverbal forecasts; Sea Level Forecast Service; Federal Maritime and\n\tHydrography Agency; oceanographic situation; meteorological situation;\n\tlearning vectors\n", "topicrank": [["feature maps", "self", "neural models", "sea levels", "procedure"], ["feature maps", "self", "neural models", "sea levels", "procedure", "number", "learning examples", "statistical model", "possible", "one"]], "textrank": [["sea level forecast", "neighbor model", "verbal forecasts", "latter one", "functional relationship"], ["sea level forecast", "neighbor model", "verbal forecasts", "latter one", "functional relationship", "kohonen networks", "new method", "feature maps", "learning", "model"]], "positionrank": [["sea levels", "feature maps", "self", "maps", "new method"], ["sea levels", "feature maps", "self", "maps", "new method", "learning procedure", "neural models", "hydrodynamic models", "learning vectors", "learning examples"]], "multipartiterank": [["feature maps", "self", "neural models", "sea levels", "procedure"], ["feature maps", "self", "neural models", "sea levels", "procedure", "number", "one", "learning examples", "statistical model", "maps"]]}, {"id": "398", "text": "An unconditionally stable extended (USE) finite-element time-domain solution of\n\tactive nonlinear microwave circuits using perfectly matched layers\nThis paper proposes an extension of the unconditionally stable finite-element\n\ttime-domain (FETD) method for the global electromagnetic analysis of\n\tactive microwave circuits. This formulation has two advantages. First,\n\tthe time-step size is no longer governed by the spatial discretization\n\tof the mesh, but rather by the Nyquist sampling criterion. Second, the\n\timplementation of the truncation by the perfectly matched layers (PML)\n\tis straightforward. An anisotropic PML absorbing material is presented\n\tfor the truncation of FETD lattices. Reflection less than -50 dB is\n\tobtained numerically over the entire propagation bandwidth in waveguide\n\tand microstrip line. A benchmark test on a microwave amplifier\n\tindicates that this extended FETD algorithm is not only superior to\n\tfinite-difference time-domain-based algorithm in mesh flexibility and\n\tsimulation accuracy, but also reduces computation time dramatically\n", "keywords": "unconditionally stable FETD method; finite-element time-domain method; global\n\telectromagnetic analysis; global EM analysis; active nonlinear\n\tmicrowave circuits; Nyquist sampling criterion; time-step size; PML\n\ttruncation; perfectly matched layers; anisotropic PML absorbing\n\tmaterial; FETD lattices truncation; waveguide; microstrip line;\n\tmicrowave amplifier; mesh flexibility; simulation accuracy; computation\n\ttime reduction\n", "topicrank": [["time", "domain solution", "finite", "fetd", "element time"], ["time", "domain solution", "finite", "fetd", "element time", "active nonlinear microwave circuits", "layers", "truncation", "extended fetd algorithm", "mesh"]], "textrank": [["extended fetd", "pml absorbing", "stable extended", "reflection less", "spatial discretization"], ["extended fetd", "pml absorbing", "stable extended", "reflection less", "spatial discretization", "step size", "domain solution", "microwave", "time", "fetd"]], "positionrank": [["element time", "active microwave circuits", "extended fetd algorithm", "difference time", "domain solution"], ["element time", "active microwave circuits", "extended fetd algorithm", "difference time", "domain solution", "computation time", "time", "domain", "microwave amplifier", "global electromagnetic analysis"]], "multipartiterank": [["domain solution", "finite", "time", "element time", "active nonlinear microwave circuits"], ["domain solution", "finite", "time", "element time", "active nonlinear microwave circuits", "fetd", "domain", "layers", "truncation", "use"]]}, {"id": "2132", "text": "Fault-tolerant computer-aided control systems with multiversion-threshold\n\tadaptation: adaptation methods, reliability estimation, and choice of\n\tan architecture\nFor multiversion majority-redundant computer-aided control systems,\n\tsystematization of adaptation methods that are stable to hardware and\n\tsoftware failures, a method for estimating their reliability from an\n\tevent graph model, and a method for selecting a standard architecture\n\twith regard for reliability requirements are studied\n", "keywords": "fault-tolerant computer-aided control systems; multiversion-threshold\n\tadaptation; reliability estimation; architecture; multiversion\n\tmajority-redundant computer-aided control systems; hardware failure\n\tstability; software failure stability; event graph model\n", "topicrank": [["adaptation", "reliability estimation", "multiversion", "control systems", "tolerant computer"], ["adaptation", "reliability estimation", "multiversion", "control systems", "tolerant computer", "architecture", "method", "threshold", "stable", "hardware"]], "textrank": [["adaptation methods", "control systems", "graph", "reliability", "computer"], ["adaptation methods", "control systems", "graph", "reliability", "computer", "adaptation", "multiversion"]], "positionrank": [["control systems", "adaptation methods", "tolerant computer", "multiversion majority", "redundant computer"], ["control systems", "adaptation methods", "tolerant computer", "multiversion majority", "redundant computer", "adaptation", "multiversion", "fault", "reliability estimation", "reliability requirements"]], "multipartiterank": [["adaptation", "multiversion", "tolerant computer", "control systems", "reliability estimation"], ["adaptation", "multiversion", "tolerant computer", "control systems", "reliability estimation", "adaptation methods", "threshold", "architecture", "method", "fault"]]}, {"id": "285", "text": "Presentation media, information complexity, and learning outcomes\nMultimedia computing provides a variety of information presentation modality\n\tcombinations. Educators have observed that visuals enhance learning\n\twhich suggests that multimedia presentations should be superior to\n\ttext-only and text with static pictures in facilitating optimal human\n\tinformation processing and, therefore, comprehension. The article\n\treports the findings from a 3 (text-only, overhead slides, and\n\tmultimedia presentation)*2 (high and low information complexity)\n\tfactorial experiment. Subjects read a text script, viewed an acetate\n\toverhead slide presentation, or viewed a multimedia presentation\n\tdepicting the greenhouse effect (low complexity) or photocopier\n\toperation (high complexity). Multimedia was superior to text-only and\n\toverhead slides for comprehension. Information complexity diminished\n\tcomprehension and perceived presentation quality. Multimedia was able\n\tto reduce the negative impact of information complexity on\n\tcomprehension and increase the extent of sustained attention to the\n\tpresentation. These findings suggest that multimedia presentations\n\tinvoke the use of both the verbal and visual working memory channels\n\tresulting in a reduction of the cognitive load imposed by increased\n\tinformation complexity. Moreover, multimedia superiority in\n\tfacilitating comprehension goes beyond its ability to increase\n\tsustained attention; the quality and effectiveness of information\n\tprocessing attained (i.e., use of verbal and visual working memory) is\n\talso significant\n", "keywords": "presentation media; information complexity; learning outcomes; cognitive\n\tprocessing limitations; human working memory; verbal working memory\n\tchannel; visual working memory channel; multimedia computing;\n\tinformation presentation modality combinations; educators; multimedia\n\tpresentations; static pictures; optimal human information processing;\n\toverhead slides; text script; acetate overhead slide presentation;\n\tmultimedia presentation; greenhouse effect; photocopier operation;\n\tcognitive load; multimedia superiority; sustained attention\n", "topicrank": [["information complexity", "comprehension", "text", "presentation media", "information presentation modality"], ["information complexity", "comprehension", "text", "presentation media", "information presentation modality", "multimedia computing", "presentation quality", "visual", "superior", "verbal"]], "textrank": [["overhead slide presentation", "information presentation", "multimedia presentation", "information complexity", "presentation"], ["overhead slide presentation", "information presentation", "multimedia presentation", "information complexity", "presentation", "negative impact", "greenhouse effect", "text script", "factorial experiment", "optimal human"]], "positionrank": [["information presentation modality", "low information complexity", "multimedia presentation", "information complexity", "overhead slide presentation"], ["information presentation modality", "low information complexity", "multimedia presentation", "information complexity", "overhead slide presentation", "presentation media", "presentation quality", "information processing", "presentation", "low complexity"]], "multipartiterank": [["information complexity", "presentation media", "comprehension", "text", "multimedia computing"], ["information complexity", "presentation media", "comprehension", "text", "multimedia computing", "information presentation modality", "variety", "outcomes", "superior", "combinations"]]}, {"id": "2177", "text": "A humanist's legacy in medical informatics: visions and accomplishments of\n\tProfessor Jean-Raoul Scherrer\nThe objective is to report on the work of Prof. Jean-Raoul Scherrer, and show\n\thow his humanist vision, medical skills and scientific background have\n\tenabled and shaped the development of medical informatics over the last\n\t30 years. Starting with the mainframe-based patient-centred hospital\n\tinformation system DIOGENE in the 70s, Prof. Scherrer developed,\n\timplemented and evolved innovative concepts of man-machine interfaces,\n\tdistributed and federated environments, leading the way with\n\tinformation systems that obstinately focused on the support of care\n\tproviders and patients. Through a rigorous design of terminologies and\n\tontologies, the DIOGENE data would then serve as a basis for the\n\tdevelopment of clinical research, data mining, and lead to innovative\n\tnatural language processing techniques. In parallel, Prof. Scherrer\n\tsupported the development of medical image management, ranging from a\n\tdistributed picture archiving and communication systems (PACS) to\n\tmolecular imaging of protein electrophoreses. Recognizing the need for\n\timproving the quality and trustworthiness of medical information of the\n\tWeb, Prof. Scherrer created the Health-On-the Net (HON) foundation.\n\tThese achievements, made possible thanks to his visionary mind, deep\n\thumanism, creativity, generosity and determination, have made of Prof.\n\tScherrer a true pioneer and leader of the human-centered,\n\tpatient-oriented application of information technology for improving\n\thealthcare\n", "keywords": "Professor Jean-Raoul Scherrer; Medical Informatics; mainframe based patient\n\tcentered hospital information system; medical image management; PACS;\n\tInternet; DIOGENE system; man-machine interfaces; distributed systems;\n\tfederated systems; data mining; natural language processing\n", "topicrank": [["medical informatics", "development", "raoul scherrer", "information systems", "medical information"], ["medical informatics", "development", "raoul scherrer", "information systems", "medical information", "diogene data", "innovative concepts", "patient", "humanist", "humanism"]], "textrank": [["information system diogene", "medical information", "medical image", "information systems", "language processing"], ["information system diogene", "medical information", "medical image", "information systems", "language processing", "prof. scherrer", "prof. jean", "diogene data", "picture archiving", "clinical research"]], "positionrank": [["medical informatics", "prof. scherrer", "medical information", "raoul scherrer", "medical image management"], ["medical informatics", "prof. scherrer", "medical information", "raoul scherrer", "medical image management", "medical skills", "humanist vision", "prof. jean", "scherrer", "humanist"]], "multipartiterank": [["medical informatics", "development", "raoul scherrer", "humanist", "information systems"], ["medical informatics", "development", "raoul scherrer", "humanist", "information systems", "innovative concepts", "diogene data", "medical information", "patient", "legacy"]]}, {"id": "1943", "text": "I-WAP: an intelligent WAP site management system\nThe popularity regarding wireless communications is such that more and more WAP\n\tsites have been developed with wireless markup language (WML).\n\tMeanwhile, to translate hypertext markup language (HTML) pages into\n\tproper WML ones becomes imperative since it is difficult for WAP users\n\tto read most contents designed for PC users via their mobile phone\n\tscreens. However, for those sites that have been maintained with\n\thypertext markup language (HTML), considerable time and manpower costs\n\twill be incurred to rebuild them with WML. In this paper, we propose an\n\tintelligent WAP site management system to cope with these problems.\n\tWith the help of the intelligent management system, the original\n\tcontents of HTML Web sites can be automatically translated to proper\n\tWAP content in an efficient way. As a consequence, the costs associated\n\twith maintaining WAP sites could be significantly reduced. The\n\tmanagement system also allows the system manager to define the\n\trelevance of numerals and keywords for removing unimportant or\n\tmeaningless contents. The original contents will be reduced and\n\treorganized to fit the size of mobile phone screens, thus reducing the\n\tcommunication cost and enhancing readability. Numerical results gained\n\tthrough various experiments have evinced the effective performance of\n\tthe WAP management system\n", "keywords": "intelligent WAP site management system; I-WAP; wireless communication; wireless\n\tmarkup language; hypertext markup language; HTML pages; mobile phone;\n\tcommunication cost; readability; wireless mobile Internet\n", "topicrank": [["intelligent wap site management system", "html", "wap", "wireless markup language", "contents"], ["intelligent wap site management system", "html", "wap", "wireless markup language", "contents", "sites", "proper wml ones", "mobile phone", "original", "manpower costs"]], "textrank": [["wap management", "wireless markup", "wap", "numerical results", "communication cost"], ["wap management", "wireless markup", "wap", "numerical results", "communication cost", "efficient way", "manpower costs", "considerable time", "contents", "markup"]], "positionrank": [["wap management system", "intelligent management system", "wap sites", "more wap", "wap users"], ["wap management system", "intelligent management system", "wap sites", "more wap", "wap users", "wap content", "management system", "wap", "wireless markup language", "html web sites"]], "multipartiterank": [["intelligent wap site management system", "wap", "wireless markup language", "html", "sites"], ["intelligent wap site management system", "wap", "wireless markup language", "html", "sites", "wml", "hypertext markup language", "proper wml ones", "mobile phone", "manpower costs"]]}, {"id": "278", "text": "Novel ZE-isomerism descriptors derived from molecular topology and their\n\tapplication to QSAR analysis\nWe introduce several series of novel ZE-isomerism descriptors derived directly\n\tfrom two-dimensional molecular topology. These descriptors make use of\n\ta quantity named ZE-isomerism correction, which is added to the vertex\n\tdegrees of atoms connected by double bonds in Z and E configurations.\n\tThis approach is similar to the one described previously for\n\ttopological chirality descriptors (Golbraikh, A., et al. J. Chem. Inf.\n\tComput. Sci. 2001, 41, 147-158). The ZE-isomerism descriptors include\n\tmodified molecular connectivity indices, overall Zagreb indices,\n\textended connectivity, overall connectivity, and topological charge\n\tindices. They can be either real or complex numbers. Mathematical\n\tproperties of different subgroups of ZE-isomerism descriptors are\n\tdiscussed. These descriptors circumvent the inability of conventional\n\ttopological indices to distinguish between Z and E isomers. The\n\tapplicability of ZE-isomerism descriptors to QSAR analysis is\n\tdemonstrated in the studies of a series of 131 anticancer agents\n\tinhibiting tubulin polymerization\n", "keywords": "ZE-isomerism descriptors; two-dimensional molecular topology; QSAR analysis;\n\tquantitative structure-activity relationship; ZE-isomerism correction;\n\tvertex degrees; double bond connected atoms; modified molecular\n\tconnectivity indices; overall Zagreb indices; extended connectivity;\n\toverall connectivity; topological charge indices; complex numbers;\n\tanticancer agents; tubulin polymerization; descriptor pharmacophore;\n\tchemical databases; molecular graphs; computer-assisted drug design;\n\ttoxicities; combinatorial chemical libraries\n", "topicrank": [["isomerism descriptors", "molecular connectivity indices", "qsar analysis", "several series", "extended connectivity"], ["isomerism descriptors", "molecular connectivity indices", "qsar analysis", "several series", "extended connectivity", "novel ze", "molecular topology", "complex numbers", "mathematical", "properties"]], "textrank": [["molecular connectivity indices", "topological chirality descriptors", "topological indices", "isomerism descriptors", "connectivity"], ["molecular connectivity indices", "topological chirality descriptors", "topological indices", "isomerism descriptors", "connectivity", "et al", "double bonds", "several series", "qsar analysis", "novel ze"]], "positionrank": [["isomerism descriptors", "novel ze", "topological chirality descriptors", "descriptors", "molecular connectivity indices"], ["isomerism descriptors", "novel ze", "topological chirality descriptors", "descriptors", "molecular connectivity indices", "ze", "dimensional molecular topology", "isomerism correction", "molecular topology", "qsar analysis"]], "multipartiterank": [["isomerism descriptors", "molecular connectivity indices", "novel ze", "qsar analysis", "molecular topology"], ["isomerism descriptors", "molecular connectivity indices", "novel ze", "qsar analysis", "molecular topology", "several series", "extended connectivity", "descriptors", "zagreb", "complex numbers"]]}, {"id": "245", "text": "Support vector machines model for classification of thermal error in machine\n\ttools\nThis paper addresses a change in the concept of machine tool thermal error\n\tprediction which has been hitherto carried out by directly mapping them\n\twith the temperature of critical elements on the machine. The model\n\tdeveloped herein using support vector machines, a powerful\n\tdata-training algorithm, seeks to account for the impact of specific\n\toperating conditions, in addition to temperature variation, on the\n\teffective prediction of thermal errors. Several experiments were\n\tconducted to study the error pattern, which was found to change\n\tsignificantly with variation in operating conditions. This model\n\tattempts to classify the error based on operating conditions. Once\n\tclassified, the error is then predicted based on the temperature\n\tstates. This paper also briefly describes the concept of the\n\timplementation of such a comprehensive model along with an on-line\n\terror assessment and calibration system in a PC-based open-architecture\n\tcontroller environment, so that it could be employed in regular\n\tproduction for the purpose of periodic calibration of machine tools\n", "keywords": "SVM; support vector machines model; thermal error classification; machine tool\n\tthermal error prediction; critical element temperature; data-training\n\talgorithm; error pattern; online error assessment; online calibration\n\tsystem; PC-based open-architecture controller environment\n", "topicrank": [["thermal error", "operating conditions", "temperature", "model", "machine"], ["thermal error", "operating conditions", "temperature", "model", "machine", "support vector machines model", "calibration system", "paper", "prediction", "concept"]], "textrank": [["machine tool thermal error", "vector machines model", "thermal error", "vector machines", "effective prediction"], ["machine tool thermal error", "vector machines model", "thermal error", "vector machines", "effective prediction", "temperature variation", "operating conditions", "critical elements", "error", "thermal"]], "positionrank": [["support vector machines", "thermal error", "machine tools", "comprehensive model", "machine tool"], ["support vector machines", "thermal error", "machine tools", "comprehensive model", "machine tool", "error assessment", "model", "error pattern", "error", "machine"]], "multipartiterank": [["thermal error", "support vector machines model", "machine", "classification", "temperature"], ["thermal error", "support vector machines model", "machine", "classification", "temperature", "model", "operating conditions", "paper", "concept", "tools"]]}, {"id": "200", "text": "Preintegration lateral inhibition enhances unsupervised learning\nA large and influential class of neural network architectures uses\n\tpostintegration lateral inhibition as a mechanism for competition. We\n\targue that these algorithms are computationally deficient in that they\n\tfail to generate, or learn, appropriate perceptual representations\n\tunder certain circumstances. An alternative neural network architecture\n\tis presented here in which nodes compete for the right to receive\n\tinputs rather than for the right to generate outputs. This form of\n\tcompetition, implemented through preintegration lateral inhibition,\n\tdoes provide appropriate coding properties and can be used to learn\n\tsuch representations efficiently. Furthermore, this architecture is\n\tconsistent with both neuroanatomical and neuropsychological data. We\n\tthus argue that preintegration lateral inhibition has computational\n\tadvantages over conventional neural network architectures while\n\tremaining equally biologically plausible\n", "keywords": "neural network architectures; postintegration lateral inhibition; competition;\n\tpreintegration lateral inhibition; neural network; unsupervised\n\tlearning\n", "topicrank": [["preintegration lateral inhibition enhances", "neural network architectures", "competition", "right", "computational"], ["preintegration lateral inhibition enhances", "neural network architectures", "competition", "right", "computational", "advantages", "influential class", "neuroanatomical", "outputs", "form"]], "textrank": [["appropriate perceptual representations", "neural network", "lateral inhibition", "appropriate coding", "certain circumstances"], ["appropriate perceptual representations", "neural network", "lateral inhibition", "appropriate coding", "certain circumstances", "influential class", "representations"]], "positionrank": [["lateral inhibition enhances", "lateral inhibition", "neural network architectures", "preintegration", "influential class"], ["lateral inhibition enhances", "lateral inhibition", "neural network architectures", "preintegration", "influential class", "appropriate coding properties", "appropriate perceptual representations", "neuropsychological data", "competition", "certain circumstances"]], "multipartiterank": [["preintegration lateral inhibition enhances", "neural network architectures", "influential class", "large", "competition"], ["preintegration lateral inhibition enhances", "neural network architectures", "influential class", "large", "competition", "right", "mechanism", "postintegration lateral inhibition", "preintegration lateral inhibition", "algorithms"]]}, {"id": "1983", "text": "Power electronics spark new simulation challenges\nThis article discusses some of the changes that have taken place in power\n\tsystems and explores some of the inherent requirements for simulation\n\ttechnologies in order to keep up with this rapidly changing\n\tenvironment. The authors describe how energy utilities are realizing\n\tthat, with the appropriate tools, they can train and sustain engineers\n\twho can maintain a great insight into system dynamics\n", "keywords": "power system computer simulation; power electronics; simulation challenges;\n\tsimulation technologies; electric utilities\n", "topicrank": [["new simulation challenges", "power electronics", "technologies", "inherent requirements", "place"], ["new simulation challenges", "power electronics", "technologies", "inherent requirements", "place", "systems", "order", "authors", "environment", "changes"]], "textrank": [["energy utilities", "inherent requirements", "power electronics", "simulation", "power"], ["energy utilities", "inherent requirements", "power electronics", "simulation", "power"]], "positionrank": [["new simulation challenges", "power electronics", "power", "simulation", "inherent requirements"], ["new simulation challenges", "power electronics", "power", "simulation", "inherent requirements", "article", "changes", "systems", "place", "order"]], "multipartiterank": [["power electronics", "new simulation challenges", "article", "place", "changes"], ["power electronics", "new simulation challenges", "article", "place", "changes", "technologies", "systems", "inherent requirements", "simulation", "power"]]}, {"id": "2057", "text": "Four factors influencing the fair market value of out-of print books. 2\nFot pt.1 see ibid., p.71-8 (2002). Data from the fifty-six titles examined\n\tqualitatively in the Patterson study are examined quantitatively. In\n\taddition to the four factors of edition, condition, dust jacket, and\n\tautograph that were hypothesized to influence the value of a book, four\n\tother factors for which information was available in the data were\n\texamined\n", "keywords": "out-of-print books; quantitative analysis; fair market value; pricing;\n\teconomics; publisher\n", "topicrank": [["factors", "fair market value", "edition", "condition", "data"], ["factors", "fair market value", "edition", "condition", "data", "dust jacket", "available", "information", "addition", "autograph"]], "textrank": [["patterson study", "fot pt.1", "print books", "market", "factors"], ["patterson study", "fot pt.1", "print books", "market", "factors"]], "positionrank": [["fair market value", "other factors", "factors", "print books", "fot pt.1"], ["fair market value", "other factors", "factors", "print books", "fot pt.1", "value", "dust jacket", "data", "ibid", "edition"]], "multipartiterank": [["factors", "fair market value", "edition", "condition", "data"], ["factors", "fair market value", "edition", "condition", "data", "dust jacket", "addition", "available", "information", "autograph"]]}, {"id": "2012", "text": "Strain contouring using Gabor filters: principle and algorithm\nMoire interferometry is a powerful technique for high sensitivity in-plane\n\tdeformation contouring. However, from an engineering viewpoint, the\n\tderivatives of displacement, i.e., strain, are the desired parameter.\n\tThus there is a need to differentiate the displacement field. Optical\n\tand digital methods have been proposed for this differentiation.\n\tOptical methods provide contours that still need to be quantified,\n\twhile digital methods suffer from drawbacks inherent in the digital\n\tdifferentiation process. We describe a novel approach of strain\n\tsegmentation for the moire pattern using a multichannel Gabor filter.\n\tAppropriate filter design allows for user-specific segmentation, which\n\tis essentially in engineering design and analysis\n", "keywords": "strain contouring; Gabor filters; algorithm; moire interferometry; high\n\tsensitivity in-plane deformation contouring; displacement; displacement\n\tfield; digital methods; optical methods; differentiation; digital\n\tdifferentiation process; strain segmentation; multichannel Gabor\n\tfilter; filter design; user-specific segmentation; engineering design;\n\tengineering analysis; image segmentation; spatial filters\n", "topicrank": [["digital methods", "moire interferometry", "strain", "displacement", "optical"], ["digital methods", "moire interferometry", "strain", "displacement", "optical", "segmentation", "differentiation", "contouring", "engineering viewpoint", "algorithm"]], "textrank": [["gabor filter", "filter design", "engineering design", "deformation contouring", "high sensitivity"], ["gabor filter", "filter design", "engineering design", "deformation contouring", "high sensitivity", "powerful technique", "gabor", "methods", "moire", "engineering"]], "positionrank": [["multichannel gabor filter", "deformation contouring", "moire interferometry", "gabor filters", "moire pattern"], ["multichannel gabor filter", "deformation contouring", "moire interferometry", "gabor filters", "moire pattern", "contouring", "powerful technique", "appropriate filter design", "high sensitivity", "engineering design"]], "multipartiterank": [["contouring", "digital methods", "moire interferometry", "displacement", "optical"], ["contouring", "digital methods", "moire interferometry", "displacement", "optical", "strain", "gabor filters", "differentiation", "algorithm", "principle"]]}, {"id": "358", "text": "Correlation of intuitionistic fuzzy sets by centroid method\nIn this paper, we propose a method to calculate the correlation coefficient of\n\tintuitionistic fuzzy sets by means of \"centroid\". This value obtained\n\tfrom our formula tell us not only the strength of relationship between\n\tthe intuitionistic fuzzy sets, but also whether the intuitionistic\n\tfuzzy sets are positively or negatively related. This approach looks\n\tbetter than previous methods which only evaluate the strength of the\n\trelation. Furthermore, we extend the \"centroid\" method to\n\tinterval-valued intuitionistic fuzzy sets. The value of the correlation\n\tcoefficient between interval-valued intuitionistic fuzzy sets lies in\n\tthe interval [-1, 1], as computed from our formula\n", "keywords": "correlation coefficient; intuitionistic fuzzy sets; centroid method;\n\tinterval-valued intuitionistic fuzzy sets\n", "topicrank": [["intuitionistic fuzzy sets", "centroid method", "interval", "correlation coefficient", "value"], ["intuitionistic fuzzy sets", "centroid method", "interval", "correlation coefficient", "value", "strength", "method", "correlation", "formula", "better"]], "textrank": [["correlation coefficient", "centroid method", "fuzzy", "coefficient", "previous"], ["correlation coefficient", "centroid method", "fuzzy", "coefficient", "previous", "centroid", "method", "correlation"]], "positionrank": [["intuitionistic fuzzy sets", "fuzzy sets", "correlation coefficient", "centroid method", "correlation"], ["intuitionistic fuzzy sets", "fuzzy sets", "correlation coefficient", "centroid method", "correlation", "method", "interval", "coefficient", "value", "paper"]], "multipartiterank": [["intuitionistic fuzzy sets", "centroid method", "interval", "correlation coefficient", "method"], ["intuitionistic fuzzy sets", "centroid method", "interval", "correlation coefficient", "method", "correlation", "value", "centroid", "strength", "means"]]}, {"id": "32", "text": "Analysis and efficient implementation of a linguistic fuzzy c-means\nThe paper is concerned with a linguistic fuzzy c-means (FCM) algorithm with\n\tvectors of fuzzy numbers as inputs. This algorithm is based on the\n\textension principle and the decomposition theorem. It turns out that\n\tusing the extension principle to extend the capability of the standard\n\tmembership update equation to deal with a linguistic vector has a huge\n\tcomputational complexity. In order to cope with this problem, an\n\tefficient method based on fuzzy arithmetic and optimization has been\n\tdeveloped and analyzed. We also carefully examine and prove that the\n\talgorithm behaves in a way similar to the FCM in the degenerate\n\tlinguistic case. Synthetic data sets and the iris data set have been\n\tused to illustrate the behavior of this linguistic version of the FCM\n", "keywords": "linguistic fuzzy c-means algorithm; fuzzy numbers; extension principle;\n\tdecomposition theorem; computational complexity; fuzzy arithmetic;\n\toptimization; linguistic vectors\n", "topicrank": [["linguistic vector", "fcm", "fuzzy numbers", "efficient implementation", "algorithm"], ["linguistic vector", "fcm", "fuzzy numbers", "efficient implementation", "algorithm", "extension principle", "means", "computational complexity", "huge", "standard"]], "textrank": [["linguistic fuzzy", "data", "linguistic", "fuzzy", "way similar"], ["linguistic fuzzy", "data", "linguistic", "fuzzy", "way similar", "computational complexity", "decomposition theorem", "extension principle", "update", "efficient"]], "positionrank": [["linguistic fuzzy c", "linguistic case", "linguistic vector", "fuzzy numbers", "efficient implementation"], ["linguistic fuzzy c", "linguistic case", "linguistic vector", "fuzzy numbers", "efficient implementation", "linguistic version", "efficient method", "analysis", "means", "synthetic data sets"]], "multipartiterank": [["linguistic vector", "fcm", "fuzzy numbers", "efficient implementation", "means"], ["linguistic vector", "fcm", "fuzzy numbers", "efficient implementation", "means", "extension principle", "algorithm", "inputs", "vectors", "huge"]]}, {"id": "261", "text": "Union outreach - a pilgrim's progress\nAs the American labor movement continues on its path toward reorganization and\n\trejuvenation, archivists are challenged to ensure that the\n\torganizational, political, and cultural changes labor unions are\n\texperiencing are fully documented. The article examines the need for\n\tlabor archivists to reach out actively to unions and the problems they\n\tface in getting their message across, not only to union leadership but\n\talso to union members. Outreach by labor archivists is vital on three\n\tcritical fronts: the need to secure union funding in support of labor\n\tarchival programs; obtaining union cooperation in reviewing and\n\tamending obsolete deposit agreements; and coordinating efforts with\n\tunions to save the records of closing district and local union offices.\n\tAttempting to resolve these outstanding issues, labor archivists are\n\tpulled between two distinct institutional cultures (one academic in\n\tnature, the other enmeshed in a union bureaucracy) and often have their\n\town labor archival programs compromised by the internal dynamics and\n\tpolitics inherent in administering large academic libraries and unions.\n\tIf labor archivists are to be successful, they must find their\n\tcollective voice within the labor movement and establish their\n\trelevancy to unions during a period of momentous change and\n\trestructuring. Moreover, archivists need to give greater thought to\n\tdesigning and implementing outreach programs that bridge the\n\tfundamental \"disconnect\" between union bureaucracies and the rank and\n\tfile, and unions and the public\n", "keywords": "American labor movement; archivists; political changes; cultural changes; labor\n\tunions; labor archivists; union leadership; union members; union\n\tfunding; labor archival programs; union cooperation; obsolete deposit\n\tagreements; union offices; institutional cultures; union bureaucracy;\n\tinternal dynamics; large academic libraries; collective voice\n", "topicrank": [["union", "archivists", "unions", "american labor movement", "outreach"], ["union", "archivists", "unions", "american labor movement", "outreach", "need", "academic", "support", "archival programs", "closing district"]], "textrank": [["labor archival programs", "changes labor", "union", "labor", "archival programs"], ["labor archival programs", "changes labor", "union", "labor", "archival programs", "greater thought", "momentous change", "collective voice", "politics inherent", "internal dynamics"]], "positionrank": [["local union offices", "american labor movement", "union cooperation", "labor archivists", "union members"], ["local union offices", "american labor movement", "union cooperation", "labor archivists", "union members", "union funding", "union leadership", "union bureaucracy", "union bureaucracies", "union"]], "multipartiterank": [["union", "archivists", "american labor movement", "pilgrim", "unions"], ["union", "archivists", "american labor movement", "pilgrim", "unions", "progress", "labor archivists", "path", "reorganization", "rejuvenation"]]}, {"id": "2193", "text": "Integrating virtual and physical context to support knowledge workers\nThe Kimura system augments and integrates independent tools into a pervasive\n\tcomputing system that monitors a user's interactions with the computer,\n\tan electronic whiteboard, and a variety of networked peripheral devices\n\tand data sources\n", "keywords": "pervasive computing; knowledge workers; networked peripheral devices;\n\telectronic whiteboard; Kimura system; data sources\n", "topicrank": [["kimura system", "interactions", "user", "pervasive", "networked peripheral devices"], ["kimura system", "interactions", "user", "pervasive", "networked peripheral devices", "computer", "variety", "independent tools", "physical context", "knowledge workers"]], "textrank": [["knowledge workers", "physical context", "peripheral", "system", "independent"], ["knowledge workers", "physical context", "peripheral", "system", "independent"]], "positionrank": [["kimura system", "knowledge workers", "physical context", "computing system", "independent tools"], ["kimura system", "knowledge workers", "physical context", "computing system", "independent tools", "networked peripheral devices", "electronic whiteboard", "interactions", "user", "data sources"]], "multipartiterank": [["kimura system", "knowledge workers", "pervasive", "independent tools", "physical context"], ["kimura system", "knowledge workers", "pervasive", "independent tools", "physical context", "interactions", "user", "networked peripheral devices", "computing system", "computer"]]}, {"id": "224", "text": "Java portability put to the test\nSun Microsystems' recently launched Java Verification Program aims to enable\n\tcompanies to assess the cross-platform portability of applications\n\twritten in Java, and to help software vendors ensure that their\n\tsolutions can run in heterogenous J2EE application server environments\n", "keywords": "Sun Microsystems; Java Verification Program; cross-platform portability\n", "topicrank": [["java portability", "sun microsystems", "test", "software vendors", "solutions"], ["java portability", "sun microsystems", "test", "software vendors", "solutions", "applications", "companies", "heterogenous j2ee application server environments"]], "textrank": [["j2ee application server", "java verification", "-", "java"], ["j2ee application server", "java verification", "-", "java"]], "positionrank": [["java verification program", "java portability", "java", "sun microsystems", "test"], ["java verification program", "java portability", "java", "sun microsystems", "test", "companies", "applications", "software vendors", "solutions"]], "multipartiterank": [["java portability", "test", "sun microsystems", "companies", "applications"], ["java portability", "test", "sun microsystems", "companies", "applications", "software vendors", "solutions", "java verification program", "heterogenous j2ee application server environments", "java"]]}, {"id": "339", "text": "An automated parallel image registration technique based on the correlation of\n\twavelet features\nWith the increasing importance of multiple multiplatform remote sensing\n\tmissions, fast and automatic integration of digital data from disparate\n\tsources has become critical to the success of these endeavors. Our work\n\tutilizes maxima of wavelet coefficients to form the basic features of a\n\tcorrelation-based automatic registration algorithm. Our wavelet-based\n\tregistration algorithm is tested successfully with data from the\n\tNational Oceanic and Atmospheric Administration (NOAA) Advanced Very\n\tHigh Resolution Radiometer (AVHRR) and the Landsat Thematic Mapper\n\t(TM), which differ by translation and/or rotation. By the choice of\n\thigh-frequency wavelet features, this method is similar to an\n\tedge-based correlation method, but by exploiting the multiresolution\n\tnature of a wavelet decomposition, our method achieves higher\n\tcomputational speeds for comparable accuracies. This algorithm has been\n\timplemented on a single-instruction multiple-data (SIMD) massively\n\tparallel computer, the MasPar MP-2, as well as on the CrayT3D, the Cray\n\tT3E, and a Beowulf cluster of Pentium workstations\n", "keywords": "geophysical measurement technique; land surface; terrain mapping; optical\n\timaging; microwave radiometry; image processing; automated parallel\n\timage registration; correlation; wavelet feature; remote sensing;\n\tautomatic registration algorithm; AVHRR; Landsat Thematic Mapper;\n\twavelet decomposition; SIMD massively parallel computing\n", "topicrank": [["wavelet features", "digital data", "automatic registration algorithm", "correlation", "method"], ["wavelet features", "digital data", "automatic registration algorithm", "correlation", "method", "high resolution radiometer", "automatic integration", "disparate", "computational speeds", "fast"]], "textrank": [["parallel image registration", "multiple multiplatform remote", "wavelet features", "automatic registration", "wavelet"], ["parallel image registration", "multiple multiplatform remote", "wavelet features", "automatic registration", "wavelet", "registration", "computational speeds", "correlation method", "advanced very", "atmospheric administration"]], "positionrank": [["frequency wavelet features", "automatic registration algorithm", "wavelet features", "registration algorithm", "wavelet coefficients"], ["frequency wavelet features", "automatic registration algorithm", "wavelet features", "registration algorithm", "wavelet coefficients", "correlation method", "wavelet decomposition", "wavelet", "parallel computer", "basic features"]], "multipartiterank": [["wavelet features", "correlation", "digital data", "automatic registration algorithm", "automatic integration"], ["wavelet features", "correlation", "digital data", "automatic registration algorithm", "automatic integration", "multiple multiplatform remote sensing", "disparate", "high resolution radiometer", "fast", "missions"]]}, {"id": "414", "text": "The efficacy of electronic telecommunications in fostering interpersonal\n\trelationships\nThe effectiveness of electronic telecommunications as a supplementary aid to\n\tinstruction and as a communication link between students, and between\n\tstudents and instructors in fostering interpersonal relationships was\n\texplored in this study. More specifically, the impacts of e-mail, one\n\tof the most accessible, convenient, and easy to use computer-mediated\n\tcommunications, on student attitudes toward the instructor,\n\tgroup-mates, and other classmates were investigated. A posttest-only\n\texperimental design was adopted. In total, 68 prospective teachers\n\tenrolling in a \"Computers in Education\" course participated in the\n\tstudy for a whole semester. Results from the study provided substantial\n\tevidence supporting e-mail's beneficial effects on student attitudes\n\ttoward the instructor and other classmates\n", "keywords": "interpersonal relationships; telecommunications; student communication link;\n\te-mail; computer-mediated communications; student attitudes; Computers\n\tin Education course; educational technology\n", "topicrank": [["study", "electronic telecommunications", "student attitudes", "interpersonal", "students"], ["study", "electronic telecommunications", "student attitudes", "interpersonal", "students", "instructor", "education", "substantial", "whole semester", "results"]], "textrank": [["experimental design", "other classmates", "student attitudes", "interpersonal relationships", "communication link"], ["experimental design", "other classmates", "student attitudes", "interpersonal relationships", "communication link", "supplementary aid", "electronic telecommunications", "-", "relationships", "interpersonal"]], "positionrank": [["electronic telecommunications", "interpersonal relationships", "supplementary aid", "relationships", "communication link"], ["electronic telecommunications", "interpersonal relationships", "supplementary aid", "relationships", "communication link", "efficacy", "effectiveness", "students", "e - mail", "instruction"]], "multipartiterank": [["study", "electronic telecommunications", "interpersonal", "student attitudes", "students"], ["study", "electronic telecommunications", "interpersonal", "student attitudes", "students", "instructor", "relationships", "effectiveness", "education", "substantial"]]}, {"id": "2036", "text": "Computer processing of data on mental impairments during the acute period of\n\tconcussion\nThe article presents results of computer processing of experimental information\n\tobtained from patients during the acute period of concussion. A number\n\tof computational procedures are described\n", "keywords": "computer processing; mental impairments; acute period of concussion;\n\tcomputational procedures\n", "topicrank": [["computer processing", "acute period", "concussion", "results", "article"], ["computer processing", "acute period", "concussion", "results", "article", "experimental information", "mental impairments", "data", "patients", "number"]], "textrank": [["mental impairments", "computer processing", "acute"], ["mental impairments", "computer processing", "acute"]], "positionrank": [["computer processing", "acute period", "mental impairments", "experimental information", "concussion"], ["computer processing", "acute period", "mental impairments", "experimental information", "concussion", "data", "article", "results", "patients", "computational procedures"]], "multipartiterank": [["computer processing", "acute period", "concussion", "results", "article"], ["computer processing", "acute period", "concussion", "results", "article", "experimental information", "mental impairments", "data", "patients", "number"]]}, {"id": "381", "text": "Robust fuzzy controlled photovoltaic power inverter with Taguchi method\nThis paper presents design and implementation of a robust fuzzy controlled\n\tphotovoltaic (PV) power inverter with Taguchi tuned scaling factors. To\n\tachieve fast transient response, small steady-state error and system\n\trobustness, a robust fuzzy controller is adopted, in which its input\n\tand output scaling factors are determined efficiently by using the\n\tTaguchi-tuning algorithm. The proposed system can operate in different\n\tmodes, grid-connection mode and stand-alone mode, and can accommodate\n\twide load variations. Simulation results and hardware measurements\n\tobtained from a prototype with a microcontroller (Intel 80196KC) are\n\tpresented to verify the theoretical discussions, and its adaptivity,\n\trobustness and feasibility\n", "keywords": "robust fuzzy controlled photovoltaic power inverter; Taguchi method; tuned\n\tscaling factors; transient response; steady-state error; system\n\trobustness; output scaling factors; grid-connection mode; stand-alone\n\tmode; load variations; microcontroller; adaptivity; feasibility\n", "topicrank": [["taguchi method", "robust fuzzy", "system", "photovoltaic power inverter", "robustness"], ["taguchi method", "robust fuzzy", "system", "photovoltaic power inverter", "robustness", "scaling factors", "connection mode", "modes", "state error", "grid"]], "textrank": [["connection mode", "tuning algorithm", "state error", "small steady", "taguchi method"], ["connection mode", "tuning algorithm", "state error", "small steady", "taguchi method", "load", "transient", "scaling", "power", "fuzzy"]], "positionrank": [["robust fuzzy controller", "robust fuzzy", "photovoltaic power inverter", "power inverter", "taguchi method"], ["robust fuzzy controller", "robust fuzzy", "photovoltaic power inverter", "power inverter", "taguchi method", "output scaling factors", "taguchi", "scaling factors", "photovoltaic", "fast transient response"]], "multipartiterank": [["robust fuzzy", "taguchi method", "photovoltaic power inverter", "taguchi", "paper"], ["robust fuzzy", "taguchi method", "photovoltaic power inverter", "taguchi", "paper", "design", "system", "scaling factors", "robustness", "implementation"]]}, {"id": "304", "text": "A Web-accessible database of characteristics of the 1,945 basic Japanese kanji\nIn 1981, the Japanese government published a list of the 1,945 basic Japanese\n\tkanji (Jooyoo Kanji-hyo), including specifications of pronunciation.\n\tThis list was established as the standard for kanji usage in print. The\n\tdatabase for 1,945 basic Japanese kanji provides 30 cells that explain\n\tin detail the various characteristics of kanji. Means, standard\n\tdeviations, distributions, and information related to previous research\n\tconcerning these kanji are provided in this paper. The database is\n\tsaved as a Microsoft Excel 2000 file for Windows. This kanji database\n\tis accessible on the Web site of the Oxford Text Archive, Oxford\n\tUniversity (http://ota.ahds.ac.uk). Using this database, researchers\n\tand educators will be able to conduct planned experiments and organize\n\tclassroom instruction on the basis of the known characteristics of\n\tselected kanji\n", "keywords": "Web-accessible database; basic Japanese kanji; Jooyoo Kanji-hyo; pronunciation;\n\tkanji usage print; cells; means; standard deviations; distributions;\n\tMicrosoft Excel 2000 file for Windows; Oxford Text Archive Web site;\n\tclassroom instruction\n", "topicrank": [["database", "basic japanese", "characteristics", "jooyoo kanji", "standard"], ["database", "basic japanese", "characteristics", "jooyoo kanji", "standard", "accessible database", "oxford text archive", "web", "list", "deviations"]], "textrank": [["japanese kanji", "web site", "kanji database", "microsoft excel", "previous research"], ["japanese kanji", "web site", "kanji database", "microsoft excel", "previous research", "various characteristics", "jooyoo kanji", "accessible database", "text", "japanese"]], "positionrank": [["accessible database", "web site", "database", "japanese government", "oxford text archive"], ["accessible database", "web site", "database", "japanese government", "oxford text archive", "web", "various characteristics", "jooyoo kanji", "characteristics", "oxford"]], "multipartiterank": [["basic japanese", "database", "characteristics", "accessible database", "web"], ["basic japanese", "database", "characteristics", "accessible database", "web", "jooyoo kanji", "standard", "list", "oxford text archive", "hyo"]]}, {"id": "341", "text": "How should team captains order golfers on the final day of the Ryder Cup\n\tmatches?\nI used game theory to examine how team captains should select their slates for\n\tthe final day of the Ryder Cup matches. Under the assumption that\n\tgolfers have different abilities and are not influenced by pressure or\n\tmomentum, I found that drawing names from a hat will do no worse than\n\tany other strategy\n", "keywords": "golf; golfer ordering; Ryder Cup final day; game theory; slate\n", "topicrank": [["ryder cup", "final day", "captains order golfers", "different abilities", "assumption"], ["ryder cup", "final day", "captains order golfers", "different abilities", "assumption", "matches", "pressure", "team captains", "momentum", "slates"]], "textrank": [["captains order", "game theory", "final day", "cup", "captains"], ["captains order", "game theory", "final day", "cup", "captains"]], "positionrank": [["ryder cup matches", "captains order golfers", "ryder cup", "final day", "team captains"], ["ryder cup matches", "captains order golfers", "ryder cup", "final day", "team captains", "golfers", "game theory", "matches", "different abilities", "slates"]], "multipartiterank": [["final day", "ryder cup", "captains order golfers", "matches", "game theory"], ["final day", "ryder cup", "captains order golfers", "matches", "game theory", "team captains", "different abilities", "slates", "assumption", "ryder cup matches"]]}, {"id": "219", "text": "Firewall card shields data\nThe SlotShield 3000 firewall on a PCI card saves power and space, but might not\n\toffer enough security for large networks\n", "keywords": "SlotShield 3000 firewall; PCI card; security; large networks\n", "topicrank": [["power", "pci card", "firewall", "slotshield", "space"], ["power", "pci card", "firewall", "slotshield", "space", "enough security", "large networks", "firewall card shields data"]], "textrank": [["card shields", "card", "enough"], ["card shields", "card", "enough"]], "positionrank": [["pci card", "firewall", "slotshield", "enough security", "power"], ["pci card", "firewall", "slotshield", "enough security", "power", "space", "large networks"]], "multipartiterank": [["power", "pci card", "firewall", "slotshield", "space"], ["power", "pci card", "firewall", "slotshield", "space", "enough security", "large networks", "firewall card shields data"]]}, {"id": "1967", "text": "Modeling daily realized futures volatility with singular spectrum analysis\nUsing singular spectrum analysis (SSA), we model the realized volatility and\n\tlogarithmic standard deviations of two important futures return series.\n\tThe realized volatility and logarithmic standard deviations are\n\tconstructed following the methodology of Andersen et al. [J. Am. Stat.\n\tAss. 96 (2001) 42-55] using intra-day transaction data. We find that\n\tSSA decomposes the volatility series quite well and effectively\n\tcaptures both the market trend (accounting for about 34-38% of the\n\ttotal variance in the series) and, more importantly, a number of\n\tunderlying market periodicities. Reliable identification of any\n\tperiodicities is extremely important for options pricing and risk\n\tmanagement and we believe that SSA can be a useful addition to the\n\tfinancial practitioners' toolbox\n", "keywords": "daily realized futures volatility; singular spectrum analysis; SSA; logarithmic\n\tstandard deviations; return series; intraday transaction data; market\n\ttrend; market periodicities; risk management; options pricing;\n\tfinancial practitioners; econophysics; asset return\n", "topicrank": [["series", "ssa", "important futures", "futures volatility", "market periodicities"], ["series", "ssa", "important futures", "futures volatility", "market periodicities", "logarithmic standard deviations", "singular spectrum analysis", "options pricing", "risk", "management"]], "textrank": [["- day transaction", "j. am .", "futures volatility", "ass .", "market"], ["- day transaction", "j. am .", "futures volatility", "ass .", "market", "et", "standard", "spectrum", "futures", "volatility"]], "positionrank": [["singular spectrum analysis", "futures volatility", "volatility series", "logarithmic standard deviations", "important futures"], ["singular spectrum analysis", "futures volatility", "volatility series", "logarithmic standard deviations", "important futures", "volatility", "ssa", "series", "andersen et al", "market periodicities"]], "multipartiterank": [["futures volatility", "series", "singular spectrum analysis", "ssa", "important futures"], ["futures volatility", "series", "singular spectrum analysis", "ssa", "important futures", "logarithmic standard deviations", "market periodicities", "volatility", "reliable identification", "options pricing"]]}, {"id": "2116", "text": "Optimization of the characteristics of computational processes in scalable\n\tresources\nThe scalableness of resources is taken to mean the possibility of the prior\n\tchange in the obtained dynamic characteristics of computational\n\tprocesses for a certain basic set of processors and the communication\n\tmedium in an effort to optimize the dynamics of software applications.\n\tA method is put forward for the generation of optimal strategies-a set\n\tof the versions of the fulfillment of programs on the basis of a vector\n\tcriterion. The method is urgent for the effective use of resources of\n\tcomputational clusters and metacomputational media and also for dynamic\n\tcontrol of processes in real time on the basis of the static scaling\n", "keywords": "computational processes; scalable resources; dynamic characteristics;\n\tcommunication medium; software applications; optimal strategies; vector\n\tcriterion; computational clusters; metacomputational media; dynamic\n\tcontrol; static scaling\n", "topicrank": [["computational processes", "resources", "computational", "certain basic set", "method"], ["computational processes", "resources", "computational", "certain basic set", "method", "characteristics", "basis", "criterion", "vector", "programs"]], "textrank": [["metacomputational media", "effective use", "optimal strategies", "software applications", "dynamic characteristics"], ["metacomputational media", "effective use", "optimal strategies", "software applications", "dynamic characteristics", "basic", "computational", "real", "dynamic", "characteristics"]], "positionrank": [["computational processes", "dynamic characteristics", "computational clusters", "processes", "certain basic set"], ["computational processes", "dynamic characteristics", "computational clusters", "processes", "certain basic set", "optimization", "characteristics", "resources", "metacomputational media", "effective use"]], "multipartiterank": [["computational processes", "resources", "characteristics", "computational", "certain basic set"], ["computational processes", "resources", "characteristics", "computational", "certain basic set", "processes", "scalable", "method", "basis", "scalableness"]]}, {"id": "2153", "text": "Post-haste. 100th robotic containerization system installed in US mail sorting\n\tcenter\nSpot welding, machine tending, material handling, picking, packing, painting,\n\tpalletizing, assembly...the list of tasks being performed by ABB robots\n\tkeeps on growing. Adding to this portfolio is a new robot\n\tcontainerization system (RCS) that ABB developed specifically for the\n\tUnited States Postal Service (USPS). The RCS has brought new levels of\n\tspeed, accuracy, efficiency and productivity to the process of sorting\n\tand containerizing mail and packages. Recently, the 100th ABB RCS was\n\tinstalled at the USPS processing and distribution center in Columbus,\n\tOhio\n", "keywords": "mail sorting center; robotic containerization system; USA; ABB robots; United\n\tStates Postal Service; mail sorting; packages sorting\n", "topicrank": [["rcs", "new robot", "center", "usps", "100th robotic containerization system"], ["rcs", "new robot", "center", "usps", "100th robotic containerization system", "us mail", "abb robots", "accuracy", "efficiency", "palletizing"]], "textrank": [["100th robotic containerization", "100th abb", "states postal", "spot welding", "us mail"], ["100th robotic containerization", "100th abb", "states postal", "spot welding", "us mail", "abb", "new", "-", "containerization", "mail"]], "positionrank": [["post - haste", "100th abb rcs", "containerization system", "us mail", "mail"], ["post - haste", "100th abb rcs", "containerization system", "us mail", "mail", "distribution center", "abb robots", "rcs", "spot welding", "machine tending"]], "multipartiterank": [["100th robotic containerization system", "rcs", "us mail", "center", "new robot"], ["100th robotic containerization system", "rcs", "us mail", "center", "new robot", "abb robots", "spot welding", "machine tending", "usps", "material handling"]]}]